{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":true,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"12/01/2022: Sedona 1.3.0-incubating is released. It adds native support of GeoParquet, DataFrame style API, Scala 2.13, Python 3.10, spatial aggregation on Flink. Please check Sedona release notes. \u00b6 08/30/2022: Sedona 1.2.1-incubating is released. It supports Spark 2.4 - 3.3. and Flink 1.12+. \u00b6 04/16/2022: Sedona 1.2.0-incubating is released. Sedona now supports geospatial stream processing in Apache Flink. \u00b6 11/23/2021: Sedona 1.1.1-incubating is released. It now supports Spark 3.2. \u00b6 10/06/2021: Sedona 1.1.0-incubating is released. R lang API is available on CRAN. Raster data and map algebra SQL functions are now supported. \u00b6","title":"Home"},{"location":"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes","text":"","title":"12/01/2022: Sedona 1.3.0-incubating is released. It adds native support of GeoParquet, DataFrame style API, Scala 2.13, Python 3.10, spatial aggregation on Flink. Please check Sedona release notes."},{"location":"#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112","text":"","title":"08/30/2022: Sedona 1.2.1-incubating is released. It supports Spark 2.4 - 3.3. and Flink 1.12+."},{"location":"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink","text":"","title":"04/16/2022: Sedona 1.2.0-incubating is released. Sedona now supports geospatial stream processing in Apache Flink."},{"location":"#11232021-sedona-111-incubating-is-released-it-now-supports-spark-32","text":"","title":"11/23/2021: Sedona 1.1.1-incubating is released. It now supports Spark 3.2."},{"location":"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported","text":"","title":"10/06/2021: Sedona 1.1.0-incubating is released. R lang API is available on CRAN. Raster data and map algebra SQL functions are now supported."},{"location":"download/","text":"GitHub repository \u00b6 Latest source code: GitHub repository Old GeoSpark releases: GitHub releases Automatically generated binary JARs (per each Master branch commit): GitHub Action Verify the integrity \u00b6 Public keys Instructions Versions \u00b6 1.3.0-incubating \u00b6 Download from ASF Checksum Signature Source code src sha512 asc Binary bin sha512 asc 1.2.1-incubating \u00b6 Download from ASF Checksum Signature Source code src sha512 asc Binary bin sha512 asc Past releases \u00b6 Past Sedona releases are archived and can be found here: https://archive.apache.org/dist/incubator/sedona/ Security \u00b6 For security issues, please refer to https://www.apache.org/security/","title":"Download"},{"location":"download/#github-repository","text":"Latest source code: GitHub repository Old GeoSpark releases: GitHub releases Automatically generated binary JARs (per each Master branch commit): GitHub Action","title":"GitHub repository"},{"location":"download/#verify-the-integrity","text":"Public keys Instructions","title":"Verify the integrity"},{"location":"download/#versions","text":"","title":"Versions"},{"location":"download/#130-incubating","text":"Download from ASF Checksum Signature Source code src sha512 asc Binary bin sha512 asc","title":"1.3.0-incubating"},{"location":"download/#121-incubating","text":"Download from ASF Checksum Signature Source code src sha512 asc Binary bin sha512 asc","title":"1.2.1-incubating"},{"location":"download/#past-releases","text":"Past Sedona releases are archived and can be found here: https://archive.apache.org/dist/incubator/sedona/","title":"Past releases"},{"location":"download/#security","text":"For security issues, please refer to https://www.apache.org/security/","title":"Security"},{"location":"api/java-api/","text":"Please read Javadoc Note: Scala can call Java APIs seamlessly. That means Scala users use the same APIs with Java users","title":"Scala/Java doc"},{"location":"api/python-api/","text":"Will be available soon.","title":"Python doc"},{"location":"api/r-api/","text":"Please read R docs","title":"R doc"},{"location":"api/flink/Aggregator/","text":"ST_Envelope_Aggr \u00b6 Introduction: Return the entire envelope boundary of all geometries in A Format: ST_Envelope_Aggr (A:geometryColumn) Since: v1.3.0 SQL example: SELECT ST_Envelope_Aggr ( pointdf . arealandmark ) FROM pointdf ST_Union_Aggr \u00b6 Introduction: Return the polygon union of all polygons in A. All inputs must be polygons. Format: ST_Union_Aggr (A:geometryColumn) Since: v1.3.0 SQL example: SELECT ST_Union_Aggr ( polygondf . polygonshape ) FROM polygondf","title":"Aggregator"},{"location":"api/flink/Aggregator/#st_envelope_aggr","text":"Introduction: Return the entire envelope boundary of all geometries in A Format: ST_Envelope_Aggr (A:geometryColumn) Since: v1.3.0 SQL example: SELECT ST_Envelope_Aggr ( pointdf . arealandmark ) FROM pointdf","title":"ST_Envelope_Aggr"},{"location":"api/flink/Aggregator/#st_union_aggr","text":"Introduction: Return the polygon union of all polygons in A. All inputs must be polygons. Format: ST_Union_Aggr (A:geometryColumn) Since: v1.3.0 SQL example: SELECT ST_Union_Aggr ( polygondf . polygonshape ) FROM polygondf","title":"ST_Union_Aggr"},{"location":"api/flink/Constructor/","text":"ST_GeomFromGeoHash \u00b6 Introduction: Create Geometry from geohash string and optional precision Format: ST_GeomFromGeoHash(geohash: string, precision: int) Since: v1.2.1 SQL example: SELECT ST_GeomFromGeoHash ( 's00twy01mt' , 4 ) AS geom ST_GeomFromGeoJSON \u00b6 Introduction: Construct a Geometry from GeoJson Format: ST_GeomFromGeoJSON (GeoJson:string) Since: v1.2.0 SQL example: SELECT ST_GeomFromGeoJSON ( polygontable . _c0 ) AS polygonshape FROM polygontable ST_GeomFromGML \u00b6 Introduction: Construct a Geometry from GML. Format: ST_GeomFromGML (gml:string) Since: v1.3.0 SQL example: SELECT ST_GeomFromGML ( '<gml:LineString srsName=\"EPSG:4269\"><gml:coordinates>-71.16028,42.258729 -71.160837,42.259112 -71.161143,42.25932</gml:coordinates></gml:LineString>' ) AS geometry ST_GeomFromKML \u00b6 Introduction: Construct a Geometry from KML. Format: ST_GeomFromKML (kml:string) Since: v1.3.0 SQL example: SELECT ST_GeomFromKML ( '<LineString><coordinates>-71.1663,42.2614 -71.1667,42.2616</coordinates></LineString>' ) AS geometry ST_GeomFromText \u00b6 Introduction: Construct a Geometry from Wkt. Alias of ST_GeomFromWKT Format: ST_GeomFromText (Wkt:string) Since: v1.2.1 SQL example: SELECT ST_GeomFromText ( 'POINT(40.7128 -74.0060)' ) AS geometry ST_GeomFromWKB \u00b6 Introduction: Construct a Geometry from WKB string or Binary Format: ST_GeomFromWKB (Wkb:string) ST_GeomFromWKB (Wkb:binary) Since: v1.2.0 SQL example: SELECT ST_GeomFromWKB ( polygontable . _c0 ) AS polygonshape FROM polygontable Format: ST_GeomFromWKB (Wkb:bytes) Since: v1.2.1 SQL example: SELECT ST_GeomFromWKB ( polygontable . _c0 ) AS polygonshape FROM polygontable ST_GeomFromWKT \u00b6 Introduction: Construct a Geometry from Wkt Format: ST_GeomFromWKT (Wkt:string) Since: v1.2.0 SQL example: SELECT ST_GeomFromWKT ( 'POINT(40.7128 -74.0060)' ) AS geometry ST_LineFromText \u00b6 Introduction: Construct a LineString from Text, delimited by Delimiter (Optional) Format: ST_LineFromText (Text:string, Delimiter:char) Since: v1.2.1 SQL example: SELECT ST_LineFromText ( 'Linestring(1 2, 3 4)' ) AS line ST_LineStringFromText \u00b6 Introduction: Construct a LineString from Text, delimited by Delimiter (Optional). Alias of ST_LineFromText Format: ST_LineStringFromText (Text:string, Delimiter:char) Since: v1.2.1 Spark SQL example: SELECT ST_LineStringFromText ( 'Linestring(1 2, 3 4)' ) AS line ST_MLineFromText \u00b6 Introduction: Construct a MultiLineString from Text and Optional SRID Format: ST_MLineFromText (Text:string, Srid: int) Since: 1.3.1 SQL example: SELECT ST_MLineFromText ( 'MULTILINESTRING((1 2, 3 4), (4 5, 6 7))' ) AS multiLine SELECT ST_MLineFromText ( 'MULTILINESTRING((1 2, 3 4), (4 5, 6 7))' , 4269 ) AS multiLine ST_MPolyFromText \u00b6 Introduction: Construct a MultiPolygon from Text and Optional SRID Format: ST_MPolyFromText (Text:string, Srid: int) Since: 1.3.1 SQL example: SELECT ST_MPolyFromText ( 'MULTIPOLYGON(((-70.916 42.1002,-70.9468 42.0946,-70.9765 42.0872 )))' ) AS multiPolygon SELECT ST_MPolyFromText ( 'MULTIPOLYGON(((-70.916 42.1002,-70.9468 42.0946,-70.9765 42.0872 )))' , 4269 ) AS multiPolygon ST_Point \u00b6 Introduction: Construct a Point from X and Y Format: ST_Point (X:decimal, Y:decimal) Since: v1.2.1 SQL example: SELECT ST_Point ( x , y ) AS pointshape FROM pointtable ST_PointFromText \u00b6 Introduction: Construct a Point from Text, delimited by Delimiter Format: ST_PointFromText (Text:string, Delimiter:char) Since: v1.2.0 SQL example: SELECT ST_PointFromText ( '40.7128,-74.0060' , ',' ) AS pointshape ST_PolygonFromEnvelope \u00b6 Introduction: Construct a Polygon from MinX, MinY, MaxX, MaxY. Format: ST_PolygonFromEnvelope (MinX:decimal, MinY:decimal, MaxX:decimal, MaxY:decimal) Since: v1.2.0 SQL example: SELECT * FROM pointdf WHERE ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . pointshape ) ST_PolygonFromText \u00b6 Introduction: Construct a Polygon from Text, delimited by Delimiter. Path must be closed Format: ST_PolygonFromText (Text:string, Delimiter:char) Since: v1.2.0 SQL example: SELECT ST_PolygonFromText ( '-74.0428197,40.6867969,-74.0421975,40.6921336,-74.0508020,40.6912794,-74.0428197,40.6867969' , ',' ) AS polygonshape","title":"Constructor"},{"location":"api/flink/Constructor/#st_geomfromgeohash","text":"Introduction: Create Geometry from geohash string and optional precision Format: ST_GeomFromGeoHash(geohash: string, precision: int) Since: v1.2.1 SQL example: SELECT ST_GeomFromGeoHash ( 's00twy01mt' , 4 ) AS geom","title":"ST_GeomFromGeoHash"},{"location":"api/flink/Constructor/#st_geomfromgeojson","text":"Introduction: Construct a Geometry from GeoJson Format: ST_GeomFromGeoJSON (GeoJson:string) Since: v1.2.0 SQL example: SELECT ST_GeomFromGeoJSON ( polygontable . _c0 ) AS polygonshape FROM polygontable","title":"ST_GeomFromGeoJSON"},{"location":"api/flink/Constructor/#st_geomfromgml","text":"Introduction: Construct a Geometry from GML. Format: ST_GeomFromGML (gml:string) Since: v1.3.0 SQL example: SELECT ST_GeomFromGML ( '<gml:LineString srsName=\"EPSG:4269\"><gml:coordinates>-71.16028,42.258729 -71.160837,42.259112 -71.161143,42.25932</gml:coordinates></gml:LineString>' ) AS geometry","title":"ST_GeomFromGML"},{"location":"api/flink/Constructor/#st_geomfromkml","text":"Introduction: Construct a Geometry from KML. Format: ST_GeomFromKML (kml:string) Since: v1.3.0 SQL example: SELECT ST_GeomFromKML ( '<LineString><coordinates>-71.1663,42.2614 -71.1667,42.2616</coordinates></LineString>' ) AS geometry","title":"ST_GeomFromKML"},{"location":"api/flink/Constructor/#st_geomfromtext","text":"Introduction: Construct a Geometry from Wkt. Alias of ST_GeomFromWKT Format: ST_GeomFromText (Wkt:string) Since: v1.2.1 SQL example: SELECT ST_GeomFromText ( 'POINT(40.7128 -74.0060)' ) AS geometry","title":"ST_GeomFromText"},{"location":"api/flink/Constructor/#st_geomfromwkb","text":"Introduction: Construct a Geometry from WKB string or Binary Format: ST_GeomFromWKB (Wkb:string) ST_GeomFromWKB (Wkb:binary) Since: v1.2.0 SQL example: SELECT ST_GeomFromWKB ( polygontable . _c0 ) AS polygonshape FROM polygontable Format: ST_GeomFromWKB (Wkb:bytes) Since: v1.2.1 SQL example: SELECT ST_GeomFromWKB ( polygontable . _c0 ) AS polygonshape FROM polygontable","title":"ST_GeomFromWKB"},{"location":"api/flink/Constructor/#st_geomfromwkt","text":"Introduction: Construct a Geometry from Wkt Format: ST_GeomFromWKT (Wkt:string) Since: v1.2.0 SQL example: SELECT ST_GeomFromWKT ( 'POINT(40.7128 -74.0060)' ) AS geometry","title":"ST_GeomFromWKT"},{"location":"api/flink/Constructor/#st_linefromtext","text":"Introduction: Construct a LineString from Text, delimited by Delimiter (Optional) Format: ST_LineFromText (Text:string, Delimiter:char) Since: v1.2.1 SQL example: SELECT ST_LineFromText ( 'Linestring(1 2, 3 4)' ) AS line","title":"ST_LineFromText"},{"location":"api/flink/Constructor/#st_linestringfromtext","text":"Introduction: Construct a LineString from Text, delimited by Delimiter (Optional). Alias of ST_LineFromText Format: ST_LineStringFromText (Text:string, Delimiter:char) Since: v1.2.1 Spark SQL example: SELECT ST_LineStringFromText ( 'Linestring(1 2, 3 4)' ) AS line","title":"ST_LineStringFromText"},{"location":"api/flink/Constructor/#st_mlinefromtext","text":"Introduction: Construct a MultiLineString from Text and Optional SRID Format: ST_MLineFromText (Text:string, Srid: int) Since: 1.3.1 SQL example: SELECT ST_MLineFromText ( 'MULTILINESTRING((1 2, 3 4), (4 5, 6 7))' ) AS multiLine SELECT ST_MLineFromText ( 'MULTILINESTRING((1 2, 3 4), (4 5, 6 7))' , 4269 ) AS multiLine","title":"ST_MLineFromText"},{"location":"api/flink/Constructor/#st_mpolyfromtext","text":"Introduction: Construct a MultiPolygon from Text and Optional SRID Format: ST_MPolyFromText (Text:string, Srid: int) Since: 1.3.1 SQL example: SELECT ST_MPolyFromText ( 'MULTIPOLYGON(((-70.916 42.1002,-70.9468 42.0946,-70.9765 42.0872 )))' ) AS multiPolygon SELECT ST_MPolyFromText ( 'MULTIPOLYGON(((-70.916 42.1002,-70.9468 42.0946,-70.9765 42.0872 )))' , 4269 ) AS multiPolygon","title":"ST_MPolyFromText"},{"location":"api/flink/Constructor/#st_point","text":"Introduction: Construct a Point from X and Y Format: ST_Point (X:decimal, Y:decimal) Since: v1.2.1 SQL example: SELECT ST_Point ( x , y ) AS pointshape FROM pointtable","title":"ST_Point"},{"location":"api/flink/Constructor/#st_pointfromtext","text":"Introduction: Construct a Point from Text, delimited by Delimiter Format: ST_PointFromText (Text:string, Delimiter:char) Since: v1.2.0 SQL example: SELECT ST_PointFromText ( '40.7128,-74.0060' , ',' ) AS pointshape","title":"ST_PointFromText"},{"location":"api/flink/Constructor/#st_polygonfromenvelope","text":"Introduction: Construct a Polygon from MinX, MinY, MaxX, MaxY. Format: ST_PolygonFromEnvelope (MinX:decimal, MinY:decimal, MaxX:decimal, MaxY:decimal) Since: v1.2.0 SQL example: SELECT * FROM pointdf WHERE ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . pointshape )","title":"ST_PolygonFromEnvelope"},{"location":"api/flink/Constructor/#st_polygonfromtext","text":"Introduction: Construct a Polygon from Text, delimited by Delimiter. Path must be closed Format: ST_PolygonFromText (Text:string, Delimiter:char) Since: v1.2.0 SQL example: SELECT ST_PolygonFromText ( '-74.0428197,40.6867969,-74.0421975,40.6921336,-74.0508020,40.6912794,-74.0428197,40.6867969' , ',' ) AS polygonshape","title":"ST_PolygonFromText"},{"location":"api/flink/Function/","text":"ST_3DDistance \u00b6 Introduction: Return the 3-dimensional minimum cartesian distance between A and B Format: ST_3DDistance (A:geometry, B:geometry) Since: v1.3.0 Example: SELECT ST_3DDistance ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf ST_AddPoint \u00b6 Introduction: Return Linestring with additional point at the given index, if position is not available the point will be added at the end of line. Format: ST_AddPoint(geom: geometry, point: geometry, position: integer) Format: ST_AddPoint(geom: geometry, point: geometry) Since: v1.3.0 Example: SELECT ST_AddPoint ( ST_GeomFromText ( \"LINESTRING(0 0, 1 1, 1 0)\" ), ST_GeomFromText ( \"Point(21 52)\" ), 1 ) SELECT ST_AddPoint ( ST_GeomFromText ( \"Linestring(0 0, 1 1, 1 0)\" ), ST_GeomFromText ( \"Point(21 52)\" )) Output: LINESTRING(0 0, 21 52, 1 1, 1 0) LINESTRING(0 0, 1 1, 1 0, 21 52) ST_Area \u00b6 Introduction: Return the area of A Format: ST_Area (A:geometry) Since: v1.3.0 Example: SELECT ST_Area ( polygondf . countyshape ) FROM polygondf ST_AsBinary \u00b6 Introduction: Return the Well-Known Binary representation of a geometry Format: ST_AsBinary (A:geometry) Since: v1.3.0 Example: SELECT ST_AsBinary ( polygondf . countyshape ) FROM polygondf ST_AsEWKB \u00b6 Introduction: Return the Extended Well-Known Binary representation of a geometry. EWKB is an extended version of WKB which includes the SRID of the geometry. The format originated in PostGIS but is supported by many GIS tools. If the geometry is lacking SRID a WKB format is produced. Format: ST_AsEWKB (A:geometry) Since: v1.3.0 Example: SELECT ST_AsEWKB ( polygondf . countyshape ) FROM polygondf ST_AsEWKT \u00b6 Introduction: Return the Extended Well-Known Text representation of a geometry. EWKT is an extended version of WKT which includes the SRID of the geometry. The format originated in PostGIS but is supported by many GIS tools. If the geometry is lacking SRID a WKT format is produced. See ST_SetSRID Format: ST_AsEWKT (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_AsEWKT ( polygondf . countyshape ) FROM polygondf ST_AsGeoJSON \u00b6 Introduction: Return the GeoJSON string representation of a geometry Format: ST_AsGeoJSON (A:geometry) Since: v1.3.0 Spark SQL example: SELECT ST_AsGeoJSON ( polygondf . countyshape ) FROM polygondf ST_AsGML \u00b6 Introduction: Return the GML string representation of a geometry Format: ST_AsGML (A:geometry) Since: v1.3.0 Spark SQL example: SELECT ST_AsGML ( polygondf . countyshape ) FROM polygondf ST_AsKML \u00b6 Introduction: Return the KML string representation of a geometry Format: ST_AsKML (A:geometry) Since: v1.3.0 Spark SQL example: SELECT ST_AsKML ( polygondf . countyshape ) FROM polygondf ST_AsText \u00b6 Introduction: Return the Well-Known Text string representation of a geometry Format: ST_AsText (A:geometry) Since: v1.3.0 Example: SELECT ST_AsText ( polygondf . countyshape ) FROM polygondf ST_Azimuth \u00b6 Introduction: Returns Azimuth for two given points in radians null otherwise. Format: ST_Azimuth(pointA: Point, pointB: Point) Since: v1.3.0 Example: SELECT ST_Azimuth ( ST_POINT ( 0 . 0 , 25 . 0 ), ST_POINT ( 0 . 0 , 0 . 0 )) Output: 3.141592653589793 ST_Boundary \u00b6 Introduction: Returns the closure of the combinatorial boundary of this Geometry. Format: ST_Boundary(geom: geometry) Since: v1.3.0 Example: SELECT ST_Boundary ( ST_GeomFromText ( 'POLYGON ((1 1, 0 0, -1 1, 1 1))' )) Output: LINEARRING (1 1, 0 0, -1 1, 1 1) ST_Buffer \u00b6 Introduction: Returns a geometry/geography that represents all points whose distance from this Geometry/geography is less than or equal to distance. Format: ST_Buffer (A:geometry, buffer: Double) Since: v1.2.0 Spark SQL example: SELECT ST_Buffer ( polygondf . countyshape , 1 ) FROM polygondf ST_BuildArea \u00b6 Introduction: Returns the areal geometry formed by the constituent linework of the input geometry. Format: ST_BuildArea (A:geometry) Since: v1.2.1 Example: SELECT ST_BuildArea ( ST_Collect ( smallDf , bigDf )) AS geom FROM smallDf , bigDf Input: MULTILINESTRING((0 0, 10 0, 10 10, 0 10, 0 0),(10 10, 20 10, 20 20, 10 20, 10 10)) Output: MULTIPOLYGON(((0 0,0 10,10 10,10 0,0 0)),((10 10,10 20,20 20,20 10,10 10))) ST_Distance \u00b6 Introduction: Return the Euclidean distance between A and B Format: ST_Distance (A:geometry, B:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_Distance ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf ST_Envelope \u00b6 Introduction: Return the envelop boundary of A Format: ST_Envelope (A:geometry) Since: v1.3.0 Example: SELECT ST_Envelope ( polygondf . countyshape ) FROM polygondf ST_ExteriorRing \u00b6 Introduction: Returns a LINESTRING representing the exterior ring (shell) of a POLYGON. Returns NULL if the geometry is not a polygon. Format: ST_ExteriorRing(A:geometry) Since: v1.2.1 Examples: SELECT ST_ExteriorRing ( df . geometry ) FROM df Input: POLYGON ((0 0, 1 1, 2 1, 0 1, 1 -1, 0 0)) Output: LINESTRING (0 0, 1 1, 2 1, 0 1, 1 -1, 0 0) ST_FlipCoordinates \u00b6 Introduction: Returns a version of the given geometry with X and Y axis flipped. Format: ST_FlipCoordinates(A:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_FlipCoordinates ( df . geometry ) FROM df Input: POINT (1 2) Output: POINT (2 1) ST_Force_2D \u00b6 Introduction: Forces the geometries into a \"2-dimensional mode\" so that all output representations will only have the X and Y coordinates Format: ST_Force_2D (A:geometry) Since: v1.2.1 Example: SELECT ST_Force_2D ( df . geometry ) AS geom FROM df Input: POLYGON((0 0 2,0 5 2,5 0 2,0 0 2),(1 1 2,3 1 2,1 3 2,1 1 2)) Output: POLYGON((0 0,0 5,5 0,0 0),(1 1,3 1,1 3,1 1)) ST_GeoHash \u00b6 Introduction: Returns GeoHash of the geometry with given precision Format: ST_GeoHash(geom: geometry, precision: int) Since: v1.2.0 Example: Query: SELECT ST_GeoHash ( ST_GeomFromText ( 'POINT(21.427834 52.042576573)' ), 5 ) AS geohash Result: +-----------------------------+ |geohash | +-----------------------------+ |u3r0p | +-----------------------------+ ST_GeometryN \u00b6 Introduction: Return the 0-based Nth geometry if the geometry is a GEOMETRYCOLLECTION, (MULTI)POINT, (MULTI)LINESTRING, MULTICURVE or (MULTI)POLYGON. Otherwise, return null Format: ST_GeometryN(geom: geometry, n: Int) Since: v1.3.0 Example: SELECT ST_GeometryN ( ST_GeomFromText ( 'MULTIPOINT((1 2), (3 4), (5 6), (8 9))' ), 1 ) Output: POINT (3 4) ST_InteriorRingN \u00b6 Introduction: Returns the Nth interior linestring ring of the polygon geometry. Returns NULL if the geometry is not a polygon or the given N is out of range Format: ST_InteriorRingN(geom: geometry, n: Int) Since: v1.3.0 Example: SELECT ST_InteriorRingN ( ST_GeomFromText ( 'POLYGON((0 0, 0 5, 5 5, 5 0, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1), (1 3, 2 3, 2 4, 1 4, 1 3), (3 3, 4 3, 4 4, 3 4, 3 3))' ), 0 ) Output: LINEARRING (1 1, 2 1, 2 2, 1 2, 1 1) ST_IsClosed \u00b6 Introduction: RETURNS true if the LINESTRING start and end point are the same. Format: ST_IsClosed(geom: geometry) Since: v1.3.0 Example: SELECT ST_IsClosed ( ST_GeomFromText ( 'LINESTRING(0 0, 1 1, 1 0)' )) ST_IsEmpty \u00b6 Introduction: Test if a geometry is empty geometry Format: ST_IsEmpty (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_IsEmpty ( polygondf . countyshape ) FROM polygondf ST_IsRing \u00b6 Introduction: RETURN true if LINESTRING is ST_IsClosed and ST_IsSimple. Format: ST_IsRing(geom: geometry) Since: v1.3.0 Example: SELECT ST_IsRing ( ST_GeomFromText ( \"LINESTRING(0 0, 0 1, 1 1, 1 0, 0 0)\" )) Output: true ST_IsSimple \u00b6 Introduction: Test if geometry's only self-intersections are at boundary points. Format: ST_IsSimple (A:geometry) Since: v1.3.0 Example: SELECT ST_IsSimple ( polygondf . countyshape ) FROM polygondf ST_IsValid \u00b6 Introduction: Test if a geometry is well formed Format: ST_IsValid (A:geometry) Since: v1.3.0 Example: SELECT ST_IsValid ( polygondf . countyshape ) FROM polygondf ST_Length \u00b6 Introduction: Return the perimeter of A Format: ST_Length (A:geometry) Since: v1.3.0 Example: SELECT ST_Length ( polygondf . countyshape ) FROM polygondf ST_LineFromMultiPoint \u00b6 Introduction: Creates a LineString from a MultiPoint geometry. Format: ST_LineFromMultiPoint (A:geometry) Since: v1.3.0 Example: SELECT ST_LineFromMultiPoint ( df . geometry ) AS geom FROM df Input: MULTIPOINT((10 40), (40 30), (20 20), (30 10)) Output: LINESTRING (10 40, 40 30, 20 20, 30 10) ST_Normalize \u00b6 Introduction: Returns the input geometry in its normalized form. Format ST_Normalize(geom: geometry) Since: v1.3.0 Example: SELECT ST_AsEWKT ( ST_Normalize ( ST_GeomFromWKT ( 'POLYGON((0 1, 1 1, 1 0, 0 0, 0 1))' ))) AS geom Result: +-----------------------------------+ |geom | +-----------------------------------+ |POLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))| +-----------------------------------+ ST_NPoints \u00b6 Introduction: Returns the number of points of the geometry Since: v1.3.0 Format: ST_NPoints (A:geometry) Example: SELECT ST_NPoints ( polygondf . countyshape ) FROM polygondf ST_NDims \u00b6 Introduction: Returns the coordinate dimension of the geometry. It supports 2 - (x,y) , 3 - (x,y,z). Currently the geometry serializer in sedona-sql does not support M dimension, 4D geometries with ZM coordinates will have their M coordinates dropped and became 3D geometries. We're working on a new geometry serializer to resolve this issue. Format: ST_NDims(geom: geometry) Since: v1.3.1 Spark SQL example with z co-rodinate: SELECT ST_NDims ( ST_GeomFromEWKT ( 'POINT(1 1 2)' )) Output: 3 Spark SQL example with x,y co-ordinate: SELECT ST_NDims ( ST_GeomFromText ( 'POINT(1 1)' )) Output: 2 ST_NumGeometries \u00b6 Introduction: Returns the number of Geometries. If geometry is a GEOMETRYCOLLECTION (or MULTI*) return the number of geometries, for single geometries will return 1. Format: ST_NumGeometries (A:geometry) Since: v1.3.0 Example: SELECT ST_NumGeometries ( df . geometry ) FROM df ST_NumInteriorRings \u00b6 Introduction: Returns number of interior rings of polygon geometries. Format: ST_NumInteriorRings(geom: geometry) Since: v1.3.0 Example: SELECT ST_NumInteriorRings ( ST_GeomFromText ( 'POLYGON ((0 0, 0 5, 5 5, 5 0, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1))' )) Output: 1 ST_PointN \u00b6 Introduction: Return the Nth point in a single linestring or circular linestring in the geometry. Negative values are counted backwards from the end of the LineString, so that -1 is the last point. Returns NULL if there is no linestring in the geometry. Format: ST_PointN(A:geometry, B:integer) Since: v1.2.1 Examples: SELECT ST_PointN ( df . geometry , 2 ) FROM df Input: LINESTRING(0 0, 1 2, 2 4, 3 6), 2 Output: POINT (1 2) Input: LINESTRING(0 0, 1 2, 2 4, 3 6), -2 Output: POINT (2 4) Input: CIRCULARSTRING(1 1, 1 2, 2 4, 3 6, 1 2, 1 1), -1 Output: POINT (1 1) ST_PointOnSurface \u00b6 Introduction: Returns a POINT guaranteed to lie on the surface. Format: ST_PointOnSurface(A:geometry) Since: v1.2.1 Examples: SELECT ST_PointOnSurface ( df . geometry ) FROM df Input: POINT (0 5) Output: POINT (0 5) Input: LINESTRING(0 5, 0 10) Output: POINT (0 5) Input: POLYGON((0 0, 0 5, 5 5, 5 0, 0 0)) Output: POINT (2.5 2.5) Input: LINESTRING(0 5 1, 0 0 1, 0 10 2) Output: POINT Z(0 0 1) ST_Reverse \u00b6 Introduction: Return the geometry with vertex order reversed Format: ST_Reverse (A:geometry) Since: v1.2.1 Example: SELECT ST_Reverse ( df . geometry ) AS geom FROM df Input: POLYGON ((-0.5 -0.5, -0.5 0.5, 0.5 0.5, 0.5 -0.5, -0.5 -0.5)) Output: POLYGON ((-0.5 -0.5, 0.5 -0.5, 0.5 0.5, -0.5 0.5, -0.5 -0.5)) ST_RemovePoint \u00b6 Introduction: Return Linestring with removed point at given index, position can be omitted and then last one will be removed. Format: ST_RemovePoint(geom: geometry, position: integer) Format: ST_RemovePoint(geom: geometry) Since: v1.3.0 Example: SELECT ST_RemovePoint ( ST_GeomFromText ( \"LINESTRING(0 0, 1 1, 1 0)\" ), 1 ) Output: LINESTRING(0 0, 1 0) ST_SetPoint \u00b6 Introduction: Replace Nth point of linestring with given point. Index is 0-based. Negative index are counted backwards, e.g., -1 is last point. Format: ST_SetPoint (linestring: geometry, index: integer, point: geometry) Since: v1.3.0 Example: SELECT ST_SetPoint ( ST_GeomFromText ( 'LINESTRING (0 0, 0 1, 1 1)' ), 2 , ST_GeomFromText ( 'POINT (1 0)' )) AS geom Result: +--------------------------------+ | geom | +--------------------------------+ | LINESTRING (0 0, 0 1, 1 0) | +--------------------------------+ ST_SetSRID \u00b6 Introduction: Sets the spatial refence system identifier (SRID) of the geometry. Format: ST_SetSRID (A:geometry, srid: integer) Since: v1.3.0 Example: SELECT ST_SetSRID ( polygondf . countyshape , 3021 ) FROM polygondf ST_SRID \u00b6 Introduction: Return the spatial refence system identifier (SRID) of the geometry. Format: ST_SRID (A:geometry) Since: v1.3.0 Example: SELECT ST_SRID ( polygondf . countyshape ) FROM polygondf ST_Transform \u00b6 Introduction: Transform the Spatial Reference System / Coordinate Reference System of A, from SourceCRS to TargetCRS For SourceCRS and TargetCRS, WKT format is also available since v1.3.1. Note By default, this function uses lat/lon order. You can use ST_FlipCoordinates to swap X and Y. Note If ST_Transform throws an Exception called \"Bursa wolf parameters required\", you need to disable the error notification in ST_Transform. You can append a boolean value at the end. Format: ST_Transform (A:geometry, SourceCRS:string, TargetCRS:string ,[Optional] DisableError) Since: v1.2.0 Spark SQL example (simple): SELECT ST_Transform ( polygondf . countyshape , 'epsg:4326' , 'epsg:3857' ) FROM polygondf Spark SQL example (with optional parameters): SELECT ST_Transform ( polygondf . countyshape , 'epsg:4326' , 'epsg:3857' , false ) FROM polygondf Note The detailed EPSG information can be searched on EPSG.io . ST_X \u00b6 Introduction: Returns X Coordinate of given Point, null otherwise. Format: ST_X(pointA: Point) Since: v1.3.0 Example: SELECT ST_X ( ST_POINT ( 0 . 0 25 . 0 )) Output: 0.0 ST_XMax \u00b6 Introduction: Returns the maximum X coordinate of a geometry Format: ST_XMax (A:geometry) Since: v1.2.1 Example: SELECT ST_XMax ( df . geometry ) AS xmax FROM df Input: POLYGON ((-1 -11, 0 10, 1 11, 2 12, -1 -11)) Output: 2 ST_XMin \u00b6 Introduction: Returns the minimum X coordinate of a geometry Format: ST_XMin (A:geometry) Since: v1.2.1 Example: SELECT ST_XMin ( df . geometry ) AS xmin FROM df Input: POLYGON ((-1 -11, 0 10, 1 11, 2 12, -1 -11)) Output: -1 ST_Y \u00b6 Introduction: Returns Y Coordinate of given Point, null otherwise. Format: ST_Y(pointA: Point) Since: v1.3.0 Example: SELECT ST_Y ( ST_POINT ( 0 . 0 25 . 0 )) Output: 25.0 ST_YMax \u00b6 Introduction: Return the minimum Y coordinate of A Format: ST_YMax (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_YMax ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output : 2 ST_YMin \u00b6 Introduction: Return the minimum Y coordinate of A Format: ST_Y_Min (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_YMin ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output : 0 ST_Z \u00b6 Introduction: Returns Z Coordinate of given Point, null otherwise. Format: ST_Z(pointA: Point) Since: v1.3.0 Example: SELECT ST_Z ( ST_POINT ( 0 . 0 25 . 0 11 . 0 )) Output: 11.0 ST_ZMax \u00b6 Introduction: Returns Z maxima of the given geometry or null if there is no Z coordinate. Format: ST_ZMax(geom: geometry) Since: v1.3.1 Spark SQL example: SELECT ST_ZMax ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output: 1.0 ST_ZMin \u00b6 Introduction: Returns Z minima of the given geometry or null if there is no Z coordinate. Format: ST_ZMin(geom: geometry) Since: v1.3.1 Spark SQL example: SELECT ST_ZMin ( ST_GeomFromText ( 'LINESTRING(1 3 4, 5 6 7)' )) Output: 4.0","title":"Function"},{"location":"api/flink/Function/#st_3ddistance","text":"Introduction: Return the 3-dimensional minimum cartesian distance between A and B Format: ST_3DDistance (A:geometry, B:geometry) Since: v1.3.0 Example: SELECT ST_3DDistance ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf","title":"ST_3DDistance"},{"location":"api/flink/Function/#st_addpoint","text":"Introduction: Return Linestring with additional point at the given index, if position is not available the point will be added at the end of line. Format: ST_AddPoint(geom: geometry, point: geometry, position: integer) Format: ST_AddPoint(geom: geometry, point: geometry) Since: v1.3.0 Example: SELECT ST_AddPoint ( ST_GeomFromText ( \"LINESTRING(0 0, 1 1, 1 0)\" ), ST_GeomFromText ( \"Point(21 52)\" ), 1 ) SELECT ST_AddPoint ( ST_GeomFromText ( \"Linestring(0 0, 1 1, 1 0)\" ), ST_GeomFromText ( \"Point(21 52)\" )) Output: LINESTRING(0 0, 21 52, 1 1, 1 0) LINESTRING(0 0, 1 1, 1 0, 21 52)","title":"ST_AddPoint"},{"location":"api/flink/Function/#st_area","text":"Introduction: Return the area of A Format: ST_Area (A:geometry) Since: v1.3.0 Example: SELECT ST_Area ( polygondf . countyshape ) FROM polygondf","title":"ST_Area"},{"location":"api/flink/Function/#st_asbinary","text":"Introduction: Return the Well-Known Binary representation of a geometry Format: ST_AsBinary (A:geometry) Since: v1.3.0 Example: SELECT ST_AsBinary ( polygondf . countyshape ) FROM polygondf","title":"ST_AsBinary"},{"location":"api/flink/Function/#st_asewkb","text":"Introduction: Return the Extended Well-Known Binary representation of a geometry. EWKB is an extended version of WKB which includes the SRID of the geometry. The format originated in PostGIS but is supported by many GIS tools. If the geometry is lacking SRID a WKB format is produced. Format: ST_AsEWKB (A:geometry) Since: v1.3.0 Example: SELECT ST_AsEWKB ( polygondf . countyshape ) FROM polygondf","title":"ST_AsEWKB"},{"location":"api/flink/Function/#st_asewkt","text":"Introduction: Return the Extended Well-Known Text representation of a geometry. EWKT is an extended version of WKT which includes the SRID of the geometry. The format originated in PostGIS but is supported by many GIS tools. If the geometry is lacking SRID a WKT format is produced. See ST_SetSRID Format: ST_AsEWKT (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_AsEWKT ( polygondf . countyshape ) FROM polygondf","title":"ST_AsEWKT"},{"location":"api/flink/Function/#st_asgeojson","text":"Introduction: Return the GeoJSON string representation of a geometry Format: ST_AsGeoJSON (A:geometry) Since: v1.3.0 Spark SQL example: SELECT ST_AsGeoJSON ( polygondf . countyshape ) FROM polygondf","title":"ST_AsGeoJSON"},{"location":"api/flink/Function/#st_asgml","text":"Introduction: Return the GML string representation of a geometry Format: ST_AsGML (A:geometry) Since: v1.3.0 Spark SQL example: SELECT ST_AsGML ( polygondf . countyshape ) FROM polygondf","title":"ST_AsGML"},{"location":"api/flink/Function/#st_askml","text":"Introduction: Return the KML string representation of a geometry Format: ST_AsKML (A:geometry) Since: v1.3.0 Spark SQL example: SELECT ST_AsKML ( polygondf . countyshape ) FROM polygondf","title":"ST_AsKML"},{"location":"api/flink/Function/#st_astext","text":"Introduction: Return the Well-Known Text string representation of a geometry Format: ST_AsText (A:geometry) Since: v1.3.0 Example: SELECT ST_AsText ( polygondf . countyshape ) FROM polygondf","title":"ST_AsText"},{"location":"api/flink/Function/#st_azimuth","text":"Introduction: Returns Azimuth for two given points in radians null otherwise. Format: ST_Azimuth(pointA: Point, pointB: Point) Since: v1.3.0 Example: SELECT ST_Azimuth ( ST_POINT ( 0 . 0 , 25 . 0 ), ST_POINT ( 0 . 0 , 0 . 0 )) Output: 3.141592653589793","title":"ST_Azimuth"},{"location":"api/flink/Function/#st_boundary","text":"Introduction: Returns the closure of the combinatorial boundary of this Geometry. Format: ST_Boundary(geom: geometry) Since: v1.3.0 Example: SELECT ST_Boundary ( ST_GeomFromText ( 'POLYGON ((1 1, 0 0, -1 1, 1 1))' )) Output: LINEARRING (1 1, 0 0, -1 1, 1 1)","title":"ST_Boundary"},{"location":"api/flink/Function/#st_buffer","text":"Introduction: Returns a geometry/geography that represents all points whose distance from this Geometry/geography is less than or equal to distance. Format: ST_Buffer (A:geometry, buffer: Double) Since: v1.2.0 Spark SQL example: SELECT ST_Buffer ( polygondf . countyshape , 1 ) FROM polygondf","title":"ST_Buffer"},{"location":"api/flink/Function/#st_buildarea","text":"Introduction: Returns the areal geometry formed by the constituent linework of the input geometry. Format: ST_BuildArea (A:geometry) Since: v1.2.1 Example: SELECT ST_BuildArea ( ST_Collect ( smallDf , bigDf )) AS geom FROM smallDf , bigDf Input: MULTILINESTRING((0 0, 10 0, 10 10, 0 10, 0 0),(10 10, 20 10, 20 20, 10 20, 10 10)) Output: MULTIPOLYGON(((0 0,0 10,10 10,10 0,0 0)),((10 10,10 20,20 20,20 10,10 10)))","title":"ST_BuildArea"},{"location":"api/flink/Function/#st_distance","text":"Introduction: Return the Euclidean distance between A and B Format: ST_Distance (A:geometry, B:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_Distance ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf","title":"ST_Distance"},{"location":"api/flink/Function/#st_envelope","text":"Introduction: Return the envelop boundary of A Format: ST_Envelope (A:geometry) Since: v1.3.0 Example: SELECT ST_Envelope ( polygondf . countyshape ) FROM polygondf","title":"ST_Envelope"},{"location":"api/flink/Function/#st_exteriorring","text":"Introduction: Returns a LINESTRING representing the exterior ring (shell) of a POLYGON. Returns NULL if the geometry is not a polygon. Format: ST_ExteriorRing(A:geometry) Since: v1.2.1 Examples: SELECT ST_ExteriorRing ( df . geometry ) FROM df Input: POLYGON ((0 0, 1 1, 2 1, 0 1, 1 -1, 0 0)) Output: LINESTRING (0 0, 1 1, 2 1, 0 1, 1 -1, 0 0)","title":"ST_ExteriorRing"},{"location":"api/flink/Function/#st_flipcoordinates","text":"Introduction: Returns a version of the given geometry with X and Y axis flipped. Format: ST_FlipCoordinates(A:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_FlipCoordinates ( df . geometry ) FROM df Input: POINT (1 2) Output: POINT (2 1)","title":"ST_FlipCoordinates"},{"location":"api/flink/Function/#st_force_2d","text":"Introduction: Forces the geometries into a \"2-dimensional mode\" so that all output representations will only have the X and Y coordinates Format: ST_Force_2D (A:geometry) Since: v1.2.1 Example: SELECT ST_Force_2D ( df . geometry ) AS geom FROM df Input: POLYGON((0 0 2,0 5 2,5 0 2,0 0 2),(1 1 2,3 1 2,1 3 2,1 1 2)) Output: POLYGON((0 0,0 5,5 0,0 0),(1 1,3 1,1 3,1 1))","title":"ST_Force_2D"},{"location":"api/flink/Function/#st_geohash","text":"Introduction: Returns GeoHash of the geometry with given precision Format: ST_GeoHash(geom: geometry, precision: int) Since: v1.2.0 Example: Query: SELECT ST_GeoHash ( ST_GeomFromText ( 'POINT(21.427834 52.042576573)' ), 5 ) AS geohash Result: +-----------------------------+ |geohash | +-----------------------------+ |u3r0p | +-----------------------------+","title":"ST_GeoHash"},{"location":"api/flink/Function/#st_geometryn","text":"Introduction: Return the 0-based Nth geometry if the geometry is a GEOMETRYCOLLECTION, (MULTI)POINT, (MULTI)LINESTRING, MULTICURVE or (MULTI)POLYGON. Otherwise, return null Format: ST_GeometryN(geom: geometry, n: Int) Since: v1.3.0 Example: SELECT ST_GeometryN ( ST_GeomFromText ( 'MULTIPOINT((1 2), (3 4), (5 6), (8 9))' ), 1 ) Output: POINT (3 4)","title":"ST_GeometryN"},{"location":"api/flink/Function/#st_interiorringn","text":"Introduction: Returns the Nth interior linestring ring of the polygon geometry. Returns NULL if the geometry is not a polygon or the given N is out of range Format: ST_InteriorRingN(geom: geometry, n: Int) Since: v1.3.0 Example: SELECT ST_InteriorRingN ( ST_GeomFromText ( 'POLYGON((0 0, 0 5, 5 5, 5 0, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1), (1 3, 2 3, 2 4, 1 4, 1 3), (3 3, 4 3, 4 4, 3 4, 3 3))' ), 0 ) Output: LINEARRING (1 1, 2 1, 2 2, 1 2, 1 1)","title":"ST_InteriorRingN"},{"location":"api/flink/Function/#st_isclosed","text":"Introduction: RETURNS true if the LINESTRING start and end point are the same. Format: ST_IsClosed(geom: geometry) Since: v1.3.0 Example: SELECT ST_IsClosed ( ST_GeomFromText ( 'LINESTRING(0 0, 1 1, 1 0)' ))","title":"ST_IsClosed"},{"location":"api/flink/Function/#st_isempty","text":"Introduction: Test if a geometry is empty geometry Format: ST_IsEmpty (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_IsEmpty ( polygondf . countyshape ) FROM polygondf","title":"ST_IsEmpty"},{"location":"api/flink/Function/#st_isring","text":"Introduction: RETURN true if LINESTRING is ST_IsClosed and ST_IsSimple. Format: ST_IsRing(geom: geometry) Since: v1.3.0 Example: SELECT ST_IsRing ( ST_GeomFromText ( \"LINESTRING(0 0, 0 1, 1 1, 1 0, 0 0)\" )) Output: true","title":"ST_IsRing"},{"location":"api/flink/Function/#st_issimple","text":"Introduction: Test if geometry's only self-intersections are at boundary points. Format: ST_IsSimple (A:geometry) Since: v1.3.0 Example: SELECT ST_IsSimple ( polygondf . countyshape ) FROM polygondf","title":"ST_IsSimple"},{"location":"api/flink/Function/#st_isvalid","text":"Introduction: Test if a geometry is well formed Format: ST_IsValid (A:geometry) Since: v1.3.0 Example: SELECT ST_IsValid ( polygondf . countyshape ) FROM polygondf","title":"ST_IsValid"},{"location":"api/flink/Function/#st_length","text":"Introduction: Return the perimeter of A Format: ST_Length (A:geometry) Since: v1.3.0 Example: SELECT ST_Length ( polygondf . countyshape ) FROM polygondf","title":"ST_Length"},{"location":"api/flink/Function/#st_linefrommultipoint","text":"Introduction: Creates a LineString from a MultiPoint geometry. Format: ST_LineFromMultiPoint (A:geometry) Since: v1.3.0 Example: SELECT ST_LineFromMultiPoint ( df . geometry ) AS geom FROM df Input: MULTIPOINT((10 40), (40 30), (20 20), (30 10)) Output: LINESTRING (10 40, 40 30, 20 20, 30 10)","title":"ST_LineFromMultiPoint"},{"location":"api/flink/Function/#st_normalize","text":"Introduction: Returns the input geometry in its normalized form. Format ST_Normalize(geom: geometry) Since: v1.3.0 Example: SELECT ST_AsEWKT ( ST_Normalize ( ST_GeomFromWKT ( 'POLYGON((0 1, 1 1, 1 0, 0 0, 0 1))' ))) AS geom Result: +-----------------------------------+ |geom | +-----------------------------------+ |POLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))| +-----------------------------------+","title":"ST_Normalize"},{"location":"api/flink/Function/#st_npoints","text":"Introduction: Returns the number of points of the geometry Since: v1.3.0 Format: ST_NPoints (A:geometry) Example: SELECT ST_NPoints ( polygondf . countyshape ) FROM polygondf","title":"ST_NPoints"},{"location":"api/flink/Function/#st_ndims","text":"Introduction: Returns the coordinate dimension of the geometry. It supports 2 - (x,y) , 3 - (x,y,z). Currently the geometry serializer in sedona-sql does not support M dimension, 4D geometries with ZM coordinates will have their M coordinates dropped and became 3D geometries. We're working on a new geometry serializer to resolve this issue. Format: ST_NDims(geom: geometry) Since: v1.3.1 Spark SQL example with z co-rodinate: SELECT ST_NDims ( ST_GeomFromEWKT ( 'POINT(1 1 2)' )) Output: 3 Spark SQL example with x,y co-ordinate: SELECT ST_NDims ( ST_GeomFromText ( 'POINT(1 1)' )) Output: 2","title":"ST_NDims"},{"location":"api/flink/Function/#st_numgeometries","text":"Introduction: Returns the number of Geometries. If geometry is a GEOMETRYCOLLECTION (or MULTI*) return the number of geometries, for single geometries will return 1. Format: ST_NumGeometries (A:geometry) Since: v1.3.0 Example: SELECT ST_NumGeometries ( df . geometry ) FROM df","title":"ST_NumGeometries"},{"location":"api/flink/Function/#st_numinteriorrings","text":"Introduction: Returns number of interior rings of polygon geometries. Format: ST_NumInteriorRings(geom: geometry) Since: v1.3.0 Example: SELECT ST_NumInteriorRings ( ST_GeomFromText ( 'POLYGON ((0 0, 0 5, 5 5, 5 0, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1))' )) Output: 1","title":"ST_NumInteriorRings"},{"location":"api/flink/Function/#st_pointn","text":"Introduction: Return the Nth point in a single linestring or circular linestring in the geometry. Negative values are counted backwards from the end of the LineString, so that -1 is the last point. Returns NULL if there is no linestring in the geometry. Format: ST_PointN(A:geometry, B:integer) Since: v1.2.1 Examples: SELECT ST_PointN ( df . geometry , 2 ) FROM df Input: LINESTRING(0 0, 1 2, 2 4, 3 6), 2 Output: POINT (1 2) Input: LINESTRING(0 0, 1 2, 2 4, 3 6), -2 Output: POINT (2 4) Input: CIRCULARSTRING(1 1, 1 2, 2 4, 3 6, 1 2, 1 1), -1 Output: POINT (1 1)","title":"ST_PointN"},{"location":"api/flink/Function/#st_pointonsurface","text":"Introduction: Returns a POINT guaranteed to lie on the surface. Format: ST_PointOnSurface(A:geometry) Since: v1.2.1 Examples: SELECT ST_PointOnSurface ( df . geometry ) FROM df Input: POINT (0 5) Output: POINT (0 5) Input: LINESTRING(0 5, 0 10) Output: POINT (0 5) Input: POLYGON((0 0, 0 5, 5 5, 5 0, 0 0)) Output: POINT (2.5 2.5) Input: LINESTRING(0 5 1, 0 0 1, 0 10 2) Output: POINT Z(0 0 1)","title":"ST_PointOnSurface"},{"location":"api/flink/Function/#st_reverse","text":"Introduction: Return the geometry with vertex order reversed Format: ST_Reverse (A:geometry) Since: v1.2.1 Example: SELECT ST_Reverse ( df . geometry ) AS geom FROM df Input: POLYGON ((-0.5 -0.5, -0.5 0.5, 0.5 0.5, 0.5 -0.5, -0.5 -0.5)) Output: POLYGON ((-0.5 -0.5, 0.5 -0.5, 0.5 0.5, -0.5 0.5, -0.5 -0.5))","title":"ST_Reverse"},{"location":"api/flink/Function/#st_removepoint","text":"Introduction: Return Linestring with removed point at given index, position can be omitted and then last one will be removed. Format: ST_RemovePoint(geom: geometry, position: integer) Format: ST_RemovePoint(geom: geometry) Since: v1.3.0 Example: SELECT ST_RemovePoint ( ST_GeomFromText ( \"LINESTRING(0 0, 1 1, 1 0)\" ), 1 ) Output: LINESTRING(0 0, 1 0)","title":"ST_RemovePoint"},{"location":"api/flink/Function/#st_setpoint","text":"Introduction: Replace Nth point of linestring with given point. Index is 0-based. Negative index are counted backwards, e.g., -1 is last point. Format: ST_SetPoint (linestring: geometry, index: integer, point: geometry) Since: v1.3.0 Example: SELECT ST_SetPoint ( ST_GeomFromText ( 'LINESTRING (0 0, 0 1, 1 1)' ), 2 , ST_GeomFromText ( 'POINT (1 0)' )) AS geom Result: +--------------------------------+ | geom | +--------------------------------+ | LINESTRING (0 0, 0 1, 1 0) | +--------------------------------+","title":"ST_SetPoint"},{"location":"api/flink/Function/#st_setsrid","text":"Introduction: Sets the spatial refence system identifier (SRID) of the geometry. Format: ST_SetSRID (A:geometry, srid: integer) Since: v1.3.0 Example: SELECT ST_SetSRID ( polygondf . countyshape , 3021 ) FROM polygondf","title":"ST_SetSRID"},{"location":"api/flink/Function/#st_srid","text":"Introduction: Return the spatial refence system identifier (SRID) of the geometry. Format: ST_SRID (A:geometry) Since: v1.3.0 Example: SELECT ST_SRID ( polygondf . countyshape ) FROM polygondf","title":"ST_SRID"},{"location":"api/flink/Function/#st_transform","text":"Introduction: Transform the Spatial Reference System / Coordinate Reference System of A, from SourceCRS to TargetCRS For SourceCRS and TargetCRS, WKT format is also available since v1.3.1. Note By default, this function uses lat/lon order. You can use ST_FlipCoordinates to swap X and Y. Note If ST_Transform throws an Exception called \"Bursa wolf parameters required\", you need to disable the error notification in ST_Transform. You can append a boolean value at the end. Format: ST_Transform (A:geometry, SourceCRS:string, TargetCRS:string ,[Optional] DisableError) Since: v1.2.0 Spark SQL example (simple): SELECT ST_Transform ( polygondf . countyshape , 'epsg:4326' , 'epsg:3857' ) FROM polygondf Spark SQL example (with optional parameters): SELECT ST_Transform ( polygondf . countyshape , 'epsg:4326' , 'epsg:3857' , false ) FROM polygondf Note The detailed EPSG information can be searched on EPSG.io .","title":"ST_Transform"},{"location":"api/flink/Function/#st_x","text":"Introduction: Returns X Coordinate of given Point, null otherwise. Format: ST_X(pointA: Point) Since: v1.3.0 Example: SELECT ST_X ( ST_POINT ( 0 . 0 25 . 0 )) Output: 0.0","title":"ST_X"},{"location":"api/flink/Function/#st_xmax","text":"Introduction: Returns the maximum X coordinate of a geometry Format: ST_XMax (A:geometry) Since: v1.2.1 Example: SELECT ST_XMax ( df . geometry ) AS xmax FROM df Input: POLYGON ((-1 -11, 0 10, 1 11, 2 12, -1 -11)) Output: 2","title":"ST_XMax"},{"location":"api/flink/Function/#st_xmin","text":"Introduction: Returns the minimum X coordinate of a geometry Format: ST_XMin (A:geometry) Since: v1.2.1 Example: SELECT ST_XMin ( df . geometry ) AS xmin FROM df Input: POLYGON ((-1 -11, 0 10, 1 11, 2 12, -1 -11)) Output: -1","title":"ST_XMin"},{"location":"api/flink/Function/#st_y","text":"Introduction: Returns Y Coordinate of given Point, null otherwise. Format: ST_Y(pointA: Point) Since: v1.3.0 Example: SELECT ST_Y ( ST_POINT ( 0 . 0 25 . 0 )) Output: 25.0","title":"ST_Y"},{"location":"api/flink/Function/#st_ymax","text":"Introduction: Return the minimum Y coordinate of A Format: ST_YMax (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_YMax ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output : 2","title":"ST_YMax"},{"location":"api/flink/Function/#st_ymin","text":"Introduction: Return the minimum Y coordinate of A Format: ST_Y_Min (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_YMin ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output : 0","title":"ST_YMin"},{"location":"api/flink/Function/#st_z","text":"Introduction: Returns Z Coordinate of given Point, null otherwise. Format: ST_Z(pointA: Point) Since: v1.3.0 Example: SELECT ST_Z ( ST_POINT ( 0 . 0 25 . 0 11 . 0 )) Output: 11.0","title":"ST_Z"},{"location":"api/flink/Function/#st_zmax","text":"Introduction: Returns Z maxima of the given geometry or null if there is no Z coordinate. Format: ST_ZMax(geom: geometry) Since: v1.3.1 Spark SQL example: SELECT ST_ZMax ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output: 1.0","title":"ST_ZMax"},{"location":"api/flink/Function/#st_zmin","text":"Introduction: Returns Z minima of the given geometry or null if there is no Z coordinate. Format: ST_ZMin(geom: geometry) Since: v1.3.1 Spark SQL example: SELECT ST_ZMin ( ST_GeomFromText ( 'LINESTRING(1 3 4, 5 6 7)' )) Output: 4.0","title":"ST_ZMin"},{"location":"api/flink/Overview/","text":"Introduction \u00b6 SedonaSQL supports SQL/MM Part3 Spatial SQL Standard. Please read the programming guide: Sedona with Flink SQL app . Sedona includes SQL operators as follows. Constructor: Construct a Geometry given an input string or coordinates Example: ST_GeomFromWKT (string). Create a Geometry from a WKT String. Function: Execute a function on the given column or columns Example: ST_Distance (A, B). Given two Geometry A and B, return the Euclidean distance of A and B. Aggregator: Return a single aggregated value on the given column Example: ST_Envelope_Aggr (Geometry column). Given a Geometry column, calculate the entire envelope boundary of this column. Predicate: Execute a logic judgement on the given columns and return true or false Example: ST_Contains (A, B). Check if A fully contains B. Return \"True\" if yes, else return \"False\".","title":"Overview"},{"location":"api/flink/Overview/#introduction","text":"SedonaSQL supports SQL/MM Part3 Spatial SQL Standard. Please read the programming guide: Sedona with Flink SQL app . Sedona includes SQL operators as follows. Constructor: Construct a Geometry given an input string or coordinates Example: ST_GeomFromWKT (string). Create a Geometry from a WKT String. Function: Execute a function on the given column or columns Example: ST_Distance (A, B). Given two Geometry A and B, return the Euclidean distance of A and B. Aggregator: Return a single aggregated value on the given column Example: ST_Envelope_Aggr (Geometry column). Given a Geometry column, calculate the entire envelope boundary of this column. Predicate: Execute a logic judgement on the given columns and return true or false Example: ST_Contains (A, B). Check if A fully contains B. Return \"True\" if yes, else return \"False\".","title":"Introduction"},{"location":"api/flink/Predicate/","text":"ST_Contains \u00b6 Introduction: Return true if A fully contains B Format: ST_Contains (A:geometry, B:geometry) Since: v1.2.0 SQL example: SELECT * FROM pointdf WHERE ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark ) ST_Disjoint \u00b6 Introduction: Return true if A and B are disjoint Format: ST_Disjoint (A:geometry, B:geometry) Since: v1.2.1 Spark SQL example: SELECT * FROM pointdf WHERE ST_Disjoinnt ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark ) ST_Intersects \u00b6 Introduction: Return true if A intersects B Format: ST_Intersects (A:geometry, B:geometry) Since: v1.2.0 SQL example: SELECT * FROM pointdf WHERE ST_Intersects ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark ) ST_Within \u00b6 Introduction: Return true if A is within B Format: ST_Within (A:geometry, B:geometry) Since: v1.3.0 SQL example: SELECT * FROM pointdf WHERE ST_Within ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 )) ST_OrderingEquals \u00b6 Introduction: Returns true if the geometries are equal and the coordinates are in the same order Format: ST_OrderingEquals(A: geometry, B: geometry) Since: v1.2.1 SQL example 1: SELECT ST_OrderingEquals ( ST_GeomFromWKT ( 'POLYGON((2 0, 0 2, -2 0, 2 0))' ), ST_GeomFromWKT ( 'POLYGON((2 0, 0 2, -2 0, 2 0))' )) Output: true SQL example 2: SELECT ST_OrderingEquals ( ST_GeomFromWKT ( 'POLYGON((2 0, 0 2, -2 0, 2 0))' ), ST_GeomFromWKT ( 'POLYGON((0 2, -2 0, 2 0, 0 2))' )) Output: false ST_Covers \u00b6 Introduction: Return true if A covers B Format: ST_Covers (A:geometry, B:geometry) Since: v1.3.0 SQL example: SELECT * FROM pointdf WHERE ST_Covers ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark ) ST_CoveredBy \u00b6 Introduction: Return true if A is covered by B Format: ST_CoveredBy (A:geometry, B:geometry) Since: v1.3.0 SQL example: SELECT * FROM pointdf WHERE ST_CoveredBy ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"Predicate"},{"location":"api/flink/Predicate/#st_contains","text":"Introduction: Return true if A fully contains B Format: ST_Contains (A:geometry, B:geometry) Since: v1.2.0 SQL example: SELECT * FROM pointdf WHERE ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark )","title":"ST_Contains"},{"location":"api/flink/Predicate/#st_disjoint","text":"Introduction: Return true if A and B are disjoint Format: ST_Disjoint (A:geometry, B:geometry) Since: v1.2.1 Spark SQL example: SELECT * FROM pointdf WHERE ST_Disjoinnt ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark )","title":"ST_Disjoint"},{"location":"api/flink/Predicate/#st_intersects","text":"Introduction: Return true if A intersects B Format: ST_Intersects (A:geometry, B:geometry) Since: v1.2.0 SQL example: SELECT * FROM pointdf WHERE ST_Intersects ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark )","title":"ST_Intersects"},{"location":"api/flink/Predicate/#st_within","text":"Introduction: Return true if A is within B Format: ST_Within (A:geometry, B:geometry) Since: v1.3.0 SQL example: SELECT * FROM pointdf WHERE ST_Within ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"ST_Within"},{"location":"api/flink/Predicate/#st_orderingequals","text":"Introduction: Returns true if the geometries are equal and the coordinates are in the same order Format: ST_OrderingEquals(A: geometry, B: geometry) Since: v1.2.1 SQL example 1: SELECT ST_OrderingEquals ( ST_GeomFromWKT ( 'POLYGON((2 0, 0 2, -2 0, 2 0))' ), ST_GeomFromWKT ( 'POLYGON((2 0, 0 2, -2 0, 2 0))' )) Output: true SQL example 2: SELECT ST_OrderingEquals ( ST_GeomFromWKT ( 'POLYGON((2 0, 0 2, -2 0, 2 0))' ), ST_GeomFromWKT ( 'POLYGON((0 2, -2 0, 2 0, 0 2))' )) Output: false","title":"ST_OrderingEquals"},{"location":"api/flink/Predicate/#st_covers","text":"Introduction: Return true if A covers B Format: ST_Covers (A:geometry, B:geometry) Since: v1.3.0 SQL example: SELECT * FROM pointdf WHERE ST_Covers ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark )","title":"ST_Covers"},{"location":"api/flink/Predicate/#st_coveredby","text":"Introduction: Return true if A is covered by B Format: ST_CoveredBy (A:geometry, B:geometry) Since: v1.3.0 SQL example: SELECT * FROM pointdf WHERE ST_CoveredBy ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"ST_CoveredBy"},{"location":"api/sql/AggregateFunction/","text":"ST_Envelope_Aggr \u00b6 Introduction: Return the entire envelope boundary of all geometries in A Format: ST_Envelope_Aggr (A:geometryColumn) Since: v1.0.0 Spark SQL example: SELECT ST_Envelope_Aggr ( pointdf . arealandmark ) FROM pointdf ST_Intersection_Aggr \u00b6 Introduction: Return the polygon intersection of all polygons in A Format: ST_Intersection_Aggr (A:geometryColumn) Since: v1.0.0 Spark SQL example: SELECT ST_Intersection_Aggr ( polygondf . polygonshape ) FROM polygondf ST_Union_Aggr \u00b6 Introduction: Return the polygon union of all polygons in A Format: ST_Union_Aggr (A:geometryColumn) Since: v1.0.0 Spark SQL example: SELECT ST_Union_Aggr ( polygondf . polygonshape ) FROM polygondf","title":"Aggregate function"},{"location":"api/sql/AggregateFunction/#st_envelope_aggr","text":"Introduction: Return the entire envelope boundary of all geometries in A Format: ST_Envelope_Aggr (A:geometryColumn) Since: v1.0.0 Spark SQL example: SELECT ST_Envelope_Aggr ( pointdf . arealandmark ) FROM pointdf","title":"ST_Envelope_Aggr"},{"location":"api/sql/AggregateFunction/#st_intersection_aggr","text":"Introduction: Return the polygon intersection of all polygons in A Format: ST_Intersection_Aggr (A:geometryColumn) Since: v1.0.0 Spark SQL example: SELECT ST_Intersection_Aggr ( polygondf . polygonshape ) FROM polygondf","title":"ST_Intersection_Aggr"},{"location":"api/sql/AggregateFunction/#st_union_aggr","text":"Introduction: Return the polygon union of all polygons in A Format: ST_Union_Aggr (A:geometryColumn) Since: v1.0.0 Spark SQL example: SELECT ST_Union_Aggr ( polygondf . polygonshape ) FROM polygondf","title":"ST_Union_Aggr"},{"location":"api/sql/Constructor/","text":"Read ESRI Shapefile \u00b6 Introduction: Construct a DataFrame from a Shapefile Since: v1.0.0 SparkSQL example: var spatialRDD = new SpatialRDD [ Geometry ] spatialRDD . rawSpatialRDD = ShapefileReader . readToGeometryRDD ( sparkSession . sparkContext , shapefileInputLocation ) var rawSpatialDf = Adapter . toDf ( spatialRDD , sparkSession ) rawSpatialDf . createOrReplaceTempView ( \"rawSpatialDf\" ) var spatialDf = sparkSession . sql ( \"\"\" | ST_GeomFromWKT(rddshape), _c1, _c2 | FROM rawSpatialDf \"\"\" . stripMargin ) spatialDf . show () spatialDf . printSchema () Note The file extensions of .shp, .shx, .dbf must be in lowercase. Assume you have a shape file called myShapefile , the file structure should be like this: - shapefile1 - shapefile2 - myshapefile - myshapefile.shp - myshapefile.shx - myshapefile.dbf - myshapefile... - ... Warning Please make sure you use ST_GeomFromWKT to create Geometry type column otherwise that column cannot be used in SedonaSQL. If the file you are reading contains non-ASCII characters you'll need to explicitly set the encoding via sedona.global.charset system property before the call to ShapefileReader.readToGeometryRDD . Example: System . setProperty ( \"sedona.global.charset\" , \"utf8\" ) ST_GeomFromGeoHash \u00b6 Introduction: Create Geometry from geohash string and optional precision Format: ST_GeomFromGeoHash(geohash: string, precision: int) Since: v1.1.1 Spark SQL example: SELECT ST_GeomFromGeoHash ( 's00twy01mt' , 4 ) AS geom result: +--------------------------------------------------------------------------------------------------------------------+ |geom | +--------------------------------------------------------------------------------------------------------------------+ |POLYGON ((0.703125 0.87890625, 0.703125 1.0546875, 1.0546875 1.0546875, 1.0546875 0.87890625, 0.703125 0.87890625)) | +--------------------------------------------------------------------------------------------------------------------+ ST_GeomFromGeoJSON \u00b6 Introduction: Construct a Geometry from GeoJson Format: ST_GeomFromGeoJSON (GeoJson:string) Since: v1.0.0 Spark SQL example: var polygonJsonDf = sparkSession . read . format ( \"csv\" ). option ( \"delimiter\" , \"\\t\" ). option ( \"header\" , \"false\" ). load ( geoJsonGeomInputLocation ) polygonJsonDf . createOrReplaceTempView ( \"polygontable\" ) polygonJsonDf . show () var polygonDf = sparkSession . sql ( \"\"\" | SELECT ST_GeomFromGeoJSON(polygontable._c0) AS countyshape | FROM polygontable \"\"\" . stripMargin ) polygonDf . show () Warning The way that SedonaSQL reads GeoJSON is different from that in SparkSQL ST_GeomFromGML \u00b6 Introduction: Construct a Geometry from GML. Format: ST_GeomFromGML (gml:string) Since: v1.3.0 SQL example: SELECT ST_GeomFromGML ( '<gml:LineString srsName=\"EPSG:4269\"><gml:coordinates>-71.16028,42.258729 -71.160837,42.259112 -71.161143,42.25932</gml:coordinates></gml:LineString>' ) AS geometry ST_GeomFromKML \u00b6 Introduction: Construct a Geometry from KML. Format: ST_GeomFromKML (kml:string) Since: v1.3.0 SQL example: SELECT ST_GeomFromKML ( '<LineString><coordinates>-71.1663,42.2614 -71.1667,42.2616</coordinates></LineString>' ) AS geometry ST_GeomFromText \u00b6 Introduction: Construct a Geometry from Wkt. If srid is not set, it defaults to 0 (unknown). Alias of ST_GeomFromWKT Format: ST_GeomFromText (Wkt:string) ST_GeomFromText (Wkt:string, srid:integer) Since: v1.0.0 The optional srid parameter was added in v1.3.1 Spark SQL example: SELECT ST_GeomFromText ( 'POINT(40.7128 -74.0060)' ) AS geometry ST_GeomFromWKB \u00b6 Introduction: Construct a Geometry from WKB string or Binary Format: ST_GeomFromWKB (Wkb:string) ST_GeomFromWKB (Wkb:binary) Since: v1.0.0 Spark SQL example: SELECT ST_GeomFromWKB ( polygontable . _c0 ) AS polygonshape FROM polygontable ST_GeomFromWKT \u00b6 Introduction: Construct a Geometry from Wkt. If srid is not set, it defaults to 0 (unknown). Format: ST_GeomFromWKT (Wkt:string) ST_GeomFromWKT (Wkt:string, srid:integer) Since: v1.0.0 The optional srid parameter was added in v1.3.1 Spark SQL example: SELECT ST_GeomFromWKT ( polygontable . _c0 ) AS polygonshape FROM polygontable SELECT ST_GeomFromWKT ( 'POINT(40.7128 -74.0060)' ) AS geometry ST_LineFromText \u00b6 Introduction: Construct a Line from Wkt text Format: ST_LineFromText (Wkt:string) Since: v1.2.1 Spark SQL example: SELECT ST_LineFromText ( linetable . _c0 ) AS lineshape FROM linetable SELECT ST_LineFromText ( 'Linestring(1 2, 3 4)' ) AS line ST_LineStringFromText \u00b6 Introduction: Construct a LineString from Text, delimited by Delimiter Format: ST_LineStringFromText (Text:string, Delimiter:char) Since: v1.0.0 Spark SQL example: SELECT ST_LineStringFromText ( linestringtable . _c0 , ',' ) AS linestringshape FROM linestringtable SELECT ST_LineStringFromText ( '-74.0428197,40.6867969,-74.0421975,40.6921336,-74.0508020,40.6912794' , ',' ) AS linestringshape ST_MLineFromText \u00b6 Introduction: Construct a MultiLineString from Wkt. If srid is not set, it defaults to 0 (unknown). Format: ST_MLineFromText (Wkt:string) ST_MLineFromText (Wkt:string, srid:integer) Since: v1.3.1 Spark SQL example: SELECT ST_MLineFromText ( 'MULTILINESTRING((1 2, 3 4), (4 5, 6 7))' ) AS multiLine ; SELECT ST_MLineFromText ( 'MULTILINESTRING((1 2, 3 4), (4 5, 6 7))' , 4269 ) AS multiLine ; ST_MPolyFromText \u00b6 Introduction: Construct a MultiPolygon from Wkt. If srid is not set, it defaults to 0 (unknown). Format: ST_MPolyFromText (Wkt:string) ST_MPolyFromText (Wkt:string, srid:integer) Since: v1.3.1 Spark SQL example: SELECT ST_MPolyFromText ( 'MULTIPOLYGON(((-70.916 42.1002,-70.9468 42.0946,-70.9765 42.0872 )))' ) AS multiPolygon SELECT ST_MPolyFromText ( 'MULTIPOLYGON(((-70.916 42.1002,-70.9468 42.0946,-70.9765 42.0872 )))' , 4269 ) AS multiPolygon ST_Point \u00b6 Introduction: Construct a Point from X and Y Format: ST_Point (X:decimal, Y:decimal) Format: ST_Point (X:decimal, Y:decimal, Z:decimal) Since: v1.0.0 Spark SQL example: SELECT ST_Point ( CAST ( pointtable . _c0 AS Decimal ( 24 , 20 )), CAST ( pointtable . _c1 AS Decimal ( 24 , 20 ))) AS pointshape FROM pointtable ST_PointFromText \u00b6 Introduction: Construct a Point from Text, delimited by Delimiter Format: ST_PointFromText (Text:string, Delimiter:char) Since: v1.0.0 Spark SQL example: SELECT ST_PointFromText ( pointtable . _c0 , ',' ) AS pointshape FROM pointtable SELECT ST_PointFromText ( '40.7128,-74.0060' , ',' ) AS pointshape ST_PolygonFromEnvelope \u00b6 Introduction: Construct a Polygon from MinX, MinY, MaxX, MaxY. Format: ST_PolygonFromEnvelope (MinX:decimal, MinY:decimal, MaxX:decimal, MaxY:decimal) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . pointshape ) ST_PolygonFromText \u00b6 Introduction: Construct a Polygon from Text, delimited by Delimiter. Path must be closed Format: ST_PolygonFromText (Text:string, Delimiter:char) Since: v1.0.0 Spark SQL example: SELECT ST_PolygonFromText ( polygontable . _c0 , ',' ) AS polygonshape FROM polygontable SELECT ST_PolygonFromText ( '-74.0428197,40.6867969,-74.0421975,40.6921336,-74.0508020,40.6912794,-74.0428197,40.6867969' , ',' ) AS polygonshape","title":"Constructor"},{"location":"api/sql/Constructor/#read-esri-shapefile","text":"Introduction: Construct a DataFrame from a Shapefile Since: v1.0.0 SparkSQL example: var spatialRDD = new SpatialRDD [ Geometry ] spatialRDD . rawSpatialRDD = ShapefileReader . readToGeometryRDD ( sparkSession . sparkContext , shapefileInputLocation ) var rawSpatialDf = Adapter . toDf ( spatialRDD , sparkSession ) rawSpatialDf . createOrReplaceTempView ( \"rawSpatialDf\" ) var spatialDf = sparkSession . sql ( \"\"\" | ST_GeomFromWKT(rddshape), _c1, _c2 | FROM rawSpatialDf \"\"\" . stripMargin ) spatialDf . show () spatialDf . printSchema () Note The file extensions of .shp, .shx, .dbf must be in lowercase. Assume you have a shape file called myShapefile , the file structure should be like this: - shapefile1 - shapefile2 - myshapefile - myshapefile.shp - myshapefile.shx - myshapefile.dbf - myshapefile... - ... Warning Please make sure you use ST_GeomFromWKT to create Geometry type column otherwise that column cannot be used in SedonaSQL. If the file you are reading contains non-ASCII characters you'll need to explicitly set the encoding via sedona.global.charset system property before the call to ShapefileReader.readToGeometryRDD . Example: System . setProperty ( \"sedona.global.charset\" , \"utf8\" )","title":"Read ESRI Shapefile"},{"location":"api/sql/Constructor/#st_geomfromgeohash","text":"Introduction: Create Geometry from geohash string and optional precision Format: ST_GeomFromGeoHash(geohash: string, precision: int) Since: v1.1.1 Spark SQL example: SELECT ST_GeomFromGeoHash ( 's00twy01mt' , 4 ) AS geom result: +--------------------------------------------------------------------------------------------------------------------+ |geom | +--------------------------------------------------------------------------------------------------------------------+ |POLYGON ((0.703125 0.87890625, 0.703125 1.0546875, 1.0546875 1.0546875, 1.0546875 0.87890625, 0.703125 0.87890625)) | +--------------------------------------------------------------------------------------------------------------------+","title":"ST_GeomFromGeoHash"},{"location":"api/sql/Constructor/#st_geomfromgeojson","text":"Introduction: Construct a Geometry from GeoJson Format: ST_GeomFromGeoJSON (GeoJson:string) Since: v1.0.0 Spark SQL example: var polygonJsonDf = sparkSession . read . format ( \"csv\" ). option ( \"delimiter\" , \"\\t\" ). option ( \"header\" , \"false\" ). load ( geoJsonGeomInputLocation ) polygonJsonDf . createOrReplaceTempView ( \"polygontable\" ) polygonJsonDf . show () var polygonDf = sparkSession . sql ( \"\"\" | SELECT ST_GeomFromGeoJSON(polygontable._c0) AS countyshape | FROM polygontable \"\"\" . stripMargin ) polygonDf . show () Warning The way that SedonaSQL reads GeoJSON is different from that in SparkSQL","title":"ST_GeomFromGeoJSON"},{"location":"api/sql/Constructor/#st_geomfromgml","text":"Introduction: Construct a Geometry from GML. Format: ST_GeomFromGML (gml:string) Since: v1.3.0 SQL example: SELECT ST_GeomFromGML ( '<gml:LineString srsName=\"EPSG:4269\"><gml:coordinates>-71.16028,42.258729 -71.160837,42.259112 -71.161143,42.25932</gml:coordinates></gml:LineString>' ) AS geometry","title":"ST_GeomFromGML"},{"location":"api/sql/Constructor/#st_geomfromkml","text":"Introduction: Construct a Geometry from KML. Format: ST_GeomFromKML (kml:string) Since: v1.3.0 SQL example: SELECT ST_GeomFromKML ( '<LineString><coordinates>-71.1663,42.2614 -71.1667,42.2616</coordinates></LineString>' ) AS geometry","title":"ST_GeomFromKML"},{"location":"api/sql/Constructor/#st_geomfromtext","text":"Introduction: Construct a Geometry from Wkt. If srid is not set, it defaults to 0 (unknown). Alias of ST_GeomFromWKT Format: ST_GeomFromText (Wkt:string) ST_GeomFromText (Wkt:string, srid:integer) Since: v1.0.0 The optional srid parameter was added in v1.3.1 Spark SQL example: SELECT ST_GeomFromText ( 'POINT(40.7128 -74.0060)' ) AS geometry","title":"ST_GeomFromText"},{"location":"api/sql/Constructor/#st_geomfromwkb","text":"Introduction: Construct a Geometry from WKB string or Binary Format: ST_GeomFromWKB (Wkb:string) ST_GeomFromWKB (Wkb:binary) Since: v1.0.0 Spark SQL example: SELECT ST_GeomFromWKB ( polygontable . _c0 ) AS polygonshape FROM polygontable","title":"ST_GeomFromWKB"},{"location":"api/sql/Constructor/#st_geomfromwkt","text":"Introduction: Construct a Geometry from Wkt. If srid is not set, it defaults to 0 (unknown). Format: ST_GeomFromWKT (Wkt:string) ST_GeomFromWKT (Wkt:string, srid:integer) Since: v1.0.0 The optional srid parameter was added in v1.3.1 Spark SQL example: SELECT ST_GeomFromWKT ( polygontable . _c0 ) AS polygonshape FROM polygontable SELECT ST_GeomFromWKT ( 'POINT(40.7128 -74.0060)' ) AS geometry","title":"ST_GeomFromWKT"},{"location":"api/sql/Constructor/#st_linefromtext","text":"Introduction: Construct a Line from Wkt text Format: ST_LineFromText (Wkt:string) Since: v1.2.1 Spark SQL example: SELECT ST_LineFromText ( linetable . _c0 ) AS lineshape FROM linetable SELECT ST_LineFromText ( 'Linestring(1 2, 3 4)' ) AS line","title":"ST_LineFromText"},{"location":"api/sql/Constructor/#st_linestringfromtext","text":"Introduction: Construct a LineString from Text, delimited by Delimiter Format: ST_LineStringFromText (Text:string, Delimiter:char) Since: v1.0.0 Spark SQL example: SELECT ST_LineStringFromText ( linestringtable . _c0 , ',' ) AS linestringshape FROM linestringtable SELECT ST_LineStringFromText ( '-74.0428197,40.6867969,-74.0421975,40.6921336,-74.0508020,40.6912794' , ',' ) AS linestringshape","title":"ST_LineStringFromText"},{"location":"api/sql/Constructor/#st_mlinefromtext","text":"Introduction: Construct a MultiLineString from Wkt. If srid is not set, it defaults to 0 (unknown). Format: ST_MLineFromText (Wkt:string) ST_MLineFromText (Wkt:string, srid:integer) Since: v1.3.1 Spark SQL example: SELECT ST_MLineFromText ( 'MULTILINESTRING((1 2, 3 4), (4 5, 6 7))' ) AS multiLine ; SELECT ST_MLineFromText ( 'MULTILINESTRING((1 2, 3 4), (4 5, 6 7))' , 4269 ) AS multiLine ;","title":"ST_MLineFromText"},{"location":"api/sql/Constructor/#st_mpolyfromtext","text":"Introduction: Construct a MultiPolygon from Wkt. If srid is not set, it defaults to 0 (unknown). Format: ST_MPolyFromText (Wkt:string) ST_MPolyFromText (Wkt:string, srid:integer) Since: v1.3.1 Spark SQL example: SELECT ST_MPolyFromText ( 'MULTIPOLYGON(((-70.916 42.1002,-70.9468 42.0946,-70.9765 42.0872 )))' ) AS multiPolygon SELECT ST_MPolyFromText ( 'MULTIPOLYGON(((-70.916 42.1002,-70.9468 42.0946,-70.9765 42.0872 )))' , 4269 ) AS multiPolygon","title":"ST_MPolyFromText"},{"location":"api/sql/Constructor/#st_point","text":"Introduction: Construct a Point from X and Y Format: ST_Point (X:decimal, Y:decimal) Format: ST_Point (X:decimal, Y:decimal, Z:decimal) Since: v1.0.0 Spark SQL example: SELECT ST_Point ( CAST ( pointtable . _c0 AS Decimal ( 24 , 20 )), CAST ( pointtable . _c1 AS Decimal ( 24 , 20 ))) AS pointshape FROM pointtable","title":"ST_Point"},{"location":"api/sql/Constructor/#st_pointfromtext","text":"Introduction: Construct a Point from Text, delimited by Delimiter Format: ST_PointFromText (Text:string, Delimiter:char) Since: v1.0.0 Spark SQL example: SELECT ST_PointFromText ( pointtable . _c0 , ',' ) AS pointshape FROM pointtable SELECT ST_PointFromText ( '40.7128,-74.0060' , ',' ) AS pointshape","title":"ST_PointFromText"},{"location":"api/sql/Constructor/#st_polygonfromenvelope","text":"Introduction: Construct a Polygon from MinX, MinY, MaxX, MaxY. Format: ST_PolygonFromEnvelope (MinX:decimal, MinY:decimal, MaxX:decimal, MaxY:decimal) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . pointshape )","title":"ST_PolygonFromEnvelope"},{"location":"api/sql/Constructor/#st_polygonfromtext","text":"Introduction: Construct a Polygon from Text, delimited by Delimiter. Path must be closed Format: ST_PolygonFromText (Text:string, Delimiter:char) Since: v1.0.0 Spark SQL example: SELECT ST_PolygonFromText ( polygontable . _c0 , ',' ) AS polygonshape FROM polygontable SELECT ST_PolygonFromText ( '-74.0428197,40.6867969,-74.0421975,40.6921336,-74.0508020,40.6912794,-74.0428197,40.6867969' , ',' ) AS polygonshape","title":"ST_PolygonFromText"},{"location":"api/sql/Function/","text":"ST_3DDistance \u00b6 Introduction: Return the 3-dimensional minimum cartesian distance between A and B Format: ST_3DDistance (A:geometry, B:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_3DDistance ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf ST_AddPoint \u00b6 Introduction: RETURN Linestring with additional point at the given index, if position is not available the point will be added at the end of line. Format: ST_AddPoint(geom: geometry, point: geometry, position: integer) Format: ST_AddPoint(geom: geometry, point: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_AddPoint ( ST_GeomFromText ( \"LINESTRING(0 0, 1 1, 1 0)\" ), ST_GeomFromText ( \"Point(21 52)\" ), 1 ) SELECT ST_AddPoint ( ST_GeomFromText ( \"Linestring(0 0, 1 1, 1 0)\" ), ST_GeomFromText ( \"Point(21 52)\" )) Output: LINESTRING(0 0, 21 52, 1 1, 1 0) LINESTRING(0 0, 1 1, 1 0, 21 52) ST_Area \u00b6 Introduction: Return the area of A Format: ST_Area (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Area ( polygondf . countyshape ) FROM polygondf ST_AsBinary \u00b6 Introduction: Return the Well-Known Binary representation of a geometry Format: ST_AsBinary (A:geometry) Since: v1.1.1 Spark SQL example: SELECT ST_AsBinary ( polygondf . countyshape ) FROM polygondf ST_AsEWKB \u00b6 Introduction: Return the Extended Well-Known Binary representation of a geometry. EWKB is an extended version of WKB which includes the SRID of the geometry. The format originated in PostGIS but is supported by many GIS tools. If the geometry is lacking SRID a WKB format is produced. Se ST_SetSRID Format: ST_AsEWKB (A:geometry) Since: v1.1.1 Spark SQL example: SELECT ST_AsEWKB ( polygondf . countyshape ) FROM polygondf ST_AsEWKT \u00b6 Introduction: Return the Extended Well-Known Text representation of a geometry. EWKT is an extended version of WKT which includes the SRID of the geometry. The format originated in PostGIS but is supported by many GIS tools. If the geometry is lacking SRID a WKT format is produced. See ST_SetSRID Format: ST_AsEWKT (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_AsEWKT ( polygondf . countyshape ) FROM polygondf ST_AsGeoJSON \u00b6 Introduction: Return the GeoJSON string representation of a geometry Format: ST_AsGeoJSON (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_AsGeoJSON ( polygondf . countyshape ) FROM polygondf ST_AsGML \u00b6 Introduction: Return the GML string representation of a geometry Format: ST_AsGML (A:geometry) Since: v1.3.0 Spark SQL example: SELECT ST_AsGML ( polygondf . countyshape ) FROM polygondf ST_AsKML \u00b6 Introduction: Return the KML string representation of a geometry Format: ST_AsKML (A:geometry) Since: v1.3.0 Spark SQL example: SELECT ST_AsKML ( polygondf . countyshape ) FROM polygondf ST_AsText \u00b6 Introduction: Return the Well-Known Text string representation of a geometry Format: ST_AsText (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_AsText ( polygondf . countyshape ) FROM polygondf ST_Azimuth \u00b6 Introduction: Returns Azimuth for two given points in radians null otherwise. Format: ST_Azimuth(pointA: Point, pointB: Point) Since: v1.0.0 Spark SQL example: SELECT ST_Azimuth ( ST_POINT ( 0 . 0 , 25 . 0 ), ST_POINT ( 0 . 0 , 0 . 0 )) Output: 3.141592653589793 ST_Boundary \u00b6 Introduction: Returns the closure of the combinatorial boundary of this Geometry. Format: ST_Boundary(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Boundary ( ST_GeomFromText ( 'POLYGON((1 1,0 0, -1 1, 1 1))' )) Output: LINESTRING (1 1, 0 0, -1 1, 1 1) ST_Buffer \u00b6 Introduction: Returns a geometry/geography that represents all points whose distance from this Geometry/geography is less than or equal to distance. Format: ST_Buffer (A:geometry, buffer: Double) Since: v1.0.0 Spark SQL example: SELECT ST_Buffer ( polygondf . countyshape , 1 ) FROM polygondf ST_BuildArea \u00b6 Introduction: Returns the areal geometry formed by the constituent linework of the input geometry. Format: ST_BuildArea (A:geometry) Since: v1.2.1 Example: SELECT ST_BuildArea ( ST_GeomFromText ( 'MULTILINESTRING((0 0, 20 0, 20 20, 0 20, 0 0),(2 2, 18 2, 18 18, 2 18, 2 2))' ) ) AS geom Result: +----------------------------------------------------------------------------+ |geom | +----------------------------------------------------------------------------+ |POLYGON((0 0,0 20,20 20,20 0,0 0),(2 2,18 2,18 18,2 18,2 2)) | +----------------------------------------------------------------------------+ ST_Centroid \u00b6 Introduction: Return the centroid point of A Format: ST_Centroid (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Centroid ( polygondf . countyshape ) FROM polygondf ST_Collect \u00b6 Introduction: Returns MultiGeometry object based on geometry column/s or array with geometries Format ST_Collect(*geom: geometry) ST_Collect(geom: array<geometry>) Since: v1.2.0 Example: SELECT ST_Collect ( ST_GeomFromText ( 'POINT(21.427834 52.042576573)' ), ST_GeomFromText ( 'POINT(45.342524 56.342354355)' ) ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |MULTIPOINT ((21.427834 52.042576573), (45.342524 56.342354355))| +---------------------------------------------------------------+ Example: SELECT ST_Collect ( Array ( ST_GeomFromText ( 'POINT(21.427834 52.042576573)' ), ST_GeomFromText ( 'POINT(45.342524 56.342354355)' ) ) ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |MULTIPOINT ((21.427834 52.042576573), (45.342524 56.342354355))| +---------------------------------------------------------------+ ST_CollectionExtract \u00b6 Introduction: Returns a homogeneous multi-geometry from a given geometry collection. The type numbers are: 1. POINT 2. LINESTRING 3. POLYGON If the type parameter is omitted a multi-geometry of the highest dimension is returned. Format: ST_CollectionExtract (A:geometry) Format: ST_CollectionExtract (A:geometry, type:Int) Since: v1.2.1 Example: WITH test_data as ( ST_GeomFromText ( 'GEOMETRYCOLLECTION(POINT(40 10), POLYGON((0 0, 0 5, 5 5, 5 0, 0 0)))' ) as geom ) SELECT ST_CollectionExtract ( geom ) as c1 , ST_CollectionExtract ( geom , 1 ) as c2 FROM test_data Result: +----------------------------------------------------------------------------+ |c1 |c2 | +----------------------------------------------------------------------------+ |MULTIPOLYGON(((0 0, 0 5, 5 5, 5 0, 0 0))) |MULTIPOINT(40 10) | | +----------------------------------------------------------------------------+ ST_ConvexHull \u00b6 Introduction: Return the Convex Hull of polgyon A Format: ST_ConvexHull (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_ConvexHull ( polygondf . countyshape ) FROM polygondf ST_Difference \u00b6 Introduction: Return the difference between geometry A and B (return part of geometry A that does not intersect geometry B) Format: ST_Difference (A:geometry, B:geometry) Since: v1.2.0 Example: SELECT ST_Difference ( ST_GeomFromWKT ( 'POLYGON ((-3 -3, 3 -3, 3 3, -3 3, -3 -3))' ), ST_GeomFromWKT ( 'POLYGON ((0 -4, 4 -4, 4 4, 0 4, 0 -4))' )) Result: POLYGON ((0 -3, -3 -3, -3 3, 0 3, 0 -3)) ST_Distance \u00b6 Introduction: Return the Euclidean distance between A and B Format: ST_Distance (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Distance ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf ST_Dump \u00b6 Introduction: It expands the geometries. If the geometry is simple (Point, Polygon Linestring etc.) it returns the geometry itself, if the geometry is collection or multi it returns record for each of collection components. Format: ST_Dump(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Dump ( ST_GeomFromText ( 'MULTIPOINT ((10 40), (40 30), (20 20), (30 10))' )) Output: [POINT (10 40), POINT (40 30), POINT (20 20), POINT (30 10)] ST_DumpPoints \u00b6 Introduction: Returns list of Points which geometry consists of. Format: ST_DumpPoints(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_DumpPoints ( ST_GeomFromText ( 'LINESTRING (0 0, 1 1, 1 0)' )) Output: [POINT (0 0), POINT (0 1), POINT (1 1), POINT (1 0), POINT (0 0)] ST_EndPoint \u00b6 Introduction: Returns last point of given linestring. Format: ST_EndPoint(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_EndPoint ( ST_GeomFromText ( 'LINESTRING(100 150,50 60, 70 80, 160 170)' )) Output: POINT(160 170) ST_Envelope \u00b6 Introduction: Return the envelop boundary of A Format: ST_Envelope (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Envelope ( polygondf . countyshape ) FROM polygondf ST_ExteriorRing \u00b6 Introduction: Returns a line string representing the exterior ring of the POLYGON geometry. Return NULL if the geometry is not a polygon. Format: ST_ExteriorRing(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_ExteriorRing ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output: LINESTRING (0 0, 1 1, 1 2, 1 1, 0 0) ST_FlipCoordinates \u00b6 Introduction: Returns a version of the given geometry with X and Y axis flipped. Format: ST_FlipCoordinates(A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_FlipCoordinates ( df . geometry ) FROM df Input: POINT (1 2) Output: POINT (2 1) ST_Force_2D \u00b6 Introduction: Forces the geometries into a \"2-dimensional mode\" so that all output representations will only have the X and Y coordinates Format: ST_Force_2D (A:geometry) Since: v1.2.1 Example: SELECT ST_AsText ( ST_Force_2D ( ST_GeomFromText ( 'POLYGON((0 0 2,0 5 2,5 0 2,0 0 2),(1 1 2,3 1 2,1 3 2,1 1 2))' )) ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |POLYGON((0 0,0 5,5 0,0 0),(1 1,3 1,1 3,1 1)) | +---------------------------------------------------------------+ ST_GeoHash \u00b6 Introduction: Returns GeoHash of the geometry with given precision Format: ST_GeoHash(geom: geometry, precision: int) Since: v1.1.1 Example: Query: SELECT ST_GeoHash ( ST_GeomFromText ( 'POINT(21.427834 52.042576573)' ), 5 ) AS geohash Result: +-----------------------------+ |geohash | +-----------------------------+ |u3r0p | +-----------------------------+ ST_GeometryN \u00b6 Introduction: Return the 0-based Nth geometry if the geometry is a GEOMETRYCOLLECTION, (MULTI)POINT, (MULTI)LINESTRING, MULTICURVE or (MULTI)POLYGON. Otherwise, return null Format: ST_GeometryN(geom: geometry, n: Int) Since: v1.0.0 Spark SQL example: SELECT ST_GeometryN ( ST_GeomFromText ( 'MULTIPOINT((1 2), (3 4), (5 6), (8 9))' ), 1 ) Output: POINT (3 4) ST_GeometryType \u00b6 Introduction: Returns the type of the geometry as a string. EG: 'ST_Linestring', 'ST_Polygon' etc. Format: ST_GeometryType (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_GeometryType ( polygondf . countyshape ) FROM polygondf ST_InteriorRingN \u00b6 Introduction: Returns the Nth interior linestring ring of the polygon geometry. Returns NULL if the geometry is not a polygon or the given N is out of range Format: ST_InteriorRingN(geom: geometry, n: Int) Since: v1.0.0 Spark SQL example: SELECT ST_InteriorRingN ( ST_GeomFromText ( 'POLYGON((0 0, 0 5, 5 5, 5 0, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1), (1 3, 2 3, 2 4, 1 4, 1 3), (3 3, 4 3, 4 4, 3 4, 3 3))' ), 0 ) Output: LINESTRING (1 1, 2 1, 2 2, 1 2, 1 1) ST_Intersection \u00b6 Introduction: Return the intersection geometry of A and B Format: ST_Intersection (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Intersection ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf ST_IsClosed \u00b6 Introduction: RETURNS true if the LINESTRING start and end point are the same. Format: ST_IsClosed(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_IsClosed ( ST_GeomFromText ( 'LINESTRING(0 0, 1 1, 1 0)' )) Output: false ST_IsEmpty \u00b6 Introduction: Test if a geometry is empty geometry Format: ST_IsEmpty (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_IsEmpty ( polygondf . countyshape ) FROM polygondf ST_IsRing \u00b6 Introduction: RETURN true if LINESTRING is ST_IsClosed and ST_IsSimple. Format: ST_IsRing(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_IsRing ( ST_GeomFromText ( \"LINESTRING(0 0, 0 1, 1 1, 1 0, 0 0)\" )) Output: true ST_IsSimple \u00b6 Introduction: Test if geometry's only self-intersections are at boundary points. Format: ST_IsSimple (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_IsSimple ( polygondf . countyshape ) FROM polygondf ST_IsValid \u00b6 Introduction: Test if a geometry is well formed Format: ST_IsValid (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_IsValid ( polygondf . countyshape ) FROM polygondf ST_Length \u00b6 Introduction: Return the perimeter of A Format: ST_Length (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Length ( polygondf . countyshape ) FROM polygondf ST_LineFromMultiPoint \u00b6 Introduction: Creates a LineString from a MultiPoint geometry. Format: ST_LineFromMultiPoint (A:geometry) Since: v1.3.0 Example: SELECT ST_AsText ( ST_LineFromMultiPoint ( ST_GeomFromText ( 'MULTIPOINT((10 40), (40 30), (20 20), (30 10))' )) ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |LINESTRING (10 40, 40 30, 20 20, 30 10) | +---------------------------------------------------------------+ ST_LineInterpolatePoint \u00b6 Introduction: Returns a point interpolated along a line. First argument must be a LINESTRING. Second argument is a Double between 0 and 1 representing fraction of total linestring length the point has to be located. Format: ST_LineInterpolatePoint (geom: geometry, fraction: Double) Since: v1.0.1 Spark SQL example: SELECT ST_LineInterpolatePoint ( ST_GeomFromWKT ( 'LINESTRING(25 50, 100 125, 150 190)' ), 0 . 2 ) as Interpolated Output: +-----------------------------------------+ |Interpolated | +-----------------------------------------+ |POINT (51.5974135047432 76.5974135047432)| +-----------------------------------------+ ST_LineMerge \u00b6 Introduction: Returns a LineString formed by sewing together the constituent line work of a MULTILINESTRING. Note Only works for MULTILINESTRING. Using other geometry will return a GEOMETRYCOLLECTION EMPTY. If the MultiLineString can't be merged, the original MULTILINESTRING is returned. Format: ST_LineMerge (A:geometry) Since: v1.0.0 SELECT ST_LineMerge ( geometry ) FROM df ST_LineSubstring \u00b6 Introduction: Return a linestring being a substring of the input one starting and ending at the given fractions of total 2d length. Second and third arguments are Double values between 0 and 1. This only works with LINESTRINGs. Format: ST_LineSubstring (geom: geometry, startfraction: Double, endfraction: Double) Since: v1.0.1 Spark SQL example: SELECT ST_LineSubstring ( ST_GeomFromWKT ( 'LINESTRING(25 50, 100 125, 150 190)' ), 0 . 333 , 0 . 666 ) as Substring Output: +------------------------------------------------------------------------------------------------+ |Substring | +------------------------------------------------------------------------------------------------+ |LINESTRING (69.28469348539744 94.28469348539744, 100 125, 111.70035626068274 140.21046313888758)| +------------------------------------------------------------------------------------------------+ ST_MakePolygon \u00b6 Introduction: Function to convert closed linestring to polygon including holes Format: ST_MakePolygon(geom: geometry, holes: array<geometry>) Since: v1.1.0 Example: Query: SELECT ST_MakePolygon ( ST_GeomFromText ( 'LINESTRING(7 -1, 7 6, 9 6, 9 1, 7 -1)' ), ARRAY ( ST_GeomFromText ( 'LINESTRING(6 2, 8 2, 8 1, 6 1, 6 2)' )) ) AS polygon Result: +----------------------------------------------------------------+ |polygon | +----------------------------------------------------------------+ |POLYGON ((7 -1, 7 6, 9 6, 9 1, 7 -1), (6 2, 8 2, 8 1, 6 1, 6 2))| +----------------------------------------------------------------+ ST_MakeValid \u00b6 Introduction: Given an invalid geometry, create a valid representation of the geometry. Collapsed geometries are either converted to empty (keepCollaped=true) or a valid geometry of lower dimension (keepCollapsed=false). Default is keepCollapsed=false. Format: ST_MakeValid (A:geometry) Format: ST_MakeValid (A:geometry, keepCollapsed:Boolean) Since: v1.0.0 Spark SQL example: WITH linestring AS ( SELECT ST_GeomFromWKT ( 'LINESTRING(1 1, 1 1)' ) AS geom ) SELECT ST_MakeValid ( geom ), ST_MakeValid ( geom , true ) FROM linestring Result: +------------------+------------------------+ |st_makevalid(geom)|st_makevalid(geom, true)| +------------------+------------------------+ | LINESTRING EMPTY| POINT (1 1)| +------------------+------------------------+ Note In Sedona up to and including version 1.2 the behaviour of ST_MakeValid was different. Be sure to check you code when upgrading. The previous implementation only worked for (multi)polygons and had a different interpretation of the second, boolean, argument. It would also sometimes return multiple geometries for a single geomtry input. ST_MinimumBoundingCircle \u00b6 Introduction: Returns the smallest circle polygon that contains a geometry. Format: ST_MinimumBoundingCircle(geom: geometry, [Optional] quadrantSegments:int) Since: v1.0.1 Spark SQL example: SELECT ST_MinimumBoundingCircle ( ST_GeomFromText ( 'POLYGON((1 1,0 0, -1 1, 1 1))' )) ST_MinimumBoundingRadius \u00b6 Introduction: Returns a struct containing the center point and radius of the smallest circle that contains a geometry. Format: ST_MinimumBoundingRadius(geom: geometry) Since: v1.0.1 Spark SQL example: SELECT ST_MinimumBoundingRadius ( ST_GeomFromText ( 'POLYGON((1 1,0 0, -1 1, 1 1))' )) ST_Multi \u00b6 Introduction: Returns a MultiGeometry object based on the geometry input. ST_Multi is basically an alias for ST_Collect with one geometry. Format ST_Multi(geom: geometry) Since: v1.2.0 Example: SELECT ST_Multi ( ST_GeomFromText ( 'POINT(1 1)' ) ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |MULTIPOINT (1 1) | +---------------------------------------------------------------+ ST_NDims \u00b6 Introduction: Returns the coordinate dimension of the geometry. It supports 2 - (x,y) , 3 - (x,y,z). Currently the geometry serializer in sedona-sql does not support M dimension, 4D geometries with ZM coordinates will have their M coordinates dropped and became 3D geometries. We're working on a new geometry serializer to resolve this issue. Format: ST_NDims(geom: geometry) Since: v1.3.1 Spark SQL example with z co-rodinate: SELECT ST_NDims ( ST_GeomFromEWKT ( 'POINT(1 1 2)' )) Output: 3 Spark SQL example with x,y co-ordinate: SELECT ST_NDims ( ST_GeomFromText ( 'POINT(1 1)' )) Output: 2 ST_Normalize \u00b6 Introduction: Returns the input geometry in its normalized form. Format ST_Normalize(geom: geometry) Since: v1.3.0 Example: SELECT ST_AsEWKT ( ST_Normalize ( ST_GeomFromWKT ( 'POLYGON((0 1, 1 1, 1 0, 0 0, 0 1))' ))) AS geom Result: +-----------------------------------+ |geom | +-----------------------------------+ |POLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))| +-----------------------------------+ ST_NPoints \u00b6 Introduction: Return points of the geometry Since: v1.0.0 Format: ST_NPoints (A:geometry) SELECT ST_NPoints ( polygondf . countyshape ) FROM polygondf ST_NumGeometries \u00b6 Introduction: Returns the number of Geometries. If geometry is a GEOMETRYCOLLECTION (or MULTI*) return the number of geometries, for single geometries will return 1. Format: ST_NumGeometries (A:geometry) Since: v1.0.0 SELECT ST_NumGeometries ( df . geometry ) FROM df ST_NumInteriorRings \u00b6 Introduction: RETURNS number of interior rings of polygon geometries. Format: ST_NumInteriorRings(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_NumInteriorRings ( ST_GeomFromText ( 'POLYGON ((0 0, 0 5, 5 5, 5 0, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1))' )) Output: 1 ST_PointN \u00b6 Introduction: Return the Nth point in a single linestring or circular linestring in the geometry. Negative values are counted backwards from the end of the LineString, so that -1 is the last point. Returns NULL if there is no linestring in the geometry. Format: ST_PointN(geom: geometry, n: integer) Since: v1.2.1 Spark SQL example: SELECT ST_PointN ( ST_GeomFromText ( \"LINESTRING(0 0, 1 2, 2 4, 3 6)\" ), 2 ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |POINT (1 2) | +---------------------------------------------------------------+ ST_PointOnSurface \u00b6 Introduction: Returns a POINT guaranteed to lie on the surface. Format: ST_PointOnSurface(A:geometry) Since: v1.2.1 Examples: SELECT ST_AsText(ST_PointOnSurface(ST_GeomFromText('POINT(0 5)'))); st_astext ------------ POINT(0 5) SELECT ST_AsText(ST_PointOnSurface(ST_GeomFromText('LINESTRING(0 5, 0 10)'))); st_astext ------------ POINT(0 5) SELECT ST_AsText(ST_PointOnSurface(ST_GeomFromText('POLYGON((0 0, 0 5, 5 5, 5 0, 0 0))'))); st_astext ---------------- POINT(2.5 2.5) SELECT ST_AsText(ST_PointOnSurface(ST_GeomFromText('LINESTRING(0 5 1, 0 0 1, 0 10 2)'))); st_astext ---------------- POINT Z(0 0 1) ST_PrecisionReduce \u00b6 Introduction: Reduce the decimals places in the coordinates of the geometry to the given number of decimal places. The last decimal place will be rounded. Format: ST_PrecisionReduce (A:geometry, B:int) Since: v1.0.0 Spark SQL example: SELECT ST_PrecisionReduce ( polygondf . countyshape , 9 ) FROM polygondf The new coordinates will only have 9 decimal places. ST_RemovePoint \u00b6 Introduction: RETURN Line with removed point at given index, position can be omitted and then last one will be removed. Format: ST_RemovePoint(geom: geometry, position: integer) Format: ST_RemovePoint(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_RemovePoint ( ST_GeomFromText ( \"LINESTRING(0 0, 1 1, 1 0)\" ), 1 ) Output: LINESTRING(0 0, 1 0) ST_Reverse \u00b6 Introduction: Return the geometry with vertex order reversed Format: ST_Reverse (A:geometry) Since: v1.2.1 Example: SELECT ST_AsText ( ST_Reverse ( ST_GeomFromText ( 'LINESTRING(0 0, 1 2, 2 4, 3 6)' )) ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |LINESTRING (3 6, 2 4, 1 2, 0 0) | +---------------------------------------------------------------+ ST_SetPoint \u00b6 Introduction: Replace Nth point of linestring with given point. Index is 0-based. Negative index are counted backwards, e.g., -1 is last point. Format: ST_SetPoint (linestring: geometry, index: integer, point: geometry) Since: v1.3.0 Example: SELECT ST_SetPoint ( ST_GeomFromText ( 'LINESTRING (0 0, 0 1, 1 1)' ), 2 , ST_GeomFromText ( 'POINT (1 0)' )) AS geom Result: +--------------------------+ |geom | +--------------------------+ |LINESTRING (0 0, 0 1, 1 0)| +--------------------------+ ST_SetSRID \u00b6 Introduction: Sets the spatial refence system identifier (SRID) of the geometry. Format: ST_SetSRID (A:geometry, srid: Integer) Since: v1.1.1 Spark SQL example: SELECT ST_SetSRID ( polygondf . countyshape , 3021 ) FROM polygondf ST_SimplifyPreserveTopology \u00b6 Introduction: Simplifies a geometry and ensures that the result is a valid geometry having the same dimension and number of components as the input, and with the components having the same topological relationship. Since: v1.0.0 Format: ST_SimplifyPreserveTopology (A:geometry, distanceTolerance: Double) SELECT ST_SimplifyPreserveTopology ( polygondf . countyshape , 10 . 0 ) FROM polygondf ST_SRID \u00b6 Introduction: Return the spatial refence system identifier (SRID) of the geometry. Format: ST_SRID (A:geometry) Since: v1.1.1 Spark SQL example: SELECT ST_SRID ( polygondf . countyshape ) FROM polygondf ST_StartPoint \u00b6 Introduction: Returns first point of given linestring. Format: ST_StartPoint(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_StartPoint ( ST_GeomFromText ( 'LINESTRING(100 150,50 60, 70 80, 160 170)' )) Output: POINT(100 150) ST_SubDivide \u00b6 Introduction: Returns list of geometries divided based of given maximum number of vertices. Format: ST_SubDivide(geom: geometry, maxVertices: int) Since: v1.1.0 Spark SQL example: SELECT ST_SubDivide ( ST_GeomFromText ( \"POLYGON((35 10, 45 45, 15 40, 10 20, 35 10), (20 30, 35 35, 30 20, 20 30))\" ), 5 ) Output: [ POLYGON((37.857142857142854 20, 35 10, 10 20, 37.857142857142854 20)), POLYGON((15 20, 10 20, 15 40, 15 20)), POLYGON((20 20, 15 20, 15 30, 20 30, 20 20)), POLYGON((26.428571428571427 20, 20 20, 20 30, 26.4285714 23.5714285, 26.4285714 20)), POLYGON((15 30, 15 40, 20 40, 20 30, 15 30)), POLYGON((20 40, 26.4285714 40, 26.4285714 32.1428571, 20 30, 20 40)), POLYGON((37.8571428 20, 30 20, 34.0476190 32.1428571, 37.8571428 32.1428571, 37.8571428 20)), POLYGON((34.0476190 34.6825396, 26.4285714 32.1428571, 26.4285714 40, 34.0476190 40, 34.0476190 34.6825396)), POLYGON((34.0476190 32.1428571, 35 35, 37.8571428 35, 37.8571428 32.1428571, 34.0476190 32.1428571)), POLYGON((35 35, 34.0476190 34.6825396, 34.0476190 35, 35 35)), POLYGON((34.0476190 35, 34.0476190 40, 37.8571428 40, 37.8571428 35, 34.0476190 35)), POLYGON((30 20, 26.4285714 20, 26.4285714 23.5714285, 30 20)), POLYGON((15 40, 37.8571428 43.8095238, 37.8571428 40, 15 40)), POLYGON((45 45, 37.8571428 20, 37.8571428 43.8095238, 45 45)) ] Spark SQL example: SELECT ST_SubDivide ( ST_GeomFromText ( \"LINESTRING(0 0, 85 85, 100 100, 120 120, 21 21, 10 10, 5 5)\" ), 5 ) Output: [ LINESTRING(0 0, 5 5) LINESTRING(5 5, 10 10) LINESTRING(10 10, 21 21) LINESTRING(21 21, 60 60) LINESTRING(60 60, 85 85) LINESTRING(85 85, 100 100) LINESTRING(100 100, 120 120) ] ST_SubDivideExplode \u00b6 Introduction: It works the same as ST_SubDivide but returns new rows with geometries instead of list. Format: ST_SubDivideExplode(geom: geometry, maxVertices: int) Since: v1.1.0 Example: Query: SELECT ST_SubDivideExplode ( ST_GeomFromText ( \"LINESTRING(0 0, 85 85, 100 100, 120 120, 21 21, 10 10, 5 5)\" ), 5 ) Result: +-----------------------------+ |geom | +-----------------------------+ |LINESTRING(0 0, 5 5) | |LINESTRING(5 5, 10 10) | |LINESTRING(10 10, 21 21) | |LINESTRING(21 21, 60 60) | |LINESTRING(60 60, 85 85) | |LINESTRING(85 85, 100 100) | |LINESTRING(100 100, 120 120) | +-----------------------------+ Using Lateral View Table: +-------------------------------------------------------------+ |geometry | +-------------------------------------------------------------+ |LINESTRING(0 0, 85 85, 100 100, 120 120, 21 21, 10 10, 5 5) | +-------------------------------------------------------------+ Query select geom from geometries LATERAL VIEW ST_SubdivideExplode ( geometry , 5 ) AS geom Result: +-----------------------------+ |geom | +-----------------------------+ |LINESTRING(0 0, 5 5) | |LINESTRING(5 5, 10 10) | |LINESTRING(10 10, 21 21) | |LINESTRING(21 21, 60 60) | |LINESTRING(60 60, 85 85) | |LINESTRING(85 85, 100 100) | |LINESTRING(100 100, 120 120) | +-----------------------------+ ST_SymDifference \u00b6 Introduction: Return the symmetrical difference between geometry A and B (return parts of geometries which are in either of the sets, but not in their intersection) Format: ST_SymDifference (A:geometry, B:geometry) Since: v1.2.0 Example: SELECT ST_SymDifference ( ST_GeomFromWKT ( 'POLYGON ((-3 -3, 3 -3, 3 3, -3 3, -3 -3))' ), ST_GeomFromWKT ( 'POLYGON ((-2 -3, 4 -3, 4 3, -2 3, -2 -3))' )) Result: MULTIPOLYGON (((-2 -3, -3 -3, -3 3, -2 3, -2 -3)), ((3 -3, 3 3, 4 3, 4 -3, 3 -3))) ST_Transform \u00b6 Introduction: Transform the Spatial Reference System / Coordinate Reference System of A, from SourceCRS to TargetCRS. For SourceCRS and TargetCRS, WKT format is also available since v1.3.1. Note By default, this function uses lat/lon order. You can use ST_FlipCoordinates to swap X and Y. Note If ST_Transform throws an Exception called \"Bursa wolf parameters required\", you need to disable the error notification in ST_Transform. You can append a boolean value at the end. Format: ST_Transform (A:geometry, SourceCRS:string, TargetCRS:string ,[Optional] DisableError) Since: v1.0.0 Spark SQL example (simple): SELECT ST_Transform ( polygondf . countyshape , 'epsg:4326' , 'epsg:3857' ) FROM polygondf Spark SQL example (with optional parameters): SELECT ST_Transform ( polygondf . countyshape , 'epsg:4326' , 'epsg:3857' , false ) FROM polygondf Note The detailed EPSG information can be searched on EPSG.io . ST_Union \u00b6 Introduction: Return the union of geometry A and B Format: ST_Union (A:geometry, B:geometry) Since: v1.2.0 Example: SELECT ST_Union ( ST_GeomFromWKT ( 'POLYGON ((-3 -3, 3 -3, 3 3, -3 3, -3 -3))' ), ST_GeomFromWKT ( 'POLYGON ((1 -2, 5 0, 1 2, 1 -2))' )) Result: POLYGON ((3 -1, 3 -3, -3 -3, -3 3, 3 3, 3 1, 5 0, 3 -1)) ST_X \u00b6 Introduction: Returns X Coordinate of given Point null otherwise. Format: ST_X(pointA: Point) Since: v1.0.0 Spark SQL example: SELECT ST_X ( ST_POINT ( 0 . 0 25 . 0 )) Output: 0.0 ST_XMax \u00b6 Introduction: Returns the maximum X coordinate of a geometry Format: ST_XMax (A:geometry) Since: v1.2.1 Example: SELECT ST_XMax ( df . geometry ) AS xmax FROM df Input: POLYGON ((-1 -11, 0 10, 1 11, 2 12, -1 -11)) Output: 2 ST_XMin \u00b6 Introduction: Returns the minimum X coordinate of a geometry Format: ST_XMin (A:geometry) Since: v1.2.1 Example: SELECT ST_XMin ( df . geometry ) AS xmin FROM df Input: POLYGON ((-1 -11, 0 10, 1 11, 2 12, -1 -11)) Output: -1 ST_Y \u00b6 Introduction: Returns Y Coordinate of given Point, null otherwise. Format: ST_Y(pointA: Point) Since: v1.0.0 Spark SQL example: SELECT ST_Y ( ST_POINT ( 0 . 0 25 . 0 )) Output: 25.0 ST_YMax \u00b6 Introduction: Return the minimum Y coordinate of A Format: ST_YMax (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_YMax ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output: 2 ST_YMin \u00b6 Introduction: Return the minimum Y coordinate of A Format: ST_Y_Min (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_YMin ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output : 0 ST_Z \u00b6 Introduction: Returns Z Coordinate of given Point, null otherwise. Format: ST_Z(pointA: Point) Since: v1.2.0 Spark SQL example: SELECT ST_Z ( ST_POINT ( 0 . 0 25 . 0 11 . 0 )) Output: 11.0 ST_ZMax \u00b6 Introduction: Returns Z maxima of the given geometry or null if there is no Z coordinate. Format: ST_ZMax(geom: geometry) Since: v1.3.1 Spark SQL example: SELECT ST_ZMax ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output: 1.0 ST_ZMin \u00b6 Introduction: Returns Z minima of the given geometry or null if there is no Z coordinate. Format: ST_ZMin(geom: geometry) Since: v1.3.1 Spark SQL example: SELECT ST_ZMin ( ST_GeomFromText ( 'LINESTRING(1 3 4, 5 6 7)' )) Output: 4.0","title":"Function"},{"location":"api/sql/Function/#st_3ddistance","text":"Introduction: Return the 3-dimensional minimum cartesian distance between A and B Format: ST_3DDistance (A:geometry, B:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_3DDistance ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf","title":"ST_3DDistance"},{"location":"api/sql/Function/#st_addpoint","text":"Introduction: RETURN Linestring with additional point at the given index, if position is not available the point will be added at the end of line. Format: ST_AddPoint(geom: geometry, point: geometry, position: integer) Format: ST_AddPoint(geom: geometry, point: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_AddPoint ( ST_GeomFromText ( \"LINESTRING(0 0, 1 1, 1 0)\" ), ST_GeomFromText ( \"Point(21 52)\" ), 1 ) SELECT ST_AddPoint ( ST_GeomFromText ( \"Linestring(0 0, 1 1, 1 0)\" ), ST_GeomFromText ( \"Point(21 52)\" )) Output: LINESTRING(0 0, 21 52, 1 1, 1 0) LINESTRING(0 0, 1 1, 1 0, 21 52)","title":"ST_AddPoint"},{"location":"api/sql/Function/#st_area","text":"Introduction: Return the area of A Format: ST_Area (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Area ( polygondf . countyshape ) FROM polygondf","title":"ST_Area"},{"location":"api/sql/Function/#st_asbinary","text":"Introduction: Return the Well-Known Binary representation of a geometry Format: ST_AsBinary (A:geometry) Since: v1.1.1 Spark SQL example: SELECT ST_AsBinary ( polygondf . countyshape ) FROM polygondf","title":"ST_AsBinary"},{"location":"api/sql/Function/#st_asewkb","text":"Introduction: Return the Extended Well-Known Binary representation of a geometry. EWKB is an extended version of WKB which includes the SRID of the geometry. The format originated in PostGIS but is supported by many GIS tools. If the geometry is lacking SRID a WKB format is produced. Se ST_SetSRID Format: ST_AsEWKB (A:geometry) Since: v1.1.1 Spark SQL example: SELECT ST_AsEWKB ( polygondf . countyshape ) FROM polygondf","title":"ST_AsEWKB"},{"location":"api/sql/Function/#st_asewkt","text":"Introduction: Return the Extended Well-Known Text representation of a geometry. EWKT is an extended version of WKT which includes the SRID of the geometry. The format originated in PostGIS but is supported by many GIS tools. If the geometry is lacking SRID a WKT format is produced. See ST_SetSRID Format: ST_AsEWKT (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_AsEWKT ( polygondf . countyshape ) FROM polygondf","title":"ST_AsEWKT"},{"location":"api/sql/Function/#st_asgeojson","text":"Introduction: Return the GeoJSON string representation of a geometry Format: ST_AsGeoJSON (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_AsGeoJSON ( polygondf . countyshape ) FROM polygondf","title":"ST_AsGeoJSON"},{"location":"api/sql/Function/#st_asgml","text":"Introduction: Return the GML string representation of a geometry Format: ST_AsGML (A:geometry) Since: v1.3.0 Spark SQL example: SELECT ST_AsGML ( polygondf . countyshape ) FROM polygondf","title":"ST_AsGML"},{"location":"api/sql/Function/#st_askml","text":"Introduction: Return the KML string representation of a geometry Format: ST_AsKML (A:geometry) Since: v1.3.0 Spark SQL example: SELECT ST_AsKML ( polygondf . countyshape ) FROM polygondf","title":"ST_AsKML"},{"location":"api/sql/Function/#st_astext","text":"Introduction: Return the Well-Known Text string representation of a geometry Format: ST_AsText (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_AsText ( polygondf . countyshape ) FROM polygondf","title":"ST_AsText"},{"location":"api/sql/Function/#st_azimuth","text":"Introduction: Returns Azimuth for two given points in radians null otherwise. Format: ST_Azimuth(pointA: Point, pointB: Point) Since: v1.0.0 Spark SQL example: SELECT ST_Azimuth ( ST_POINT ( 0 . 0 , 25 . 0 ), ST_POINT ( 0 . 0 , 0 . 0 )) Output: 3.141592653589793","title":"ST_Azimuth"},{"location":"api/sql/Function/#st_boundary","text":"Introduction: Returns the closure of the combinatorial boundary of this Geometry. Format: ST_Boundary(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Boundary ( ST_GeomFromText ( 'POLYGON((1 1,0 0, -1 1, 1 1))' )) Output: LINESTRING (1 1, 0 0, -1 1, 1 1)","title":"ST_Boundary"},{"location":"api/sql/Function/#st_buffer","text":"Introduction: Returns a geometry/geography that represents all points whose distance from this Geometry/geography is less than or equal to distance. Format: ST_Buffer (A:geometry, buffer: Double) Since: v1.0.0 Spark SQL example: SELECT ST_Buffer ( polygondf . countyshape , 1 ) FROM polygondf","title":"ST_Buffer"},{"location":"api/sql/Function/#st_buildarea","text":"Introduction: Returns the areal geometry formed by the constituent linework of the input geometry. Format: ST_BuildArea (A:geometry) Since: v1.2.1 Example: SELECT ST_BuildArea ( ST_GeomFromText ( 'MULTILINESTRING((0 0, 20 0, 20 20, 0 20, 0 0),(2 2, 18 2, 18 18, 2 18, 2 2))' ) ) AS geom Result: +----------------------------------------------------------------------------+ |geom | +----------------------------------------------------------------------------+ |POLYGON((0 0,0 20,20 20,20 0,0 0),(2 2,18 2,18 18,2 18,2 2)) | +----------------------------------------------------------------------------+","title":"ST_BuildArea"},{"location":"api/sql/Function/#st_centroid","text":"Introduction: Return the centroid point of A Format: ST_Centroid (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Centroid ( polygondf . countyshape ) FROM polygondf","title":"ST_Centroid"},{"location":"api/sql/Function/#st_collect","text":"Introduction: Returns MultiGeometry object based on geometry column/s or array with geometries Format ST_Collect(*geom: geometry) ST_Collect(geom: array<geometry>) Since: v1.2.0 Example: SELECT ST_Collect ( ST_GeomFromText ( 'POINT(21.427834 52.042576573)' ), ST_GeomFromText ( 'POINT(45.342524 56.342354355)' ) ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |MULTIPOINT ((21.427834 52.042576573), (45.342524 56.342354355))| +---------------------------------------------------------------+ Example: SELECT ST_Collect ( Array ( ST_GeomFromText ( 'POINT(21.427834 52.042576573)' ), ST_GeomFromText ( 'POINT(45.342524 56.342354355)' ) ) ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |MULTIPOINT ((21.427834 52.042576573), (45.342524 56.342354355))| +---------------------------------------------------------------+","title":"ST_Collect"},{"location":"api/sql/Function/#st_collectionextract","text":"Introduction: Returns a homogeneous multi-geometry from a given geometry collection. The type numbers are: 1. POINT 2. LINESTRING 3. POLYGON If the type parameter is omitted a multi-geometry of the highest dimension is returned. Format: ST_CollectionExtract (A:geometry) Format: ST_CollectionExtract (A:geometry, type:Int) Since: v1.2.1 Example: WITH test_data as ( ST_GeomFromText ( 'GEOMETRYCOLLECTION(POINT(40 10), POLYGON((0 0, 0 5, 5 5, 5 0, 0 0)))' ) as geom ) SELECT ST_CollectionExtract ( geom ) as c1 , ST_CollectionExtract ( geom , 1 ) as c2 FROM test_data Result: +----------------------------------------------------------------------------+ |c1 |c2 | +----------------------------------------------------------------------------+ |MULTIPOLYGON(((0 0, 0 5, 5 5, 5 0, 0 0))) |MULTIPOINT(40 10) | | +----------------------------------------------------------------------------+","title":"ST_CollectionExtract"},{"location":"api/sql/Function/#st_convexhull","text":"Introduction: Return the Convex Hull of polgyon A Format: ST_ConvexHull (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_ConvexHull ( polygondf . countyshape ) FROM polygondf","title":"ST_ConvexHull"},{"location":"api/sql/Function/#st_difference","text":"Introduction: Return the difference between geometry A and B (return part of geometry A that does not intersect geometry B) Format: ST_Difference (A:geometry, B:geometry) Since: v1.2.0 Example: SELECT ST_Difference ( ST_GeomFromWKT ( 'POLYGON ((-3 -3, 3 -3, 3 3, -3 3, -3 -3))' ), ST_GeomFromWKT ( 'POLYGON ((0 -4, 4 -4, 4 4, 0 4, 0 -4))' )) Result: POLYGON ((0 -3, -3 -3, -3 3, 0 3, 0 -3))","title":"ST_Difference"},{"location":"api/sql/Function/#st_distance","text":"Introduction: Return the Euclidean distance between A and B Format: ST_Distance (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Distance ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf","title":"ST_Distance"},{"location":"api/sql/Function/#st_dump","text":"Introduction: It expands the geometries. If the geometry is simple (Point, Polygon Linestring etc.) it returns the geometry itself, if the geometry is collection or multi it returns record for each of collection components. Format: ST_Dump(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Dump ( ST_GeomFromText ( 'MULTIPOINT ((10 40), (40 30), (20 20), (30 10))' )) Output: [POINT (10 40), POINT (40 30), POINT (20 20), POINT (30 10)]","title":"ST_Dump"},{"location":"api/sql/Function/#st_dumppoints","text":"Introduction: Returns list of Points which geometry consists of. Format: ST_DumpPoints(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_DumpPoints ( ST_GeomFromText ( 'LINESTRING (0 0, 1 1, 1 0)' )) Output: [POINT (0 0), POINT (0 1), POINT (1 1), POINT (1 0), POINT (0 0)]","title":"ST_DumpPoints"},{"location":"api/sql/Function/#st_endpoint","text":"Introduction: Returns last point of given linestring. Format: ST_EndPoint(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_EndPoint ( ST_GeomFromText ( 'LINESTRING(100 150,50 60, 70 80, 160 170)' )) Output: POINT(160 170)","title":"ST_EndPoint"},{"location":"api/sql/Function/#st_envelope","text":"Introduction: Return the envelop boundary of A Format: ST_Envelope (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Envelope ( polygondf . countyshape ) FROM polygondf","title":"ST_Envelope"},{"location":"api/sql/Function/#st_exteriorring","text":"Introduction: Returns a line string representing the exterior ring of the POLYGON geometry. Return NULL if the geometry is not a polygon. Format: ST_ExteriorRing(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_ExteriorRing ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output: LINESTRING (0 0, 1 1, 1 2, 1 1, 0 0)","title":"ST_ExteriorRing"},{"location":"api/sql/Function/#st_flipcoordinates","text":"Introduction: Returns a version of the given geometry with X and Y axis flipped. Format: ST_FlipCoordinates(A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_FlipCoordinates ( df . geometry ) FROM df Input: POINT (1 2) Output: POINT (2 1)","title":"ST_FlipCoordinates"},{"location":"api/sql/Function/#st_force_2d","text":"Introduction: Forces the geometries into a \"2-dimensional mode\" so that all output representations will only have the X and Y coordinates Format: ST_Force_2D (A:geometry) Since: v1.2.1 Example: SELECT ST_AsText ( ST_Force_2D ( ST_GeomFromText ( 'POLYGON((0 0 2,0 5 2,5 0 2,0 0 2),(1 1 2,3 1 2,1 3 2,1 1 2))' )) ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |POLYGON((0 0,0 5,5 0,0 0),(1 1,3 1,1 3,1 1)) | +---------------------------------------------------------------+","title":"ST_Force_2D"},{"location":"api/sql/Function/#st_geohash","text":"Introduction: Returns GeoHash of the geometry with given precision Format: ST_GeoHash(geom: geometry, precision: int) Since: v1.1.1 Example: Query: SELECT ST_GeoHash ( ST_GeomFromText ( 'POINT(21.427834 52.042576573)' ), 5 ) AS geohash Result: +-----------------------------+ |geohash | +-----------------------------+ |u3r0p | +-----------------------------+","title":"ST_GeoHash"},{"location":"api/sql/Function/#st_geometryn","text":"Introduction: Return the 0-based Nth geometry if the geometry is a GEOMETRYCOLLECTION, (MULTI)POINT, (MULTI)LINESTRING, MULTICURVE or (MULTI)POLYGON. Otherwise, return null Format: ST_GeometryN(geom: geometry, n: Int) Since: v1.0.0 Spark SQL example: SELECT ST_GeometryN ( ST_GeomFromText ( 'MULTIPOINT((1 2), (3 4), (5 6), (8 9))' ), 1 ) Output: POINT (3 4)","title":"ST_GeometryN"},{"location":"api/sql/Function/#st_geometrytype","text":"Introduction: Returns the type of the geometry as a string. EG: 'ST_Linestring', 'ST_Polygon' etc. Format: ST_GeometryType (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_GeometryType ( polygondf . countyshape ) FROM polygondf","title":"ST_GeometryType"},{"location":"api/sql/Function/#st_interiorringn","text":"Introduction: Returns the Nth interior linestring ring of the polygon geometry. Returns NULL if the geometry is not a polygon or the given N is out of range Format: ST_InteriorRingN(geom: geometry, n: Int) Since: v1.0.0 Spark SQL example: SELECT ST_InteriorRingN ( ST_GeomFromText ( 'POLYGON((0 0, 0 5, 5 5, 5 0, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1), (1 3, 2 3, 2 4, 1 4, 1 3), (3 3, 4 3, 4 4, 3 4, 3 3))' ), 0 ) Output: LINESTRING (1 1, 2 1, 2 2, 1 2, 1 1)","title":"ST_InteriorRingN"},{"location":"api/sql/Function/#st_intersection","text":"Introduction: Return the intersection geometry of A and B Format: ST_Intersection (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Intersection ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf","title":"ST_Intersection"},{"location":"api/sql/Function/#st_isclosed","text":"Introduction: RETURNS true if the LINESTRING start and end point are the same. Format: ST_IsClosed(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_IsClosed ( ST_GeomFromText ( 'LINESTRING(0 0, 1 1, 1 0)' )) Output: false","title":"ST_IsClosed"},{"location":"api/sql/Function/#st_isempty","text":"Introduction: Test if a geometry is empty geometry Format: ST_IsEmpty (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_IsEmpty ( polygondf . countyshape ) FROM polygondf","title":"ST_IsEmpty"},{"location":"api/sql/Function/#st_isring","text":"Introduction: RETURN true if LINESTRING is ST_IsClosed and ST_IsSimple. Format: ST_IsRing(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_IsRing ( ST_GeomFromText ( \"LINESTRING(0 0, 0 1, 1 1, 1 0, 0 0)\" )) Output: true","title":"ST_IsRing"},{"location":"api/sql/Function/#st_issimple","text":"Introduction: Test if geometry's only self-intersections are at boundary points. Format: ST_IsSimple (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_IsSimple ( polygondf . countyshape ) FROM polygondf","title":"ST_IsSimple"},{"location":"api/sql/Function/#st_isvalid","text":"Introduction: Test if a geometry is well formed Format: ST_IsValid (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_IsValid ( polygondf . countyshape ) FROM polygondf","title":"ST_IsValid"},{"location":"api/sql/Function/#st_length","text":"Introduction: Return the perimeter of A Format: ST_Length (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Length ( polygondf . countyshape ) FROM polygondf","title":"ST_Length"},{"location":"api/sql/Function/#st_linefrommultipoint","text":"Introduction: Creates a LineString from a MultiPoint geometry. Format: ST_LineFromMultiPoint (A:geometry) Since: v1.3.0 Example: SELECT ST_AsText ( ST_LineFromMultiPoint ( ST_GeomFromText ( 'MULTIPOINT((10 40), (40 30), (20 20), (30 10))' )) ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |LINESTRING (10 40, 40 30, 20 20, 30 10) | +---------------------------------------------------------------+","title":"ST_LineFromMultiPoint"},{"location":"api/sql/Function/#st_lineinterpolatepoint","text":"Introduction: Returns a point interpolated along a line. First argument must be a LINESTRING. Second argument is a Double between 0 and 1 representing fraction of total linestring length the point has to be located. Format: ST_LineInterpolatePoint (geom: geometry, fraction: Double) Since: v1.0.1 Spark SQL example: SELECT ST_LineInterpolatePoint ( ST_GeomFromWKT ( 'LINESTRING(25 50, 100 125, 150 190)' ), 0 . 2 ) as Interpolated Output: +-----------------------------------------+ |Interpolated | +-----------------------------------------+ |POINT (51.5974135047432 76.5974135047432)| +-----------------------------------------+","title":"ST_LineInterpolatePoint"},{"location":"api/sql/Function/#st_linemerge","text":"Introduction: Returns a LineString formed by sewing together the constituent line work of a MULTILINESTRING. Note Only works for MULTILINESTRING. Using other geometry will return a GEOMETRYCOLLECTION EMPTY. If the MultiLineString can't be merged, the original MULTILINESTRING is returned. Format: ST_LineMerge (A:geometry) Since: v1.0.0 SELECT ST_LineMerge ( geometry ) FROM df","title":"ST_LineMerge"},{"location":"api/sql/Function/#st_linesubstring","text":"Introduction: Return a linestring being a substring of the input one starting and ending at the given fractions of total 2d length. Second and third arguments are Double values between 0 and 1. This only works with LINESTRINGs. Format: ST_LineSubstring (geom: geometry, startfraction: Double, endfraction: Double) Since: v1.0.1 Spark SQL example: SELECT ST_LineSubstring ( ST_GeomFromWKT ( 'LINESTRING(25 50, 100 125, 150 190)' ), 0 . 333 , 0 . 666 ) as Substring Output: +------------------------------------------------------------------------------------------------+ |Substring | +------------------------------------------------------------------------------------------------+ |LINESTRING (69.28469348539744 94.28469348539744, 100 125, 111.70035626068274 140.21046313888758)| +------------------------------------------------------------------------------------------------+","title":"ST_LineSubstring"},{"location":"api/sql/Function/#st_makepolygon","text":"Introduction: Function to convert closed linestring to polygon including holes Format: ST_MakePolygon(geom: geometry, holes: array<geometry>) Since: v1.1.0 Example: Query: SELECT ST_MakePolygon ( ST_GeomFromText ( 'LINESTRING(7 -1, 7 6, 9 6, 9 1, 7 -1)' ), ARRAY ( ST_GeomFromText ( 'LINESTRING(6 2, 8 2, 8 1, 6 1, 6 2)' )) ) AS polygon Result: +----------------------------------------------------------------+ |polygon | +----------------------------------------------------------------+ |POLYGON ((7 -1, 7 6, 9 6, 9 1, 7 -1), (6 2, 8 2, 8 1, 6 1, 6 2))| +----------------------------------------------------------------+","title":"ST_MakePolygon"},{"location":"api/sql/Function/#st_makevalid","text":"Introduction: Given an invalid geometry, create a valid representation of the geometry. Collapsed geometries are either converted to empty (keepCollaped=true) or a valid geometry of lower dimension (keepCollapsed=false). Default is keepCollapsed=false. Format: ST_MakeValid (A:geometry) Format: ST_MakeValid (A:geometry, keepCollapsed:Boolean) Since: v1.0.0 Spark SQL example: WITH linestring AS ( SELECT ST_GeomFromWKT ( 'LINESTRING(1 1, 1 1)' ) AS geom ) SELECT ST_MakeValid ( geom ), ST_MakeValid ( geom , true ) FROM linestring Result: +------------------+------------------------+ |st_makevalid(geom)|st_makevalid(geom, true)| +------------------+------------------------+ | LINESTRING EMPTY| POINT (1 1)| +------------------+------------------------+ Note In Sedona up to and including version 1.2 the behaviour of ST_MakeValid was different. Be sure to check you code when upgrading. The previous implementation only worked for (multi)polygons and had a different interpretation of the second, boolean, argument. It would also sometimes return multiple geometries for a single geomtry input.","title":"ST_MakeValid"},{"location":"api/sql/Function/#st_minimumboundingcircle","text":"Introduction: Returns the smallest circle polygon that contains a geometry. Format: ST_MinimumBoundingCircle(geom: geometry, [Optional] quadrantSegments:int) Since: v1.0.1 Spark SQL example: SELECT ST_MinimumBoundingCircle ( ST_GeomFromText ( 'POLYGON((1 1,0 0, -1 1, 1 1))' ))","title":"ST_MinimumBoundingCircle"},{"location":"api/sql/Function/#st_minimumboundingradius","text":"Introduction: Returns a struct containing the center point and radius of the smallest circle that contains a geometry. Format: ST_MinimumBoundingRadius(geom: geometry) Since: v1.0.1 Spark SQL example: SELECT ST_MinimumBoundingRadius ( ST_GeomFromText ( 'POLYGON((1 1,0 0, -1 1, 1 1))' ))","title":"ST_MinimumBoundingRadius"},{"location":"api/sql/Function/#st_multi","text":"Introduction: Returns a MultiGeometry object based on the geometry input. ST_Multi is basically an alias for ST_Collect with one geometry. Format ST_Multi(geom: geometry) Since: v1.2.0 Example: SELECT ST_Multi ( ST_GeomFromText ( 'POINT(1 1)' ) ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |MULTIPOINT (1 1) | +---------------------------------------------------------------+","title":"ST_Multi"},{"location":"api/sql/Function/#st_ndims","text":"Introduction: Returns the coordinate dimension of the geometry. It supports 2 - (x,y) , 3 - (x,y,z). Currently the geometry serializer in sedona-sql does not support M dimension, 4D geometries with ZM coordinates will have their M coordinates dropped and became 3D geometries. We're working on a new geometry serializer to resolve this issue. Format: ST_NDims(geom: geometry) Since: v1.3.1 Spark SQL example with z co-rodinate: SELECT ST_NDims ( ST_GeomFromEWKT ( 'POINT(1 1 2)' )) Output: 3 Spark SQL example with x,y co-ordinate: SELECT ST_NDims ( ST_GeomFromText ( 'POINT(1 1)' )) Output: 2","title":"ST_NDims"},{"location":"api/sql/Function/#st_normalize","text":"Introduction: Returns the input geometry in its normalized form. Format ST_Normalize(geom: geometry) Since: v1.3.0 Example: SELECT ST_AsEWKT ( ST_Normalize ( ST_GeomFromWKT ( 'POLYGON((0 1, 1 1, 1 0, 0 0, 0 1))' ))) AS geom Result: +-----------------------------------+ |geom | +-----------------------------------+ |POLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))| +-----------------------------------+","title":"ST_Normalize"},{"location":"api/sql/Function/#st_npoints","text":"Introduction: Return points of the geometry Since: v1.0.0 Format: ST_NPoints (A:geometry) SELECT ST_NPoints ( polygondf . countyshape ) FROM polygondf","title":"ST_NPoints"},{"location":"api/sql/Function/#st_numgeometries","text":"Introduction: Returns the number of Geometries. If geometry is a GEOMETRYCOLLECTION (or MULTI*) return the number of geometries, for single geometries will return 1. Format: ST_NumGeometries (A:geometry) Since: v1.0.0 SELECT ST_NumGeometries ( df . geometry ) FROM df","title":"ST_NumGeometries"},{"location":"api/sql/Function/#st_numinteriorrings","text":"Introduction: RETURNS number of interior rings of polygon geometries. Format: ST_NumInteriorRings(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_NumInteriorRings ( ST_GeomFromText ( 'POLYGON ((0 0, 0 5, 5 5, 5 0, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1))' )) Output: 1","title":"ST_NumInteriorRings"},{"location":"api/sql/Function/#st_pointn","text":"Introduction: Return the Nth point in a single linestring or circular linestring in the geometry. Negative values are counted backwards from the end of the LineString, so that -1 is the last point. Returns NULL if there is no linestring in the geometry. Format: ST_PointN(geom: geometry, n: integer) Since: v1.2.1 Spark SQL example: SELECT ST_PointN ( ST_GeomFromText ( \"LINESTRING(0 0, 1 2, 2 4, 3 6)\" ), 2 ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |POINT (1 2) | +---------------------------------------------------------------+","title":"ST_PointN"},{"location":"api/sql/Function/#st_pointonsurface","text":"Introduction: Returns a POINT guaranteed to lie on the surface. Format: ST_PointOnSurface(A:geometry) Since: v1.2.1 Examples: SELECT ST_AsText(ST_PointOnSurface(ST_GeomFromText('POINT(0 5)'))); st_astext ------------ POINT(0 5) SELECT ST_AsText(ST_PointOnSurface(ST_GeomFromText('LINESTRING(0 5, 0 10)'))); st_astext ------------ POINT(0 5) SELECT ST_AsText(ST_PointOnSurface(ST_GeomFromText('POLYGON((0 0, 0 5, 5 5, 5 0, 0 0))'))); st_astext ---------------- POINT(2.5 2.5) SELECT ST_AsText(ST_PointOnSurface(ST_GeomFromText('LINESTRING(0 5 1, 0 0 1, 0 10 2)'))); st_astext ---------------- POINT Z(0 0 1)","title":"ST_PointOnSurface"},{"location":"api/sql/Function/#st_precisionreduce","text":"Introduction: Reduce the decimals places in the coordinates of the geometry to the given number of decimal places. The last decimal place will be rounded. Format: ST_PrecisionReduce (A:geometry, B:int) Since: v1.0.0 Spark SQL example: SELECT ST_PrecisionReduce ( polygondf . countyshape , 9 ) FROM polygondf The new coordinates will only have 9 decimal places.","title":"ST_PrecisionReduce"},{"location":"api/sql/Function/#st_removepoint","text":"Introduction: RETURN Line with removed point at given index, position can be omitted and then last one will be removed. Format: ST_RemovePoint(geom: geometry, position: integer) Format: ST_RemovePoint(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_RemovePoint ( ST_GeomFromText ( \"LINESTRING(0 0, 1 1, 1 0)\" ), 1 ) Output: LINESTRING(0 0, 1 0)","title":"ST_RemovePoint"},{"location":"api/sql/Function/#st_reverse","text":"Introduction: Return the geometry with vertex order reversed Format: ST_Reverse (A:geometry) Since: v1.2.1 Example: SELECT ST_AsText ( ST_Reverse ( ST_GeomFromText ( 'LINESTRING(0 0, 1 2, 2 4, 3 6)' )) ) AS geom Result: +---------------------------------------------------------------+ |geom | +---------------------------------------------------------------+ |LINESTRING (3 6, 2 4, 1 2, 0 0) | +---------------------------------------------------------------+","title":"ST_Reverse"},{"location":"api/sql/Function/#st_setpoint","text":"Introduction: Replace Nth point of linestring with given point. Index is 0-based. Negative index are counted backwards, e.g., -1 is last point. Format: ST_SetPoint (linestring: geometry, index: integer, point: geometry) Since: v1.3.0 Example: SELECT ST_SetPoint ( ST_GeomFromText ( 'LINESTRING (0 0, 0 1, 1 1)' ), 2 , ST_GeomFromText ( 'POINT (1 0)' )) AS geom Result: +--------------------------+ |geom | +--------------------------+ |LINESTRING (0 0, 0 1, 1 0)| +--------------------------+","title":"ST_SetPoint"},{"location":"api/sql/Function/#st_setsrid","text":"Introduction: Sets the spatial refence system identifier (SRID) of the geometry. Format: ST_SetSRID (A:geometry, srid: Integer) Since: v1.1.1 Spark SQL example: SELECT ST_SetSRID ( polygondf . countyshape , 3021 ) FROM polygondf","title":"ST_SetSRID"},{"location":"api/sql/Function/#st_simplifypreservetopology","text":"Introduction: Simplifies a geometry and ensures that the result is a valid geometry having the same dimension and number of components as the input, and with the components having the same topological relationship. Since: v1.0.0 Format: ST_SimplifyPreserveTopology (A:geometry, distanceTolerance: Double) SELECT ST_SimplifyPreserveTopology ( polygondf . countyshape , 10 . 0 ) FROM polygondf","title":"ST_SimplifyPreserveTopology"},{"location":"api/sql/Function/#st_srid","text":"Introduction: Return the spatial refence system identifier (SRID) of the geometry. Format: ST_SRID (A:geometry) Since: v1.1.1 Spark SQL example: SELECT ST_SRID ( polygondf . countyshape ) FROM polygondf","title":"ST_SRID"},{"location":"api/sql/Function/#st_startpoint","text":"Introduction: Returns first point of given linestring. Format: ST_StartPoint(geom: geometry) Since: v1.0.0 Spark SQL example: SELECT ST_StartPoint ( ST_GeomFromText ( 'LINESTRING(100 150,50 60, 70 80, 160 170)' )) Output: POINT(100 150)","title":"ST_StartPoint"},{"location":"api/sql/Function/#st_subdivide","text":"Introduction: Returns list of geometries divided based of given maximum number of vertices. Format: ST_SubDivide(geom: geometry, maxVertices: int) Since: v1.1.0 Spark SQL example: SELECT ST_SubDivide ( ST_GeomFromText ( \"POLYGON((35 10, 45 45, 15 40, 10 20, 35 10), (20 30, 35 35, 30 20, 20 30))\" ), 5 ) Output: [ POLYGON((37.857142857142854 20, 35 10, 10 20, 37.857142857142854 20)), POLYGON((15 20, 10 20, 15 40, 15 20)), POLYGON((20 20, 15 20, 15 30, 20 30, 20 20)), POLYGON((26.428571428571427 20, 20 20, 20 30, 26.4285714 23.5714285, 26.4285714 20)), POLYGON((15 30, 15 40, 20 40, 20 30, 15 30)), POLYGON((20 40, 26.4285714 40, 26.4285714 32.1428571, 20 30, 20 40)), POLYGON((37.8571428 20, 30 20, 34.0476190 32.1428571, 37.8571428 32.1428571, 37.8571428 20)), POLYGON((34.0476190 34.6825396, 26.4285714 32.1428571, 26.4285714 40, 34.0476190 40, 34.0476190 34.6825396)), POLYGON((34.0476190 32.1428571, 35 35, 37.8571428 35, 37.8571428 32.1428571, 34.0476190 32.1428571)), POLYGON((35 35, 34.0476190 34.6825396, 34.0476190 35, 35 35)), POLYGON((34.0476190 35, 34.0476190 40, 37.8571428 40, 37.8571428 35, 34.0476190 35)), POLYGON((30 20, 26.4285714 20, 26.4285714 23.5714285, 30 20)), POLYGON((15 40, 37.8571428 43.8095238, 37.8571428 40, 15 40)), POLYGON((45 45, 37.8571428 20, 37.8571428 43.8095238, 45 45)) ] Spark SQL example: SELECT ST_SubDivide ( ST_GeomFromText ( \"LINESTRING(0 0, 85 85, 100 100, 120 120, 21 21, 10 10, 5 5)\" ), 5 ) Output: [ LINESTRING(0 0, 5 5) LINESTRING(5 5, 10 10) LINESTRING(10 10, 21 21) LINESTRING(21 21, 60 60) LINESTRING(60 60, 85 85) LINESTRING(85 85, 100 100) LINESTRING(100 100, 120 120) ]","title":"ST_SubDivide"},{"location":"api/sql/Function/#st_subdivideexplode","text":"Introduction: It works the same as ST_SubDivide but returns new rows with geometries instead of list. Format: ST_SubDivideExplode(geom: geometry, maxVertices: int) Since: v1.1.0 Example: Query: SELECT ST_SubDivideExplode ( ST_GeomFromText ( \"LINESTRING(0 0, 85 85, 100 100, 120 120, 21 21, 10 10, 5 5)\" ), 5 ) Result: +-----------------------------+ |geom | +-----------------------------+ |LINESTRING(0 0, 5 5) | |LINESTRING(5 5, 10 10) | |LINESTRING(10 10, 21 21) | |LINESTRING(21 21, 60 60) | |LINESTRING(60 60, 85 85) | |LINESTRING(85 85, 100 100) | |LINESTRING(100 100, 120 120) | +-----------------------------+ Using Lateral View Table: +-------------------------------------------------------------+ |geometry | +-------------------------------------------------------------+ |LINESTRING(0 0, 85 85, 100 100, 120 120, 21 21, 10 10, 5 5) | +-------------------------------------------------------------+ Query select geom from geometries LATERAL VIEW ST_SubdivideExplode ( geometry , 5 ) AS geom Result: +-----------------------------+ |geom | +-----------------------------+ |LINESTRING(0 0, 5 5) | |LINESTRING(5 5, 10 10) | |LINESTRING(10 10, 21 21) | |LINESTRING(21 21, 60 60) | |LINESTRING(60 60, 85 85) | |LINESTRING(85 85, 100 100) | |LINESTRING(100 100, 120 120) | +-----------------------------+","title":"ST_SubDivideExplode"},{"location":"api/sql/Function/#st_symdifference","text":"Introduction: Return the symmetrical difference between geometry A and B (return parts of geometries which are in either of the sets, but not in their intersection) Format: ST_SymDifference (A:geometry, B:geometry) Since: v1.2.0 Example: SELECT ST_SymDifference ( ST_GeomFromWKT ( 'POLYGON ((-3 -3, 3 -3, 3 3, -3 3, -3 -3))' ), ST_GeomFromWKT ( 'POLYGON ((-2 -3, 4 -3, 4 3, -2 3, -2 -3))' )) Result: MULTIPOLYGON (((-2 -3, -3 -3, -3 3, -2 3, -2 -3)), ((3 -3, 3 3, 4 3, 4 -3, 3 -3)))","title":"ST_SymDifference"},{"location":"api/sql/Function/#st_transform","text":"Introduction: Transform the Spatial Reference System / Coordinate Reference System of A, from SourceCRS to TargetCRS. For SourceCRS and TargetCRS, WKT format is also available since v1.3.1. Note By default, this function uses lat/lon order. You can use ST_FlipCoordinates to swap X and Y. Note If ST_Transform throws an Exception called \"Bursa wolf parameters required\", you need to disable the error notification in ST_Transform. You can append a boolean value at the end. Format: ST_Transform (A:geometry, SourceCRS:string, TargetCRS:string ,[Optional] DisableError) Since: v1.0.0 Spark SQL example (simple): SELECT ST_Transform ( polygondf . countyshape , 'epsg:4326' , 'epsg:3857' ) FROM polygondf Spark SQL example (with optional parameters): SELECT ST_Transform ( polygondf . countyshape , 'epsg:4326' , 'epsg:3857' , false ) FROM polygondf Note The detailed EPSG information can be searched on EPSG.io .","title":"ST_Transform"},{"location":"api/sql/Function/#st_union","text":"Introduction: Return the union of geometry A and B Format: ST_Union (A:geometry, B:geometry) Since: v1.2.0 Example: SELECT ST_Union ( ST_GeomFromWKT ( 'POLYGON ((-3 -3, 3 -3, 3 3, -3 3, -3 -3))' ), ST_GeomFromWKT ( 'POLYGON ((1 -2, 5 0, 1 2, 1 -2))' )) Result: POLYGON ((3 -1, 3 -3, -3 -3, -3 3, 3 3, 3 1, 5 0, 3 -1))","title":"ST_Union"},{"location":"api/sql/Function/#st_x","text":"Introduction: Returns X Coordinate of given Point null otherwise. Format: ST_X(pointA: Point) Since: v1.0.0 Spark SQL example: SELECT ST_X ( ST_POINT ( 0 . 0 25 . 0 )) Output: 0.0","title":"ST_X"},{"location":"api/sql/Function/#st_xmax","text":"Introduction: Returns the maximum X coordinate of a geometry Format: ST_XMax (A:geometry) Since: v1.2.1 Example: SELECT ST_XMax ( df . geometry ) AS xmax FROM df Input: POLYGON ((-1 -11, 0 10, 1 11, 2 12, -1 -11)) Output: 2","title":"ST_XMax"},{"location":"api/sql/Function/#st_xmin","text":"Introduction: Returns the minimum X coordinate of a geometry Format: ST_XMin (A:geometry) Since: v1.2.1 Example: SELECT ST_XMin ( df . geometry ) AS xmin FROM df Input: POLYGON ((-1 -11, 0 10, 1 11, 2 12, -1 -11)) Output: -1","title":"ST_XMin"},{"location":"api/sql/Function/#st_y","text":"Introduction: Returns Y Coordinate of given Point, null otherwise. Format: ST_Y(pointA: Point) Since: v1.0.0 Spark SQL example: SELECT ST_Y ( ST_POINT ( 0 . 0 25 . 0 )) Output: 25.0","title":"ST_Y"},{"location":"api/sql/Function/#st_ymax","text":"Introduction: Return the minimum Y coordinate of A Format: ST_YMax (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_YMax ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output: 2","title":"ST_YMax"},{"location":"api/sql/Function/#st_ymin","text":"Introduction: Return the minimum Y coordinate of A Format: ST_Y_Min (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_YMin ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output : 0","title":"ST_YMin"},{"location":"api/sql/Function/#st_z","text":"Introduction: Returns Z Coordinate of given Point, null otherwise. Format: ST_Z(pointA: Point) Since: v1.2.0 Spark SQL example: SELECT ST_Z ( ST_POINT ( 0 . 0 25 . 0 11 . 0 )) Output: 11.0","title":"ST_Z"},{"location":"api/sql/Function/#st_zmax","text":"Introduction: Returns Z maxima of the given geometry or null if there is no Z coordinate. Format: ST_ZMax(geom: geometry) Since: v1.3.1 Spark SQL example: SELECT ST_ZMax ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output: 1.0","title":"ST_ZMax"},{"location":"api/sql/Function/#st_zmin","text":"Introduction: Returns Z minima of the given geometry or null if there is no Z coordinate. Format: ST_ZMin(geom: geometry) Since: v1.3.1 Spark SQL example: SELECT ST_ZMin ( ST_GeomFromText ( 'LINESTRING(1 3 4, 5 6 7)' )) Output: 4.0","title":"ST_ZMin"},{"location":"api/sql/Optimizer/","text":"SedonaSQL query optimizer \u00b6 Sedona Spatial operators fully supports Apache SparkSQL query optimizer. It has the following query optimization features: Automatically optimizes range join query and distance join query. Automatically performs predicate pushdown. Range join \u00b6 Introduction: Find geometries from A and geometries from B such that each geometry pair satisfies a certain predicate. Most predicates supported by SedonaSQL can trigger a range join. Spark SQL Example: SELECT * FROM polygondf , pointdf WHERE ST_Contains ( polygondf . polygonshape , pointdf . pointshape ) SELECT * FROM polygondf , pointdf WHERE ST_Intersects ( polygondf . polygonshape , pointdf . pointshape ) SELECT * FROM pointdf , polygondf WHERE ST_Within ( pointdf . pointshape , polygondf . polygonshape ) Spark SQL Physical plan: == Physical Plan == RangeJoin polygonshape#20: geometry, pointshape#43: geometry, false :- Project [st_polygonfromenvelope(cast(_c0#0 as decimal(24,20)), cast(_c1#1 as decimal(24,20)), cast(_c2#2 as decimal(24,20)), cast(_c3#3 as decimal(24,20)), mypolygonid) AS polygonshape#20] : +- *FileScan csv +- Project [st_point(cast(_c0#31 as decimal(24,20)), cast(_c1#32 as decimal(24,20)), myPointId) AS pointshape#43] +- *FileScan csv Note All join queries in SedonaSQL are inner joins Distance join \u00b6 Introduction: Find geometries from A and geometries from B such that the internal Euclidean distance of each geometry pair is less or equal than a certain distance Spark SQL Example: Only consider fully within a certain distance SELECT * FROM pointdf1 , pointdf2 WHERE ST_Distance ( pointdf1 . pointshape1 , pointdf2 . pointshape2 ) < 2 Consider intersects within a certain distance SELECT * FROM pointdf1 , pointdf2 WHERE ST_Distance ( pointdf1 . pointshape1 , pointdf2 . pointshape2 ) <= 2 Spark SQL Physical plan: == Physical Plan == DistanceJoin pointshape1#12: geometry, pointshape2#33: geometry, 2.0, true :- Project [st_point(cast(_c0#0 as decimal(24,20)), cast(_c1#1 as decimal(24,20)), myPointId) AS pointshape1#12] : +- *FileScan csv +- Project [st_point(cast(_c0#21 as decimal(24,20)), cast(_c1#22 as decimal(24,20)), myPointId) AS pointshape2#33] +- *FileScan csv Warning Sedona doesn't control the distance's unit (degree or meter). It is same with the geometry. To change the geometry's unit, please transform the coordinate reference system. See ST_Transform . Broadcast join \u00b6 Introduction: Perform a range join or distance join but broadcast one of the sides of the join. This maintains the partitioning of the non-broadcast side and doesn't require a shuffle. Sedona uses broadcast join only if the correct side has a broadcast hint. The supported join type - broadcast side combinations are * Inner - either side, preferring to broadcast left if both sides have the hint * Left semi - broadcast right * Left anti - broadcast right * Left outer - broadcast right * Right outer - broadcast left pointDf . alias ( \"pointDf\" ). join ( broadcast ( polygonDf ). alias ( \"polygonDf\" ), expr ( \"ST_Contains(polygonDf.polygonshape, pointDf.pointshape)\" )) Spark SQL Physical plan: == Physical Plan == BroadcastIndexJoin pointshape#52: geometry, BuildRight, BuildRight, false ST_Contains(polygonshape#30, pointshape#52) :- Project [st_point(cast(_c0#48 as decimal(24,20)), cast(_c1#49 as decimal(24,20))) AS pointshape#52] : +- FileScan csv +- SpatialIndex polygonshape#30: geometry, QUADTREE, [id=#62] +- Project [st_polygonfromenvelope(cast(_c0#22 as decimal(24,20)), cast(_c1#23 as decimal(24,20)), cast(_c2#24 as decimal(24,20)), cast(_c3#25 as decimal(24,20))) AS polygonshape#30] +- FileScan csv This also works for distance joins: pointDf1 . alias ( \"pointDf1\" ). join ( broadcast ( pointDf2 ). alias ( \"pointDf2\" ), expr ( \"ST_Distance(pointDf1.pointshape, pointDf2.pointshape) <= 2\" )) Spark SQL Physical plan: == Physical Plan == BroadcastIndexJoin pointshape#52: geometry, BuildRight, BuildLeft, true, 2.0 ST_Distance(pointshape#52, pointshape#415) <= 2.0 :- Project [st_point(cast(_c0#48 as decimal(24,20)), cast(_c1#49 as decimal(24,20))) AS pointshape#52] : +- FileScan csv +- SpatialIndex pointshape#415: geometry, QUADTREE, [id=#1068] +- Project [st_point(cast(_c0#48 as decimal(24,20)), cast(_c1#49 as decimal(24,20))) AS pointshape#415] +- FileScan csv Note: If the distance is an expression, it is only evaluated on the first argument to ST_Distance ( pointDf1 above). Predicate pushdown \u00b6 Introduction: Given a join query and a predicate in the same WHERE clause, first executes the Predicate as a filter, then executes the join query* Spark SQL Example: SELECT * FROM polygondf , pointdf WHERE ST_Contains ( polygondf . polygonshape , pointdf . pointshape ) AND ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 101 . 0 , 501 . 0 , 601 . 0 ), polygondf . polygonshape ) Spark SQL Physical plan: == Physical Plan == RangeJoin polygonshape#20: geometry, pointshape#43: geometry, false :- Project [st_polygonfromenvelope(cast(_c0#0 as decimal(24,20)), cast(_c1#1 as decimal(24,20)), cast(_c2#2 as decimal(24,20)), cast(_c3#3 as decimal(24,20)), mypolygonid) AS polygonshape#20] : +- Filter **org.apache.spark.sql.sedona_sql.expressions.ST_Contains$** : +- *FileScan csv +- Project [st_point(cast(_c0#31 as decimal(24,20)), cast(_c1#32 as decimal(24,20)), myPointId) AS pointshape#43] +- *FileScan csv","title":"Join query (optimizer)"},{"location":"api/sql/Optimizer/#sedonasql-query-optimizer","text":"Sedona Spatial operators fully supports Apache SparkSQL query optimizer. It has the following query optimization features: Automatically optimizes range join query and distance join query. Automatically performs predicate pushdown.","title":"SedonaSQL query optimizer"},{"location":"api/sql/Optimizer/#range-join","text":"Introduction: Find geometries from A and geometries from B such that each geometry pair satisfies a certain predicate. Most predicates supported by SedonaSQL can trigger a range join. Spark SQL Example: SELECT * FROM polygondf , pointdf WHERE ST_Contains ( polygondf . polygonshape , pointdf . pointshape ) SELECT * FROM polygondf , pointdf WHERE ST_Intersects ( polygondf . polygonshape , pointdf . pointshape ) SELECT * FROM pointdf , polygondf WHERE ST_Within ( pointdf . pointshape , polygondf . polygonshape ) Spark SQL Physical plan: == Physical Plan == RangeJoin polygonshape#20: geometry, pointshape#43: geometry, false :- Project [st_polygonfromenvelope(cast(_c0#0 as decimal(24,20)), cast(_c1#1 as decimal(24,20)), cast(_c2#2 as decimal(24,20)), cast(_c3#3 as decimal(24,20)), mypolygonid) AS polygonshape#20] : +- *FileScan csv +- Project [st_point(cast(_c0#31 as decimal(24,20)), cast(_c1#32 as decimal(24,20)), myPointId) AS pointshape#43] +- *FileScan csv Note All join queries in SedonaSQL are inner joins","title":"Range join"},{"location":"api/sql/Optimizer/#distance-join","text":"Introduction: Find geometries from A and geometries from B such that the internal Euclidean distance of each geometry pair is less or equal than a certain distance Spark SQL Example: Only consider fully within a certain distance SELECT * FROM pointdf1 , pointdf2 WHERE ST_Distance ( pointdf1 . pointshape1 , pointdf2 . pointshape2 ) < 2 Consider intersects within a certain distance SELECT * FROM pointdf1 , pointdf2 WHERE ST_Distance ( pointdf1 . pointshape1 , pointdf2 . pointshape2 ) <= 2 Spark SQL Physical plan: == Physical Plan == DistanceJoin pointshape1#12: geometry, pointshape2#33: geometry, 2.0, true :- Project [st_point(cast(_c0#0 as decimal(24,20)), cast(_c1#1 as decimal(24,20)), myPointId) AS pointshape1#12] : +- *FileScan csv +- Project [st_point(cast(_c0#21 as decimal(24,20)), cast(_c1#22 as decimal(24,20)), myPointId) AS pointshape2#33] +- *FileScan csv Warning Sedona doesn't control the distance's unit (degree or meter). It is same with the geometry. To change the geometry's unit, please transform the coordinate reference system. See ST_Transform .","title":"Distance join"},{"location":"api/sql/Optimizer/#broadcast-join","text":"Introduction: Perform a range join or distance join but broadcast one of the sides of the join. This maintains the partitioning of the non-broadcast side and doesn't require a shuffle. Sedona uses broadcast join only if the correct side has a broadcast hint. The supported join type - broadcast side combinations are * Inner - either side, preferring to broadcast left if both sides have the hint * Left semi - broadcast right * Left anti - broadcast right * Left outer - broadcast right * Right outer - broadcast left pointDf . alias ( \"pointDf\" ). join ( broadcast ( polygonDf ). alias ( \"polygonDf\" ), expr ( \"ST_Contains(polygonDf.polygonshape, pointDf.pointshape)\" )) Spark SQL Physical plan: == Physical Plan == BroadcastIndexJoin pointshape#52: geometry, BuildRight, BuildRight, false ST_Contains(polygonshape#30, pointshape#52) :- Project [st_point(cast(_c0#48 as decimal(24,20)), cast(_c1#49 as decimal(24,20))) AS pointshape#52] : +- FileScan csv +- SpatialIndex polygonshape#30: geometry, QUADTREE, [id=#62] +- Project [st_polygonfromenvelope(cast(_c0#22 as decimal(24,20)), cast(_c1#23 as decimal(24,20)), cast(_c2#24 as decimal(24,20)), cast(_c3#25 as decimal(24,20))) AS polygonshape#30] +- FileScan csv This also works for distance joins: pointDf1 . alias ( \"pointDf1\" ). join ( broadcast ( pointDf2 ). alias ( \"pointDf2\" ), expr ( \"ST_Distance(pointDf1.pointshape, pointDf2.pointshape) <= 2\" )) Spark SQL Physical plan: == Physical Plan == BroadcastIndexJoin pointshape#52: geometry, BuildRight, BuildLeft, true, 2.0 ST_Distance(pointshape#52, pointshape#415) <= 2.0 :- Project [st_point(cast(_c0#48 as decimal(24,20)), cast(_c1#49 as decimal(24,20))) AS pointshape#52] : +- FileScan csv +- SpatialIndex pointshape#415: geometry, QUADTREE, [id=#1068] +- Project [st_point(cast(_c0#48 as decimal(24,20)), cast(_c1#49 as decimal(24,20))) AS pointshape#415] +- FileScan csv Note: If the distance is an expression, it is only evaluated on the first argument to ST_Distance ( pointDf1 above).","title":"Broadcast join"},{"location":"api/sql/Optimizer/#predicate-pushdown","text":"Introduction: Given a join query and a predicate in the same WHERE clause, first executes the Predicate as a filter, then executes the join query* Spark SQL Example: SELECT * FROM polygondf , pointdf WHERE ST_Contains ( polygondf . polygonshape , pointdf . pointshape ) AND ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 101 . 0 , 501 . 0 , 601 . 0 ), polygondf . polygonshape ) Spark SQL Physical plan: == Physical Plan == RangeJoin polygonshape#20: geometry, pointshape#43: geometry, false :- Project [st_polygonfromenvelope(cast(_c0#0 as decimal(24,20)), cast(_c1#1 as decimal(24,20)), cast(_c2#2 as decimal(24,20)), cast(_c3#3 as decimal(24,20)), mypolygonid) AS polygonshape#20] : +- Filter **org.apache.spark.sql.sedona_sql.expressions.ST_Contains$** : +- *FileScan csv +- Project [st_point(cast(_c0#31 as decimal(24,20)), cast(_c1#32 as decimal(24,20)), myPointId) AS pointshape#43] +- *FileScan csv","title":"Predicate pushdown"},{"location":"api/sql/Overview/","text":"Introduction \u00b6 Function list \u00b6 SedonaSQL supports SQL/MM Part3 Spatial SQL Standard. It includes four kinds of SQL operators as follows. All these operators can be directly called through: var myDataFrame = sparkSession . sql ( \"YOUR_SQL\" ) Alternatively, expr and selectExpr can be used: myDataFrame . withColumn ( \"geometry\" , expr ( \"ST_*\" )). selectExpr ( \"ST_*\" ) Constructor: Construct a Geometry given an input string or coordinates Example: ST_GeomFromWKT (string). Create a Geometry from a WKT String. Documentation: Here Function: Execute a function on the given column or columns Example: ST_Distance (A, B). Given two Geometry A and B, return the Euclidean distance of A and B. Documentation: Here Aggregate function: Return the aggregated value on the given column Example: ST_Envelope_Aggr (Geometry column). Given a Geometry column, calculate the entire envelope boundary of this column. Documentation: Here Predicate: Execute a logic judgement on the given columns and return true or false Example: ST_Contains (A, B). Check if A fully contains B. Return \"True\" if yes, else return \"False\". Documentation: Here Sedona also provides an Adapter to convert SpatialRDD <-> DataFrame. Please read Adapter Scaladoc SedonaSQL supports SparkSQL query optimizer, documentation is Here Quick start \u00b6 The detailed explanation is here Write a SQL/DataFrame application . Add Sedona-core and Sedona-SQL into your project POM.xml or build.sbt Declare your Spark Session sparkSession = SparkSession . builder (). config ( \"spark.serializer\" , \"org.apache.spark.serializer.KryoSerializer\" ). config ( \"spark.kryo.registrator\" , \"org.apache.sedona.core.serde.SedonaKryoRegistrator\" ). master ( \"local[*]\" ). appName ( \"mySedonaSQLdemo\" ). getOrCreate () Add the following line after your SparkSession declaration: import org . apache . sedona . sql . utils . SedonaSQLRegistrator SedonaSQLRegistrator . registerAll ( sparkSession )","title":"Quick start"},{"location":"api/sql/Overview/#introduction","text":"","title":"Introduction"},{"location":"api/sql/Overview/#function-list","text":"SedonaSQL supports SQL/MM Part3 Spatial SQL Standard. It includes four kinds of SQL operators as follows. All these operators can be directly called through: var myDataFrame = sparkSession . sql ( \"YOUR_SQL\" ) Alternatively, expr and selectExpr can be used: myDataFrame . withColumn ( \"geometry\" , expr ( \"ST_*\" )). selectExpr ( \"ST_*\" ) Constructor: Construct a Geometry given an input string or coordinates Example: ST_GeomFromWKT (string). Create a Geometry from a WKT String. Documentation: Here Function: Execute a function on the given column or columns Example: ST_Distance (A, B). Given two Geometry A and B, return the Euclidean distance of A and B. Documentation: Here Aggregate function: Return the aggregated value on the given column Example: ST_Envelope_Aggr (Geometry column). Given a Geometry column, calculate the entire envelope boundary of this column. Documentation: Here Predicate: Execute a logic judgement on the given columns and return true or false Example: ST_Contains (A, B). Check if A fully contains B. Return \"True\" if yes, else return \"False\". Documentation: Here Sedona also provides an Adapter to convert SpatialRDD <-> DataFrame. Please read Adapter Scaladoc SedonaSQL supports SparkSQL query optimizer, documentation is Here","title":"Function list"},{"location":"api/sql/Overview/#quick-start","text":"The detailed explanation is here Write a SQL/DataFrame application . Add Sedona-core and Sedona-SQL into your project POM.xml or build.sbt Declare your Spark Session sparkSession = SparkSession . builder (). config ( \"spark.serializer\" , \"org.apache.spark.serializer.KryoSerializer\" ). config ( \"spark.kryo.registrator\" , \"org.apache.sedona.core.serde.SedonaKryoRegistrator\" ). master ( \"local[*]\" ). appName ( \"mySedonaSQLdemo\" ). getOrCreate () Add the following line after your SparkSession declaration: import org . apache . sedona . sql . utils . SedonaSQLRegistrator SedonaSQLRegistrator . registerAll ( sparkSession )","title":"Quick start"},{"location":"api/sql/Parameter/","text":"Usage \u00b6 SedonaSQL supports many parameters. To change their values, Set it through SparkConf: sparkSession = SparkSession . builder (). config ( \"spark.serializer\" , \"org.apache.spark.serializer.KryoSerializer\" ). config ( \"spark.kryo.registrator\" , \"org.apache.sedona.core.serde.SedonaKryoRegistrator\" ). config ( \"sedona.global.index\" , \"true\" ) master ( \"local[*]\" ). appName ( \"mySedonaSQLdemo\" ). getOrCreate () Check your current SedonaSQL configuration: val sedonaConf = new SedonaConf ( sparkSession . conf ) println ( sedonaConf ) Sedona parameters can be changed at runtime: sparkSession . conf . set ( \"sedona.global.index\" , \"false\" ) Explanation \u00b6 sedona.global.index Use spatial index (currently, only supports in SQL range join and SQL distance join) Default: true Possible values: true, false sedona.global.indextype Spatial index type, only valid when \"sedona.global.index\" is true Default: quadtree Possible values: rtree, quadtree sedona.join.gridtype Spatial partitioning grid type for join query Default: kdbtree Possible values: quadtree, kdbtree sedona.join.indexbuildside (Advanced users only!) The side which Sedona builds spatial indices on Default: left Possible values: left, right sedona.join.numpartition (Advanced users only!) Number of partitions for both sides in a join query Default: -1, which means use the existing partitions Possible values: any integers sedona.join.spatitionside (Advanced users only!) The dominant side in spatial partitioning stage Default: left Possible values: left, right","title":"Parameter"},{"location":"api/sql/Parameter/#usage","text":"SedonaSQL supports many parameters. To change their values, Set it through SparkConf: sparkSession = SparkSession . builder (). config ( \"spark.serializer\" , \"org.apache.spark.serializer.KryoSerializer\" ). config ( \"spark.kryo.registrator\" , \"org.apache.sedona.core.serde.SedonaKryoRegistrator\" ). config ( \"sedona.global.index\" , \"true\" ) master ( \"local[*]\" ). appName ( \"mySedonaSQLdemo\" ). getOrCreate () Check your current SedonaSQL configuration: val sedonaConf = new SedonaConf ( sparkSession . conf ) println ( sedonaConf ) Sedona parameters can be changed at runtime: sparkSession . conf . set ( \"sedona.global.index\" , \"false\" )","title":"Usage"},{"location":"api/sql/Parameter/#explanation","text":"sedona.global.index Use spatial index (currently, only supports in SQL range join and SQL distance join) Default: true Possible values: true, false sedona.global.indextype Spatial index type, only valid when \"sedona.global.index\" is true Default: quadtree Possible values: rtree, quadtree sedona.join.gridtype Spatial partitioning grid type for join query Default: kdbtree Possible values: quadtree, kdbtree sedona.join.indexbuildside (Advanced users only!) The side which Sedona builds spatial indices on Default: left Possible values: left, right sedona.join.numpartition (Advanced users only!) Number of partitions for both sides in a join query Default: -1, which means use the existing partitions Possible values: any integers sedona.join.spatitionside (Advanced users only!) The dominant side in spatial partitioning stage Default: left Possible values: left, right","title":"Explanation"},{"location":"api/sql/Predicate/","text":"ST_Contains \u00b6 Introduction: Return true if A fully contains B Format: ST_Contains (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark ) ST_Crosses \u00b6 Introduction: Return true if A crosses B Format: ST_Crosses (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Crosses ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 )) ST_Disjoint \u00b6 Introduction: Return true if A and B are disjoint Format: ST_Disjoint (A:geometry, B:geometry) Since: v1.2.1 Spark SQL example: SELECT * FROM geom WHERE ST_Disjoinnt ( geom . geom_a , geom . geom_b ) ST_Equals \u00b6 Introduction: Return true if A equals to B Format: ST_Equals (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Equals ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 )) ST_Intersects \u00b6 Introduction: Return true if A intersects B Format: ST_Intersects (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Intersects ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark ) ST_OrderingEquals \u00b6 Introduction: Returns true if the geometries are equal and the coordinates are in the same order Format: ST_OrderingEquals(A: geometry, B: geometry) Since: v1.2.1 Spark SQL example 1: SELECT ST_OrderingEquals ( ST_GeomFromWKT ( 'POLYGON((2 0, 0 2, -2 0, 2 0))' ), ST_GeomFromWKT ( 'POLYGON((2 0, 0 2, -2 0, 2 0))' )) Output: true Spark SQL example 2: SELECT ST_OrderingEquals ( ST_GeomFromWKT ( 'POLYGON((2 0, 0 2, -2 0, 2 0))' ), ST_GeomFromWKT ( 'POLYGON((0 2, -2 0, 2 0, 0 2))' )) Output: false ST_Overlaps \u00b6 Introduction: Return true if A overlaps B Format: ST_Overlaps (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM geom WHERE ST_Overlaps ( geom . geom_a , geom . geom_b ) ST_Touches \u00b6 Introduction: Return true if A touches B Format: ST_Touches (A:geometry, B:geometry) Since: v1.0.0 SELECT * FROM pointdf WHERE ST_Touches ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 )) ST_Within \u00b6 Introduction: Return true if A is fully contained by B Format: ST_Within (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Within ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 )) ST_Covers \u00b6 Introduction: Return true if A covers B Format: ST_Covers (A:geometry, B:geometry) Since: v1.3.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Covers ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark ) ST_CoveredBy \u00b6 Introduction: Return true if A is covered by B Format: ST_CoveredBy (A:geometry, B:geometry) Since: v1.3.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_CoveredBy ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"Predicate"},{"location":"api/sql/Predicate/#st_contains","text":"Introduction: Return true if A fully contains B Format: ST_Contains (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark )","title":"ST_Contains"},{"location":"api/sql/Predicate/#st_crosses","text":"Introduction: Return true if A crosses B Format: ST_Crosses (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Crosses ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"ST_Crosses"},{"location":"api/sql/Predicate/#st_disjoint","text":"Introduction: Return true if A and B are disjoint Format: ST_Disjoint (A:geometry, B:geometry) Since: v1.2.1 Spark SQL example: SELECT * FROM geom WHERE ST_Disjoinnt ( geom . geom_a , geom . geom_b )","title":"ST_Disjoint"},{"location":"api/sql/Predicate/#st_equals","text":"Introduction: Return true if A equals to B Format: ST_Equals (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Equals ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"ST_Equals"},{"location":"api/sql/Predicate/#st_intersects","text":"Introduction: Return true if A intersects B Format: ST_Intersects (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Intersects ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark )","title":"ST_Intersects"},{"location":"api/sql/Predicate/#st_orderingequals","text":"Introduction: Returns true if the geometries are equal and the coordinates are in the same order Format: ST_OrderingEquals(A: geometry, B: geometry) Since: v1.2.1 Spark SQL example 1: SELECT ST_OrderingEquals ( ST_GeomFromWKT ( 'POLYGON((2 0, 0 2, -2 0, 2 0))' ), ST_GeomFromWKT ( 'POLYGON((2 0, 0 2, -2 0, 2 0))' )) Output: true Spark SQL example 2: SELECT ST_OrderingEquals ( ST_GeomFromWKT ( 'POLYGON((2 0, 0 2, -2 0, 2 0))' ), ST_GeomFromWKT ( 'POLYGON((0 2, -2 0, 2 0, 0 2))' )) Output: false","title":"ST_OrderingEquals"},{"location":"api/sql/Predicate/#st_overlaps","text":"Introduction: Return true if A overlaps B Format: ST_Overlaps (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM geom WHERE ST_Overlaps ( geom . geom_a , geom . geom_b )","title":"ST_Overlaps"},{"location":"api/sql/Predicate/#st_touches","text":"Introduction: Return true if A touches B Format: ST_Touches (A:geometry, B:geometry) Since: v1.0.0 SELECT * FROM pointdf WHERE ST_Touches ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"ST_Touches"},{"location":"api/sql/Predicate/#st_within","text":"Introduction: Return true if A is fully contained by B Format: ST_Within (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Within ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"ST_Within"},{"location":"api/sql/Predicate/#st_covers","text":"Introduction: Return true if A covers B Format: ST_Covers (A:geometry, B:geometry) Since: v1.3.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Covers ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark )","title":"ST_Covers"},{"location":"api/sql/Predicate/#st_coveredby","text":"Introduction: Return true if A is covered by B Format: ST_CoveredBy (A:geometry, B:geometry) Since: v1.3.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_CoveredBy ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"ST_CoveredBy"},{"location":"api/sql/Raster-loader/","text":"Geotiff Dataframe Loader \u00b6 Introduction: The GeoTiff loader of Sedona is a Spark built-in data source. It can read a single geotiff image or a number of geotiff images into a DataFrame. Since: v1.1.0 Spark SQL example: The input path could be a path to a single GeoTiff image or a directory of GeoTiff images. You can optionally append an option to drop invalid images. The geometry bound of each image is automatically loaded as a Sedona geometry and is transformed to WGS84 (EPSG:4326) reference system. var geotiffDF = sparkSession . read . format ( \"geotiff\" ). option ( \"dropInvalid\" , true ). load ( \"YOUR_PATH\" ) geotiffDF . printSchema () Output: |-- image: struct (nullable = true) | |-- origin: string (nullable = true) | |-- Geometry: geometry (nullable = true) | |-- height: integer (nullable = true) | |-- width: integer (nullable = true) | |-- nBands: integer (nullable = true) | |-- data: array (nullable = true) | | |-- element: double (containsNull = true) There are three more optional parameters for reading GeoTiff: |-- readfromCRS: Coordinate reference system of the geometry coordinates representing the location of the Geotiff. An example value of readfromCRS is EPSG:4326. |-- readToCRS: If you want to tranform the Geotiff location geometry coordinates to a different coordinate reference system, you can define the target coordinate reference system with this option. |-- disableErrorInCRS: (Default value false) => Indicates whether to ignore errors in CRS transformation. An example with all GeoTiff read options: var geotiffDF = sparkSession . read . format ( \"geotiff\" ). option ( \"dropInvalid\" , true ). option ( \"readFromCRS\" , \"EPSG:4499\" ). option ( \"readToCRS\" , \"EPSG:4326\" ). option ( \"disableErrorInCRS\" , true ). load ( \"YOUR_PATH\" ) geotiffDF . printSchema () Output: |-- image: struct (nullable = true) | |-- origin: string (nullable = true) | |-- Geometry: geometry (nullable = true) | |-- height: integer (nullable = true) | |-- width: integer (nullable = true) | |-- nBands: integer (nullable = true) | |-- data: array (nullable = true) | | |-- element: double (containsNull = true) You can also select sub-attributes individually to construct a new DataFrame geotiffDF = geotiffDF . selectExpr ( \"image.origin as origin\" , \"ST_GeomFromWkt(image.geometry) as Geom\" , \"image.height as height\" , \"image.width as width\" , \"image.data as data\" , \"image.nBands as bands\" ) geotiffDF . createOrReplaceTempView ( \"GeotiffDataframe\" ) geotiffDF . show () Output: +--------------------+--------------------+------+-----+--------------------+-----+ | origin| Geom|height|width| data|bands| +--------------------+--------------------+------+-----+--------------------+-----+ |file:///home/hp/D...|POLYGON ((-58.699...| 32| 32|[1058.0, 1039.0, ...| 4| |file:///home/hp/D...|POLYGON ((-58.297...| 32| 32|[1258.0, 1298.0, ...| 4| +--------------------+--------------------+------+-----+--------------------+-----+ Geotiff Dataframe Writer \u00b6 Introduction: You can write a GeoTiff dataframe as GeoTiff images using the spark write feature with the format geotiff . Since: v1.2.1 Spark SQL example: The schema of the GeoTiff dataframe to be written can be one of the following two schemas: |-- image: struct (nullable = true) | |-- origin: string (nullable = true) | |-- Geometry: geometry (nullable = true) | |-- height: integer (nullable = true) | |-- width: integer (nullable = true) | |-- nBands: integer (nullable = true) | |-- data: array (nullable = true) | | |-- element: double (containsNull = true) or |-- origin: string (nullable = true) |-- Geometry: geometry (nullable = true) |-- height: integer (nullable = true) |-- width: integer (nullable = true) |-- nBands: integer (nullable = true) |-- data: array (nullable = true) | |-- element: double (containsNull = true) Field names can be renamed, but schema should exactly match with one of the above two schemas. The output path could be a path to a directory where GeoTiff images will be saved. If the directory already exists, write should be called in overwrite mode. var dfToWrite = sparkSession . read . format ( \"geotiff\" ). option ( \"dropInvalid\" , true ). option ( \"readToCRS\" , \"EPSG:4326\" ). load ( \"PATH_TO_INPUT_GEOTIFF_IMAGES\" ) dfToWrite . write . format ( \"geotiff\" ). save ( \"DESTINATION_PATH\" ) You can override an existing path with the following approach: dfToWrite . write . mode ( \"overwrite\" ). format ( \"geotiff\" ). save ( \"DESTINATION_PATH\" ) You can also extract the columns nested within image column and write the dataframe as GeoTiff image. dfToWrite = dfToWrite . selectExpr ( \"image.origin as origin\" , \"image.geometry as geometry\" , \"image.height as height\" , \"image.width as width\" , \"image.data as data\" , \"image.nBands as nBands\" ) dfToWrite . write . mode ( \"overwrite\" ). format ( \"geotiff\" ). save ( \"DESTINATION_PATH\" ) If you want the saved GeoTiff images not to be distributed into multiple partitions, you can call coalesce to merge all files in a single partition. dfToWrite . coalesce ( 1 ). write . mode ( \"overwrite\" ). format ( \"geotiff\" ). save ( \"DESTINATION_PATH\" ) In case, you rename the columns of GeoTiff dataframe, you can set the corresponding column names with the option parameter. All available optional parameters are listed below: |-- writeToCRS: (Default value \"EPSG:4326\") => Coordinate reference system of the geometry coordinates representing the location of the Geotiff. |-- fieldImage: (Default value \"image\") => Indicates the image column of GeoTiff DataFrame. |-- fieldOrigin: (Default value \"origin\") => Indicates the origin column of GeoTiff DataFrame. |-- fieldNBands: (Default value \"nBands\") => Indicates the nBands column of GeoTiff DataFrame. |-- fieldWidth: (Default value \"width\") => Indicates the width column of GeoTiff DataFrame. |-- fieldHeight: (Default value \"height\") => Indicates the height column of GeoTiff DataFrame. |-- fieldGeometry: (Default value \"geometry\") => Indicates the geometry column of GeoTiff DataFrame. |-- fieldData: (Default value \"data\") => Indicates the data column of GeoTiff DataFrame. An example: dfToWrite = sparkSession . read . format ( \"geotiff\" ). option ( \"dropInvalid\" , true ). option ( \"readToCRS\" , \"EPSG:4326\" ). load ( \"PATH_TO_INPUT_GEOTIFF_IMAGES\" ) dfToWrite = dfToWrite . selectExpr ( \"image.origin as source\" , \"ST_GeomFromWkt(image.geometry) as geom\" , \"image.height as height\" , \"image.width as width\" , \"image.data as data\" , \"image.nBands as bands\" ) dfToWrite . write . mode ( \"overwrite\" ). format ( \"geotiff\" ). option ( \"writeToCRS\" , \"EPSG:4326\" ). option ( \"fieldOrigin\" , \"source\" ). option ( \"fieldGeometry\" , \"geom\" ). option ( \"fieldNBands\" , \"bands\" ). save ( \"DESTINATION_PATH\" ) RS_Array \u00b6 Introduction: Create an array that is filled by the given value Format: RS_Array(length:Int, value: Decimal) Since: v1.1.0 Spark SQL example: SELECT RS_Array ( height * width , 0.0 ) RS_Base64 \u00b6 Introduction: Return a Base64 String from a geotiff image Format: RS_Base64 (height:Int, width:Int, redBand: Array[Double], greenBand: Array[Double], blackBand: Array[Double], optional: alphaBand: Array[Double]) Since: v1.1.0 Spark SQL example: val BandDF = spark . sql ( \"select RS_Base64(h, w, band1, band2, RS_Array(h*w, 0)) as baseString from dataframe\" ) BandDF . show () Output: +--------------------+ | baseString| +--------------------+ |QJCIAAAAAABAkDwAA...| |QJOoAAAAAABAlEgAA...| +--------------------+ Note Although the 3 RGB bands are mandatory, you can use RS_Array(h*w, 0.0) to create an array (zeroed out, size = h * w) as input. RS_GetBand \u00b6 Introduction: Return a particular band from Geotiff Dataframe The number of total bands can be obtained from the GeoTiff loader Format: RS_GetBand (allBandValues: Array[Double], targetBand:Int, totalBands:Int) Since: v1.1.0 Note Index of targetBand starts from 1 (instead of 0). Index of the first band is 1. Spark SQL example: val BandDF = spark . sql ( \"select RS_GetBand(data, 2, Band) as targetBand from GeotiffDataframe\" ) BandDF . show () Output: +--------------------+ | targetBand| +--------------------+ |[1058.0, 1039.0, ...| |[1258.0, 1298.0, ...| +--------------------+ RS_HTML \u00b6 Introduction: Return a html img tag with the base64 string embedded Format: RS_HTML(base64:String, optional: width_in_px:String) Spark SQL example: df . selectExpr ( \"RS_HTML(encodedstring, '300') as htmlstring\" ). show () Output: +--------------------+ | htmlstring| +--------------------+ | < img src = \"data:im...| |<img src=\" data:im ...| + -------------------- +","title":"Raster input and output"},{"location":"api/sql/Raster-loader/#geotiff-dataframe-loader","text":"Introduction: The GeoTiff loader of Sedona is a Spark built-in data source. It can read a single geotiff image or a number of geotiff images into a DataFrame. Since: v1.1.0 Spark SQL example: The input path could be a path to a single GeoTiff image or a directory of GeoTiff images. You can optionally append an option to drop invalid images. The geometry bound of each image is automatically loaded as a Sedona geometry and is transformed to WGS84 (EPSG:4326) reference system. var geotiffDF = sparkSession . read . format ( \"geotiff\" ). option ( \"dropInvalid\" , true ). load ( \"YOUR_PATH\" ) geotiffDF . printSchema () Output: |-- image: struct (nullable = true) | |-- origin: string (nullable = true) | |-- Geometry: geometry (nullable = true) | |-- height: integer (nullable = true) | |-- width: integer (nullable = true) | |-- nBands: integer (nullable = true) | |-- data: array (nullable = true) | | |-- element: double (containsNull = true) There are three more optional parameters for reading GeoTiff: |-- readfromCRS: Coordinate reference system of the geometry coordinates representing the location of the Geotiff. An example value of readfromCRS is EPSG:4326. |-- readToCRS: If you want to tranform the Geotiff location geometry coordinates to a different coordinate reference system, you can define the target coordinate reference system with this option. |-- disableErrorInCRS: (Default value false) => Indicates whether to ignore errors in CRS transformation. An example with all GeoTiff read options: var geotiffDF = sparkSession . read . format ( \"geotiff\" ). option ( \"dropInvalid\" , true ). option ( \"readFromCRS\" , \"EPSG:4499\" ). option ( \"readToCRS\" , \"EPSG:4326\" ). option ( \"disableErrorInCRS\" , true ). load ( \"YOUR_PATH\" ) geotiffDF . printSchema () Output: |-- image: struct (nullable = true) | |-- origin: string (nullable = true) | |-- Geometry: geometry (nullable = true) | |-- height: integer (nullable = true) | |-- width: integer (nullable = true) | |-- nBands: integer (nullable = true) | |-- data: array (nullable = true) | | |-- element: double (containsNull = true) You can also select sub-attributes individually to construct a new DataFrame geotiffDF = geotiffDF . selectExpr ( \"image.origin as origin\" , \"ST_GeomFromWkt(image.geometry) as Geom\" , \"image.height as height\" , \"image.width as width\" , \"image.data as data\" , \"image.nBands as bands\" ) geotiffDF . createOrReplaceTempView ( \"GeotiffDataframe\" ) geotiffDF . show () Output: +--------------------+--------------------+------+-----+--------------------+-----+ | origin| Geom|height|width| data|bands| +--------------------+--------------------+------+-----+--------------------+-----+ |file:///home/hp/D...|POLYGON ((-58.699...| 32| 32|[1058.0, 1039.0, ...| 4| |file:///home/hp/D...|POLYGON ((-58.297...| 32| 32|[1258.0, 1298.0, ...| 4| +--------------------+--------------------+------+-----+--------------------+-----+","title":"Geotiff Dataframe Loader"},{"location":"api/sql/Raster-loader/#geotiff-dataframe-writer","text":"Introduction: You can write a GeoTiff dataframe as GeoTiff images using the spark write feature with the format geotiff . Since: v1.2.1 Spark SQL example: The schema of the GeoTiff dataframe to be written can be one of the following two schemas: |-- image: struct (nullable = true) | |-- origin: string (nullable = true) | |-- Geometry: geometry (nullable = true) | |-- height: integer (nullable = true) | |-- width: integer (nullable = true) | |-- nBands: integer (nullable = true) | |-- data: array (nullable = true) | | |-- element: double (containsNull = true) or |-- origin: string (nullable = true) |-- Geometry: geometry (nullable = true) |-- height: integer (nullable = true) |-- width: integer (nullable = true) |-- nBands: integer (nullable = true) |-- data: array (nullable = true) | |-- element: double (containsNull = true) Field names can be renamed, but schema should exactly match with one of the above two schemas. The output path could be a path to a directory where GeoTiff images will be saved. If the directory already exists, write should be called in overwrite mode. var dfToWrite = sparkSession . read . format ( \"geotiff\" ). option ( \"dropInvalid\" , true ). option ( \"readToCRS\" , \"EPSG:4326\" ). load ( \"PATH_TO_INPUT_GEOTIFF_IMAGES\" ) dfToWrite . write . format ( \"geotiff\" ). save ( \"DESTINATION_PATH\" ) You can override an existing path with the following approach: dfToWrite . write . mode ( \"overwrite\" ). format ( \"geotiff\" ). save ( \"DESTINATION_PATH\" ) You can also extract the columns nested within image column and write the dataframe as GeoTiff image. dfToWrite = dfToWrite . selectExpr ( \"image.origin as origin\" , \"image.geometry as geometry\" , \"image.height as height\" , \"image.width as width\" , \"image.data as data\" , \"image.nBands as nBands\" ) dfToWrite . write . mode ( \"overwrite\" ). format ( \"geotiff\" ). save ( \"DESTINATION_PATH\" ) If you want the saved GeoTiff images not to be distributed into multiple partitions, you can call coalesce to merge all files in a single partition. dfToWrite . coalesce ( 1 ). write . mode ( \"overwrite\" ). format ( \"geotiff\" ). save ( \"DESTINATION_PATH\" ) In case, you rename the columns of GeoTiff dataframe, you can set the corresponding column names with the option parameter. All available optional parameters are listed below: |-- writeToCRS: (Default value \"EPSG:4326\") => Coordinate reference system of the geometry coordinates representing the location of the Geotiff. |-- fieldImage: (Default value \"image\") => Indicates the image column of GeoTiff DataFrame. |-- fieldOrigin: (Default value \"origin\") => Indicates the origin column of GeoTiff DataFrame. |-- fieldNBands: (Default value \"nBands\") => Indicates the nBands column of GeoTiff DataFrame. |-- fieldWidth: (Default value \"width\") => Indicates the width column of GeoTiff DataFrame. |-- fieldHeight: (Default value \"height\") => Indicates the height column of GeoTiff DataFrame. |-- fieldGeometry: (Default value \"geometry\") => Indicates the geometry column of GeoTiff DataFrame. |-- fieldData: (Default value \"data\") => Indicates the data column of GeoTiff DataFrame. An example: dfToWrite = sparkSession . read . format ( \"geotiff\" ). option ( \"dropInvalid\" , true ). option ( \"readToCRS\" , \"EPSG:4326\" ). load ( \"PATH_TO_INPUT_GEOTIFF_IMAGES\" ) dfToWrite = dfToWrite . selectExpr ( \"image.origin as source\" , \"ST_GeomFromWkt(image.geometry) as geom\" , \"image.height as height\" , \"image.width as width\" , \"image.data as data\" , \"image.nBands as bands\" ) dfToWrite . write . mode ( \"overwrite\" ). format ( \"geotiff\" ). option ( \"writeToCRS\" , \"EPSG:4326\" ). option ( \"fieldOrigin\" , \"source\" ). option ( \"fieldGeometry\" , \"geom\" ). option ( \"fieldNBands\" , \"bands\" ). save ( \"DESTINATION_PATH\" )","title":"Geotiff Dataframe Writer"},{"location":"api/sql/Raster-loader/#rs_array","text":"Introduction: Create an array that is filled by the given value Format: RS_Array(length:Int, value: Decimal) Since: v1.1.0 Spark SQL example: SELECT RS_Array ( height * width , 0.0 )","title":"RS_Array"},{"location":"api/sql/Raster-loader/#rs_base64","text":"Introduction: Return a Base64 String from a geotiff image Format: RS_Base64 (height:Int, width:Int, redBand: Array[Double], greenBand: Array[Double], blackBand: Array[Double], optional: alphaBand: Array[Double]) Since: v1.1.0 Spark SQL example: val BandDF = spark . sql ( \"select RS_Base64(h, w, band1, band2, RS_Array(h*w, 0)) as baseString from dataframe\" ) BandDF . show () Output: +--------------------+ | baseString| +--------------------+ |QJCIAAAAAABAkDwAA...| |QJOoAAAAAABAlEgAA...| +--------------------+ Note Although the 3 RGB bands are mandatory, you can use RS_Array(h*w, 0.0) to create an array (zeroed out, size = h * w) as input.","title":"RS_Base64"},{"location":"api/sql/Raster-loader/#rs_getband","text":"Introduction: Return a particular band from Geotiff Dataframe The number of total bands can be obtained from the GeoTiff loader Format: RS_GetBand (allBandValues: Array[Double], targetBand:Int, totalBands:Int) Since: v1.1.0 Note Index of targetBand starts from 1 (instead of 0). Index of the first band is 1. Spark SQL example: val BandDF = spark . sql ( \"select RS_GetBand(data, 2, Band) as targetBand from GeotiffDataframe\" ) BandDF . show () Output: +--------------------+ | targetBand| +--------------------+ |[1058.0, 1039.0, ...| |[1258.0, 1298.0, ...| +--------------------+","title":"RS_GetBand"},{"location":"api/sql/Raster-loader/#rs_html","text":"Introduction: Return a html img tag with the base64 string embedded Format: RS_HTML(base64:String, optional: width_in_px:String) Spark SQL example: df . selectExpr ( \"RS_HTML(encodedstring, '300') as htmlstring\" ). show () Output: +--------------------+ | htmlstring| +--------------------+ | < img src = \"data:im...| |<img src=\" data:im ...| + -------------------- +","title":"RS_HTML"},{"location":"api/sql/Raster-operators/","text":"RS_Add \u00b6 Introduction: Add two spectral bands in a Geotiff image Format: RS_Add (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val sumDF = spark . sql ( \"select RS_Add(band1, band2) as sumOfBands from dataframe\" ) RS_Append \u00b6 Introduction: Appends a new band to the end of Geotiff image data and returns the new data. The new band to be appended can be a normalized difference index between two bands (example: NBR, NDBI). Normalized difference index between two bands can be calculated with RS_NormalizedDifference operator described earlier in this page. Specific bands can be retrieved using RS_GetBand operator described here . Format: RS_Append(data: Array[Double], newBand: Array[Double], nBands: Int) Since: v1.2.1 Spark SQL example: val dfAppended = spark . sql ( \"select RS_Append(data, normalizedDifference, nBands) as dataEdited from dataframe\" ) RS_BitwiseAND \u00b6 Introduction: Find Bitwise AND between two bands of Geotiff image Format: RS_BitwiseAND (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val biwiseandDF = spark . sql ( \"select RS_BitwiseAND(band1, band2) as andvalue from dataframe\" ) RS_BitwiseOR \u00b6 Introduction: Find Bitwise OR between two bands of Geotiff image Format: RS_BitwiseOR (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val biwiseorDF = spark . sql ( \"select RS_BitwiseOR(band1, band2) as or from dataframe\" ) RS_Count \u00b6 Introduction: Returns count of a particular value from a spectral band in a raster image Format: RS_Count (Band1: Array[Double], Target: Double) Since: v1.1.0 Spark SQL example: val countDF = spark . sql ( \"select RS_Count(band1, target) as count from dataframe\" ) RS_Divide \u00b6 Introduction: Divide band1 with band2 from a geotiff image Format: RS_Divide (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val multiplyDF = spark . sql ( \"select RS_Divide(band1, band2) as divideBands from dataframe\" ) RS_FetchRegion \u00b6 Introduction: Fetch a subset of region from given Geotiff image based on minimumX, minimumY, maximumX and maximumY index as well original height and width of image Format: RS_FetchRegion (Band: Array[Double], coordinates: Array[Int], dimenstions: Array[Int]) Since: v1.1.0 Spark SQL example: val region = spark . sql ( \"select RS_FetchRegion(Band,Array(0, 0, 1, 2),Array(3, 3)) as Region from dataframe\" ) RS_GreaterThan \u00b6 Introduction: Mask all the values with 1 which are greater than a particular target value Format: RS_GreaterThan (Band: Array[Double], Target: Double) Since: v1.1.0 Spark SQL example: val greaterDF = spark . sql ( \"select RS_GreaterThan(band, target) as maskedvalues from dataframe\" ) RS_GreaterThanEqual \u00b6 Introduction: Mask all the values with 1 which are greater than equal to a particular target value Format: RS_GreaterThanEqual (Band: Array[Double], Target: Double) Since: v1.1.0 Spark SQL example: val greaterEqualDF = spark . sql ( \"select RS_GreaterThanEqual(band, target) as maskedvalues from dataframe\" ) RS_LessThan \u00b6 Introduction: Mask all the values with 1 which are less than a particular target value Format: RS_LessThan (Band: Array[Double], Target: Double) Since: v1.1.0 Spark SQL example: val lessDF = spark . sql ( \"select RS_LessThan(band, target) as maskedvalues from dataframe\" ) RS_LessThanEqual \u00b6 Introduction: Mask all the values with 1 which are less than equal to a particular target value Format: RS_LessThanEqual (Band: Array[Double], Target: Double) Since: v1.1.0 Spark SQL example: val lessEqualDF = spark . sql ( \"select RS_LessThanEqual(band, target) as maskedvalues from dataframe\" ) RS_LogicalDifference \u00b6 Introduction: Return value from band 1 if a value in band1 and band2 are different, else return 0 Format: RS_LogicalDifference (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val logicalDifference = spark . sql ( \"select RS_LogicalDifference(band1, band2) as logdifference from dataframe\" ) RS_LogicalOver \u00b6 Introduction: Return value from band1 if it's not equal to 0, else return band2 value Format: RS_LogicalOver (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val logicalOver = spark . sql ( \"select RS_LogicalOver(band1, band2) as logover from dataframe\" ) RS_Mean \u00b6 Introduction: Returns Mean value for a spectral band in a Geotiff image Format: RS_Mean (Band: Array[Double]) Since: v1.1.0 Spark SQL example: val meanDF = spark . sql ( \"select RS_Mean(band) as mean from dataframe\" ) RS_Mode \u00b6 Introduction: Returns Mode from a spectral band in a Geotiff image in form of an array Format: RS_Mode (Band: Array[Double]) Since: v1.1.0 Spark SQL example: val modeDF = spark . sql ( \"select RS_Mode(band) as mode from dataframe\" ) RS_Modulo \u00b6 Introduction: Find modulo of pixels with respect to a particular value Format: RS_Modulo (Band: Array[Double], Target: Double) Since: v1.1.0 Spark SQL example: val moduloDF = spark . sql ( \"select RS_Modulo(band, target) as modulo from dataframe\" ) RS_Multiply \u00b6 Introduction: Multiply two spectral bands in a Geotiff image Format: RS_Multiply (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val multiplyDF = spark . sql ( \"select RS_Multiply(band1, band2) as multiplyBands from dataframe\" ) RS_MultiplyFactor \u00b6 Introduction: Multiply a factor to a spectral band in a geotiff image Format: RS_MultiplyFactor (Band1: Array[Double], Factor: Int) Since: v1.1.0 Spark SQL example: val multiplyFactorDF = spark . sql ( \"select RS_MultiplyFactor(band1, 2) as multiplyfactor from dataframe\" ) RS_Normalize \u00b6 Introduction: Normalize the value in the array to [0, 255] Since: v1.1.0 Spark SQL example SELECT RS_Normalize ( band ) RS_NormalizedDifference \u00b6 Introduction: Returns Normalized Difference between two bands(band2 and band1) in a Geotiff image(example: NDVI, NDBI) Format: RS_NormalizedDifference (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val normalizedDF = spark . sql ( \"select RS_NormalizedDifference(band1, band2) as normdifference from dataframe\" ) RS_SquareRoot \u00b6 Introduction: Find Square root of band values in a geotiff image Format: RS_SquareRoot (Band: Array[Double]) Since: v1.1.0 Spark SQL example: val rootDF = spark . sql ( \"select RS_SquareRoot(band) as squareroot from dataframe\" ) RS_Subtract \u00b6 Introduction: Subtract two spectral bands in a Geotiff image(band2 - band1) Format: RS_Subtract (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val subtractDF = spark . sql ( \"select RS_Subtract(band1, band2) as differenceOfOfBands from dataframe\" )","title":"Raster operators"},{"location":"api/sql/Raster-operators/#rs_add","text":"Introduction: Add two spectral bands in a Geotiff image Format: RS_Add (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val sumDF = spark . sql ( \"select RS_Add(band1, band2) as sumOfBands from dataframe\" )","title":"RS_Add"},{"location":"api/sql/Raster-operators/#rs_append","text":"Introduction: Appends a new band to the end of Geotiff image data and returns the new data. The new band to be appended can be a normalized difference index between two bands (example: NBR, NDBI). Normalized difference index between two bands can be calculated with RS_NormalizedDifference operator described earlier in this page. Specific bands can be retrieved using RS_GetBand operator described here . Format: RS_Append(data: Array[Double], newBand: Array[Double], nBands: Int) Since: v1.2.1 Spark SQL example: val dfAppended = spark . sql ( \"select RS_Append(data, normalizedDifference, nBands) as dataEdited from dataframe\" )","title":"RS_Append"},{"location":"api/sql/Raster-operators/#rs_bitwiseand","text":"Introduction: Find Bitwise AND between two bands of Geotiff image Format: RS_BitwiseAND (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val biwiseandDF = spark . sql ( \"select RS_BitwiseAND(band1, band2) as andvalue from dataframe\" )","title":"RS_BitwiseAND"},{"location":"api/sql/Raster-operators/#rs_bitwiseor","text":"Introduction: Find Bitwise OR between two bands of Geotiff image Format: RS_BitwiseOR (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val biwiseorDF = spark . sql ( \"select RS_BitwiseOR(band1, band2) as or from dataframe\" )","title":"RS_BitwiseOR"},{"location":"api/sql/Raster-operators/#rs_count","text":"Introduction: Returns count of a particular value from a spectral band in a raster image Format: RS_Count (Band1: Array[Double], Target: Double) Since: v1.1.0 Spark SQL example: val countDF = spark . sql ( \"select RS_Count(band1, target) as count from dataframe\" )","title":"RS_Count"},{"location":"api/sql/Raster-operators/#rs_divide","text":"Introduction: Divide band1 with band2 from a geotiff image Format: RS_Divide (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val multiplyDF = spark . sql ( \"select RS_Divide(band1, band2) as divideBands from dataframe\" )","title":"RS_Divide"},{"location":"api/sql/Raster-operators/#rs_fetchregion","text":"Introduction: Fetch a subset of region from given Geotiff image based on minimumX, minimumY, maximumX and maximumY index as well original height and width of image Format: RS_FetchRegion (Band: Array[Double], coordinates: Array[Int], dimenstions: Array[Int]) Since: v1.1.0 Spark SQL example: val region = spark . sql ( \"select RS_FetchRegion(Band,Array(0, 0, 1, 2),Array(3, 3)) as Region from dataframe\" )","title":"RS_FetchRegion"},{"location":"api/sql/Raster-operators/#rs_greaterthan","text":"Introduction: Mask all the values with 1 which are greater than a particular target value Format: RS_GreaterThan (Band: Array[Double], Target: Double) Since: v1.1.0 Spark SQL example: val greaterDF = spark . sql ( \"select RS_GreaterThan(band, target) as maskedvalues from dataframe\" )","title":"RS_GreaterThan"},{"location":"api/sql/Raster-operators/#rs_greaterthanequal","text":"Introduction: Mask all the values with 1 which are greater than equal to a particular target value Format: RS_GreaterThanEqual (Band: Array[Double], Target: Double) Since: v1.1.0 Spark SQL example: val greaterEqualDF = spark . sql ( \"select RS_GreaterThanEqual(band, target) as maskedvalues from dataframe\" )","title":"RS_GreaterThanEqual"},{"location":"api/sql/Raster-operators/#rs_lessthan","text":"Introduction: Mask all the values with 1 which are less than a particular target value Format: RS_LessThan (Band: Array[Double], Target: Double) Since: v1.1.0 Spark SQL example: val lessDF = spark . sql ( \"select RS_LessThan(band, target) as maskedvalues from dataframe\" )","title":"RS_LessThan"},{"location":"api/sql/Raster-operators/#rs_lessthanequal","text":"Introduction: Mask all the values with 1 which are less than equal to a particular target value Format: RS_LessThanEqual (Band: Array[Double], Target: Double) Since: v1.1.0 Spark SQL example: val lessEqualDF = spark . sql ( \"select RS_LessThanEqual(band, target) as maskedvalues from dataframe\" )","title":"RS_LessThanEqual"},{"location":"api/sql/Raster-operators/#rs_logicaldifference","text":"Introduction: Return value from band 1 if a value in band1 and band2 are different, else return 0 Format: RS_LogicalDifference (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val logicalDifference = spark . sql ( \"select RS_LogicalDifference(band1, band2) as logdifference from dataframe\" )","title":"RS_LogicalDifference"},{"location":"api/sql/Raster-operators/#rs_logicalover","text":"Introduction: Return value from band1 if it's not equal to 0, else return band2 value Format: RS_LogicalOver (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val logicalOver = spark . sql ( \"select RS_LogicalOver(band1, band2) as logover from dataframe\" )","title":"RS_LogicalOver"},{"location":"api/sql/Raster-operators/#rs_mean","text":"Introduction: Returns Mean value for a spectral band in a Geotiff image Format: RS_Mean (Band: Array[Double]) Since: v1.1.0 Spark SQL example: val meanDF = spark . sql ( \"select RS_Mean(band) as mean from dataframe\" )","title":"RS_Mean"},{"location":"api/sql/Raster-operators/#rs_mode","text":"Introduction: Returns Mode from a spectral band in a Geotiff image in form of an array Format: RS_Mode (Band: Array[Double]) Since: v1.1.0 Spark SQL example: val modeDF = spark . sql ( \"select RS_Mode(band) as mode from dataframe\" )","title":"RS_Mode"},{"location":"api/sql/Raster-operators/#rs_modulo","text":"Introduction: Find modulo of pixels with respect to a particular value Format: RS_Modulo (Band: Array[Double], Target: Double) Since: v1.1.0 Spark SQL example: val moduloDF = spark . sql ( \"select RS_Modulo(band, target) as modulo from dataframe\" )","title":"RS_Modulo"},{"location":"api/sql/Raster-operators/#rs_multiply","text":"Introduction: Multiply two spectral bands in a Geotiff image Format: RS_Multiply (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val multiplyDF = spark . sql ( \"select RS_Multiply(band1, band2) as multiplyBands from dataframe\" )","title":"RS_Multiply"},{"location":"api/sql/Raster-operators/#rs_multiplyfactor","text":"Introduction: Multiply a factor to a spectral band in a geotiff image Format: RS_MultiplyFactor (Band1: Array[Double], Factor: Int) Since: v1.1.0 Spark SQL example: val multiplyFactorDF = spark . sql ( \"select RS_MultiplyFactor(band1, 2) as multiplyfactor from dataframe\" )","title":"RS_MultiplyFactor"},{"location":"api/sql/Raster-operators/#rs_normalize","text":"Introduction: Normalize the value in the array to [0, 255] Since: v1.1.0 Spark SQL example SELECT RS_Normalize ( band )","title":"RS_Normalize"},{"location":"api/sql/Raster-operators/#rs_normalizeddifference","text":"Introduction: Returns Normalized Difference between two bands(band2 and band1) in a Geotiff image(example: NDVI, NDBI) Format: RS_NormalizedDifference (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val normalizedDF = spark . sql ( \"select RS_NormalizedDifference(band1, band2) as normdifference from dataframe\" )","title":"RS_NormalizedDifference"},{"location":"api/sql/Raster-operators/#rs_squareroot","text":"Introduction: Find Square root of band values in a geotiff image Format: RS_SquareRoot (Band: Array[Double]) Since: v1.1.0 Spark SQL example: val rootDF = spark . sql ( \"select RS_SquareRoot(band) as squareroot from dataframe\" )","title":"RS_SquareRoot"},{"location":"api/sql/Raster-operators/#rs_subtract","text":"Introduction: Subtract two spectral bands in a Geotiff image(band2 - band1) Format: RS_Subtract (Band1: Array[Double], Band2: Array[Double]) Since: v1.1.0 Spark SQL example: val subtractDF = spark . sql ( \"select RS_Subtract(band1, band2) as differenceOfOfBands from dataframe\" )","title":"RS_Subtract"},{"location":"api/viz/java-api/","text":"Please read Javadoc Note: Scala can call Java APIs seamlessly. That means Scala users use the same APIs with Java users","title":"RDD"},{"location":"api/viz/sql/","text":"Quick start \u00b6 The detailed explanation is here: Visualize Spatial DataFrame/RDD . Add Sedona-core, Sedona-SQL,Sedona-Viz into your project POM.xml or build.sbt Declare your Spark Session sparkSession = SparkSession . builder (). config ( \"spark.serializer\" , \"org.apache.spark.serializer.KryoSerializer\" ). config ( \"spark.kryo.registrator\" , \"org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator\" ). master ( \"local[*]\" ). appName ( \"mySedonaVizDemo\" ). getOrCreate () Add the following lines after your SparkSession declaration: SedonaSQLRegistrator . registerAll ( sparkSession ) SedonaVizRegistrator . registerAll ( sparkSession ) Regular functions \u00b6 ST_Colorize \u00b6 Introduction: Given the weight of a pixel, return the corresponding color. The weight can be the spatial aggregation of spatial objects or spatial observations such as temperature and humidity. Note The color is encoded to an Integer type value in DataFrame. When you print it, it will show some nonsense values. You can just treat them as colors in GeoSparkViz. Format: ST_Colorize (weight:Double, maxWeight:Double, mandatory color: string (Optional)) Since: v1.0.0 Produce various colors - heat map This function will normalize the weight according to the max weight among all pixels. Different pixel obtains different color. Spark SQL example: SELECT pixels . px , ST_Colorize ( pixels . weight , 999 ) AS color FROM pixels Produce uniform colors - scatter plot If a mandatory color name is put as the third input argument, this function will directly ouput this color, without considering the weights. In this case, every pixel will possess the same color. Spark SQL example: SELECT pixels . px , ST_Colorize ( pixels . weight , 999 , 'red' ) AS color FROM pixels Here are some example color names can be entered: \"firebrick\" \"#aa38e0\" \"0x40A8CC\" \"rgba(112,36,228,0.9)\" Please refer to AWT Colors for a list of pre-defined colors. ST_EncodeImage \u00b6 Introduction: Return the base64 string representation of a Java PNG BufferedImage. This is specific for the server-client environment. For example, transfer the base64 string from GeoSparkViz to Apache Zeppelin. Format: ST_EncodeImage (A:image) Since: v1.0.0 Spark SQL example: SELECT ST_EncodeImage ( images . img ) FROM images ST_Pixelize \u00b6 Introduction: Convert a geometry to an array of pixels given a resolution You should use it together with Lateral View and Explode Format: ST_Pixelize (A:geometry, ResolutionX:int, ResolutionY:int, Boundary:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Pixelize ( shape , 256 , 256 , ( ST_Envelope_Aggr ( shape ) FROM pointtable )) FROM polygondf ST_TileName \u00b6 Introduction: Return the map tile name for a given zoom level. Please refer to OpenStreetMap ZoomLevel and OpenStreetMap tile name . Note Tile name is formatted as a \"Z-X-Y\" string. Z is zoom level. X is tile coordinate on X axis. Y is tile coordinate on Y axis. Format: ST_TileName (A:pixel, ZoomLevel:int) Since: v1.0.0 Spark SQL example: SELECT ST_TileName ( pixels . px , 3 ) FROM pixels Aggregate functions \u00b6 ST_Render \u00b6 Introduction: Given a group of pixels and their colors, return a single Java PNG BufferedImage. The 3 rd parameter is optional and it is the zoom level. You should use zoom level when you want to render tiles, instead of a single image. Format: ST_Render (A:pixel, B:color, C:Integer - optional zoom level) Since: v1.0.0 Spark SQL example: SELECT tilename , ST_Render ( pixels . px , pixels . color ) AS tileimg FROM pixels GROUP BY tilename","title":"DataFrame/SQL"},{"location":"api/viz/sql/#quick-start","text":"The detailed explanation is here: Visualize Spatial DataFrame/RDD . Add Sedona-core, Sedona-SQL,Sedona-Viz into your project POM.xml or build.sbt Declare your Spark Session sparkSession = SparkSession . builder (). config ( \"spark.serializer\" , \"org.apache.spark.serializer.KryoSerializer\" ). config ( \"spark.kryo.registrator\" , \"org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator\" ). master ( \"local[*]\" ). appName ( \"mySedonaVizDemo\" ). getOrCreate () Add the following lines after your SparkSession declaration: SedonaSQLRegistrator . registerAll ( sparkSession ) SedonaVizRegistrator . registerAll ( sparkSession )","title":"Quick start"},{"location":"api/viz/sql/#regular-functions","text":"","title":"Regular functions"},{"location":"api/viz/sql/#st_colorize","text":"Introduction: Given the weight of a pixel, return the corresponding color. The weight can be the spatial aggregation of spatial objects or spatial observations such as temperature and humidity. Note The color is encoded to an Integer type value in DataFrame. When you print it, it will show some nonsense values. You can just treat them as colors in GeoSparkViz. Format: ST_Colorize (weight:Double, maxWeight:Double, mandatory color: string (Optional)) Since: v1.0.0","title":"ST_Colorize"},{"location":"api/viz/sql/#st_encodeimage","text":"Introduction: Return the base64 string representation of a Java PNG BufferedImage. This is specific for the server-client environment. For example, transfer the base64 string from GeoSparkViz to Apache Zeppelin. Format: ST_EncodeImage (A:image) Since: v1.0.0 Spark SQL example: SELECT ST_EncodeImage ( images . img ) FROM images","title":"ST_EncodeImage"},{"location":"api/viz/sql/#st_pixelize","text":"Introduction: Convert a geometry to an array of pixels given a resolution You should use it together with Lateral View and Explode Format: ST_Pixelize (A:geometry, ResolutionX:int, ResolutionY:int, Boundary:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Pixelize ( shape , 256 , 256 , ( ST_Envelope_Aggr ( shape ) FROM pointtable )) FROM polygondf","title":"ST_Pixelize"},{"location":"api/viz/sql/#st_tilename","text":"Introduction: Return the map tile name for a given zoom level. Please refer to OpenStreetMap ZoomLevel and OpenStreetMap tile name . Note Tile name is formatted as a \"Z-X-Y\" string. Z is zoom level. X is tile coordinate on X axis. Y is tile coordinate on Y axis. Format: ST_TileName (A:pixel, ZoomLevel:int) Since: v1.0.0 Spark SQL example: SELECT ST_TileName ( pixels . px , 3 ) FROM pixels","title":"ST_TileName"},{"location":"api/viz/sql/#aggregate-functions","text":"","title":"Aggregate functions"},{"location":"api/viz/sql/#st_render","text":"Introduction: Given a group of pixels and their colors, return a single Java PNG BufferedImage. The 3 rd parameter is optional and it is the zoom level. You should use zoom level when you want to render tiles, instead of a single image. Format: ST_Render (A:pixel, B:color, C:Integer - optional zoom level) Since: v1.0.0 Spark SQL example: SELECT tilename , ST_Render ( pixels . px , pixels . color ) AS tileimg FROM pixels GROUP BY tilename","title":"ST_Render"},{"location":"archive/api/GeoSpark-Python-API/","text":"Will be available soon.","title":"Python doc"},{"location":"archive/api/GeoSpark-Scala-and-Java-API/","text":"Scala and Java API \u00b6 GeoSpark Scala and Java API: http://www.public.asu.edu/~jiayu2/geospark/javadoc/ The \"SNAPSHOT\" folder has the API for the latest GeoSpark SNAPSHOT version. Note: Scala can call Java APIs seamlessly. That means GeoSpark Scala users use the same APIs with GeoSpark Java users.","title":"Scala/Java doc"},{"location":"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api","text":"GeoSpark Scala and Java API: http://www.public.asu.edu/~jiayu2/geospark/javadoc/ The \"SNAPSHOT\" folder has the API for the latest GeoSpark SNAPSHOT version. Note: Scala can call Java APIs seamlessly. That means GeoSpark Scala users use the same APIs with GeoSpark Java users.","title":"Scala and Java API"},{"location":"archive/api/sql/GeoSparkSQL-AggregateFunction/","text":"ST_Envelope_Aggr \u00b6 Introduction: Return the entire envelope boundary of all geometries in A Format: ST_Envelope_Aggr (A:geometryColumn) Since: v1.0.0 Spark SQL example: SELECT ST_Envelope_Aggr ( pointdf . arealandmark ) FROM pointdf ST_Union_Aggr \u00b6 Introduction: Return the polygon union of all polygons in A Format: ST_Union_Aggr (A:geometryColumn) Since: v1.0.0 Spark SQL example: SELECT ST_Union_Aggr ( polygondf . polygonshape ) FROM polygondf ST_Intersection_Aggr \u00b6 Introduction: Return the polygon intersection of all polygons in A Format: ST_Intersection_Aggr (A:geometryColumn) Since: v1.2.1 Spark SQL example: SELECT ST_Intersection_Aggr ( polygondf . polygonshape ) FROM polygondf","title":"Aggregate function"},{"location":"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr","text":"Introduction: Return the entire envelope boundary of all geometries in A Format: ST_Envelope_Aggr (A:geometryColumn) Since: v1.0.0 Spark SQL example: SELECT ST_Envelope_Aggr ( pointdf . arealandmark ) FROM pointdf","title":"ST_Envelope_Aggr"},{"location":"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr","text":"Introduction: Return the polygon union of all polygons in A Format: ST_Union_Aggr (A:geometryColumn) Since: v1.0.0 Spark SQL example: SELECT ST_Union_Aggr ( polygondf . polygonshape ) FROM polygondf","title":"ST_Union_Aggr"},{"location":"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr","text":"Introduction: Return the polygon intersection of all polygons in A Format: ST_Intersection_Aggr (A:geometryColumn) Since: v1.2.1 Spark SQL example: SELECT ST_Intersection_Aggr ( polygondf . polygonshape ) FROM polygondf","title":"ST_Intersection_Aggr"},{"location":"archive/api/sql/GeoSparkSQL-Constructor/","text":"Note UUIDs ensure the shape uniqueness of a geometry. It can be any strings. This is only needed when you want to convert an Spatial DataFrame to an Spatial RDD and let each geometry carry some non-spatial attributes (e.g., price, age, ...). ST_GeomFromWKT \u00b6 Introduction: Construct a Geometry from Wkt. Unlimited UUID strings can be appended. Format: ST_GeomFromWKT (Wkt:string, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: SELECT ST_GeomFromWKT ( polygontable . _c0 ) AS polygonshape FROM polygontable SELECT ST_GeomFromWKT ( 'POINT(40.7128,-74.0060)' ) AS geometry ST_GeomFromWKB \u00b6 Introduction: Construct a Geometry from WKB string. Unlimited UUID strings can be appended. Format: ST_GeomFromWKB (Wkb:string, UUID1, UUID2, ...) Since: v1.2.0 Spark SQL example: SELECT ST_GeomFromWKB ( polygontable . _c0 ) AS polygonshape FROM polygontable ST_GeomFromGeoJSON \u00b6 Introduction: Construct a Geometry from GeoJson. Unlimited UUID strings can be appended. Format: ST_GeomFromGeoJSON (GeoJson:string, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: var polygonJsonDf = sparkSession . read . format ( \"csv\" ). option ( \"delimiter\" , \"\\t\" ). option ( \"header\" , \"false\" ). load ( geoJsonGeomInputLocation ) polygonJsonDf . createOrReplaceTempView ( \"polygontable\" ) polygonJsonDf . show () var polygonDf = sparkSession . sql ( \"\"\" | SELECT ST_GeomFromGeoJSON(polygontable._c0) AS countyshape | FROM polygontable \"\"\" . stripMargin ) polygonDf . show () Warning The way that GeoSparkSQL reads GeoJSON is different from that in SparkSQL Read ESRI Shapefile \u00b6 Introduction: Construct a DataFrame from a Shapefile Since: v1.0.0 SparkSQL example: var spatialRDD = new SpatialRDD [ Geometry ] spatialRDD . rawSpatialRDD = ShapefileReader . readToGeometryRDD ( sparkSession . sparkContext , shapefileInputLocation ) var rawSpatialDf = Adapter . toDf ( spatialRDD , sparkSession ) rawSpatialDf . createOrReplaceTempView ( \"rawSpatialDf\" ) var spatialDf = sparkSession . sql ( \"\"\" | ST_GeomFromWKT(rddshape), _c1, _c2 | FROM rawSpatialDf \"\"\" . stripMargin ) spatialDf . show () spatialDf . printSchema () Note The file extensions of .shp, .shx, .dbf must be in lowercase. Assume you have a shape file called myShapefile , the file structure should be like this: - shapefile1 - shapefile2 - myshapefile - myshapefile.shp - myshapefile.shx - myshapefile.dbf - myshapefile... - ... Warning Please make sure you use ST_GeomFromWKT to create Geometry type column otherwise that column cannot be used in GeoSparkSQL. If the file you are reading contains non-ASCII characters you'll need to explicitly set the encoding via geospark.global.charset system property before the call to ShapefileReader.readToGeometryRDD . Example: System . setProperty ( \"geospark.global.charset\" , \"utf8\" ) ST_Point \u00b6 Introduction: Construct a Point from X and Y. Unlimited UUID strings can be appended. Format: ST_Point (X:decimal, Y:decimal, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: SELECT ST_Point ( CAST ( pointtable . _c0 AS Decimal ( 24 , 20 )), CAST ( pointtable . _c1 AS Decimal ( 24 , 20 ))) AS pointshape FROM pointtable ST_PointFromText \u00b6 Introduction: Construct a Point from Text, delimited by Delimiter. Unlimited UUID strings can be appended. Format: ST_PointFromText (Text:string, Delimiter:char, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: SELECT ST_PointFromText ( pointtable . _c0 , ',' ) AS pointshape FROM pointtable SELECT ST_PointFromText ( '40.7128,-74.0060' , ',' ) AS pointshape ST_PolygonFromText \u00b6 Introduction: Construct a Polygon from Text, delimited by Delimiter. Path must be closed. Unlimited UUID strings can be appended. Format: ST_PolygonFromText (Text:string, Delimiter:char, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: SELECT ST_PolygonFromText ( polygontable . _c0 , ',' ) AS polygonshape FROM polygontable SELECT ST_PolygonFromText ( '-74.0428197,40.6867969,-74.0421975,40.6921336,-74.0508020,40.6912794,-74.0428197,40.6867969' , ',' ) AS polygonshape ST_LineStringFromText \u00b6 Introduction: Construct a LineString from Text, delimited by Delimiter. Unlimited UUID strings can be appended. Format: ST_LineStringFromText (Text:string, Delimiter:char, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: SELECT ST_LineStringFromText ( linestringtable . _c0 , ',' ) AS linestringshape FROM linestringtable SELECT ST_LineStringFromText ( '-74.0428197,40.6867969,-74.0421975,40.6921336,-74.0508020,40.6912794' , ',' ) AS linestringshape ST_PolygonFromEnvelope \u00b6 Introduction: Construct a Polygon from MinX, MinY, MaxX, MaxY. Unlimited UUID strings can be appended. Format: ST_PolygonFromEnvelope (MinX:decimal, MinY:decimal, MaxX:decimal, MaxY:decimal, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . pointshape ) ST_Circle \u00b6 Introduction: Construct a Circle from A with a Radius. Format: ST_Circle (A:Geometry, Radius:decimal) Since: v1.0.0 - v1.1.3 Spark SQL example: SELECT ST_Circle ( pointdf . pointshape , 1 . 0 ) FROM pointdf Note GeoSpark doesn't control the radius's unit (degree or meter). It is same with the geometry. To change the geometry's unit, please transform the coordinate reference system. See ST_Transform .","title":"Constructor"},{"location":"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt","text":"Introduction: Construct a Geometry from Wkt. Unlimited UUID strings can be appended. Format: ST_GeomFromWKT (Wkt:string, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: SELECT ST_GeomFromWKT ( polygontable . _c0 ) AS polygonshape FROM polygontable SELECT ST_GeomFromWKT ( 'POINT(40.7128,-74.0060)' ) AS geometry","title":"ST_GeomFromWKT"},{"location":"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb","text":"Introduction: Construct a Geometry from WKB string. Unlimited UUID strings can be appended. Format: ST_GeomFromWKB (Wkb:string, UUID1, UUID2, ...) Since: v1.2.0 Spark SQL example: SELECT ST_GeomFromWKB ( polygontable . _c0 ) AS polygonshape FROM polygontable","title":"ST_GeomFromWKB"},{"location":"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson","text":"Introduction: Construct a Geometry from GeoJson. Unlimited UUID strings can be appended. Format: ST_GeomFromGeoJSON (GeoJson:string, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: var polygonJsonDf = sparkSession . read . format ( \"csv\" ). option ( \"delimiter\" , \"\\t\" ). option ( \"header\" , \"false\" ). load ( geoJsonGeomInputLocation ) polygonJsonDf . createOrReplaceTempView ( \"polygontable\" ) polygonJsonDf . show () var polygonDf = sparkSession . sql ( \"\"\" | SELECT ST_GeomFromGeoJSON(polygontable._c0) AS countyshape | FROM polygontable \"\"\" . stripMargin ) polygonDf . show () Warning The way that GeoSparkSQL reads GeoJSON is different from that in SparkSQL","title":"ST_GeomFromGeoJSON"},{"location":"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile","text":"Introduction: Construct a DataFrame from a Shapefile Since: v1.0.0 SparkSQL example: var spatialRDD = new SpatialRDD [ Geometry ] spatialRDD . rawSpatialRDD = ShapefileReader . readToGeometryRDD ( sparkSession . sparkContext , shapefileInputLocation ) var rawSpatialDf = Adapter . toDf ( spatialRDD , sparkSession ) rawSpatialDf . createOrReplaceTempView ( \"rawSpatialDf\" ) var spatialDf = sparkSession . sql ( \"\"\" | ST_GeomFromWKT(rddshape), _c1, _c2 | FROM rawSpatialDf \"\"\" . stripMargin ) spatialDf . show () spatialDf . printSchema () Note The file extensions of .shp, .shx, .dbf must be in lowercase. Assume you have a shape file called myShapefile , the file structure should be like this: - shapefile1 - shapefile2 - myshapefile - myshapefile.shp - myshapefile.shx - myshapefile.dbf - myshapefile... - ... Warning Please make sure you use ST_GeomFromWKT to create Geometry type column otherwise that column cannot be used in GeoSparkSQL. If the file you are reading contains non-ASCII characters you'll need to explicitly set the encoding via geospark.global.charset system property before the call to ShapefileReader.readToGeometryRDD . Example: System . setProperty ( \"geospark.global.charset\" , \"utf8\" )","title":"Read ESRI Shapefile"},{"location":"archive/api/sql/GeoSparkSQL-Constructor/#st_point","text":"Introduction: Construct a Point from X and Y. Unlimited UUID strings can be appended. Format: ST_Point (X:decimal, Y:decimal, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: SELECT ST_Point ( CAST ( pointtable . _c0 AS Decimal ( 24 , 20 )), CAST ( pointtable . _c1 AS Decimal ( 24 , 20 ))) AS pointshape FROM pointtable","title":"ST_Point"},{"location":"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext","text":"Introduction: Construct a Point from Text, delimited by Delimiter. Unlimited UUID strings can be appended. Format: ST_PointFromText (Text:string, Delimiter:char, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: SELECT ST_PointFromText ( pointtable . _c0 , ',' ) AS pointshape FROM pointtable SELECT ST_PointFromText ( '40.7128,-74.0060' , ',' ) AS pointshape","title":"ST_PointFromText"},{"location":"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext","text":"Introduction: Construct a Polygon from Text, delimited by Delimiter. Path must be closed. Unlimited UUID strings can be appended. Format: ST_PolygonFromText (Text:string, Delimiter:char, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: SELECT ST_PolygonFromText ( polygontable . _c0 , ',' ) AS polygonshape FROM polygontable SELECT ST_PolygonFromText ( '-74.0428197,40.6867969,-74.0421975,40.6921336,-74.0508020,40.6912794,-74.0428197,40.6867969' , ',' ) AS polygonshape","title":"ST_PolygonFromText"},{"location":"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext","text":"Introduction: Construct a LineString from Text, delimited by Delimiter. Unlimited UUID strings can be appended. Format: ST_LineStringFromText (Text:string, Delimiter:char, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: SELECT ST_LineStringFromText ( linestringtable . _c0 , ',' ) AS linestringshape FROM linestringtable SELECT ST_LineStringFromText ( '-74.0428197,40.6867969,-74.0421975,40.6921336,-74.0508020,40.6912794' , ',' ) AS linestringshape","title":"ST_LineStringFromText"},{"location":"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope","text":"Introduction: Construct a Polygon from MinX, MinY, MaxX, MaxY. Unlimited UUID strings can be appended. Format: ST_PolygonFromEnvelope (MinX:decimal, MinY:decimal, MaxX:decimal, MaxY:decimal, UUID1, UUID2, ...) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . pointshape )","title":"ST_PolygonFromEnvelope"},{"location":"archive/api/sql/GeoSparkSQL-Constructor/#st_circle","text":"Introduction: Construct a Circle from A with a Radius. Format: ST_Circle (A:Geometry, Radius:decimal) Since: v1.0.0 - v1.1.3 Spark SQL example: SELECT ST_Circle ( pointdf . pointshape , 1 . 0 ) FROM pointdf Note GeoSpark doesn't control the radius's unit (degree or meter). It is same with the geometry. To change the geometry's unit, please transform the coordinate reference system. See ST_Transform .","title":"ST_Circle"},{"location":"archive/api/sql/GeoSparkSQL-Function/","text":"ST_Distance \u00b6 Introduction: Return the Euclidean distance between A and B Format: ST_Distance (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Distance ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf ST_ConvexHull \u00b6 Introduction: Return the Convex Hull of polgyon A Format: ST_ConvexHull (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_ConvexHull ( polygondf . countyshape ) FROM polygondf ST_Envelope \u00b6 Introduction: Return the envelop boundary of A Format: ST_Envelope (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Envelope ( polygondf . countyshape ) FROM polygondf ST_Length \u00b6 Introduction: Return the perimeter of A Format: ST_Length (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Length ( polygondf . countyshape ) FROM polygondf ST_Area \u00b6 Introduction: Return the area of A Format: ST_Area (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Area ( polygondf . countyshape ) FROM polygondf ST_Centroid \u00b6 Introduction: Return the centroid point of A Format: ST_Centroid (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Centroid ( polygondf . countyshape ) FROM polygondf ST_Transform \u00b6 Introduction: Transform the Spatial Reference System / Coordinate Reference System of A, from SourceCRS to TargetCRS Note By default, ST_Transform assumes Longitude/Latitude is your coordinate X/Y. If this is not the case, set UseLongitudeLatitudeOrder as \"false\". Note If ST_Transform throws an Exception called \"Bursa wolf parameters required\", you need to disable the error notification in ST_Transform. You can append a boolean value at the end. Format: ST_Transform (A:geometry, SourceCRS:string, TargetCRS:string, [Optional] UseLongitudeLatitudeOrder:Boolean, [Optional] DisableError) Since: v1.0.0 Spark SQL example (simple): SELECT ST_Transform ( polygondf . countyshape , 'epsg:4326' , 'epsg:3857' ) FROM polygondf Spark SQL example (with optional parameters): SELECT ST_Transform ( polygondf . countyshape , 'epsg:4326' , 'epsg:3857' , true , false ) FROM polygondf Note The detailed EPSG information can be searched on EPSG.io . ST_Intersection \u00b6 Introduction: Return the intersection geometry of A and B Format: ST_Intersection (A:geometry, B:geometry) Since: v1.1.0 Spark SQL example: SELECT ST_Intersection ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf ST_IsValid \u00b6 Introduction: Test if a geometry is well formed Format: ST_IsValid (A:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_IsValid ( polygondf . countyshape ) FROM polygondf ST_MakeValid \u00b6 Introduction: Given an invalid polygon or multipolygon and removeHoles boolean flag, create a valid representation of the geometry. Format: ST_MakeValid (A:geometry, removeHoles:Boolean) Since: v1.2.0 Spark SQL example: SELECT geometryValid . polygon FROM table LATERAL VIEW ST_MakeValid ( polygon , false ) geometryValid AS polygon Note Might return multiple polygons from a only one invalid polygon That's the reason why we need to use the LATERAL VIEW expression Note Throws an exception if the geometry isn't polygon or multipolygon ST_PrecisionReduce \u00b6 Introduction: Reduce the decimals places in the coordinates of the geometry to the given number of decimal places. The last decimal place will be rounded. Format: ST_PrecisionReduce (A:geometry, B:int) Since: v1.2.0 Spark SQL example: SELECT ST_PrecisionReduce ( polygondf . countyshape , 9 ) FROM polygondf The new coordinates will only have 9 decimal places. ST_IsSimple \u00b6 Introduction: Test if geometry's only self-intersections are at boundary points. Format: ST_IsSimple (A:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_IsSimple ( polygondf . countyshape ) FROM polygondf ST_Buffer \u00b6 Introduction: Returns a geometry/geography that represents all points whose distance from this Geometry/geography is less than or equal to distance. Format: ST_Buffer (A:geometry, buffer: Double) Since: v1.2.0 Spark SQL example: SELECT ST_Buffer ( polygondf . countyshape , 1 ) FROM polygondf ST_AsText \u00b6 Introduction: Return the Well-Known Text string representation of a geometry Format: ST_AsText (A:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_AsText ( polygondf . countyshape ) FROM polygondf ST_AsGeoJSON \u00b6 Introduction: Return the GeoJSON string representation of a geometry Format: ST_AsGeoJSON (A:geometry) Since: v1.3.2 Spark SQL example: SELECT ST_AsGeoJSON ( polygondf . countyshape ) FROM polygondf ST_NPoints \u00b6 Introduction: Return points of the geometry Since: v1.2.1 Format: ST_NPoints (A:geometry) SELECT ST_NPoints ( polygondf . countyshape ) FROM polygondf ST_SimplifyPreserveTopology \u00b6 Introduction: Simplifies a geometry and ensures that the result is a valid geometry having the same dimension and number of components as the input, and with the components having the same topological relationship. Since: v1.2.1 Format: ST_SimplifyPreserveTopology (A:geometry, distanceTolerance: Double) SELECT ST_SimplifyPreserveTopology ( polygondf . countyshape , 10 . 0 ) FROM polygondf ST_GeometryType \u00b6 Introduction: Returns the type of the geometry as a string. EG: 'ST_Linestring', 'ST_Polygon' etc. Format: ST_GeometryType (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_GeometryType ( polygondf . countyshape ) FROM polygondf ST_LineMerge \u00b6 Introduction: Returns a LineString formed by sewing together the constituent line work of a MULTILINESTRING. Note Only works for MULTILINESTRING. Using other geometry will return a GEOMETRYCOLLECTION EMPTY. If the MultiLineString can't be merged, the original MULTILINESTRING is returned. Format: ST_LineMerge (A:geometry) Since: v1.3.2 SELECT ST_LineMerge ( geometry ) FROM df ST_Azimuth \u00b6 Introduction: Returns Azimuth for two given points in radians null otherwise. Format: ST_Azimuth(pointA: Point, pointB: Point) Since: v1.3.2 Spark SQL example: SELECT ST_Azimuth ( ST_POINT ( 0 . 0 25 . 0 ), ST_POINT ( 0 . 0 0 . 0 )) Output: 3.141592653589793 ST_X \u00b6 Introduction: Returns X Coordinate of given Point null otherwise. Format: ST_X(pointA: Point) Since: v1.3.2 Spark SQL example: SELECT ST_X ( ST_POINT ( 0 . 0 25 . 0 )) Output: 0.0 ST_Y \u00b6 Introduction: Returns Y Coordinate of given Point, null otherwise. Format: ST_Y(pointA: Point) Since: v1.3.2 Spark SQL example: SELECT ST_Y ( ST_POINT ( 0 . 0 25 . 0 )) Output: 25.0 ST_StartPoint \u00b6 Introduction: Returns first point of given linestring. Format: ST_StartPoint(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_StartPoint ( ST_GeomFromText ( 'LINESTRING(100 150,50 60, 70 80, 160 170)' )) Output: POINT(100 150) ST_EndPoint \u00b6 Introduction: Returns last point of given linestring. Format: ST_EndPoint(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_EndPoint ( ST_GeomFromText ( 'LINESTRING(100 150,50 60, 70 80, 160 170)' )) Output: POINT(160 170) ST_Boundary \u00b6 Introduction: Returns the closure of the combinatorial boundary of this Geometry. Format: ST_Boundary(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_Boundary ( ST_GeomFromText ( 'POLYGON((1 1,0 0, -1 1, 1 1))' )) Output: LINESTRING (1 1, 0 0, -1 1, 1 1) ST_ExteriorRing \u00b6 Introduction: Returns a line string representing the exterior ring of the POLYGON geometry. Return NULL if the geometry is not a polygon. Format: ST_ExteriorRing(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_ExteriorRing ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output: LINESTRING (0 0, 1 1, 1 2, 1 1, 0 0) ST_GeometryN \u00b6 Introduction: Return the 1-based Nth geometry if the geometry is a GEOMETRYCOLLECTION, (MULTI)POINT, (MULTI)LINESTRING, MULTICURVE or (MULTI)POLYGON Otherwise, return null Format: ST_GeometryN(geom: geometry, n: Int) Since: v1.3.2 Spark SQL example: SELECT ST_GeometryN ( ST_GeomFromText ( 'MULTIPOINT((1 2), (3 4), (5 6), (8 9))' ), 1 ) Output: POINT (3 4) ST_InteriorRingN \u00b6 Introduction: Returns the Nth interior linestring ring of the polygon geometry. Returns NULL if the geometry is not a polygon or the given N is out of range Format: ST_InteriorRingN(geom: geometry, n: Int) Since: v1.3.2 Spark SQL example: SELECT ST_InteriorRingN ( ST_GeomFromText ( 'POLYGON((0 0, 0 5, 5 5, 5 0, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1), (1 3, 2 3, 2 4, 1 4, 1 3), (3 3, 4 3, 4 4, 3 4, 3 3))' ), 0 ) Output: LINESTRING (1 1, 2 1, 2 2, 1 2, 1 1) ST_Dump \u00b6 Introduction: It expands the geometries. If the geometry is simple (Point, Polygon Linestring etc.) it returns the geometry itself, if the geometry is collection or multi it returns record for each of collection components. Format: ST_Dump(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_Dump ( ST_GeomFromText ( 'MULTIPOINT ((10 40), (40 30), (20 20), (30 10))' )) Output: [POINT (10 40), POINT (40 30), POINT (20 20), POINT (30 10)] ST_DumpPoints \u00b6 Introduction: Returns list of Points which geometry consists of. Format: ST_DumpPoints(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_DumpPoints ( ST_GeomFromText ( 'LINESTRING (0 0, 1 1, 1 0)' )) Output: [POINT (0 0), POINT (0 1), POINT (1 1), POINT (1 0), POINT (0 0)] ST_IsClosed \u00b6 Introduction: RETURNS true if the LINESTRING start and end point are the same. Format: ST_IsClosed(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_IsClosed ( ST_GeomFromText ( 'LINESTRING(0 0, 1 1, 1 0)' )) Output: false ST_NumInteriorRings \u00b6 Introduction: RETURNS number of interior rings of polygon geometries. Format: ST_NumInteriorRings(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_NumInteriorRings ( ST_GeomFromText ( 'POLYGON ((0 0, 0 5, 5 5, 5 0, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1))' )) Output: 1 ST_AddPoint \u00b6 Introduction: RETURN Linestring with additional point at the given index, if position is not available the point will be added at the end of line. Format: ST_AddPoint(geom: geometry, point: geometry, position: integer) Format: ST_AddPoint(geom: geometry, point: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_AddPoint ( ST_GeomFromText ( \"LINESTRING(0 0, 1 1, 1 0)\" ), ST_GeomFromText ( \"Point(21 52)\" ), 1 ) SELECT ST_AddPoint ( ST_GeomFromText ( \"Linestring(0 0, 1 1, 1 0)\" ), ST_GeomFromText ( \"Point(21 52)\" )) Output: LINESTRING(0 0, 21 52, 1 1, 1 0) LINESTRING(0 0, 1 1, 1 0, 21 52) ST_RemovePoint \u00b6 Introduction: RETURN Line with removed point at given index, position can be omitted and then last one will be removed. Format: ST_RemovePoint(geom: geometry, position: integer) Format: ST_RemovePoint(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_RemovePoint ( ST_GeomFromText ( \"LINESTRING(0 0, 1 1, 1 0)\" ), 1 ) Output: LINESTRING(0 0, 1 0) ST_IsRing \u00b6 Introduction: RETURN true if LINESTRING is ST_IsClosed and ST_IsSimple. Format: ST_IsRing(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_IsRing ( ST_GeomFromText ( \"LINESTRING(0 0, 0 1, 1 1, 1 0, 0 0)\" )) Output: true ST_NumGeometries \u00b6 Introduction: Returns the number of Geometries. If geometry is a GEOMETRYCOLLECTION (or MULTI*) return the number of geometries, for single geometries will return 1. Format: ST_NumGeometries (A:geometry) Since: v1.3.2 SELECT ST_NumGeometries ( df . geometry ) FROM df","title":"Function"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_distance","text":"Introduction: Return the Euclidean distance between A and B Format: ST_Distance (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Distance ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf","title":"ST_Distance"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_convexhull","text":"Introduction: Return the Convex Hull of polgyon A Format: ST_ConvexHull (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_ConvexHull ( polygondf . countyshape ) FROM polygondf","title":"ST_ConvexHull"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_envelope","text":"Introduction: Return the envelop boundary of A Format: ST_Envelope (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Envelope ( polygondf . countyshape ) FROM polygondf","title":"ST_Envelope"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_length","text":"Introduction: Return the perimeter of A Format: ST_Length (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Length ( polygondf . countyshape ) FROM polygondf","title":"ST_Length"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_area","text":"Introduction: Return the area of A Format: ST_Area (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Area ( polygondf . countyshape ) FROM polygondf","title":"ST_Area"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_centroid","text":"Introduction: Return the centroid point of A Format: ST_Centroid (A:geometry) Since: v1.0.0 Spark SQL example: SELECT ST_Centroid ( polygondf . countyshape ) FROM polygondf","title":"ST_Centroid"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_transform","text":"Introduction: Transform the Spatial Reference System / Coordinate Reference System of A, from SourceCRS to TargetCRS Note By default, ST_Transform assumes Longitude/Latitude is your coordinate X/Y. If this is not the case, set UseLongitudeLatitudeOrder as \"false\". Note If ST_Transform throws an Exception called \"Bursa wolf parameters required\", you need to disable the error notification in ST_Transform. You can append a boolean value at the end. Format: ST_Transform (A:geometry, SourceCRS:string, TargetCRS:string, [Optional] UseLongitudeLatitudeOrder:Boolean, [Optional] DisableError) Since: v1.0.0 Spark SQL example (simple): SELECT ST_Transform ( polygondf . countyshape , 'epsg:4326' , 'epsg:3857' ) FROM polygondf Spark SQL example (with optional parameters): SELECT ST_Transform ( polygondf . countyshape , 'epsg:4326' , 'epsg:3857' , true , false ) FROM polygondf Note The detailed EPSG information can be searched on EPSG.io .","title":"ST_Transform"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_intersection","text":"Introduction: Return the intersection geometry of A and B Format: ST_Intersection (A:geometry, B:geometry) Since: v1.1.0 Spark SQL example: SELECT ST_Intersection ( polygondf . countyshape , polygondf . countyshape ) FROM polygondf","title":"ST_Intersection"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_isvalid","text":"Introduction: Test if a geometry is well formed Format: ST_IsValid (A:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_IsValid ( polygondf . countyshape ) FROM polygondf","title":"ST_IsValid"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_makevalid","text":"Introduction: Given an invalid polygon or multipolygon and removeHoles boolean flag, create a valid representation of the geometry. Format: ST_MakeValid (A:geometry, removeHoles:Boolean) Since: v1.2.0 Spark SQL example: SELECT geometryValid . polygon FROM table LATERAL VIEW ST_MakeValid ( polygon , false ) geometryValid AS polygon Note Might return multiple polygons from a only one invalid polygon That's the reason why we need to use the LATERAL VIEW expression Note Throws an exception if the geometry isn't polygon or multipolygon","title":"ST_MakeValid"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce","text":"Introduction: Reduce the decimals places in the coordinates of the geometry to the given number of decimal places. The last decimal place will be rounded. Format: ST_PrecisionReduce (A:geometry, B:int) Since: v1.2.0 Spark SQL example: SELECT ST_PrecisionReduce ( polygondf . countyshape , 9 ) FROM polygondf The new coordinates will only have 9 decimal places.","title":"ST_PrecisionReduce"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_issimple","text":"Introduction: Test if geometry's only self-intersections are at boundary points. Format: ST_IsSimple (A:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_IsSimple ( polygondf . countyshape ) FROM polygondf","title":"ST_IsSimple"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_buffer","text":"Introduction: Returns a geometry/geography that represents all points whose distance from this Geometry/geography is less than or equal to distance. Format: ST_Buffer (A:geometry, buffer: Double) Since: v1.2.0 Spark SQL example: SELECT ST_Buffer ( polygondf . countyshape , 1 ) FROM polygondf","title":"ST_Buffer"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_astext","text":"Introduction: Return the Well-Known Text string representation of a geometry Format: ST_AsText (A:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_AsText ( polygondf . countyshape ) FROM polygondf","title":"ST_AsText"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson","text":"Introduction: Return the GeoJSON string representation of a geometry Format: ST_AsGeoJSON (A:geometry) Since: v1.3.2 Spark SQL example: SELECT ST_AsGeoJSON ( polygondf . countyshape ) FROM polygondf","title":"ST_AsGeoJSON"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_npoints","text":"Introduction: Return points of the geometry Since: v1.2.1 Format: ST_NPoints (A:geometry) SELECT ST_NPoints ( polygondf . countyshape ) FROM polygondf","title":"ST_NPoints"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology","text":"Introduction: Simplifies a geometry and ensures that the result is a valid geometry having the same dimension and number of components as the input, and with the components having the same topological relationship. Since: v1.2.1 Format: ST_SimplifyPreserveTopology (A:geometry, distanceTolerance: Double) SELECT ST_SimplifyPreserveTopology ( polygondf . countyshape , 10 . 0 ) FROM polygondf","title":"ST_SimplifyPreserveTopology"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype","text":"Introduction: Returns the type of the geometry as a string. EG: 'ST_Linestring', 'ST_Polygon' etc. Format: ST_GeometryType (A:geometry) Since: v1.2.1 Spark SQL example: SELECT ST_GeometryType ( polygondf . countyshape ) FROM polygondf","title":"ST_GeometryType"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_linemerge","text":"Introduction: Returns a LineString formed by sewing together the constituent line work of a MULTILINESTRING. Note Only works for MULTILINESTRING. Using other geometry will return a GEOMETRYCOLLECTION EMPTY. If the MultiLineString can't be merged, the original MULTILINESTRING is returned. Format: ST_LineMerge (A:geometry) Since: v1.3.2 SELECT ST_LineMerge ( geometry ) FROM df","title":"ST_LineMerge"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_azimuth","text":"Introduction: Returns Azimuth for two given points in radians null otherwise. Format: ST_Azimuth(pointA: Point, pointB: Point) Since: v1.3.2 Spark SQL example: SELECT ST_Azimuth ( ST_POINT ( 0 . 0 25 . 0 ), ST_POINT ( 0 . 0 0 . 0 )) Output: 3.141592653589793","title":"ST_Azimuth"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_x","text":"Introduction: Returns X Coordinate of given Point null otherwise. Format: ST_X(pointA: Point) Since: v1.3.2 Spark SQL example: SELECT ST_X ( ST_POINT ( 0 . 0 25 . 0 )) Output: 0.0","title":"ST_X"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_y","text":"Introduction: Returns Y Coordinate of given Point, null otherwise. Format: ST_Y(pointA: Point) Since: v1.3.2 Spark SQL example: SELECT ST_Y ( ST_POINT ( 0 . 0 25 . 0 )) Output: 25.0","title":"ST_Y"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_startpoint","text":"Introduction: Returns first point of given linestring. Format: ST_StartPoint(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_StartPoint ( ST_GeomFromText ( 'LINESTRING(100 150,50 60, 70 80, 160 170)' )) Output: POINT(100 150)","title":"ST_StartPoint"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_endpoint","text":"Introduction: Returns last point of given linestring. Format: ST_EndPoint(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_EndPoint ( ST_GeomFromText ( 'LINESTRING(100 150,50 60, 70 80, 160 170)' )) Output: POINT(160 170)","title":"ST_EndPoint"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_boundary","text":"Introduction: Returns the closure of the combinatorial boundary of this Geometry. Format: ST_Boundary(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_Boundary ( ST_GeomFromText ( 'POLYGON((1 1,0 0, -1 1, 1 1))' )) Output: LINESTRING (1 1, 0 0, -1 1, 1 1)","title":"ST_Boundary"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring","text":"Introduction: Returns a line string representing the exterior ring of the POLYGON geometry. Return NULL if the geometry is not a polygon. Format: ST_ExteriorRing(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_ExteriorRing ( ST_GeomFromText ( 'POLYGON((0 0 1, 1 1 1, 1 2 1, 1 1 1, 0 0 1))' )) Output: LINESTRING (0 0, 1 1, 1 2, 1 1, 0 0)","title":"ST_ExteriorRing"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_geometryn","text":"Introduction: Return the 1-based Nth geometry if the geometry is a GEOMETRYCOLLECTION, (MULTI)POINT, (MULTI)LINESTRING, MULTICURVE or (MULTI)POLYGON Otherwise, return null Format: ST_GeometryN(geom: geometry, n: Int) Since: v1.3.2 Spark SQL example: SELECT ST_GeometryN ( ST_GeomFromText ( 'MULTIPOINT((1 2), (3 4), (5 6), (8 9))' ), 1 ) Output: POINT (3 4)","title":"ST_GeometryN"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn","text":"Introduction: Returns the Nth interior linestring ring of the polygon geometry. Returns NULL if the geometry is not a polygon or the given N is out of range Format: ST_InteriorRingN(geom: geometry, n: Int) Since: v1.3.2 Spark SQL example: SELECT ST_InteriorRingN ( ST_GeomFromText ( 'POLYGON((0 0, 0 5, 5 5, 5 0, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1), (1 3, 2 3, 2 4, 1 4, 1 3), (3 3, 4 3, 4 4, 3 4, 3 3))' ), 0 ) Output: LINESTRING (1 1, 2 1, 2 2, 1 2, 1 1)","title":"ST_InteriorRingN"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_dump","text":"Introduction: It expands the geometries. If the geometry is simple (Point, Polygon Linestring etc.) it returns the geometry itself, if the geometry is collection or multi it returns record for each of collection components. Format: ST_Dump(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_Dump ( ST_GeomFromText ( 'MULTIPOINT ((10 40), (40 30), (20 20), (30 10))' )) Output: [POINT (10 40), POINT (40 30), POINT (20 20), POINT (30 10)]","title":"ST_Dump"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints","text":"Introduction: Returns list of Points which geometry consists of. Format: ST_DumpPoints(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_DumpPoints ( ST_GeomFromText ( 'LINESTRING (0 0, 1 1, 1 0)' )) Output: [POINT (0 0), POINT (0 1), POINT (1 1), POINT (1 0), POINT (0 0)]","title":"ST_DumpPoints"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_isclosed","text":"Introduction: RETURNS true if the LINESTRING start and end point are the same. Format: ST_IsClosed(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_IsClosed ( ST_GeomFromText ( 'LINESTRING(0 0, 1 1, 1 0)' )) Output: false","title":"ST_IsClosed"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings","text":"Introduction: RETURNS number of interior rings of polygon geometries. Format: ST_NumInteriorRings(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_NumInteriorRings ( ST_GeomFromText ( 'POLYGON ((0 0, 0 5, 5 5, 5 0, 0 0), (1 1, 2 1, 2 2, 1 2, 1 1))' )) Output: 1","title":"ST_NumInteriorRings"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_addpoint","text":"Introduction: RETURN Linestring with additional point at the given index, if position is not available the point will be added at the end of line. Format: ST_AddPoint(geom: geometry, point: geometry, position: integer) Format: ST_AddPoint(geom: geometry, point: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_AddPoint ( ST_GeomFromText ( \"LINESTRING(0 0, 1 1, 1 0)\" ), ST_GeomFromText ( \"Point(21 52)\" ), 1 ) SELECT ST_AddPoint ( ST_GeomFromText ( \"Linestring(0 0, 1 1, 1 0)\" ), ST_GeomFromText ( \"Point(21 52)\" )) Output: LINESTRING(0 0, 21 52, 1 1, 1 0) LINESTRING(0 0, 1 1, 1 0, 21 52)","title":"ST_AddPoint"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_removepoint","text":"Introduction: RETURN Line with removed point at given index, position can be omitted and then last one will be removed. Format: ST_RemovePoint(geom: geometry, position: integer) Format: ST_RemovePoint(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_RemovePoint ( ST_GeomFromText ( \"LINESTRING(0 0, 1 1, 1 0)\" ), 1 ) Output: LINESTRING(0 0, 1 0)","title":"ST_RemovePoint"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_isring","text":"Introduction: RETURN true if LINESTRING is ST_IsClosed and ST_IsSimple. Format: ST_IsRing(geom: geometry) Since: v1.3.2 Spark SQL example: SELECT ST_IsRing ( ST_GeomFromText ( \"LINESTRING(0 0, 0 1, 1 1, 1 0, 0 0)\" )) Output: true","title":"ST_IsRing"},{"location":"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries","text":"Introduction: Returns the number of Geometries. If geometry is a GEOMETRYCOLLECTION (or MULTI*) return the number of geometries, for single geometries will return 1. Format: ST_NumGeometries (A:geometry) Since: v1.3.2 SELECT ST_NumGeometries ( df . geometry ) FROM df","title":"ST_NumGeometries"},{"location":"archive/api/sql/GeoSparkSQL-Optimizer/","text":"GeoSparkSQL query optimizer \u00b6 GeoSpark Spatial operators fully supports Apache SparkSQL query optimizer. It has the following query optimization features: Automatically optimizes range join query and distance join query. Automatically performs predicate pushdown. Range join \u00b6 Introduction: Find geometries from A and geometries from B such that each geometry pair satisfies a certain predicate. Most predicates supported by GeoSparkSQL can trigger a range join. Spark SQL Example: SELECT * FROM polygondf , pointdf WHERE ST_Contains ( polygondf . polygonshape , pointdf . pointshape ) SELECT * FROM polygondf , pointdf WHERE ST_Intersects ( polygondf . polygonshape , pointdf . pointshape ) SELECT * FROM pointdf , polygondf WHERE ST_Within ( pointdf . pointshape , polygondf . polygonshape ) Spark SQL Physical plan: == Physical Plan == RangeJoin polygonshape#20: geometry, pointshape#43: geometry, false :- Project [st_polygonfromenvelope(cast(_c0#0 as decimal(24,20)), cast(_c1#1 as decimal(24,20)), cast(_c2#2 as decimal(24,20)), cast(_c3#3 as decimal(24,20)), mypolygonid) AS polygonshape#20] : +- *FileScan csv +- Project [st_point(cast(_c0#31 as decimal(24,20)), cast(_c1#32 as decimal(24,20)), myPointId) AS pointshape#43] +- *FileScan csv Note All join queries in GeoSparkSQL are inner joins Distance join \u00b6 Introduction: Find geometries from A and geometries from B such that the internal Euclidean distance of each geometry pair is less or equal than a certain distance Spark SQL Example: Only consider fully within a certain distance SELECT * FROM pointdf1 , pointdf2 WHERE ST_Distance ( pointdf1 . pointshape1 , pointdf2 . pointshape2 ) < 2 Consider intersects within a certain distance SELECT * FROM pointdf1 , pointdf2 WHERE ST_Distance ( pointdf1 . pointshape1 , pointdf2 . pointshape2 ) <= 2 Spark SQL Physical plan: == Physical Plan == DistanceJoin pointshape1#12: geometry, pointshape2#33: geometry, 2.0, true :- Project [st_point(cast(_c0#0 as decimal(24,20)), cast(_c1#1 as decimal(24,20)), myPointId) AS pointshape1#12] : +- *FileScan csv +- Project [st_point(cast(_c0#21 as decimal(24,20)), cast(_c1#22 as decimal(24,20)), myPointId) AS pointshape2#33] +- *FileScan csv Warning GeoSpark doesn't control the distance's unit (degree or meter). It is same with the geometry. To change the geometry's unit, please transform the coordinate reference system. See ST_Transform . Predicate pushdown \u00b6 Introduction: Given a join query and a predicate in the same WHERE clause, first executes the Predicate as a filter, then executes the join query* Spark SQL Example: SELECT * FROM polygondf , pointdf WHERE ST_Contains ( polygondf . polygonshape , pointdf . pointshape ) AND ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 101 . 0 , 501 . 0 , 601 . 0 ), polygondf . polygonshape ) Spark SQL Physical plan: == Physical Plan == RangeJoin polygonshape#20: geometry, pointshape#43: geometry, false :- Project [st_polygonfromenvelope(cast(_c0#0 as decimal(24,20)), cast(_c1#1 as decimal(24,20)), cast(_c2#2 as decimal(24,20)), cast(_c3#3 as decimal(24,20)), mypolygonid) AS polygonshape#20] : +- Filter **org.apache.spark.sql.geosparksql.expressions.ST_Contains$** : +- *FileScan csv +- Project [st_point(cast(_c0#31 as decimal(24,20)), cast(_c1#32 as decimal(24,20)), myPointId) AS pointshape#43] +- *FileScan csv","title":"Join query (optimizer)"},{"location":"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer","text":"GeoSpark Spatial operators fully supports Apache SparkSQL query optimizer. It has the following query optimization features: Automatically optimizes range join query and distance join query. Automatically performs predicate pushdown.","title":"GeoSparkSQL query optimizer"},{"location":"archive/api/sql/GeoSparkSQL-Optimizer/#range-join","text":"Introduction: Find geometries from A and geometries from B such that each geometry pair satisfies a certain predicate. Most predicates supported by GeoSparkSQL can trigger a range join. Spark SQL Example: SELECT * FROM polygondf , pointdf WHERE ST_Contains ( polygondf . polygonshape , pointdf . pointshape ) SELECT * FROM polygondf , pointdf WHERE ST_Intersects ( polygondf . polygonshape , pointdf . pointshape ) SELECT * FROM pointdf , polygondf WHERE ST_Within ( pointdf . pointshape , polygondf . polygonshape ) Spark SQL Physical plan: == Physical Plan == RangeJoin polygonshape#20: geometry, pointshape#43: geometry, false :- Project [st_polygonfromenvelope(cast(_c0#0 as decimal(24,20)), cast(_c1#1 as decimal(24,20)), cast(_c2#2 as decimal(24,20)), cast(_c3#3 as decimal(24,20)), mypolygonid) AS polygonshape#20] : +- *FileScan csv +- Project [st_point(cast(_c0#31 as decimal(24,20)), cast(_c1#32 as decimal(24,20)), myPointId) AS pointshape#43] +- *FileScan csv Note All join queries in GeoSparkSQL are inner joins","title":"Range join"},{"location":"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join","text":"Introduction: Find geometries from A and geometries from B such that the internal Euclidean distance of each geometry pair is less or equal than a certain distance Spark SQL Example: Only consider fully within a certain distance SELECT * FROM pointdf1 , pointdf2 WHERE ST_Distance ( pointdf1 . pointshape1 , pointdf2 . pointshape2 ) < 2 Consider intersects within a certain distance SELECT * FROM pointdf1 , pointdf2 WHERE ST_Distance ( pointdf1 . pointshape1 , pointdf2 . pointshape2 ) <= 2 Spark SQL Physical plan: == Physical Plan == DistanceJoin pointshape1#12: geometry, pointshape2#33: geometry, 2.0, true :- Project [st_point(cast(_c0#0 as decimal(24,20)), cast(_c1#1 as decimal(24,20)), myPointId) AS pointshape1#12] : +- *FileScan csv +- Project [st_point(cast(_c0#21 as decimal(24,20)), cast(_c1#22 as decimal(24,20)), myPointId) AS pointshape2#33] +- *FileScan csv Warning GeoSpark doesn't control the distance's unit (degree or meter). It is same with the geometry. To change the geometry's unit, please transform the coordinate reference system. See ST_Transform .","title":"Distance join"},{"location":"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown","text":"Introduction: Given a join query and a predicate in the same WHERE clause, first executes the Predicate as a filter, then executes the join query* Spark SQL Example: SELECT * FROM polygondf , pointdf WHERE ST_Contains ( polygondf . polygonshape , pointdf . pointshape ) AND ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 101 . 0 , 501 . 0 , 601 . 0 ), polygondf . polygonshape ) Spark SQL Physical plan: == Physical Plan == RangeJoin polygonshape#20: geometry, pointshape#43: geometry, false :- Project [st_polygonfromenvelope(cast(_c0#0 as decimal(24,20)), cast(_c1#1 as decimal(24,20)), cast(_c2#2 as decimal(24,20)), cast(_c3#3 as decimal(24,20)), mypolygonid) AS polygonshape#20] : +- Filter **org.apache.spark.sql.geosparksql.expressions.ST_Contains$** : +- *FileScan csv +- Project [st_point(cast(_c0#31 as decimal(24,20)), cast(_c1#32 as decimal(24,20)), myPointId) AS pointshape#43] +- *FileScan csv","title":"Predicate pushdown"},{"location":"archive/api/sql/GeoSparkSQL-Overview/","text":"Introduction \u00b6 Function list \u00b6 GeoSparkSQL supports SQL/MM Part3 Spatial SQL Standard. It includes four kinds of SQL operators as follows. All these operators can be directly called through: var myDataFrame = sparkSession . sql ( \"YOUR_SQL\" ) Constructor: Construct a Geometry given an input string or coordinates Example: ST_GeomFromWKT (string). Create a Geometry from a WKT String. Documentation: Here Function: Execute a function on the given column or columns Example: ST_Distance (A, B). Given two Geometry A and B, return the Euclidean distance of A and B. Documentation: Here Aggregate function: Return the aggregated value on the given column Example: ST_Envelope_Aggr (Geometry column). Given a Geometry column, calculate the entire envelope boundary of this column. Documentation: Here Predicate: Execute a logic judgement on the given columns and return true or false Example: ST_Contains (A, B). Check if A fully contains B. Return \"True\" if yes, else return \"False\". Documentation: Here GeoSparkSQL supports SparkSQL query optimizer, documentation is Here Quick start \u00b6 The detailed explanation is here Write a SQL/DataFrame application . Add GeoSpark-core and GeoSparkSQL into your project POM.xml or build.sbt Declare your Spark Session sparkSession = SparkSession . builder (). config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ). config ( \"spark.kryo.registrator\" , classOf [ GeoSparkKryoRegistrator ]. getName ). master ( \"local[*]\" ). appName ( \"myGeoSparkSQLdemo\" ). getOrCreate () Add the following line after your SparkSession declaration: GeoSparkSQLRegistrator . registerAll ( sparkSession )","title":"Quick start"},{"location":"archive/api/sql/GeoSparkSQL-Overview/#introduction","text":"","title":"Introduction"},{"location":"archive/api/sql/GeoSparkSQL-Overview/#function-list","text":"GeoSparkSQL supports SQL/MM Part3 Spatial SQL Standard. It includes four kinds of SQL operators as follows. All these operators can be directly called through: var myDataFrame = sparkSession . sql ( \"YOUR_SQL\" ) Constructor: Construct a Geometry given an input string or coordinates Example: ST_GeomFromWKT (string). Create a Geometry from a WKT String. Documentation: Here Function: Execute a function on the given column or columns Example: ST_Distance (A, B). Given two Geometry A and B, return the Euclidean distance of A and B. Documentation: Here Aggregate function: Return the aggregated value on the given column Example: ST_Envelope_Aggr (Geometry column). Given a Geometry column, calculate the entire envelope boundary of this column. Documentation: Here Predicate: Execute a logic judgement on the given columns and return true or false Example: ST_Contains (A, B). Check if A fully contains B. Return \"True\" if yes, else return \"False\". Documentation: Here GeoSparkSQL supports SparkSQL query optimizer, documentation is Here","title":"Function list"},{"location":"archive/api/sql/GeoSparkSQL-Overview/#quick-start","text":"The detailed explanation is here Write a SQL/DataFrame application . Add GeoSpark-core and GeoSparkSQL into your project POM.xml or build.sbt Declare your Spark Session sparkSession = SparkSession . builder (). config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ). config ( \"spark.kryo.registrator\" , classOf [ GeoSparkKryoRegistrator ]. getName ). master ( \"local[*]\" ). appName ( \"myGeoSparkSQLdemo\" ). getOrCreate () Add the following line after your SparkSession declaration: GeoSparkSQLRegistrator . registerAll ( sparkSession )","title":"Quick start"},{"location":"archive/api/sql/GeoSparkSQL-Parameter/","text":"Usage \u00b6 GeoSparkSQL supports many parameters. To change their values, Set it through SparkConf: sparkSession = SparkSession . builder (). config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ). config ( \"spark.kryo.registrator\" , classOf [ GeoSparkKryoRegistrator ]. getName ). config ( \"geospark.global.index\" , \"true\" ) master ( \"local[*]\" ). appName ( \"myGeoSparkSQLdemo\" ). getOrCreate () Check your current GeoSparkSQL configuration: val geosparkConf = new GeoSparkConf ( sparkSession . sparkContext . getConf ) println ( geosparkConf ) Explanation \u00b6 geospark.global.index Use spatial index (currently, only supports in SQL range join and SQL distance join) Default: true Possible values: true, false geospark.global.indextype Spatial index type, only valid when \"geospark.global.index\" is true Default: rtree Possible values: rtree, quadtree geospark.join.gridtype Spatial partitioning grid type for join query Default: quadtree Possible values: quadtree, kdbtree, rtree, voronoi geospark.join.numpartition (Advanced users only!) Number of partitions for both sides in a join query Default: -1, which means use the existing partitions Possible values: any integers geospark.join.indexbuildside (Advanced users only!) The side which GeoSpark builds spatial indices on Default: left Possible values: left, right geospark.join.spatitionside (Advanced users only!) The dominant side in spatial partitioning stage Default: left Possible values: left, right","title":"Parameter"},{"location":"archive/api/sql/GeoSparkSQL-Parameter/#usage","text":"GeoSparkSQL supports many parameters. To change their values, Set it through SparkConf: sparkSession = SparkSession . builder (). config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ). config ( \"spark.kryo.registrator\" , classOf [ GeoSparkKryoRegistrator ]. getName ). config ( \"geospark.global.index\" , \"true\" ) master ( \"local[*]\" ). appName ( \"myGeoSparkSQLdemo\" ). getOrCreate () Check your current GeoSparkSQL configuration: val geosparkConf = new GeoSparkConf ( sparkSession . sparkContext . getConf ) println ( geosparkConf )","title":"Usage"},{"location":"archive/api/sql/GeoSparkSQL-Parameter/#explanation","text":"geospark.global.index Use spatial index (currently, only supports in SQL range join and SQL distance join) Default: true Possible values: true, false geospark.global.indextype Spatial index type, only valid when \"geospark.global.index\" is true Default: rtree Possible values: rtree, quadtree geospark.join.gridtype Spatial partitioning grid type for join query Default: quadtree Possible values: quadtree, kdbtree, rtree, voronoi geospark.join.numpartition (Advanced users only!) Number of partitions for both sides in a join query Default: -1, which means use the existing partitions Possible values: any integers geospark.join.indexbuildside (Advanced users only!) The side which GeoSpark builds spatial indices on Default: left Possible values: left, right geospark.join.spatitionside (Advanced users only!) The dominant side in spatial partitioning stage Default: left Possible values: left, right","title":"Explanation"},{"location":"archive/api/sql/GeoSparkSQL-Predicate/","text":"ST_Contains \u00b6 Introduction: Return true if A fully contains B Format: ST_Contains (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark ) ST_Intersects \u00b6 Introduction: Return true if A intersects B Format: ST_Intersects (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Intersects ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark ) ST_Within \u00b6 Introduction: Return true if A is fully contained by B Format: ST_Within (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Within ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 )) ST_Equals \u00b6 Introduction: Return true if A equals to B Format: ST_Equals (A:geometry, B:geometry) Since: v1.2.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Equals ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 )) ST_Crosses \u00b6 Introduction: Return true if A crosses B Format: ST_Crosses (A:geometry, B:geometry) Since: v1.2.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Crosses ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 )) ST_Touches \u00b6 Introduction: Return true if A touches B Format: ST_Touches (A:geometry, B:geometry) Since: v1.2.0 SELECT * FROM pointdf WHERE ST_Touches ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 )) ST_Overlaps \u00b6 Introduction: Return true if A overlaps B Format: ST_Overlaps (A:geometry, B:geometry) Since: v1.2.0 Spark SQL example: SELECT * FROM geom WHERE ST_Overlaps ( geom . geom_a , geom . geom_b )","title":"Predicate"},{"location":"archive/api/sql/GeoSparkSQL-Predicate/#st_contains","text":"Introduction: Return true if A fully contains B Format: ST_Contains (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark )","title":"ST_Contains"},{"location":"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects","text":"Introduction: Return true if A intersects B Format: ST_Intersects (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Intersects ( ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ), pointdf . arealandmark )","title":"ST_Intersects"},{"location":"archive/api/sql/GeoSparkSQL-Predicate/#st_within","text":"Introduction: Return true if A is fully contained by B Format: ST_Within (A:geometry, B:geometry) Since: v1.0.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Within ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"ST_Within"},{"location":"archive/api/sql/GeoSparkSQL-Predicate/#st_equals","text":"Introduction: Return true if A equals to B Format: ST_Equals (A:geometry, B:geometry) Since: v1.2.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Equals ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"ST_Equals"},{"location":"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses","text":"Introduction: Return true if A crosses B Format: ST_Crosses (A:geometry, B:geometry) Since: v1.2.0 Spark SQL example: SELECT * FROM pointdf WHERE ST_Crosses ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"ST_Crosses"},{"location":"archive/api/sql/GeoSparkSQL-Predicate/#st_touches","text":"Introduction: Return true if A touches B Format: ST_Touches (A:geometry, B:geometry) Since: v1.2.0 SELECT * FROM pointdf WHERE ST_Touches ( pointdf . arealandmark , ST_PolygonFromEnvelope ( 1 . 0 , 100 . 0 , 1000 . 0 , 1100 . 0 ))","title":"ST_Touches"},{"location":"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps","text":"Introduction: Return true if A overlaps B Format: ST_Overlaps (A:geometry, B:geometry) Since: v1.2.0 Spark SQL example: SELECT * FROM geom WHERE ST_Overlaps ( geom . geom_a , geom . geom_b )","title":"ST_Overlaps"},{"location":"archive/api/sql/GeoSparkSQL-javadoc/","text":"Scala and Java API \u00b6 GeoSparkSQL Scala and Java API: http://www.public.asu.edu/~jiayu2/geosparksql/javadoc/ The \"SNAPSHOT\" folder has the API for the latest GeoSpark SNAPSHOT version. Note: Scala can call Java APIs seamlessly. That means GeoSpark Scala users use the same APIs with GeoSpark Java users.","title":"JavaDoc"},{"location":"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api","text":"GeoSparkSQL Scala and Java API: http://www.public.asu.edu/~jiayu2/geosparksql/javadoc/ The \"SNAPSHOT\" folder has the API for the latest GeoSpark SNAPSHOT version. Note: Scala can call Java APIs seamlessly. That means GeoSpark Scala users use the same APIs with GeoSpark Java users.","title":"Scala and Java API"},{"location":"archive/api/viz/Babylon-Scala-and-Java-API/","text":"Scala and Java API for RDD \u00b6 GeoSpark-Viz Scala and Java API: http://www.public.asu.edu/~jiayu2/geosparkviz/javadoc/ Note: Scala can call Java APIs seamlessly. That means GeoSparkViz Scala users use the same APIs with GeoSparkViz Java users.","title":"RDD"},{"location":"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd","text":"GeoSpark-Viz Scala and Java API: http://www.public.asu.edu/~jiayu2/geosparkviz/javadoc/ Note: Scala can call Java APIs seamlessly. That means GeoSparkViz Scala users use the same APIs with GeoSparkViz Java users.","title":"Scala and Java API for RDD"},{"location":"archive/api/viz/sql/","text":"Quick start \u00b6 The detailed explanation is here: Visualize Spatial DataFrame/RDD . Add GeoSpark-core, GeoSparkSQL, GeoSparkViz into your project POM.xml or build.sbt Declare your Spark Session sparkSession = SparkSession . builder (). config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ). config ( \"spark.kryo.registrator\" , classOf [ GeoSparkVizKryoRegistrator ]. getName ). master ( \"local[*]\" ). appName ( \"myGeoSparkVizDemo\" ). getOrCreate () Add the following lines after your SparkSession declaration: GeoSparkSQLRegistrator . registerAll ( sparkSession ) GeoSparkVizRegistrator . registerAll ( sparkSession ) Regular functions \u00b6 ST_Pixelize \u00b6 Introduction: Return a pixel for a given resolution Format: ST_Pixelize (A:geometry, ResolutionX:int, ResolutionY:int, Boundary:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_Pixelize ( shape , 256 , 256 , ( ST_Envelope_Aggr ( shape ) FROM pointtable )) FROM polygondf ST_TileName \u00b6 Introduction: Return the map tile name for a given zoom level. Please refer to OpenStreetMap ZoomLevel and OpenStreetMap tile name . Note Tile name is formatted as a \"Z-X-Y\" string. Z is zoom level. X is tile coordinate on X axis. Y is tile coordinate on Y axis. Format: ST_TileName (A:pixel, ZoomLevel:int) Since: v1.2.0 Spark SQL example: SELECT ST_TileName ( pixels . px , 3 ) FROM pixels ST_Colorize \u00b6 Introduction: Given the weight of a pixel, return the corresponding color. The weight can be the spatial aggregation of spatial objects or spatial observations such as temperature and humidity. Note The color is encoded to an Integer type value in DataFrame. When you print it, it will show some nonsense values. You can just treat them as colors in GeoSparkViz. Format: ST_Colorize (weight:Double, maxWeight:Double, mandatory color: string (Optional)) Since: v1.2.0 Produce various colors - heat map This function will normalize the weight according to the max weight among all pixels. Different pixel obtains different color. Spark SQL example: SELECT pixels . px , ST_Colorize ( pixels . weight , 999 ) AS color FROM pixels Produce uniform colors - scatter plot If a mandatory color name is put as the third input argument, this function will directly ouput this color, without considering the weights. In this case, every pixel will possess the same color. Spark SQL example: SELECT pixels . px , ST_Colorize ( pixels . weight , 999 , 'red' ) AS color FROM pixels Here are some example color names can be entered: \"firebrick\" \"#aa38e0\" \"0x40A8CC\" \"rgba(112,36,228,0.9)\" Please refer to AWT Colors for a list of pre-defined colors. ST_EncodeImage \u00b6 Introduction: Return the base64 string representation of a Java PNG BufferedImage. This is specific for the server-client environment. For example, transfer the base64 string from GeoSparkViz to Apache Zeppelin. Format: ST_EncodeImage (A:image) Since: v1.2.0 Spark SQL example: SELECT ST_EncodeImage ( images . img ) FROM images Aggregate functions \u00b6 ST_Render \u00b6 Introduction: Given a group of pixels and their colors, return a single Java PNG BufferedImage Format: ST_Render (A:pixel, B:color) Since: v1.2.0 Spark SQL example: SELECT tilename , ST_Render ( pixels . px , pixels . color ) AS tileimg FROM pixels GROUP BY tilename","title":"DataFrame/SQL"},{"location":"archive/api/viz/sql/#quick-start","text":"The detailed explanation is here: Visualize Spatial DataFrame/RDD . Add GeoSpark-core, GeoSparkSQL, GeoSparkViz into your project POM.xml or build.sbt Declare your Spark Session sparkSession = SparkSession . builder (). config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ). config ( \"spark.kryo.registrator\" , classOf [ GeoSparkVizKryoRegistrator ]. getName ). master ( \"local[*]\" ). appName ( \"myGeoSparkVizDemo\" ). getOrCreate () Add the following lines after your SparkSession declaration: GeoSparkSQLRegistrator . registerAll ( sparkSession ) GeoSparkVizRegistrator . registerAll ( sparkSession )","title":"Quick start"},{"location":"archive/api/viz/sql/#regular-functions","text":"","title":"Regular functions"},{"location":"archive/api/viz/sql/#st_pixelize","text":"Introduction: Return a pixel for a given resolution Format: ST_Pixelize (A:geometry, ResolutionX:int, ResolutionY:int, Boundary:geometry) Since: v1.2.0 Spark SQL example: SELECT ST_Pixelize ( shape , 256 , 256 , ( ST_Envelope_Aggr ( shape ) FROM pointtable )) FROM polygondf","title":"ST_Pixelize"},{"location":"archive/api/viz/sql/#st_tilename","text":"Introduction: Return the map tile name for a given zoom level. Please refer to OpenStreetMap ZoomLevel and OpenStreetMap tile name . Note Tile name is formatted as a \"Z-X-Y\" string. Z is zoom level. X is tile coordinate on X axis. Y is tile coordinate on Y axis. Format: ST_TileName (A:pixel, ZoomLevel:int) Since: v1.2.0 Spark SQL example: SELECT ST_TileName ( pixels . px , 3 ) FROM pixels","title":"ST_TileName"},{"location":"archive/api/viz/sql/#st_colorize","text":"Introduction: Given the weight of a pixel, return the corresponding color. The weight can be the spatial aggregation of spatial objects or spatial observations such as temperature and humidity. Note The color is encoded to an Integer type value in DataFrame. When you print it, it will show some nonsense values. You can just treat them as colors in GeoSparkViz. Format: ST_Colorize (weight:Double, maxWeight:Double, mandatory color: string (Optional)) Since: v1.2.0","title":"ST_Colorize"},{"location":"archive/api/viz/sql/#st_encodeimage","text":"Introduction: Return the base64 string representation of a Java PNG BufferedImage. This is specific for the server-client environment. For example, transfer the base64 string from GeoSparkViz to Apache Zeppelin. Format: ST_EncodeImage (A:image) Since: v1.2.0 Spark SQL example: SELECT ST_EncodeImage ( images . img ) FROM images","title":"ST_EncodeImage"},{"location":"archive/api/viz/sql/#aggregate-functions","text":"","title":"Aggregate functions"},{"location":"archive/api/viz/sql/#st_render","text":"Introduction: Given a group of pixels and their colors, return a single Java PNG BufferedImage Format: ST_Render (A:pixel, B:color) Since: v1.2.0 Spark SQL example: SELECT tilename , ST_Render ( pixels . px , pixels . color ) AS tileimg FROM pixels GROUP BY tilename","title":"ST_Render"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/","text":"Apache Spark 2.X versions \u00b6 Please add the following dependencies into your POM.xml or build.sbt GeoSpark-Core \u00b6 groupId: org.datasyslab artifactId: geospark version: 1.3.1 GeoSpark-SQL \u00b6 For SparkSQL-2.3 \u00b6 groupId: org.datasyslab artifactId: geospark-sql_2.3 version: 1.3.1 For SparkSQL-2.2 \u00b6 groupId: org.datasyslab artifactId: geospark-sql_2.2 version: 1.3.1 For SparkSQL-2.1 \u00b6 groupId: org.datasyslab artifactId: geospark-sql_2.1 version: 1.3.1 GeoSpark-Viz 1.2.0 and later \u00b6 For SparkSQL-2.3 \u00b6 groupId: org.datasyslab artifactId: geospark-viz_2.3 version: 1.3.1 For SparkSQL-2.2 \u00b6 groupId: org.datasyslab artifactId: geospark-viz_2.2 version: 1.3.1 For SparkSQL-2.1 \u00b6 groupId: org.datasyslab artifactId: geospark-viz_2.1 version: 1.3.1 GeoSpark-Viz 1.1.3 and earlier \u00b6 groupId: org.datasyslab artifactId: geospark-viz version: 1.1.3 Apache Spark 1.X versions \u00b6 Please add the following dependencies into your POM.xml or build.sbt GeoSpark-Core \u00b6 groupId: org.datasyslab artifactId: geospark version: 0.8.2-spark-1.x GeoSpark-Viz \u00b6 groupId: org.datasyslab artifactId: babylon version: 0.2.1-spark-1.x SNAPSHOT versions \u00b6 Sometimes GeoSpark has a SNAPSHOT version for the upcoming release. \"SNAPSHOT\" is uppercase. groupId: org.datasyslab artifactId: geospark version: 1.3.2-SNAPSHOT groupId: org.datasyslab artifactId: geospark-sql_2.3 version: 1.3.2-SNAPSHOT groupId: org.datasyslab artifactId: geospark-viz version: 1.3.2-SNAPSHOT In order to download SNAPSHOTs, you need to add the following repositories in your POM.XML or build.sbt build.sbt \u00b6 resolvers += \"Sonatype OSS Snapshots\" at \" https://oss.sonatype.org/content/repositories/snapshots \" POM.XML \u00b6 <profiles> <profile> <id> allow-snapshots </id> <activation><activeByDefault> true </activeByDefault></activation> <repositories> <repository> <id> snapshots-repo </id> <url> https://oss.sonatype.org/content/repositories/snapshots </url> <releases><enabled> false </enabled></releases> <snapshots><enabled> true </enabled></snapshots> </repository> </repositories> </profile> </profiles>","title":"Maven Central coordinate"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions","text":"Please add the following dependencies into your POM.xml or build.sbt","title":"Apache Spark 2.X versions"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core","text":"groupId: org.datasyslab artifactId: geospark version: 1.3.1","title":"GeoSpark-Core"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-sql","text":"","title":"GeoSpark-SQL"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23","text":"groupId: org.datasyslab artifactId: geospark-sql_2.3 version: 1.3.1","title":"For SparkSQL-2.3"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22","text":"groupId: org.datasyslab artifactId: geospark-sql_2.2 version: 1.3.1","title":"For SparkSQL-2.2"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21","text":"groupId: org.datasyslab artifactId: geospark-sql_2.1 version: 1.3.1","title":"For SparkSQL-2.1"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-120-and-later","text":"","title":"GeoSpark-Viz 1.2.0 and later"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23_1","text":"groupId: org.datasyslab artifactId: geospark-viz_2.3 version: 1.3.1","title":"For SparkSQL-2.3"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22_1","text":"groupId: org.datasyslab artifactId: geospark-viz_2.2 version: 1.3.1","title":"For SparkSQL-2.2"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21_1","text":"groupId: org.datasyslab artifactId: geospark-viz_2.1 version: 1.3.1","title":"For SparkSQL-2.1"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier","text":"groupId: org.datasyslab artifactId: geospark-viz version: 1.1.3","title":"GeoSpark-Viz 1.1.3 and earlier"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions","text":"Please add the following dependencies into your POM.xml or build.sbt","title":"Apache Spark 1.X versions"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1","text":"groupId: org.datasyslab artifactId: geospark version: 0.8.2-spark-1.x","title":"GeoSpark-Core"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz","text":"groupId: org.datasyslab artifactId: babylon version: 0.2.1-spark-1.x","title":"GeoSpark-Viz"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions","text":"Sometimes GeoSpark has a SNAPSHOT version for the upcoming release. \"SNAPSHOT\" is uppercase. groupId: org.datasyslab artifactId: geospark version: 1.3.2-SNAPSHOT groupId: org.datasyslab artifactId: geospark-sql_2.3 version: 1.3.2-SNAPSHOT groupId: org.datasyslab artifactId: geospark-viz version: 1.3.2-SNAPSHOT In order to download SNAPSHOTs, you need to add the following repositories in your POM.XML or build.sbt","title":"SNAPSHOT versions"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#buildsbt","text":"resolvers += \"Sonatype OSS Snapshots\" at \" https://oss.sonatype.org/content/repositories/snapshots \"","title":"build.sbt"},{"location":"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml","text":"<profiles> <profile> <id> allow-snapshots </id> <activation><activeByDefault> true </activeByDefault></activation> <repositories> <repository> <id> snapshots-repo </id> <url> https://oss.sonatype.org/content/repositories/snapshots </url> <releases><enabled> false </enabled></releases> <snapshots><enabled> true </enabled></snapshots> </repository> </repositories> </profile> </profiles>","title":"POM.XML"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/","text":"v1.3.1 \u00b6 This version includes the official release of GeoSpark Python wrapper. It also contains a number of bug fixes and new functions. The tutorial section provides some articles to explain the usage of GeoSpark Python wrapper. GeoSpark Core Bug fix: Issue # 344 and PR # 365 : GeoJSON reader cannot handle \"id\" Issue # 420 and PR # 421 : Cannot handle null value in geojson properties PR # 422 : Use HTTPS to resolve dependencies in Maven Build New functions: Issue # 399 and PR # 401 : saveAsWKB PR # 402 : saveAsWKT GeoSpark SQL New functions: PR # 359 : ST_NPoints PR # 373 : ST_GeometryType PR # 398 : ST_SimplifyPreserveTopology PR # 406 : ST_MakeValid PR # 416 : ST_Intersection_aggr Performance: Issue # 345 and PR # 346 : the performance issue of Adapter.toDF() function Bug fix: Issue # 395 and PR # 396 : Fix the geometry col bug in Adapter GeoSpark Viz Bug fix: Issue # 378 and PR # 379 : Classpath issue when integrating GeoSparkViz with s3 GeoSpark Python Add new GeoSpark python wrapper for RDD and SQL APIs Contributors (12) Mariano Gonzalez Pawe\u0142 Koci\u0144ski Semen Komissarov Jonathan Leitschuh Netanel Malka Keivan Shahida Sachio Wakai Hui Wang Wrussia Jia Yu Harry Zhu Ilya Zverev v1.3.0 \u00b6 This release has been skipped due to a bug in GeoSpark Python wrapper. v1.2.0 \u00b6 This version contains numerous bug fixes, new functions, and new GeoSpark module. License change From MIT to Apache License 2.0 GeoSpark Core Bug fix: Issue # 224 load GeoJSON non-spatial attributes. Issue # 228 Shapefiel Reader fails to handle UNDEFINED type. Issue # 320 Read CSV ArrayIndexOutOfBoundsException New functions: PR # 270 # 298 Add GeoJSON Reader to load GeoJSON with all attributes. See GeoSpark doc for an example. PR # 314 Add WktReader and WkbReader. Their usage is simialr to GeoJSON reader. GeoSpark SQL Bug fix: Issue # 244 JTS side location conflict Issue # 245 Drop ST_Circle in 1.2.0 Issue # 288 ST_isValid fails Issue # 321 ST_Point doesn't accept null user data PR # 284 ST_Union_Aggr bug PR # 331 Adapter doesn't handle null values New SQL functions: ST_IsValid ST_PrecisionReduce ST_Touches ST_Overlaps ST_Equals ST_Crosses ST_IsSimple ST_AsText Behavior / API change: GeoSpark Adapter will automatically carry all attributes between DataFrame and RDD. No need to use UUID in SQL ST functions to pass values. Please read GeoSpark doc . GeoSpark Viz Bug fix: Issue # 231 Pixel NullPointException Issue # 234 OutOfMemory for large images New functions Add the DataFrame support. Please read GeoSpark doc ST_Pixelize ST_TileName ST_Colorize ST_EncodeImage ST_Render Behavior / API change GeoSparkViz Maven coordinate changed. You need to specify Spark version. Please read GeoSpark Maven coordinate GeoSpark-Zeppelin New functions Add the support of connecting GeoSpark and Zeppelin Add the support of connecting GeoSparkViz and Zeppelin Contributors (13) Anton Peniaziev, Avshalom Orenstein, Jia Yu, Jordan Perr-Sauer, JulienPeloton, Sergii Mikhtoniuk, Netanel Malka, Rishabh Mishra, sagar1993, Shi-Hao Liu, Serhuela, tociek, Wrussia v1.1.3 \u00b6 This version contains a critical bug fix for GeoSpark-core RDD API. GeoSpark Core Fixed Issue # 222 : geometry toString() method has cumulative non-spatial attributes. See PR # 223 GeoSpark SQL None GeoSpark Viz None v1.1.2 \u00b6 This version contains several bug fixes and several small improvements. GeoSpark Core Added WKB input format support (Issue # 2 , 213 ): See PR # 203 , 216 . Thanks for the patch from Lucas C.! Added empty constructors for typed SpatialRDDs. This is especially useful when the users want to load a persisted RDD from disk and assemble a typed SpatialRDD by themselves. See PR # 211 Fixed Issue # 214 : duplicated geometry parts when print each Geometry in a SpatialRDD to a String using toString() method. See PR # 216 GeoSpark SQL Added ST_GeomFromWKB expression (Issue # 2 ): See PR # 203 . Thanks for the patch from Lucas C.! Fixed Issue # 193 : IllegalArgumentException in RangeJoin: Number of partitions must be >= 0. See PR # 207 Fixed Issue # 204 : Wrong ST_Intersection result. See PR # 205 [For Developer] Separate the expression catalog and the udf registrator to simplify the steps of merging patches among different Spark versions. See PR # 209 GeoSpark Viz None v1.1.1 \u00b6 This release has been skipped due to wrong Maven Central configuration. v1.1.0 \u00b6 This version adds very efficient R-Tree and Quad-Tree index serializers and supports Apache Spark and SparkSQL 2.3. See Maven Central coordinate to locate the particular version. GeoSpark Core Fixed Issue # 185 : CRStransform throws Exception for Bursa wolf parameters. See PR # 189 . Fixed Issue # 190 : Shapefile reader doesn't support Chinese characters (\u4e2d\u6587\u5b57\u7b26). See PR # 192 . Add R-Tree and Quad-Tree index serializer. GeoSpark custom index serializer has around 2 times smaller index size and faster serialization than Apache Spark kryo serializer. See PR # 177 . GeoSpark SQL Fixed Issue # 194 : doesn't support Spark 2.3. Fixed Issue # 188 :ST_ConvexHull should accept any type of geometry as an input. See PR # 189 . Add ST_Intersection function. See Issue # 110 and PR # 189 . GeoSpark Viz Fixed Issue # 154 : GeoSpark kryp serializer and GeoSparkViz conflict. See PR # 178 v1.0.1 \u00b6 GeoSpark Core Fixed Issue # 170 GeoSpark SQL Fixed Issue # 171 Added the support of SparkSQL 2.2. GeoSpark-SQL for Spark 2.1 is published separately ( Maven Coordinates ). GeoSpark Viz None v1.0.0 \u00b6 GeoSpark Core Add GeoSparkConf class to read GeoSparkConf from SparkConf GeoSpark SQL Initial release: fully supports SQL/MM-Part3 Spatial SQL standard GeoSpark Viz Republish GeoSpark Viz under \"GeoSparkViz\" folder. All \"Babylon\" strings have been replaced to \"GeoSparkViz\" v0.9.1 (GeoSpark-core) \u00b6 Bug fixes : Fixed \"Missing values when reading Shapefile\": Issue #141 Performance improvement : Solved Issue #91 , #103 , #104 , #125 , #150 . Add GeoSpark customized Kryo Serializer to significantly reduce memory footprint. This serializer which follows Shapefile compression rule takes less memory than the default Kryo. See PR 139 . Delete the duplicate removal by using Reference Point concept. This eliminates one data shuffle but still guarantees the accuracy. See PR 131 . New Functionalities added : SpatialJoinQueryFlat/DistanceJoinQueryFlat returns the join query in a flat way following database iteration model: Each row has fixed two members [Polygon, Point]. This API is more efficient for unbalanced length of join results. The left and right shapes in Range query, Distance query, Range join query, Distance join query can be switched. The index side in Range query, Distance query, Range join query, Distance join query can be switched. The generic SpatialRdd supports heterogenous geometries Add KDB-Tree spatial partitioning method which is more balanced than Quad-Tree Range query, Distance query, Range join query, Distance join query, KNN query supports heterogenous inputs. v0.8.2 (GeoSpark-core) \u00b6 Bug fixes : Fix the shapefile RDD null pointer bug when running in cluster mode. See Issue https://github.com/DataSystemsLab/GeoSpark/issues/115 New function added : Provide granular control to SpatialRDD sampling utils. SpatialRDD has a setter and getter for a parameter called \"sampleNumber\". The user can manually specify the sample size for spatial partitioning. v0.8.1 (GeoSpark-core) \u00b6 Bug fixes : (1) Fix the blank DBF attribute error when load DBF along with SHX file. (2) Allow user to call CRS transformation function at any time. Previously, it was only allowed in GeoSpark constructors v0.8.0 (GeoSpark-core) \u00b6 New input format added : GeoSpark is able to load and query ESRI ShapeFile (.shp, .shx, .dbf) from local disk and HDFS! Users first need to build a Shapefile RDD by giving Spark Context and an input path then call ShapefileRDD.getSpatialRDD to retrieve Spatial RDD. ( Scala Example , Java Example ) Join Query Performance enhancement 1 : GeoSpark provides a new Quad-Tree Spatial Partitioning method to speed up Join Query. Users need to pass GridType.QUADTREE parameter to RDD1.spatialPartitioning() function. Then users need to use RDD1.partitionTree in RDD2.spatialPartitioning() function. This Quad-Tree partitioning method (1) avoids overflowed spatial objects when partitioning spatial objects. (2) checking a spatial object against the Quad-Tree grids is completed in a log complexity tree search. ( Scala Example , Java Example ) Join Query Performance enhancement 2 : Internally, GeoSpark uses zipPartitions instead of CoGroup to join two Spatial RDD so that the incurred shuffle overhead decreases. SpatialRDD Initialization Performance enhancement : GeoSpark uses mapPartition instead of flatMapToPair to generate Spatial Objects. This will speed up the calculation. API changed : Since it chooses mapPartition API in mappers, GeoSpark no longer supports the old user supplified format mapper. However, if you are using your own format mapper for old GeoSpark version, you just need to add one more loop to fit in GeoSpark 0.8.0. Please see GeoSpark user supplied format mapper examples Alternative SpatialRDD constructor added : GeoSpark no longer forces users to provide StorageLevel parameter in their SpatialRDD constructors. This will siginicantly accelerate all Spatial RDD initialization. If he only needs Spatial Range Query and KNN query, the user can totally remove this parameter from their constructors. If he needs Spatial Join Query or Distance Join Query but he knows his dataset boundary and approximate total count, the user can also remove StorageLevel parameter and append a Envelope type dataset boundary and an approxmiate total count as additional parameters. If he needs Spatial Join Query or Distance Join Query but knows nothing about his dataset , the user still has to pass StorageLevel parameter. Bug fix : Fix bug Issue #97 and Issue #100 . v0.1 - v0.7 \u00b6 Version Summary 0.7.0 Coordinate Reference System (CRS) Transformation (aka. Coordinate projection) added: GeoSpark allows users to transform the original CRS (e.g., degree based coordinates such as EPSG:4326 and WGS84) to any other CRS (e.g., meter based coordinates such as EPSG:3857) so that it can accurately process both geographic data and geometrical data. Please specify your desired CRS in GeoSpark Spatial RDD constructor ( Example ); Unnecessary dependencies removed : NetCDF/HDF support depends on SerNetCDF . SetNetCDF becomes optional dependency to reduce fat jar size; Default JDK/JRE change to JDK/JRE 1.8 : To satisfy CRS transformation requirement, GeoSpark is compiled by JDK 1.8 by default; Bug fix : fix a small format bug when output spatial RDD to disk. 0.6.2 New input format added: Add a new input format mapper called EarthdataHDFPointMapper so that GeoSpark can load, query and save NASA Petabytes NetCDF/HDF Earth Data ( Scala Example , Java Example ); Bug fix: Print UserData attribute when output Spatial RDDs as GeoJSON or regular text file 0.6.1 Bug fixes: Fix typos LineString DistanceJoin API 0.6.0 Major updates: (1) DistanceJoin is merged into JoinQuery. GeoSpark now supports complete DistanceJoin between Points, Polygons, and LineStrings. (2) Add Refine Phase to Spatial Range and Join Query. Use real polygon coordinates instead of its MBR to filter the final results. API changes: All spatial range and join queries now take a parameter called ConsiderBoundaryIntersection . This will tell GeoSpark whether returns the objects intersect with windows. 0.5.3 Bug fix: Fix Issue #69 : Now, if two objects have the same coordinates but different non-spatial attributes (UserData), GeoSpark treats them as different objects. 0.5.2 Bug fix: Fix Issue #58 and Issue #60 ; Performance enhancement: (1) Deprecate all old Spatial RDD constructors. See the JavaDoc here . (2) Recommend the new SRDD constructors which take an additional RDD storage level and automatically cache rawSpatialRDD to accelerate internal SRDD analyze step 0.5.1 Bug fix: (1) GeoSpark: Fix inaccurate KNN result when K is large (2) GeoSpark: Replace incompatible Spark API call Issue #55 ; (3) Babylon: Remove JPG output format temporarily due to the lack of OpenJDK support 0.5.0 Major updates: We are pleased to announce the initial version of Babylon a large-scale in-memory geospatial visualization system extending GeoSpark. Babylon and GeoSpark are integrated together. You can just import GeoSpark and enjoy! More details are available here: Babylon GeoSpatial Visualization 0.4.0 Major updates: ( Example ) 1. Refactor constrcutor API usage. 2. Simplify Spatial Join Query API. 3. Add native support for LineStringRDD; Functionality enhancement: 1. Release the persist function back to users. 2. Add more exception explanations. 0.3.2 Functionality enhancement: 1. JTSplus Spatial Objects now carry the original input data. Each object stores \"UserData\" and provides getter and setter. 2. Add a new SpatialRDD constructor to transform a regular data RDD to a spatial partitioned SpatialRDD. 0.3.1 Bug fix: Support Apache Spark 2.X version, fix a bug which results in inaccurate results when doing join query, add more unit test cases 0.3 Major updates: Significantly shorten query time on spatial join for skewed data; Support load balanced spatial partitioning methods (also serve as the global index); Optimize code for iterative spatial data mining 0.2 Improve code structure and refactor API 0.1 Support spatial range, join and Knn GeoSpark-Viz (old) \u00b6 Version Summary 0.2.2 Add the support of new output storage : Now the user is able to output gigapixel or megapixel resolution images (image tiles or stitched single image) to HDFS and Amazon S3. Please use the new ImageGenerator not the BabylonImageGenerator class. 0.2.1 Performance enhancement : significantly accelerate single image generation pipeline. Bug fix :fix a bug in scatter plot parallel rendering. 0.2.0 API updates for Issue #80 : 1. Babylon now has two different OverlayOperators for raster image and vector image: RasterOverlayOperator and VectorOverlayOperator; 2. Babylon merged old SparkImageGenerator and NativeJavaGenerator into a new BabylonImageGenerator which has neat APIs; New feature: Babylon can use Scatter Plot to visualize NASA Petabytes NetCDF/HDF format Earth Data. ( Scala Example , Java Example ) 0.1.1 Major updates: Babylon supports vector image and outputs SVG image format 0.1.0 Major updates: Babylon initial version supports raster images","title":"Release notes"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v131","text":"This version includes the official release of GeoSpark Python wrapper. It also contains a number of bug fixes and new functions. The tutorial section provides some articles to explain the usage of GeoSpark Python wrapper. GeoSpark Core Bug fix: Issue # 344 and PR # 365 : GeoJSON reader cannot handle \"id\" Issue # 420 and PR # 421 : Cannot handle null value in geojson properties PR # 422 : Use HTTPS to resolve dependencies in Maven Build New functions: Issue # 399 and PR # 401 : saveAsWKB PR # 402 : saveAsWKT GeoSpark SQL New functions: PR # 359 : ST_NPoints PR # 373 : ST_GeometryType PR # 398 : ST_SimplifyPreserveTopology PR # 406 : ST_MakeValid PR # 416 : ST_Intersection_aggr Performance: Issue # 345 and PR # 346 : the performance issue of Adapter.toDF() function Bug fix: Issue # 395 and PR # 396 : Fix the geometry col bug in Adapter GeoSpark Viz Bug fix: Issue # 378 and PR # 379 : Classpath issue when integrating GeoSparkViz with s3 GeoSpark Python Add new GeoSpark python wrapper for RDD and SQL APIs Contributors (12) Mariano Gonzalez Pawe\u0142 Koci\u0144ski Semen Komissarov Jonathan Leitschuh Netanel Malka Keivan Shahida Sachio Wakai Hui Wang Wrussia Jia Yu Harry Zhu Ilya Zverev","title":"v1.3.1"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v130","text":"This release has been skipped due to a bug in GeoSpark Python wrapper.","title":"v1.3.0"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v120","text":"This version contains numerous bug fixes, new functions, and new GeoSpark module. License change From MIT to Apache License 2.0 GeoSpark Core Bug fix: Issue # 224 load GeoJSON non-spatial attributes. Issue # 228 Shapefiel Reader fails to handle UNDEFINED type. Issue # 320 Read CSV ArrayIndexOutOfBoundsException New functions: PR # 270 # 298 Add GeoJSON Reader to load GeoJSON with all attributes. See GeoSpark doc for an example. PR # 314 Add WktReader and WkbReader. Their usage is simialr to GeoJSON reader. GeoSpark SQL Bug fix: Issue # 244 JTS side location conflict Issue # 245 Drop ST_Circle in 1.2.0 Issue # 288 ST_isValid fails Issue # 321 ST_Point doesn't accept null user data PR # 284 ST_Union_Aggr bug PR # 331 Adapter doesn't handle null values New SQL functions: ST_IsValid ST_PrecisionReduce ST_Touches ST_Overlaps ST_Equals ST_Crosses ST_IsSimple ST_AsText Behavior / API change: GeoSpark Adapter will automatically carry all attributes between DataFrame and RDD. No need to use UUID in SQL ST functions to pass values. Please read GeoSpark doc . GeoSpark Viz Bug fix: Issue # 231 Pixel NullPointException Issue # 234 OutOfMemory for large images New functions Add the DataFrame support. Please read GeoSpark doc ST_Pixelize ST_TileName ST_Colorize ST_EncodeImage ST_Render Behavior / API change GeoSparkViz Maven coordinate changed. You need to specify Spark version. Please read GeoSpark Maven coordinate GeoSpark-Zeppelin New functions Add the support of connecting GeoSpark and Zeppelin Add the support of connecting GeoSparkViz and Zeppelin Contributors (13) Anton Peniaziev, Avshalom Orenstein, Jia Yu, Jordan Perr-Sauer, JulienPeloton, Sergii Mikhtoniuk, Netanel Malka, Rishabh Mishra, sagar1993, Shi-Hao Liu, Serhuela, tociek, Wrussia","title":"v1.2.0"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v113","text":"This version contains a critical bug fix for GeoSpark-core RDD API. GeoSpark Core Fixed Issue # 222 : geometry toString() method has cumulative non-spatial attributes. See PR # 223 GeoSpark SQL None GeoSpark Viz None","title":"v1.1.3"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v112","text":"This version contains several bug fixes and several small improvements. GeoSpark Core Added WKB input format support (Issue # 2 , 213 ): See PR # 203 , 216 . Thanks for the patch from Lucas C.! Added empty constructors for typed SpatialRDDs. This is especially useful when the users want to load a persisted RDD from disk and assemble a typed SpatialRDD by themselves. See PR # 211 Fixed Issue # 214 : duplicated geometry parts when print each Geometry in a SpatialRDD to a String using toString() method. See PR # 216 GeoSpark SQL Added ST_GeomFromWKB expression (Issue # 2 ): See PR # 203 . Thanks for the patch from Lucas C.! Fixed Issue # 193 : IllegalArgumentException in RangeJoin: Number of partitions must be >= 0. See PR # 207 Fixed Issue # 204 : Wrong ST_Intersection result. See PR # 205 [For Developer] Separate the expression catalog and the udf registrator to simplify the steps of merging patches among different Spark versions. See PR # 209 GeoSpark Viz None","title":"v1.1.2"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v111","text":"This release has been skipped due to wrong Maven Central configuration.","title":"v1.1.1"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v110","text":"This version adds very efficient R-Tree and Quad-Tree index serializers and supports Apache Spark and SparkSQL 2.3. See Maven Central coordinate to locate the particular version. GeoSpark Core Fixed Issue # 185 : CRStransform throws Exception for Bursa wolf parameters. See PR # 189 . Fixed Issue # 190 : Shapefile reader doesn't support Chinese characters (\u4e2d\u6587\u5b57\u7b26). See PR # 192 . Add R-Tree and Quad-Tree index serializer. GeoSpark custom index serializer has around 2 times smaller index size and faster serialization than Apache Spark kryo serializer. See PR # 177 . GeoSpark SQL Fixed Issue # 194 : doesn't support Spark 2.3. Fixed Issue # 188 :ST_ConvexHull should accept any type of geometry as an input. See PR # 189 . Add ST_Intersection function. See Issue # 110 and PR # 189 . GeoSpark Viz Fixed Issue # 154 : GeoSpark kryp serializer and GeoSparkViz conflict. See PR # 178","title":"v1.1.0"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v101","text":"GeoSpark Core Fixed Issue # 170 GeoSpark SQL Fixed Issue # 171 Added the support of SparkSQL 2.2. GeoSpark-SQL for Spark 2.1 is published separately ( Maven Coordinates ). GeoSpark Viz None","title":"v1.0.1"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v100","text":"GeoSpark Core Add GeoSparkConf class to read GeoSparkConf from SparkConf GeoSpark SQL Initial release: fully supports SQL/MM-Part3 Spatial SQL standard GeoSpark Viz Republish GeoSpark Viz under \"GeoSparkViz\" folder. All \"Babylon\" strings have been replaced to \"GeoSparkViz\"","title":"v1.0.0"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core","text":"Bug fixes : Fixed \"Missing values when reading Shapefile\": Issue #141 Performance improvement : Solved Issue #91 , #103 , #104 , #125 , #150 . Add GeoSpark customized Kryo Serializer to significantly reduce memory footprint. This serializer which follows Shapefile compression rule takes less memory than the default Kryo. See PR 139 . Delete the duplicate removal by using Reference Point concept. This eliminates one data shuffle but still guarantees the accuracy. See PR 131 . New Functionalities added : SpatialJoinQueryFlat/DistanceJoinQueryFlat returns the join query in a flat way following database iteration model: Each row has fixed two members [Polygon, Point]. This API is more efficient for unbalanced length of join results. The left and right shapes in Range query, Distance query, Range join query, Distance join query can be switched. The index side in Range query, Distance query, Range join query, Distance join query can be switched. The generic SpatialRdd supports heterogenous geometries Add KDB-Tree spatial partitioning method which is more balanced than Quad-Tree Range query, Distance query, Range join query, Distance join query, KNN query supports heterogenous inputs.","title":"v0.9.1 (GeoSpark-core)"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core","text":"Bug fixes : Fix the shapefile RDD null pointer bug when running in cluster mode. See Issue https://github.com/DataSystemsLab/GeoSpark/issues/115 New function added : Provide granular control to SpatialRDD sampling utils. SpatialRDD has a setter and getter for a parameter called \"sampleNumber\". The user can manually specify the sample size for spatial partitioning.","title":"v0.8.2 (GeoSpark-core)"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core","text":"Bug fixes : (1) Fix the blank DBF attribute error when load DBF along with SHX file. (2) Allow user to call CRS transformation function at any time. Previously, it was only allowed in GeoSpark constructors","title":"v0.8.1 (GeoSpark-core)"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core","text":"New input format added : GeoSpark is able to load and query ESRI ShapeFile (.shp, .shx, .dbf) from local disk and HDFS! Users first need to build a Shapefile RDD by giving Spark Context and an input path then call ShapefileRDD.getSpatialRDD to retrieve Spatial RDD. ( Scala Example , Java Example ) Join Query Performance enhancement 1 : GeoSpark provides a new Quad-Tree Spatial Partitioning method to speed up Join Query. Users need to pass GridType.QUADTREE parameter to RDD1.spatialPartitioning() function. Then users need to use RDD1.partitionTree in RDD2.spatialPartitioning() function. This Quad-Tree partitioning method (1) avoids overflowed spatial objects when partitioning spatial objects. (2) checking a spatial object against the Quad-Tree grids is completed in a log complexity tree search. ( Scala Example , Java Example ) Join Query Performance enhancement 2 : Internally, GeoSpark uses zipPartitions instead of CoGroup to join two Spatial RDD so that the incurred shuffle overhead decreases. SpatialRDD Initialization Performance enhancement : GeoSpark uses mapPartition instead of flatMapToPair to generate Spatial Objects. This will speed up the calculation. API changed : Since it chooses mapPartition API in mappers, GeoSpark no longer supports the old user supplified format mapper. However, if you are using your own format mapper for old GeoSpark version, you just need to add one more loop to fit in GeoSpark 0.8.0. Please see GeoSpark user supplied format mapper examples Alternative SpatialRDD constructor added : GeoSpark no longer forces users to provide StorageLevel parameter in their SpatialRDD constructors. This will siginicantly accelerate all Spatial RDD initialization. If he only needs Spatial Range Query and KNN query, the user can totally remove this parameter from their constructors. If he needs Spatial Join Query or Distance Join Query but he knows his dataset boundary and approximate total count, the user can also remove StorageLevel parameter and append a Envelope type dataset boundary and an approxmiate total count as additional parameters. If he needs Spatial Join Query or Distance Join Query but knows nothing about his dataset , the user still has to pass StorageLevel parameter. Bug fix : Fix bug Issue #97 and Issue #100 .","title":"v0.8.0 (GeoSpark-core)"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07","text":"Version Summary 0.7.0 Coordinate Reference System (CRS) Transformation (aka. Coordinate projection) added: GeoSpark allows users to transform the original CRS (e.g., degree based coordinates such as EPSG:4326 and WGS84) to any other CRS (e.g., meter based coordinates such as EPSG:3857) so that it can accurately process both geographic data and geometrical data. Please specify your desired CRS in GeoSpark Spatial RDD constructor ( Example ); Unnecessary dependencies removed : NetCDF/HDF support depends on SerNetCDF . SetNetCDF becomes optional dependency to reduce fat jar size; Default JDK/JRE change to JDK/JRE 1.8 : To satisfy CRS transformation requirement, GeoSpark is compiled by JDK 1.8 by default; Bug fix : fix a small format bug when output spatial RDD to disk. 0.6.2 New input format added: Add a new input format mapper called EarthdataHDFPointMapper so that GeoSpark can load, query and save NASA Petabytes NetCDF/HDF Earth Data ( Scala Example , Java Example ); Bug fix: Print UserData attribute when output Spatial RDDs as GeoJSON or regular text file 0.6.1 Bug fixes: Fix typos LineString DistanceJoin API 0.6.0 Major updates: (1) DistanceJoin is merged into JoinQuery. GeoSpark now supports complete DistanceJoin between Points, Polygons, and LineStrings. (2) Add Refine Phase to Spatial Range and Join Query. Use real polygon coordinates instead of its MBR to filter the final results. API changes: All spatial range and join queries now take a parameter called ConsiderBoundaryIntersection . This will tell GeoSpark whether returns the objects intersect with windows. 0.5.3 Bug fix: Fix Issue #69 : Now, if two objects have the same coordinates but different non-spatial attributes (UserData), GeoSpark treats them as different objects. 0.5.2 Bug fix: Fix Issue #58 and Issue #60 ; Performance enhancement: (1) Deprecate all old Spatial RDD constructors. See the JavaDoc here . (2) Recommend the new SRDD constructors which take an additional RDD storage level and automatically cache rawSpatialRDD to accelerate internal SRDD analyze step 0.5.1 Bug fix: (1) GeoSpark: Fix inaccurate KNN result when K is large (2) GeoSpark: Replace incompatible Spark API call Issue #55 ; (3) Babylon: Remove JPG output format temporarily due to the lack of OpenJDK support 0.5.0 Major updates: We are pleased to announce the initial version of Babylon a large-scale in-memory geospatial visualization system extending GeoSpark. Babylon and GeoSpark are integrated together. You can just import GeoSpark and enjoy! More details are available here: Babylon GeoSpatial Visualization 0.4.0 Major updates: ( Example ) 1. Refactor constrcutor API usage. 2. Simplify Spatial Join Query API. 3. Add native support for LineStringRDD; Functionality enhancement: 1. Release the persist function back to users. 2. Add more exception explanations. 0.3.2 Functionality enhancement: 1. JTSplus Spatial Objects now carry the original input data. Each object stores \"UserData\" and provides getter and setter. 2. Add a new SpatialRDD constructor to transform a regular data RDD to a spatial partitioned SpatialRDD. 0.3.1 Bug fix: Support Apache Spark 2.X version, fix a bug which results in inaccurate results when doing join query, add more unit test cases 0.3 Major updates: Significantly shorten query time on spatial join for skewed data; Support load balanced spatial partitioning methods (also serve as the global index); Optimize code for iterative spatial data mining 0.2 Improve code structure and refactor API 0.1 Support spatial range, join and Knn","title":"v0.1 - v0.7"},{"location":"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old","text":"Version Summary 0.2.2 Add the support of new output storage : Now the user is able to output gigapixel or megapixel resolution images (image tiles or stitched single image) to HDFS and Amazon S3. Please use the new ImageGenerator not the BabylonImageGenerator class. 0.2.1 Performance enhancement : significantly accelerate single image generation pipeline. Bug fix :fix a bug in scatter plot parallel rendering. 0.2.0 API updates for Issue #80 : 1. Babylon now has two different OverlayOperators for raster image and vector image: RasterOverlayOperator and VectorOverlayOperator; 2. Babylon merged old SparkImageGenerator and NativeJavaGenerator into a new BabylonImageGenerator which has neat APIs; New feature: Babylon can use Scatter Plot to visualize NASA Petabytes NetCDF/HDF format Earth Data. ( Scala Example , Java Example ) 0.1.1 Major updates: Babylon supports vector image and outputs SVG image format 0.1.0 Major updates: Babylon initial version supports raster images","title":"GeoSpark-Viz (old)"},{"location":"archive/download/cluster/","text":"Set up your Apache Spark cluster \u00b6 Download a Spark distribution from Spark download page . Preliminary \u00b6 Set up password-less SSH on your cluster. Each master-worker pair should have bi-directional password-less SSH. Make sure you have installed JRE 1.8 or later. Add the list of your workers' IP address in ./conf/slaves Besides the necessary Spark settings, you may need to add the following lines in Spark configuration files to avoid GeoSpark memory errors: In ./conf/spark-defaults.conf spark.driver.memory 10g spark.network.timeout 1000s spark.driver.maxResultSize 5g spark.driver.memory tells Spark to allocate enough memory for the driver program because GeoSpark needs to build global grid files (global index) on the driver program. If you have a large amount of data (normally, over 100 GB), set this parameter to 2~5 GB will be good. Otherwise, you may observe \"out of memory\" error. spark.network.timeout is the default timeout for all network interactions. Sometimes, spatial join query takes longer time to shuffle data. This will ensure Spark has enough patience to wait for the result. spark.driver.maxResultSize is the limit of total size of serialized results of all partitions for each Spark action. Sometimes, the result size of spatial queries is large. The \"Collect\" operation may throw errors. For more details of Spark parameters, please visit Spark Website . Start your cluster \u00b6 Go the root folder of the uncompressed Apache Spark folder. Start your spark cluster via a terminal ./sbin/start-all.sh","title":"Set up Spark cluser"},{"location":"archive/download/cluster/#set-up-your-apache-spark-cluster","text":"Download a Spark distribution from Spark download page .","title":"Set up your Apache Spark cluster"},{"location":"archive/download/cluster/#preliminary","text":"Set up password-less SSH on your cluster. Each master-worker pair should have bi-directional password-less SSH. Make sure you have installed JRE 1.8 or later. Add the list of your workers' IP address in ./conf/slaves Besides the necessary Spark settings, you may need to add the following lines in Spark configuration files to avoid GeoSpark memory errors: In ./conf/spark-defaults.conf spark.driver.memory 10g spark.network.timeout 1000s spark.driver.maxResultSize 5g spark.driver.memory tells Spark to allocate enough memory for the driver program because GeoSpark needs to build global grid files (global index) on the driver program. If you have a large amount of data (normally, over 100 GB), set this parameter to 2~5 GB will be good. Otherwise, you may observe \"out of memory\" error. spark.network.timeout is the default timeout for all network interactions. Sometimes, spatial join query takes longer time to shuffle data. This will ensure Spark has enough patience to wait for the result. spark.driver.maxResultSize is the limit of total size of serialized results of all partitions for each Spark action. Sometimes, the result size of spatial queries is large. The \"Collect\" operation may throw errors. For more details of Spark parameters, please visit Spark Website .","title":"Preliminary"},{"location":"archive/download/cluster/#start-your-cluster","text":"Go the root folder of the uncompressed Apache Spark folder. Start your spark cluster via a terminal ./sbin/start-all.sh","title":"Start your cluster"},{"location":"archive/download/compile/","text":"Compile GeoSpark \u00b6 Some GeoSpark hackers may want to change some source code to fit in their own scenarios. To compile GeoSpark source code, you first need to download GeoSpark source code: Download / Git clone GeoSpark source code from GeoSpark Github repo . Compile the source code \u00b6 GeoSpark is a a project with three modules, core, sql, and viz. Each module is a Scala/Java mixed project which is managed by Apache Maven 3. Make sure your machine has Java 1.8 and Apache Maven 3. To compile all modules, please make sure you are in the root folder of three modules. Then enter the following command in the terminal: mvn clean install -DskipTests This command will first delete the old binary files and compile all three modules. This compilation will skip the unit tests of GeoSpark. To compile a module of GeoSpark, please make sure you are in the folder of that module. Then enter the same command. To run unit tests, just simply remove -DskipTests option. The command is like this: mvn clean install Warning The unit tests of all three modules may take up to 30 minutes. Compile the documentation \u00b6 The source code of GeoSpark documentation website is written in Markdown and then compiled by MkDocs. The website is built upon Material for MkDocs template . In GeoSpark repository, MkDocs configuration file mkdocs.yml is in the root folder and all documentation source code is in docs folder. To compile the source code and test the website on your local machine, please read MkDocs Tutorial and Materials for MkDocs Tutorial . After installing MkDocs and MkDocs-Material, run the command in GeoSpark root folder: mkdocs serve","title":"Compile the source code"},{"location":"archive/download/compile/#compile-geospark","text":"Some GeoSpark hackers may want to change some source code to fit in their own scenarios. To compile GeoSpark source code, you first need to download GeoSpark source code: Download / Git clone GeoSpark source code from GeoSpark Github repo .","title":"Compile GeoSpark"},{"location":"archive/download/compile/#compile-the-source-code","text":"GeoSpark is a a project with three modules, core, sql, and viz. Each module is a Scala/Java mixed project which is managed by Apache Maven 3. Make sure your machine has Java 1.8 and Apache Maven 3. To compile all modules, please make sure you are in the root folder of three modules. Then enter the following command in the terminal: mvn clean install -DskipTests This command will first delete the old binary files and compile all three modules. This compilation will skip the unit tests of GeoSpark. To compile a module of GeoSpark, please make sure you are in the folder of that module. Then enter the same command. To run unit tests, just simply remove -DskipTests option. The command is like this: mvn clean install Warning The unit tests of all three modules may take up to 30 minutes.","title":"Compile the source code"},{"location":"archive/download/compile/#compile-the-documentation","text":"The source code of GeoSpark documentation website is written in Markdown and then compiled by MkDocs. The website is built upon Material for MkDocs template . In GeoSpark repository, MkDocs configuration file mkdocs.yml is in the root folder and all documentation source code is in docs folder. To compile the source code and test the website on your local machine, please read MkDocs Tutorial and Materials for MkDocs Tutorial . After installing MkDocs and MkDocs-Material, run the command in GeoSpark root folder: mkdocs serve","title":"Compile the documentation"},{"location":"archive/download/overview/","text":"Direct download \u00b6 GeoSpark source code is hosted on GeoSpark GitHub repository . GeoSpark pre-compiled JARs are hosted on GeoSpark GitHub Releases . GeoSpark pre-compiled JARs are hosted on Maven Central . GeoSpark release notes are here Release notes . Install GeoSpark \u00b6 Before starting the GeoSpark journey, you need to make sure your Apache Spark cluster is ready. There are two ways to use a Scala or Java library with Apache Spark. You can user either one to run GeoSpark. Spark interactive Scala shell: easy to start, good for new learners to try simple functions Self-contained Scala / Java project: a steep learning curve of package management, but good for large projects","title":"Quick start"},{"location":"archive/download/overview/#direct-download","text":"GeoSpark source code is hosted on GeoSpark GitHub repository . GeoSpark pre-compiled JARs are hosted on GeoSpark GitHub Releases . GeoSpark pre-compiled JARs are hosted on Maven Central . GeoSpark release notes are here Release notes .","title":"Direct download"},{"location":"archive/download/overview/#install-geospark","text":"Before starting the GeoSpark journey, you need to make sure your Apache Spark cluster is ready. There are two ways to use a Scala or Java library with Apache Spark. You can user either one to run GeoSpark. Spark interactive Scala shell: easy to start, good for new learners to try simple functions Self-contained Scala / Java project: a steep learning curve of package management, but good for large projects","title":"Install GeoSpark"},{"location":"archive/download/project/","text":"Self-contained Spark projects \u00b6 A self-contained project allows you to create multiple Scala / Java files and write complex logics in one place. To use GeoSpark in your self-contained Spark project, you just need to add GeoSpark as a dependency in your POM.xml or build.sbt. Quick start \u00b6 To add GeoSpark as dependencies, please read GeoSpark Maven Central coordinates Use GeoSpark Template project to start: GeoSpark Template Project Compile your project using SBT or Maven. Make sure you obtain the fat jar which packages all dependencies. Submit your compiled fat jar to Spark cluster. Make sure you are in the root folder of Spark distribution. Then run the following command: ./bin/spark-submit --master spark://YOUR-IP:7077 /Path/To/YourJar.jar Note The detailed explanation of spark-submit is available on Spark website . How to use GeoSpark in an IDE \u00b6 Select an IDE \u00b6 To develop a complex GeoSpark project, we suggest you use IntelliJ IDEA. It supports JVM languages, Scala and Java, and many dependency management systems, Maven and SBT. Eclipse is also fine if you just want to use Java and Maven. Open GeoSpark template project \u00b6 Select a proper GeoSpark project you want from GeoSpark Template Project . In this tutorial, we use GeoSparkSQL Scala project as an example. Open the folder that contains build.sbt file in your IDE. The IDE may take a while to index dependencies and source code. Try GeoSpark SQL functions \u00b6 In your IDE, run ScalaExample.scala file. You don't need to change anything in this file. The IDE will run all SQL queries in this example in local mode. Package the project \u00b6 To run this project in cluster mode, you have to package this project to a JAR and then run it using spark-submit command. Before packaging this project, you always need to check two places: Remove the hardcoded Master IP master(\"local[*]\") . This hardcoded IP is only needed when you run this project in an IDE. var sparkSession : SparkSession = SparkSession . builder () . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) . config ( \"spark.kryo.registrator\" , classOf [ GeoSparkKryoRegistrator ]. getName ) . master ( \"local[*]\" ) . appName ( \"GeoSparkSQL-demo\" ). getOrCreate () In build.sbt (or POM.xml), set Spark dependency scope to provided instead of compile . compile is only needed when you run this project in an IDE. org.apache.spark\" %% \"spark-core\" % SparkVersion % \"compile, org.apache.spark\" %% \"spark-sql\" % SparkVersion % \"compile Warning Forgetting to change the package scope will lead to a very big fat JAR and dependency conflicts when call spark-submit . For more details, please visit Maven Dependency Scope . Make sure your downloaded Spark binary distribution is the same version with the Spark used in your build.sbt or POM.xml . Submit the compiled jar \u00b6 Go to ./target/scala-2.11 folder and find a jar called GeoSparkSQLScalaTemplate-0.1.0.jar . Note that, this JAR normally is larger than 1MB. (If you use POM.xml, the jar is under ./target folder) Submit this JAR using spark-submit . Local mode: ./bin/spark-submit /Path/To/YourJar.jar Cluster mode: ./bin/spark-submit --master spark://YOUR-IP:7077 /Path/To/YourJar.jar","title":"Self-contained project"},{"location":"archive/download/project/#self-contained-spark-projects","text":"A self-contained project allows you to create multiple Scala / Java files and write complex logics in one place. To use GeoSpark in your self-contained Spark project, you just need to add GeoSpark as a dependency in your POM.xml or build.sbt.","title":"Self-contained Spark projects"},{"location":"archive/download/project/#quick-start","text":"To add GeoSpark as dependencies, please read GeoSpark Maven Central coordinates Use GeoSpark Template project to start: GeoSpark Template Project Compile your project using SBT or Maven. Make sure you obtain the fat jar which packages all dependencies. Submit your compiled fat jar to Spark cluster. Make sure you are in the root folder of Spark distribution. Then run the following command: ./bin/spark-submit --master spark://YOUR-IP:7077 /Path/To/YourJar.jar Note The detailed explanation of spark-submit is available on Spark website .","title":"Quick start"},{"location":"archive/download/project/#how-to-use-geospark-in-an-ide","text":"","title":"How to use GeoSpark in an IDE"},{"location":"archive/download/project/#select-an-ide","text":"To develop a complex GeoSpark project, we suggest you use IntelliJ IDEA. It supports JVM languages, Scala and Java, and many dependency management systems, Maven and SBT. Eclipse is also fine if you just want to use Java and Maven.","title":"Select an IDE"},{"location":"archive/download/project/#open-geospark-template-project","text":"Select a proper GeoSpark project you want from GeoSpark Template Project . In this tutorial, we use GeoSparkSQL Scala project as an example. Open the folder that contains build.sbt file in your IDE. The IDE may take a while to index dependencies and source code.","title":"Open GeoSpark template project"},{"location":"archive/download/project/#try-geospark-sql-functions","text":"In your IDE, run ScalaExample.scala file. You don't need to change anything in this file. The IDE will run all SQL queries in this example in local mode.","title":"Try GeoSpark SQL functions"},{"location":"archive/download/project/#package-the-project","text":"To run this project in cluster mode, you have to package this project to a JAR and then run it using spark-submit command. Before packaging this project, you always need to check two places: Remove the hardcoded Master IP master(\"local[*]\") . This hardcoded IP is only needed when you run this project in an IDE. var sparkSession : SparkSession = SparkSession . builder () . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) . config ( \"spark.kryo.registrator\" , classOf [ GeoSparkKryoRegistrator ]. getName ) . master ( \"local[*]\" ) . appName ( \"GeoSparkSQL-demo\" ). getOrCreate () In build.sbt (or POM.xml), set Spark dependency scope to provided instead of compile . compile is only needed when you run this project in an IDE. org.apache.spark\" %% \"spark-core\" % SparkVersion % \"compile, org.apache.spark\" %% \"spark-sql\" % SparkVersion % \"compile Warning Forgetting to change the package scope will lead to a very big fat JAR and dependency conflicts when call spark-submit . For more details, please visit Maven Dependency Scope . Make sure your downloaded Spark binary distribution is the same version with the Spark used in your build.sbt or POM.xml .","title":"Package the project"},{"location":"archive/download/project/#submit-the-compiled-jar","text":"Go to ./target/scala-2.11 folder and find a jar called GeoSparkSQLScalaTemplate-0.1.0.jar . Note that, this JAR normally is larger than 1MB. (If you use POM.xml, the jar is under ./target folder) Submit this JAR using spark-submit . Local mode: ./bin/spark-submit /Path/To/YourJar.jar Cluster mode: ./bin/spark-submit --master spark://YOUR-IP:7077 /Path/To/YourJar.jar","title":"Submit the compiled jar"},{"location":"archive/download/scalashell/","text":"Spark Scala shell \u00b6 Spark distribution provides an interactive Scala shell that allows a user to execute Scala code in a terminal. This mode currently works with GeoSpark-core and GeoSparkViz. Download GeoSpark jar automatically \u00b6 Have your Spark cluster ready. Run Spark shell with --packages option. This command will automatically download GeoSpark jars from Maven Central. ./bin/spark-shell --packages org.datasyslab:geospark:GEOSPARK_VERSION Local mode: test GeoSpark without setting up a cluster ./bin/spark-shell --packages org.datasyslab:geospark:1.2.0,org.datasyslab:geospark-sql_2.3:1.2.0,org.datasyslab:geospark-viz_2.3:1.2.0 Cluster mode: you need to specify Spark Master IP ./bin/spark-shell --master spark://localhost:7077 --packages org.datasyslab:geospark:1.2.0,org.datasyslab:geospark-sql_2.3:1.2.0,org.datasyslab:geospark-viz_2.3:1.2.0 Download GeoSpark jar manually \u00b6 Have your Spark cluster ready. Download GeoSpark jars: Download the pre-compiled jars from GeoSpark Releases on GitHub Download / Git clone GeoSpark source code and compile the code by yourself: mvn clean install -DskipTests Run Spark shell with --jars option. ./bin/spark-shell --jars /Path/To/GeoSparkJars.jar Local mode: test GeoSpark without setting up a cluster ./bin/spark-shell --jars geospark-1.0.1.jar,geospark-viz-1.0.1.jar Cluster mode: you need to specify Spark Master IP ./bin/spark-shell --master spark://localhost:7077 --jars geospark-1.0.1.jar,geospark-viz-1.0.1.jar","title":"Spark Scala shell"},{"location":"archive/download/scalashell/#spark-scala-shell","text":"Spark distribution provides an interactive Scala shell that allows a user to execute Scala code in a terminal. This mode currently works with GeoSpark-core and GeoSparkViz.","title":"Spark Scala shell"},{"location":"archive/download/scalashell/#download-geospark-jar-automatically","text":"Have your Spark cluster ready. Run Spark shell with --packages option. This command will automatically download GeoSpark jars from Maven Central. ./bin/spark-shell --packages org.datasyslab:geospark:GEOSPARK_VERSION Local mode: test GeoSpark without setting up a cluster ./bin/spark-shell --packages org.datasyslab:geospark:1.2.0,org.datasyslab:geospark-sql_2.3:1.2.0,org.datasyslab:geospark-viz_2.3:1.2.0 Cluster mode: you need to specify Spark Master IP ./bin/spark-shell --master spark://localhost:7077 --packages org.datasyslab:geospark:1.2.0,org.datasyslab:geospark-sql_2.3:1.2.0,org.datasyslab:geospark-viz_2.3:1.2.0","title":"Download GeoSpark jar automatically"},{"location":"archive/download/scalashell/#download-geospark-jar-manually","text":"Have your Spark cluster ready. Download GeoSpark jars: Download the pre-compiled jars from GeoSpark Releases on GitHub Download / Git clone GeoSpark source code and compile the code by yourself: mvn clean install -DskipTests Run Spark shell with --jars option. ./bin/spark-shell --jars /Path/To/GeoSparkJars.jar Local mode: test GeoSpark without setting up a cluster ./bin/spark-shell --jars geospark-1.0.1.jar,geospark-viz-1.0.1.jar Cluster mode: you need to specify Spark Master IP ./bin/spark-shell --master spark://localhost:7077 --jars geospark-1.0.1.jar,geospark-viz-1.0.1.jar","title":"Download GeoSpark jar manually"},{"location":"archive/download/zeppelin/","text":"Install GeoSpark-Zeppelin \u00b6 Warning Known issue : due to an issue in Leaflet JS, GeoSpark-core can only plot each geometry (point, line string and polygon) as a point on Zeppelin map. To enjoy the scalable and full-fleged visualization, please use GeoSparkViz to plot scatter plots and heat maps on Zeppelin map. Compatibility \u00b6 Apache Spark 2.1+ Apache Zeppelin 0.8.1+ GeoSpark 1.2.0+: GeoSpark-core, GeoSpark-SQL, GeoSpark-Viz Installation \u00b6 Note You only need to do Step 1 and 2 only if you cannot see GeoSpark-Zeppelin in Zeppelin Helium package list. Create Helium folder (optional) \u00b6 Create a folder called helium in Zeppelin root folder. Add GeoSpark-Zeppelin description (optional) \u00b6 Create a file called geospark-zeppelin.json in this folder and put the following content in this file. You need to change the artifact path! { \"type\": \"VISUALIZATION\", \"name\": \"geospark-zeppelin\", \"description\": \"Zeppelin visualization support for GeoSpark\", \"artifact\": \"/Absolute/Path/GeoSpark/geospark-zeppelin\", \"license\": \"BSD-2-Clause\", \"icon\": \"<i class='fa fa-globe'></i>\" } Enable GeoSpark-Zeppelin \u00b6 Restart Zeppelin then open Zeppelin Helium interface and enable GeoSpark-Zeppelin. Add GeoSpark dependencies in Zeppelin Spark Interpreter \u00b6 Visualize GeoSparkSQL results \u00b6 Display GeoSparkViz results \u00b6 Now, you are good to go! Please read GeoSpark-Zeppelin tutorial for a hands-on tutorial.","title":"Install GeoSpark-Zeppelin"},{"location":"archive/download/zeppelin/#install-geospark-zeppelin","text":"Warning Known issue : due to an issue in Leaflet JS, GeoSpark-core can only plot each geometry (point, line string and polygon) as a point on Zeppelin map. To enjoy the scalable and full-fleged visualization, please use GeoSparkViz to plot scatter plots and heat maps on Zeppelin map.","title":"Install GeoSpark-Zeppelin"},{"location":"archive/download/zeppelin/#compatibility","text":"Apache Spark 2.1+ Apache Zeppelin 0.8.1+ GeoSpark 1.2.0+: GeoSpark-core, GeoSpark-SQL, GeoSpark-Viz","title":"Compatibility"},{"location":"archive/download/zeppelin/#installation","text":"Note You only need to do Step 1 and 2 only if you cannot see GeoSpark-Zeppelin in Zeppelin Helium package list.","title":"Installation"},{"location":"archive/download/zeppelin/#create-helium-folder-optional","text":"Create a folder called helium in Zeppelin root folder.","title":"Create Helium folder (optional)"},{"location":"archive/download/zeppelin/#add-geospark-zeppelin-description-optional","text":"Create a file called geospark-zeppelin.json in this folder and put the following content in this file. You need to change the artifact path! { \"type\": \"VISUALIZATION\", \"name\": \"geospark-zeppelin\", \"description\": \"Zeppelin visualization support for GeoSpark\", \"artifact\": \"/Absolute/Path/GeoSpark/geospark-zeppelin\", \"license\": \"BSD-2-Clause\", \"icon\": \"<i class='fa fa-globe'></i>\" }","title":"Add GeoSpark-Zeppelin description (optional)"},{"location":"archive/download/zeppelin/#enable-geospark-zeppelin","text":"Restart Zeppelin then open Zeppelin Helium interface and enable GeoSpark-Zeppelin.","title":"Enable GeoSpark-Zeppelin"},{"location":"archive/download/zeppelin/#add-geospark-dependencies-in-zeppelin-spark-interpreter","text":"","title":"Add GeoSpark dependencies in Zeppelin Spark Interpreter"},{"location":"archive/download/zeppelin/#visualize-geosparksql-results","text":"","title":"Visualize GeoSparkSQL results"},{"location":"archive/download/zeppelin/#display-geosparkviz-results","text":"Now, you are good to go! Please read GeoSpark-Zeppelin tutorial for a hands-on tutorial.","title":"Display GeoSparkViz results"},{"location":"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/","text":"Advanced tutorial: Tune your GeoSpark RDD application \u00b6 Before getting into this advanced tutorial, please make sure that you have tried several GeoSpark functions on your local machine. Pick a proper GeoSpark version \u00b6 The versions of GeoSpark have three levels: X.X.X (i.e., 0.8.1). In addition, GeoSpark also supports Spark 1.X in Spark1.X version. The first level means that this verion contains big structure redesign which may bring big changes in APIs and performance. Hopefully, we can see these big changes in GeoSpark 1.X version. The second level (i.e., 0.8) indicates that this version contains significant performance enhancement, big new features and API changes. An old GeoSpark user who wants to pick this version needs to be careful about the API changes. Before you move to this version, please read GeoSpark version release notes and make sure you are ready to accept the API changes. The third level (i.e., 0.8.1) tells that this version only contains bug fixes, some small new features and slight performance enhancement. This version will not contain any API changes. Moving to this version is safe. We highly suggest all GeoSpark users that stay at the same level move to the latest version in this level. Choose a proper Spatial RDD constructor \u00b6 GeoSpark provides a number of constructors for each SpatialRDD (PointRDD, PolygonRDD and LineStringRDD). In general, you have two options to start with. Initialize a SpatialRDD from your data source such as HDFS and S3. A typical example is as follows: public PointRDD ( JavaSparkContext sparkContext , String InputLocation , Integer Offset , FileDataSplitter splitter , boolean carryInputData , Integer partitions , StorageLevel newLevel ) Initialize a SpatialRDD from an existing RDD. A typical example is as follows: public PointRDD ( JavaRDD < Point > rawSpatialRDD , StorageLevel newLevel ) You may notice that these constructors all take as input a \"StorageLevel\" parameter. This is to tell Apache Spark cache the \"rawSpatialRDD\", one attribute of SpatialRDD. The reason why GeoSpark does this is that GeoSpark wants to calculate the dataset boundary and approximate total count using several Apache Spark \"Action\"s. These information are useful when doing Spatial Join Query and Distance Join Query. However, in some cases, you may know well about your datasets. If so, you can manually provide these information by calling this kind of Spatial RDD constructors: public PointRDD ( JavaSparkContext sparkContext , String InputLocation , Integer Offset , FileDataSplitter splitter , boolean carryInputData , Integer partitions , Envelope datasetBoundary , Integer approximateTotalCount ) { Manually providing the dataset boundary and approxmiate total count helps GeoSpark avoiding several slow \"Action\"s during initialization. Cache the Spatial RDD that is repeatedly used \u00b6 Each SpatialRDD (PointRDD, PolygonRDD and LineStringRDD) possesses four RDD attributes. They are: rawSpatialRDD: The RDD generated by SpatialRDD constructors. spatialPartitionedRDD: The RDD generated by spatial partition a rawSpatialRDD. Note that: this RDD has replicated spatial objects. indexedRawRDD: The RDD generated by indexing a rawSpatialRDD. indexedRDD: The RDD generated by indexing a spatialPartitionedRDD. Note that: this RDD has replicated spatial objects. These four RDDs don't co-exist so you don't need to worry about the memory issue. These four RDDs are invoked in different queries: Spatial Range Query / KNN Query, no index: rawSpatialRDD is used. Spatial Range Query / KNN Query, use index: indexedRawRDD is used. Spatial Join Query / Distance Join Query, no index: spatialPartitionedRDD is used. Spatial Join Query / Distance Join Query, use index: indexed RDD is used. Therefore, if you use one of the queries above many times, you'd better cache the associated RDD into memory. There are several possible use cases: In Spatial Data Mining such as Spatial Autocorrelation and Spatial Co-location Pattern Mining, you may need to use Spatial Join / Spatial Self-join iteratively in order to calculate the adjacency matrix. If so, please cache the spatialPartitionedRDD/indexedRDD which is queries many times. In Spark RDD sharing applications such as Livy and Spark Job Server , many users may do Spatial Range Query / KNN Query on the same Spatial RDD with different query predicates. You'd better cache the rawSpatialRDD/indexedRawRDD. Be aware of Spatial RDD partitions \u00b6 Sometimes users complain that the execution time is slow in some cases. As the first step, you should always consider increasing the number of your SpatialRDD partitions (2 - 8 times more than the original number). You can do this when you initialize a SpatialRDD. This may significantly improve your performance. After that, you may consider tuning some other parameters in Apache Spark. For example, you may use Kyro serializer or change the RDD fraction that is cached into memory.","title":"Tune GeoSpark RDD application"},{"location":"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application","text":"Before getting into this advanced tutorial, please make sure that you have tried several GeoSpark functions on your local machine.","title":"Advanced tutorial: Tune your GeoSpark RDD application"},{"location":"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version","text":"The versions of GeoSpark have three levels: X.X.X (i.e., 0.8.1). In addition, GeoSpark also supports Spark 1.X in Spark1.X version. The first level means that this verion contains big structure redesign which may bring big changes in APIs and performance. Hopefully, we can see these big changes in GeoSpark 1.X version. The second level (i.e., 0.8) indicates that this version contains significant performance enhancement, big new features and API changes. An old GeoSpark user who wants to pick this version needs to be careful about the API changes. Before you move to this version, please read GeoSpark version release notes and make sure you are ready to accept the API changes. The third level (i.e., 0.8.1) tells that this version only contains bug fixes, some small new features and slight performance enhancement. This version will not contain any API changes. Moving to this version is safe. We highly suggest all GeoSpark users that stay at the same level move to the latest version in this level.","title":"Pick a proper GeoSpark version"},{"location":"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor","text":"GeoSpark provides a number of constructors for each SpatialRDD (PointRDD, PolygonRDD and LineStringRDD). In general, you have two options to start with. Initialize a SpatialRDD from your data source such as HDFS and S3. A typical example is as follows: public PointRDD ( JavaSparkContext sparkContext , String InputLocation , Integer Offset , FileDataSplitter splitter , boolean carryInputData , Integer partitions , StorageLevel newLevel ) Initialize a SpatialRDD from an existing RDD. A typical example is as follows: public PointRDD ( JavaRDD < Point > rawSpatialRDD , StorageLevel newLevel ) You may notice that these constructors all take as input a \"StorageLevel\" parameter. This is to tell Apache Spark cache the \"rawSpatialRDD\", one attribute of SpatialRDD. The reason why GeoSpark does this is that GeoSpark wants to calculate the dataset boundary and approximate total count using several Apache Spark \"Action\"s. These information are useful when doing Spatial Join Query and Distance Join Query. However, in some cases, you may know well about your datasets. If so, you can manually provide these information by calling this kind of Spatial RDD constructors: public PointRDD ( JavaSparkContext sparkContext , String InputLocation , Integer Offset , FileDataSplitter splitter , boolean carryInputData , Integer partitions , Envelope datasetBoundary , Integer approximateTotalCount ) { Manually providing the dataset boundary and approxmiate total count helps GeoSpark avoiding several slow \"Action\"s during initialization.","title":"Choose a proper Spatial RDD constructor"},{"location":"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used","text":"Each SpatialRDD (PointRDD, PolygonRDD and LineStringRDD) possesses four RDD attributes. They are: rawSpatialRDD: The RDD generated by SpatialRDD constructors. spatialPartitionedRDD: The RDD generated by spatial partition a rawSpatialRDD. Note that: this RDD has replicated spatial objects. indexedRawRDD: The RDD generated by indexing a rawSpatialRDD. indexedRDD: The RDD generated by indexing a spatialPartitionedRDD. Note that: this RDD has replicated spatial objects. These four RDDs don't co-exist so you don't need to worry about the memory issue. These four RDDs are invoked in different queries: Spatial Range Query / KNN Query, no index: rawSpatialRDD is used. Spatial Range Query / KNN Query, use index: indexedRawRDD is used. Spatial Join Query / Distance Join Query, no index: spatialPartitionedRDD is used. Spatial Join Query / Distance Join Query, use index: indexed RDD is used. Therefore, if you use one of the queries above many times, you'd better cache the associated RDD into memory. There are several possible use cases: In Spatial Data Mining such as Spatial Autocorrelation and Spatial Co-location Pattern Mining, you may need to use Spatial Join / Spatial Self-join iteratively in order to calculate the adjacency matrix. If so, please cache the spatialPartitionedRDD/indexedRDD which is queries many times. In Spark RDD sharing applications such as Livy and Spark Job Server , many users may do Spatial Range Query / KNN Query on the same Spatial RDD with different query predicates. You'd better cache the rawSpatialRDD/indexedRawRDD.","title":"Cache the Spatial RDD that is repeatedly used"},{"location":"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions","text":"Sometimes users complain that the execution time is slow in some cases. As the first step, you should always consider increasing the number of your SpatialRDD partitions (2 - 8 times more than the original number). You can do this when you initialize a SpatialRDD. This may significantly improve your performance. After that, you may consider tuning some other parameters in Apache Spark. For example, you may use Kyro serializer or change the RDD fraction that is cached into memory.","title":"Be aware of Spatial RDD partitions"},{"location":"archive/tutorial/GeoSpark-Runnable-DEMO/","text":"GeoSpark Template Project contains six template projects for GeoSpark, GeoSparkSQL and GeoSparkViz. The template projects have been configured properly. You are able to compile, package, and run the code locally without any extra coding . Scala/Java Template Project","title":"GeoSpark template project"},{"location":"archive/tutorial/benchmark/","text":"Benchmark \u00b6 We welcome people to use GeoSpark for benchmark purpose. To achieve the best performance or enjoy all features of GeoSpark, Please always use the latest version or state the version used in your benchmark so that we can trace back to the issues. Please consider using GeoSpark core instead of GeoSparkSQL. Due to the limitation of SparkSQL (for instance, not support clustered index), we are not able to expose all features to SparkSQL. Please open GeoSpark kryo serializer to reduce the memory footprint.","title":"Benchmark"},{"location":"archive/tutorial/benchmark/#benchmark","text":"We welcome people to use GeoSpark for benchmark purpose. To achieve the best performance or enjoy all features of GeoSpark, Please always use the latest version or state the version used in your benchmark so that we can trace back to the issues. Please consider using GeoSpark core instead of GeoSparkSQL. Due to the limitation of SparkSQL (for instance, not support clustered index), we are not able to expose all features to SparkSQL. Please open GeoSpark kryo serializer to reduce the memory footprint.","title":"Benchmark"},{"location":"archive/tutorial/faq/","text":"Coming soon... For now, please read GeoSpark Github FAQ Issues .","title":"Frequently Asked Questions"},{"location":"archive/tutorial/geospark-core-python/","text":"Spatial RDD Applications in Python \u00b6 Introduction \u00b6 GeoSpark provides a Python wrapper on GeoSpark core Java/Scala library. GeoSpark SpatialRDDs (and other classes when it was necessary) have implemented meta classes which allow to use overloaded functions, methods and constructors to be the most similar to Java/Scala API as possible. GeoSpark-core provides five special SpatialRDDs: PointRDD PolygonRDD LineStringRDD CircleRDD RectangleRDD All of them can be imported from geospark.core.SpatialRDD module geospark has written serializers which convert GeoSpark SpatialRDD to Python objects. Converting will produce GeoData objects which have 2 attributes: geom: shapely.geometry.BaseGeometry userData: str geom attribute holds geometry representation as shapely objects. userData is string representation of other attributes separated by \"\\t\" GeoData has one method to get user data. getUserData() -> str Installing the package \u00b6 GeoSpark extends pyspark functions which depend on Python packages and Scala libraries. To see all dependencies please look at the dependencies section. https://pypi.org/project/pyspark/ . This package needs 2 jar files to work properly: geospark.jar geo_wrapper.jar Note To enable GeoSpark Core functionality without GeoSparkSQL there is no need to copy jar files from geospark/jars location. You can use jar files from Maven repositories. Since GeoSpark 1.3.0 it is possible also to use maven jars for GeoSparkSQL instead of geospark/jars/../geospark-sql jars files. This package automatically copies the newest GeoSpark jar files using upload_jars function, please follow the example below. upload_jars from pyspark.sql import SparkSession from geospark.register import upload_jars from geospark.register import GeoSparkRegistrator upload_jars () spark = SparkSession . builder . \\ getOrCreate () GeoSparkRegistrator . registerAll ( spark ) Function upload_jars () uses findspark Python package to upload jar files to executor and nodes. To avoid copying all the time, jar files can be put in directory SPARK_HOME/jars or any other path specified in Spark config files. Installing from PyPi repositories \u00b6 Please use command below pip install geospark Installing from wheel file \u00b6 pipenv run python -m pip install dist/geospark-1.3.1-py3-none-any.whl or pip install dist/geospark-1.3.1-py3-none-any.whl Installing from source \u00b6 python3 setup.py install GeoSpark Serializers \u00b6 GeoSpark has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. conf . set ( \"spark.serializer\" , KryoSerializer . getName ) conf . set ( \"spark.kryo.registrator\" , GeoSparkKryoRegistrator . getName ) Create a SpatialRDD \u00b6 Create a typed SpatialRDD \u00b6 GeoSpark-core provides three special SpatialRDDs: PointRDD PolygonRDD LineStringRDD CircleRDD RectangleRDD They can be loaded from CSV, TSV, WKT, WKB, Shapefiles, GeoJSON formats. To pass the format to SpatialRDD constructor please use FileDataSplitter enumeration. geospark SpatialRDDs (and other classes when it was necessary) have implemented meta classes which allow to use overloaded functions how Scala/Java GeoSpark API allows. ex. from pyspark import StorageLevel from geospark.core.SpatialRDD import PointRDD from geospark.core.enums import FileDataSplitter input_location = \"checkin.csv\" offset = 0 # The point long/lat starts from Column 0 splitter = FileDataSplitter . CSV # FileDataSplitter enumeration carry_other_attributes = True # Carry Column 2 (hotel, gas, bar...) level = StorageLevel . MEMORY_ONLY # Storage level from pyspark s_epsg = \"epsg:4326\" # Source epsg code t_epsg = \"epsg:5070\" # target epsg code point_rdd = PointRDD ( sc , input_location , offset , splitter , carry_other_attributes ) point_rdd = PointRDD ( sc , input_location , splitter , carry_other_attributes , level , s_epsg , t_epsg ) point_rdd = PointRDD ( sparkContext = sc , InputLocation = input_location , Offset = offset , splitter = splitter , carryInputData = carry_other_attributes ) From SparkSQL DataFrame To create spatialRDD from other formats you can use adapter between Spark DataFrame and SpatialRDD Load data in GeoSparkSQL. csv_point_input_location = \"/tests/resources/county_small.tsv\" df = spark . read . \\ format ( \"csv\" ) . \\ option ( \"delimiter\" , \" \\t \" ) . \\ option ( \"header\" , \"false\" ) . \\ load ( csv_point_input_location ) df . createOrReplaceTempView ( \"counties\" ) Create a Geometry type column in GeoSparkSQL spatial_df = spark . sql ( \"\"\" SELECT ST_GeomFromWKT(_c0) as geom, _c6 as county_name FROM counties \"\"\" ) spatial_df . printSchema () root |-- geom: geometry (nullable = false) |-- county_name: string (nullable = true) Use GeoSparkSQL DataFrame-RDD Adapter to convert a DataFrame to an SpatialRDD Note that, you have to name your column geometry from geospark.utils.adapter import Adapter spatial_rdd = Adapter . toSpatialRdd ( spatial_df ) spatial_rdd . analyze () spatial_rdd . boundaryEnvelope <geospark.core.geom_types.Envelope object at 0x7f1e5f29fe10> or pass Geometry column name as a second argument spatial_rdd = Adapter . toSpatialRdd ( spatial_df , \"geom\" ) For WKT/WKB/GeoJSON data, please use ST_GeomFromWKT / ST_GeomFromWKB / ST_GeomFromGeoJSON instead. Read other attributes in an SpatialRDD \u00b6 Each SpatialRDD can carry non-spatial attributes such as price, age and name as long as the user sets carryOtherAttributes as TRUE . The other attributes are combined together to a string and stored in UserData field of each geometry. To retrieve the UserData field, use the following code: rdd_with_other_attributes = object_rdd . rawSpatialRDD . map ( lambda x : x . getUserData ()) Write a Spatial Range Query \u00b6 from geospark.core.geom.envelope import Envelope from geospark.core.spatialOperator import RangeQuery range_query_window = Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) consider_boundary_intersection = False ## Only return gemeotries fully covered by the window using_index = False query_result = RangeQuery . SpatialRangeQuery ( spatial_rdd , range_query_window , consider_boundary_intersection , using_index ) Range query window \u00b6 Besides the rectangle (Envelope) type range query window, GeoSpark range query window can be Point Polygon LineString The code to create a point is as follows: To create shapely geometries please follow official shapely documentation Use spatial indexes \u00b6 GeoSpark provides two types of spatial indexes, Quad-Tree R-Tree Once you specify an index type, GeoSpark will build a local tree index on each of the SpatialRDD partition. To utilize a spatial index in a spatial range query, use the following code: from geospark.core.geom.envelope import Envelope from geospark.core.enums import IndexType from geospark.core.spatialOperator import RangeQuery range_query_window = Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) consider_boundary_intersection = False ## Only return gemeotries fully covered by the window build_on_spatial_partitioned_rdd = False ## Set to TRUE only if run join query spatial_rdd . buildIndex ( IndexType . QUADTREE , build_on_spatial_partitioned_rdd ) using_index = True query_result = RangeQuery . SpatialRangeQuery ( spatial_rdd , range_query_window , consider_boundary_intersection , using_index ) Output format \u00b6 The output format of the spatial range query is another RDD which consists of GeoData objects. SpatialRangeQuery result can be used as RDD with map or other spark RDD funtions. Also it can be used as Python objects when using collect method. Example: query_result . map ( lambda x : x . geom . length ) . collect () [ 1.5900840000000045, 1.5906639999999896, 1.1110299999999995, 1.1096700000000084, 1.1415619999999933, 1.1386399999999952, 1.1415619999999933, 1.1418860000000137, 1.1392780000000045, ... ] Or transformed to GeoPandas GeoDataFrame import geopandas as gpd gpd . GeoDataFrame ( query_result . map ( lambda x : [ x . geom , x . userData ]) . collect (), columns = [ \"geom\" , \"user_data\" ], geometry = \"geom\" ) Write a Spatial KNN Query \u00b6 A spatial K Nearnest Neighbor query takes as input a K, a query point and an SpatialRDD and finds the K geometries in the RDD which are the closest to he query point. Assume you now have an SpatialRDD (typed or generic). You can use the following code to issue an Spatial KNN Query on it. from geospark.core.spatialOperator import KNNQuery from shapely.geometry import Point point = Point ( - 84.01 , 34.01 ) k = 1000 ## K Nearest Neighbors using_index = False result = KNNQuery . SpatialKnnQuery ( object_rdd , point , k , using_index ) Query center geometry \u00b6 Besides the Point type, GeoSpark KNN query center can be Polygon LineString To create Polygon or Linestring object please follow Shapely official documentation Use spatial indexes \u00b6 To utilize a spatial index in a spatial KNN query, use the following code: from geospark.core.spatialOperator import KNNQuery from geospark.core.enums import IndexType from shapely.geometry import Point point = Point ( - 84.01 , 34.01 ) k = 5 ## K Nearest Neighbors build_on_spatial_partitioned_rdd = False ## Set to TRUE only if run join query spatial_rdd . buildIndex ( IndexType . RTREE , build_on_spatial_partitioned_rdd ) using_index = True result = KNNQuery . SpatialKnnQuery ( spatial_rdd , point , k , using_index ) Warning Only R-Tree index supports Spatial KNN query Output format \u00b6 The output format of the spatial KNN query is a list of GeoData objects. The list has K GeoData objects. Example: >> result [ GeoData , GeoData , GeoData , GeoData , GeoData ] Write a Spatial Join Query \u00b6 A spatial join query takes as input two Spatial RDD A and B. For each geometry in A, finds the geometries (from B) covered/intersected by it. A and B can be any geometry type and are not necessary to have the same geometry type. Assume you now have two SpatialRDDs (typed or generic). You can use the following code to issue an Spatial Join Query on them. from geospark.core.enums import GridType from geospark.core.spatialOperator import JoinQuery consider_boundary_intersection = False ## Only return geometries fully covered by each query window in queryWindowRDD using_index = False object_rdd . analyze () object_rdd . spatialPartitioning ( GridType . KDBTREE ) query_window_rdd . spatialPartitioning ( object_rdd . getPartitioner ()) result = JoinQuery . SpatialJoinQuery ( object_rdd , query_window_rdd , using_index , consider_boundary_intersection ) Result of SpatialJoinQuery is RDD which consists of GeoData instance and list of GeoData instances which spatially intersects or are covered by GeoData. result . collect ()) [ [GeoData, [GeoData, GeoData, GeoData, GeoData]], [GeoData, [GeoData, GeoData, GeoData]], [GeoData, [GeoData]], [GeoData, [GeoData, GeoData]], ... [GeoData, [GeoData, GeoData]] ] Use spatial partitioning \u00b6 GeoSpark spatial partitioning method can significantly speed up the join query. Three spatial partitioning methods are available: KDB-Tree, Quad-Tree and R-Tree. Two SpatialRDD must be partitioned by the same way. If you first partition SpatialRDD A, then you must use the partitioner of A to partition B. object_rdd . spatialPartitioning ( GridType . KDBTREE ) query_window_rdd . spatialPartitioning ( object_rdd . getPartitioner ()) Or query_window_rdd . spatialPartitioning ( GridType . KDBTREE ) object_rdd . spatialPartitioning ( query_window_rdd . getPartitioner ()) Use spatial indexes \u00b6 To utilize a spatial index in a spatial join query, use the following code: from geospark.core.enums import GridType from geospark.core.enums import IndexType from geospark.core.spatialOperator import JoinQuery object_rdd . spatialPartitioning ( GridType . KDBTREE ) query_window_rdd . spatialPartitioning ( object_rdd . getPartitioner ()) build_on_spatial_partitioned_rdd = True ## Set to TRUE only if run join query using_index = True query_window_rdd . buildIndex ( IndexType . QUADTREE , build_on_spatial_partitioned_rdd ) result = JoinQuery . SpatialJoinQueryFlat ( object_rdd , query_window_rdd , using_index , True ) The index should be built on either one of two SpatialRDDs. In general, you should build it on the larger SpatialRDD. Output format \u00b6 The output format of the spatial join query is a PairRDD. In this PairRDD, each object is a pair of two GeoData objects. The left one is the GeoData from object_rdd and the right one is the GeoData from the query_window_rdd. Point,Polygon Point,Polygon Point,Polygon Polygon,Polygon LineString,LineString Polygon,LineString ... example result . collect () [ [GeoData, GeoData], [GeoData, GeoData], [GeoData, GeoData], [GeoData, GeoData], ... [GeoData, GeoData], [GeoData, GeoData] ] Each object on the left is covered/intersected by the object on the right. Write a Distance Join Query \u00b6 A distance join query takes two spatial RDD assuming that we have two SpatialRDD's: object_rdd spatial_rdd And finds the geometries (from spatial_rdd) are within given distance to it. spatial_rdd and object_rdd can be any geometry type (point, line, polygon) and are not necessary to have the same geometry type You can use the following code to issue an Distance Join Query on them. from geospark.core.SpatialRDD import CircleRDD from geospark.core.enums import GridType from geospark.core.spatialOperator import JoinQuery object_rdd . analyze () circle_rdd = CircleRDD ( object_rdd , 0.1 ) ## Create a CircleRDD using the given distance circle_rdd . analyze () circle_rdd . spatialPartitioning ( GridType . KDBTREE ) spatial_rdd . spatialPartitioning ( circle_rdd . getPartitioner ()) consider_boundary_intersection = False ## Only return gemeotries fully covered by each query window in queryWindowRDD using_index = False result = JoinQuery . DistanceJoinQueryFlat ( spatial_rdd , circle_rdd , using_index , consider_boundary_intersection ) Output format \u00b6 Result for this query is RDD which holds two GeoData objects within list of lists. Example: result . collect () [[GeoData, GeoData], [GeoData, GeoData] ...] It is possible to do some RDD operation on result data ex. Getting polygon centroid. result . map ( lambda x : x [ 0 ] . geom . centroid ) . collect () [ <shapely.geometry.point.Point at 0x7efee2d28128>, <shapely.geometry.point.Point at 0x7efee2d280b8>, <shapely.geometry.point.Point at 0x7efee2d28fd0>, <shapely.geometry.point.Point at 0x7efee2d28080>, ... ] Save to permanent storage \u00b6 You can always save an SpatialRDD back to some permanent storage such as HDFS and Amazon S3. You can save distributed SpatialRDD to WKT, GeoJSON and object files. Note Non-spatial attributes such as price, age and name will also be stored to permanent storage. Save an SpatialRDD (not indexed) \u00b6 Typed SpatialRDD and generic SpatialRDD can be saved to permanent storage. Save to distributed WKT text file Use the following code to save an SpatialRDD as a distributed WKT text file: object_rdd . rawSpatialRDD . saveAsTextFile ( \"hdfs://PATH\" ) object_rdd . saveAsWKT ( \"hdfs://PATH\" ) Save to distributed WKB text file Use the following code to save an SpatialRDD as a distributed WKB text file: object_rdd . saveAsWKB ( \"hdfs://PATH\" ) Save to distributed GeoJSON text file Use the following code to save an SpatialRDD as a distributed GeoJSON text file: object_rdd . saveAsGeoJSON ( \"hdfs://PATH\" ) Save to distributed object file Use the following code to save an SpatialRDD as a distributed object file: object_rdd . rawJvmSpatialRDD . saveAsObjectFile ( \"hdfs://PATH\" ) Note Each object in a distributed object file is a byte array (not human-readable). This byte array is the serialized format of a Geometry or a SpatialIndex. Save an SpatialRDD (indexed) \u00b6 Indexed typed SpatialRDD and generic SpatialRDD can be saved to permanent storage. However, the indexed SpatialRDD has to be stored as a distributed object file. Save to distributed object file Use the following code to save an SpatialRDD as a distributed object file: object_rdd . indexedRawRDD . saveAsObjectFile ( \"hdfs://PATH\" ) Save an SpatialRDD (spatialPartitioned W/O indexed) \u00b6 A spatial partitioned RDD can be saved to permanent storage but Spark is not able to maintain the same RDD partition Id of the original RDD. This will lead to wrong join query results. We are working on some solutions. Stay tuned! Reload a saved SpatialRDD \u00b6 You can easily reload an SpatialRDD that has been saved to a distributed object file . Load to a typed SpatialRDD Use the following code to reload the PointRDD/PolygonRDD/LineStringRDD: from geospark.core.formatMapper.disc_utils import load_spatial_rdd_from_disc , GeoType polygon_rdd = load_spatial_rdd_from_disc ( sc , \"hdfs://PATH\" , GeoType . POLYGON ) point_rdd = load_spatial_rdd_from_disc ( sc , \"hdfs://PATH\" , GeoType . POINT ) linestring_rdd = load_spatial_rdd_from_disc ( sc , \"hdfs://PATH\" , GeoType . LINESTRING ) Load to a generic SpatialRDD Use the following code to reload the SpatialRDD: saved_rdd = load_spatial_rdd_from_disc ( sc , \"hdfs://PATH\" , GeoType . GEOMETRY ) Use the following code to reload the indexed SpatialRDD: saved_rdd = SpatialRDD () saved_rdd . indexedRawRDD = load_spatial_index_rdd_from_disc ( sc , \"hdfs://PATH\" ) Read from other Geometry files \u00b6 All below methods will return SpatialRDD object which can be used with Spatial functions such as Spatial Join etc. Read from WKT file \u00b6 from geospark.core.formatMapper import WktReader WktReader . readToGeometryRDD ( sc , wkt_geometries_location , 0 , True , False ) <geospark.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2fbf250> Read from WKB file \u00b6 from geospark.core.formatMapper import WkbReader WkbReader . readToGeometryRDD ( sc , wkb_geometries_location , 0 , True , False ) <geospark.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2eece50> Read from GeoJson file \u00b6 from geospark.core.formatMapper import GeoJsonReader GeoJsonReader . readToGeometryRDD ( sc , geo_json_file_location ) <geospark.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2eecb90> Read from Shapefile \u00b6 from geospark.core.formatMapper.shapefileParser import ShapefileReader ShapefileReader . readToGeometryRDD ( sc , shape_file_location ) <geospark.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2ee0710> Supported versions \u00b6 Currently this python wrapper supports the following Spark, GeoSpark and Python versions Apache Spark \u00b6 2.2 2.3 2.4 GeoSpark \u00b6 1.3.1 1.2.0 Python \u00b6 3.6 3.7 Note Other versions may also work (or partially) but were not tested yet","title":"Spatial RDD in Python"},{"location":"archive/tutorial/geospark-core-python/#spatial-rdd-applications-in-python","text":"","title":"Spatial RDD Applications in Python"},{"location":"archive/tutorial/geospark-core-python/#introduction","text":"GeoSpark provides a Python wrapper on GeoSpark core Java/Scala library. GeoSpark SpatialRDDs (and other classes when it was necessary) have implemented meta classes which allow to use overloaded functions, methods and constructors to be the most similar to Java/Scala API as possible. GeoSpark-core provides five special SpatialRDDs: PointRDD PolygonRDD LineStringRDD CircleRDD RectangleRDD All of them can be imported from geospark.core.SpatialRDD module geospark has written serializers which convert GeoSpark SpatialRDD to Python objects. Converting will produce GeoData objects which have 2 attributes: geom: shapely.geometry.BaseGeometry userData: str geom attribute holds geometry representation as shapely objects. userData is string representation of other attributes separated by \"\\t\" GeoData has one method to get user data. getUserData() -> str","title":"Introduction"},{"location":"archive/tutorial/geospark-core-python/#installing-the-package","text":"GeoSpark extends pyspark functions which depend on Python packages and Scala libraries. To see all dependencies please look at the dependencies section. https://pypi.org/project/pyspark/ . This package needs 2 jar files to work properly: geospark.jar geo_wrapper.jar Note To enable GeoSpark Core functionality without GeoSparkSQL there is no need to copy jar files from geospark/jars location. You can use jar files from Maven repositories. Since GeoSpark 1.3.0 it is possible also to use maven jars for GeoSparkSQL instead of geospark/jars/../geospark-sql jars files. This package automatically copies the newest GeoSpark jar files using upload_jars function, please follow the example below. upload_jars from pyspark.sql import SparkSession from geospark.register import upload_jars from geospark.register import GeoSparkRegistrator upload_jars () spark = SparkSession . builder . \\ getOrCreate () GeoSparkRegistrator . registerAll ( spark ) Function upload_jars () uses findspark Python package to upload jar files to executor and nodes. To avoid copying all the time, jar files can be put in directory SPARK_HOME/jars or any other path specified in Spark config files.","title":"Installing the package"},{"location":"archive/tutorial/geospark-core-python/#installing-from-pypi-repositories","text":"Please use command below pip install geospark","title":"Installing from PyPi repositories"},{"location":"archive/tutorial/geospark-core-python/#installing-from-wheel-file","text":"pipenv run python -m pip install dist/geospark-1.3.1-py3-none-any.whl or pip install dist/geospark-1.3.1-py3-none-any.whl","title":"Installing from wheel file"},{"location":"archive/tutorial/geospark-core-python/#installing-from-source","text":"python3 setup.py install","title":"Installing from source"},{"location":"archive/tutorial/geospark-core-python/#geospark-serializers","text":"GeoSpark has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. conf . set ( \"spark.serializer\" , KryoSerializer . getName ) conf . set ( \"spark.kryo.registrator\" , GeoSparkKryoRegistrator . getName )","title":"GeoSpark Serializers"},{"location":"archive/tutorial/geospark-core-python/#create-a-spatialrdd","text":"","title":"Create a SpatialRDD"},{"location":"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd","text":"GeoSpark-core provides three special SpatialRDDs: PointRDD PolygonRDD LineStringRDD CircleRDD RectangleRDD They can be loaded from CSV, TSV, WKT, WKB, Shapefiles, GeoJSON formats. To pass the format to SpatialRDD constructor please use FileDataSplitter enumeration. geospark SpatialRDDs (and other classes when it was necessary) have implemented meta classes which allow to use overloaded functions how Scala/Java GeoSpark API allows. ex. from pyspark import StorageLevel from geospark.core.SpatialRDD import PointRDD from geospark.core.enums import FileDataSplitter input_location = \"checkin.csv\" offset = 0 # The point long/lat starts from Column 0 splitter = FileDataSplitter . CSV # FileDataSplitter enumeration carry_other_attributes = True # Carry Column 2 (hotel, gas, bar...) level = StorageLevel . MEMORY_ONLY # Storage level from pyspark s_epsg = \"epsg:4326\" # Source epsg code t_epsg = \"epsg:5070\" # target epsg code point_rdd = PointRDD ( sc , input_location , offset , splitter , carry_other_attributes ) point_rdd = PointRDD ( sc , input_location , splitter , carry_other_attributes , level , s_epsg , t_epsg ) point_rdd = PointRDD ( sparkContext = sc , InputLocation = input_location , Offset = offset , splitter = splitter , carryInputData = carry_other_attributes )","title":"Create a typed SpatialRDD"},{"location":"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd","text":"Each SpatialRDD can carry non-spatial attributes such as price, age and name as long as the user sets carryOtherAttributes as TRUE . The other attributes are combined together to a string and stored in UserData field of each geometry. To retrieve the UserData field, use the following code: rdd_with_other_attributes = object_rdd . rawSpatialRDD . map ( lambda x : x . getUserData ())","title":"Read other attributes in an SpatialRDD"},{"location":"archive/tutorial/geospark-core-python/#write-a-spatial-range-query","text":"from geospark.core.geom.envelope import Envelope from geospark.core.spatialOperator import RangeQuery range_query_window = Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) consider_boundary_intersection = False ## Only return gemeotries fully covered by the window using_index = False query_result = RangeQuery . SpatialRangeQuery ( spatial_rdd , range_query_window , consider_boundary_intersection , using_index )","title":"Write a Spatial Range Query"},{"location":"archive/tutorial/geospark-core-python/#range-query-window","text":"Besides the rectangle (Envelope) type range query window, GeoSpark range query window can be Point Polygon LineString The code to create a point is as follows: To create shapely geometries please follow official shapely documentation","title":"Range query window"},{"location":"archive/tutorial/geospark-core-python/#use-spatial-indexes","text":"GeoSpark provides two types of spatial indexes, Quad-Tree R-Tree Once you specify an index type, GeoSpark will build a local tree index on each of the SpatialRDD partition. To utilize a spatial index in a spatial range query, use the following code: from geospark.core.geom.envelope import Envelope from geospark.core.enums import IndexType from geospark.core.spatialOperator import RangeQuery range_query_window = Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) consider_boundary_intersection = False ## Only return gemeotries fully covered by the window build_on_spatial_partitioned_rdd = False ## Set to TRUE only if run join query spatial_rdd . buildIndex ( IndexType . QUADTREE , build_on_spatial_partitioned_rdd ) using_index = True query_result = RangeQuery . SpatialRangeQuery ( spatial_rdd , range_query_window , consider_boundary_intersection , using_index )","title":"Use spatial indexes"},{"location":"archive/tutorial/geospark-core-python/#output-format","text":"The output format of the spatial range query is another RDD which consists of GeoData objects. SpatialRangeQuery result can be used as RDD with map or other spark RDD funtions. Also it can be used as Python objects when using collect method. Example: query_result . map ( lambda x : x . geom . length ) . collect () [ 1.5900840000000045, 1.5906639999999896, 1.1110299999999995, 1.1096700000000084, 1.1415619999999933, 1.1386399999999952, 1.1415619999999933, 1.1418860000000137, 1.1392780000000045, ... ] Or transformed to GeoPandas GeoDataFrame import geopandas as gpd gpd . GeoDataFrame ( query_result . map ( lambda x : [ x . geom , x . userData ]) . collect (), columns = [ \"geom\" , \"user_data\" ], geometry = \"geom\" )","title":"Output format"},{"location":"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query","text":"A spatial K Nearnest Neighbor query takes as input a K, a query point and an SpatialRDD and finds the K geometries in the RDD which are the closest to he query point. Assume you now have an SpatialRDD (typed or generic). You can use the following code to issue an Spatial KNN Query on it. from geospark.core.spatialOperator import KNNQuery from shapely.geometry import Point point = Point ( - 84.01 , 34.01 ) k = 1000 ## K Nearest Neighbors using_index = False result = KNNQuery . SpatialKnnQuery ( object_rdd , point , k , using_index )","title":"Write a Spatial KNN Query"},{"location":"archive/tutorial/geospark-core-python/#query-center-geometry","text":"Besides the Point type, GeoSpark KNN query center can be Polygon LineString To create Polygon or Linestring object please follow Shapely official documentation","title":"Query center geometry"},{"location":"archive/tutorial/geospark-core-python/#use-spatial-indexes_1","text":"To utilize a spatial index in a spatial KNN query, use the following code: from geospark.core.spatialOperator import KNNQuery from geospark.core.enums import IndexType from shapely.geometry import Point point = Point ( - 84.01 , 34.01 ) k = 5 ## K Nearest Neighbors build_on_spatial_partitioned_rdd = False ## Set to TRUE only if run join query spatial_rdd . buildIndex ( IndexType . RTREE , build_on_spatial_partitioned_rdd ) using_index = True result = KNNQuery . SpatialKnnQuery ( spatial_rdd , point , k , using_index ) Warning Only R-Tree index supports Spatial KNN query","title":"Use spatial indexes"},{"location":"archive/tutorial/geospark-core-python/#output-format_1","text":"The output format of the spatial KNN query is a list of GeoData objects. The list has K GeoData objects. Example: >> result [ GeoData , GeoData , GeoData , GeoData , GeoData ]","title":"Output format"},{"location":"archive/tutorial/geospark-core-python/#write-a-spatial-join-query","text":"A spatial join query takes as input two Spatial RDD A and B. For each geometry in A, finds the geometries (from B) covered/intersected by it. A and B can be any geometry type and are not necessary to have the same geometry type. Assume you now have two SpatialRDDs (typed or generic). You can use the following code to issue an Spatial Join Query on them. from geospark.core.enums import GridType from geospark.core.spatialOperator import JoinQuery consider_boundary_intersection = False ## Only return geometries fully covered by each query window in queryWindowRDD using_index = False object_rdd . analyze () object_rdd . spatialPartitioning ( GridType . KDBTREE ) query_window_rdd . spatialPartitioning ( object_rdd . getPartitioner ()) result = JoinQuery . SpatialJoinQuery ( object_rdd , query_window_rdd , using_index , consider_boundary_intersection ) Result of SpatialJoinQuery is RDD which consists of GeoData instance and list of GeoData instances which spatially intersects or are covered by GeoData. result . collect ()) [ [GeoData, [GeoData, GeoData, GeoData, GeoData]], [GeoData, [GeoData, GeoData, GeoData]], [GeoData, [GeoData]], [GeoData, [GeoData, GeoData]], ... [GeoData, [GeoData, GeoData]] ]","title":"Write a Spatial Join Query"},{"location":"archive/tutorial/geospark-core-python/#use-spatial-partitioning","text":"GeoSpark spatial partitioning method can significantly speed up the join query. Three spatial partitioning methods are available: KDB-Tree, Quad-Tree and R-Tree. Two SpatialRDD must be partitioned by the same way. If you first partition SpatialRDD A, then you must use the partitioner of A to partition B. object_rdd . spatialPartitioning ( GridType . KDBTREE ) query_window_rdd . spatialPartitioning ( object_rdd . getPartitioner ()) Or query_window_rdd . spatialPartitioning ( GridType . KDBTREE ) object_rdd . spatialPartitioning ( query_window_rdd . getPartitioner ())","title":"Use spatial partitioning"},{"location":"archive/tutorial/geospark-core-python/#use-spatial-indexes_2","text":"To utilize a spatial index in a spatial join query, use the following code: from geospark.core.enums import GridType from geospark.core.enums import IndexType from geospark.core.spatialOperator import JoinQuery object_rdd . spatialPartitioning ( GridType . KDBTREE ) query_window_rdd . spatialPartitioning ( object_rdd . getPartitioner ()) build_on_spatial_partitioned_rdd = True ## Set to TRUE only if run join query using_index = True query_window_rdd . buildIndex ( IndexType . QUADTREE , build_on_spatial_partitioned_rdd ) result = JoinQuery . SpatialJoinQueryFlat ( object_rdd , query_window_rdd , using_index , True ) The index should be built on either one of two SpatialRDDs. In general, you should build it on the larger SpatialRDD.","title":"Use spatial indexes"},{"location":"archive/tutorial/geospark-core-python/#output-format_2","text":"The output format of the spatial join query is a PairRDD. In this PairRDD, each object is a pair of two GeoData objects. The left one is the GeoData from object_rdd and the right one is the GeoData from the query_window_rdd. Point,Polygon Point,Polygon Point,Polygon Polygon,Polygon LineString,LineString Polygon,LineString ... example result . collect () [ [GeoData, GeoData], [GeoData, GeoData], [GeoData, GeoData], [GeoData, GeoData], ... [GeoData, GeoData], [GeoData, GeoData] ] Each object on the left is covered/intersected by the object on the right.","title":"Output format"},{"location":"archive/tutorial/geospark-core-python/#write-a-distance-join-query","text":"A distance join query takes two spatial RDD assuming that we have two SpatialRDD's: object_rdd spatial_rdd And finds the geometries (from spatial_rdd) are within given distance to it. spatial_rdd and object_rdd can be any geometry type (point, line, polygon) and are not necessary to have the same geometry type You can use the following code to issue an Distance Join Query on them. from geospark.core.SpatialRDD import CircleRDD from geospark.core.enums import GridType from geospark.core.spatialOperator import JoinQuery object_rdd . analyze () circle_rdd = CircleRDD ( object_rdd , 0.1 ) ## Create a CircleRDD using the given distance circle_rdd . analyze () circle_rdd . spatialPartitioning ( GridType . KDBTREE ) spatial_rdd . spatialPartitioning ( circle_rdd . getPartitioner ()) consider_boundary_intersection = False ## Only return gemeotries fully covered by each query window in queryWindowRDD using_index = False result = JoinQuery . DistanceJoinQueryFlat ( spatial_rdd , circle_rdd , using_index , consider_boundary_intersection )","title":"Write a Distance Join Query"},{"location":"archive/tutorial/geospark-core-python/#output-format_3","text":"Result for this query is RDD which holds two GeoData objects within list of lists. Example: result . collect () [[GeoData, GeoData], [GeoData, GeoData] ...] It is possible to do some RDD operation on result data ex. Getting polygon centroid. result . map ( lambda x : x [ 0 ] . geom . centroid ) . collect () [ <shapely.geometry.point.Point at 0x7efee2d28128>, <shapely.geometry.point.Point at 0x7efee2d280b8>, <shapely.geometry.point.Point at 0x7efee2d28fd0>, <shapely.geometry.point.Point at 0x7efee2d28080>, ... ]","title":"Output format"},{"location":"archive/tutorial/geospark-core-python/#save-to-permanent-storage","text":"You can always save an SpatialRDD back to some permanent storage such as HDFS and Amazon S3. You can save distributed SpatialRDD to WKT, GeoJSON and object files. Note Non-spatial attributes such as price, age and name will also be stored to permanent storage.","title":"Save to permanent storage"},{"location":"archive/tutorial/geospark-core-python/#save-an-spatialrdd-not-indexed","text":"Typed SpatialRDD and generic SpatialRDD can be saved to permanent storage.","title":"Save an SpatialRDD (not indexed)"},{"location":"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed","text":"Indexed typed SpatialRDD and generic SpatialRDD can be saved to permanent storage. However, the indexed SpatialRDD has to be stored as a distributed object file.","title":"Save an SpatialRDD (indexed)"},{"location":"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed","text":"A spatial partitioned RDD can be saved to permanent storage but Spark is not able to maintain the same RDD partition Id of the original RDD. This will lead to wrong join query results. We are working on some solutions. Stay tuned!","title":"Save an SpatialRDD (spatialPartitioned W/O indexed)"},{"location":"archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd","text":"You can easily reload an SpatialRDD that has been saved to a distributed object file .","title":"Reload a saved SpatialRDD"},{"location":"archive/tutorial/geospark-core-python/#read-from-other-geometry-files","text":"All below methods will return SpatialRDD object which can be used with Spatial functions such as Spatial Join etc.","title":"Read from other Geometry files"},{"location":"archive/tutorial/geospark-core-python/#read-from-wkt-file","text":"from geospark.core.formatMapper import WktReader WktReader . readToGeometryRDD ( sc , wkt_geometries_location , 0 , True , False ) <geospark.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2fbf250>","title":"Read from WKT file"},{"location":"archive/tutorial/geospark-core-python/#read-from-wkb-file","text":"from geospark.core.formatMapper import WkbReader WkbReader . readToGeometryRDD ( sc , wkb_geometries_location , 0 , True , False ) <geospark.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2eece50>","title":"Read from WKB file"},{"location":"archive/tutorial/geospark-core-python/#read-from-geojson-file","text":"from geospark.core.formatMapper import GeoJsonReader GeoJsonReader . readToGeometryRDD ( sc , geo_json_file_location ) <geospark.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2eecb90>","title":"Read from GeoJson file"},{"location":"archive/tutorial/geospark-core-python/#read-from-shapefile","text":"from geospark.core.formatMapper.shapefileParser import ShapefileReader ShapefileReader . readToGeometryRDD ( sc , shape_file_location ) <geospark.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2ee0710>","title":"Read from Shapefile"},{"location":"archive/tutorial/geospark-core-python/#supported-versions","text":"Currently this python wrapper supports the following Spark, GeoSpark and Python versions","title":"Supported versions"},{"location":"archive/tutorial/geospark-core-python/#apache-spark","text":"2.2 2.3 2.4","title":"Apache Spark"},{"location":"archive/tutorial/geospark-core-python/#geospark","text":"1.3.1 1.2.0","title":"GeoSpark"},{"location":"archive/tutorial/geospark-core-python/#python","text":"3.6 3.7 Note Other versions may also work (or partially) but were not tested yet","title":"Python"},{"location":"archive/tutorial/geospark-sql-python/","text":"Spatial SQL Application in Python \u00b6 Introduction \u00b6 GeoSPark provides a Python wrapper for its Spatial SQL / DataFrame interface. The official repository for GeoSpark can be found at https://github.com/DataSystemsLab/GeoSpark . This package allows users to use all GeoSparkSQL functions and transform it to Python Shapely geometry objects. Also it allows to create Spark DataFrame with GeoSpark UDT from Shapely geometry objects. Spark DataFrame can be converted to GeoPandas easily, in addition all fiona drivers for shape file are available to load data from files and convert them to Spark DataFrame. Please look at examples. Installation \u00b6 GeoSpark extends pyspark functions which depends on Python packages and Scala libraries. To see all dependencies please look at Dependencies section. https://pypi.org/project/pyspark/ . Package needs 2 jar files to work properly: geospark.jar geospark-sql.jar geo_wrapper.jar Note Since GeoSpark 1.3.0 it is possible also to use maven jars for GeoSparkSQL instead of geospark/jars/../geospark-sql jars files. This package automatically copies the newest GeoSpark jar files using function, please follow the example below. upload_jars from pyspark.sql import SparkSession from geospark.register import upload_jars from geospark.register import GeoSparkRegistrator upload_jars () spark = SparkSession . builder . \\ getOrCreate () GeoSparkRegistrator . registerAll ( spark ) Function upload_jars () uses findspark Python package to upload jar files to executor and nodes. To avoid copying all the time, jar files can be put in directory SPARK_HOME/jars or any other path specified in Spark config files. Installing from PyPi repositories \u00b6 Please use command below pip install geospark Installing from wheel file \u00b6 pipenv run python -m pip install dist/geospark-1.3.1-py3-none-any.whl or pip install dist/geospark-1.3.1-py3-none-any.whl Installing from source \u00b6 python3 setup.py install Core Classes and methods. \u00b6 GeoSparkRegistrator.registerAll(spark: pyspark.sql.SparkSession) -> bool This is the core of whole package. Class method registers all GeoSparkSQL functions (available for used GeoSparkSQL version). To check available functions please look at GeoSparkSQL section. :param spark: pyspark.sql.SparkSession, spark session instance upload_jars() -> NoReturn Function uses findspark Python module to upload newest GeoSpark jars to Spark executor and nodes. GeometryType() Class which handle serialization and deserialization between GeoSpark geometries and Shapely BaseGeometry types. KryoSerializer.getName -> str Class property which returns org.apache.spark.serializer.KryoSerializer string, which simplify using GeoSpark Serializers. GeoSparkKryoRegistrator.getName -> str Class property which returns org.datasyslab.geospark.serde.GeoSparkKryoRegistrator string, which simplify using GeoSpark Serializers. Writing Application \u00b6 Use KryoSerializer.getName and GeoSparkKryoRegistrator.getName class properties to reduce memory impact, reffering to GeoSpark docs . To do that use spark config as follows: . config ( \"spark.serializer\" , KryoSerializer . getName ) . config ( \"spark.kryo.registrator\" , GeoSparkKryoRegistrator . getName ) If jars was not uploaded manually please use function upload_jars() To turn on GeoSparkSQL function inside pyspark code use GeoSparkRegistrator.registerAll method on existing pyspark.sql.SparkSession instance ex. GeoSparkRegistrator.registerAll(spark) After that all the functions from GeoSparkSQL will be available, moreover using collect or toPandas methods on Spark DataFrame will return Shapely BaseGeometry objects. Based on GeoPandas DataFrame, Pandas DataFrame with shapely objects or Sequence with shapely objects, Spark DataFrame can be created using spark.createDataFrame method. To specify Schema with geometry inside please use GeometryType() instance (look at examples section to see that in practice). Examples \u00b6 GeoSparkSQL \u00b6 All GeoSparkSQL functions (list depends on GeoSparkSQL version) are available in Python API. For documentation please look at GeoSpark website For example use GeoSparkSQL for Spatial Join. counties = spark . \\ read . \\ option ( \"delimiter\" , \"|\" ) . \\ option ( \"header\" , \"true\" ) . \\ csv ( \"counties.csv\" ) counties . createOrReplaceTempView ( \"county\" ) counties_geom = spark . sql ( \"SELECT county_code, st_geomFromWKT(geom) as geometry from county\" ) counties_geom . show ( 5 ) +-----------+--------------------+ |county_code| geometry| +-----------+--------------------+ | 1815|POLYGON ((21.6942...| | 1410|POLYGON ((22.7238...| | 1418|POLYGON ((21.1100...| | 1425|POLYGON ((20.9891...| | 1427|POLYGON ((19.5087...| +-----------+--------------------+ import geopandas as gpd points = gpd . read_file ( \"gis_osm_pois_free_1.shp\" ) points_geom = spark . createDataFrame ( points [[ \"fclass\" , \"geometry\" ]] ) points_geom . show ( 5 , False ) +---------+-----------------------------+ |fclass |geometry | +---------+-----------------------------+ |camp_site|POINT (15.3393145 52.3504247)| |chalet |POINT (14.8709625 52.691693) | |motel |POINT (15.0946636 52.3130396)| |atm |POINT (15.0732014 52.3141083)| |hotel |POINT (15.0696777 52.3143013)| +---------+-----------------------------+ points_geom . createOrReplaceTempView ( \"pois\" ) counties_geom . createOrReplaceTempView ( \"counties\" ) spatial_join_result = spark . sql ( \"\"\" SELECT c.county_code, p.fclass FROM pois AS p, counties AS c WHERE ST_Intersects(p.geometry, c.geometry) \"\"\" ) spatial_join_result . explain () == Physical Plan == *(2) Project [county_code#230, fclass#239] +- RangeJoin geometry#240: geometry, geometry#236: geometry, true :- Scan ExistingRDD[fclass#239,geometry#240] +- Project [county_code#230, st_geomfromwkt(geom#232) AS geometry#236] +- *(1) FileScan csv [county_code#230,geom#232] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/projects/geospark/counties.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<county_code:string,geom:string> Calculating Number of Pois within counties per fclass. pois_per_county = spatial_join_result . groupBy ( \"county_code\" , \"fclass\" ) . \\ count () pois_per_county . show ( 5 , False ) +-----------+---------+-----+ |county_code|fclass |count| +-----------+---------+-----+ |0805 |atm |6 | |0805 |bench |75 | |0803 |museum |9 | |0802 |fast_food|5 | |0862 |atm |20 | +-----------+---------+-----+ Integration with GeoPandas and Shapely \u00b6 geospark has implemented serializers and deserializers which allows to convert GeoSpark Geometry objects into Shapely BaseGeometry objects. Based on that it is possible to load the data with geopandas from file (look at Fiona possible drivers) and create Spark DataFrame based on GeoDataFrame object. Example, loading the data from shapefile using geopandas read_file method and create Spark DataFrame based on GeoDataFrame: import geopandas as gpd from pyspark.sql import SparkSession from geospark.register import GeoSparkRegistrator spark = SparkSession . builder . \\ getOrCreate () GeoSparkRegistrator . registerAll ( spark ) gdf = gpd . read_file ( \"gis_osm_pois_free_1.shp\" ) spark . createDataFrame ( gdf ) . show () +---------+----+-----------+--------------------+--------------------+ | osm_id|code| fclass| name| geometry| +---------+----+-----------+--------------------+--------------------+ | 26860257|2422| camp_site| de Kroon|POINT (15.3393145...| | 26860294|2406| chalet| Le\u015bne Ustronie|POINT (14.8709625...| | 29947493|2402| motel| null|POINT (15.0946636...| | 29947498|2602| atm| null|POINT (15.0732014...| | 29947499|2401| hotel| null|POINT (15.0696777...| | 29947505|2401| hotel| null|POINT (15.0155749...| +---------+----+-----------+--------------------+--------------------+ Reading data with Spark and converting to GeoPandas import geopandas as gpd from pyspark.sql import SparkSession from geospark.register import GeoSparkRegistrator spark = SparkSession . builder . \\ getOrCreate () GeoSparkRegistrator . registerAll ( spark ) counties = spark . \\ read . \\ option ( \"delimiter\" , \"|\" ) . \\ option ( \"header\" , \"true\" ) . \\ csv ( \"counties.csv\" ) counties . createOrReplaceTempView ( \"county\" ) counties_geom = spark . sql ( \"SELECT *, st_geomFromWKT(geom) as geometry from county\" ) df = counties_geom . toPandas () gdf = gpd . GeoDataFrame ( df , geometry = \"geometry\" ) gdf . plot ( figsize = ( 10 , 8 ), column = \"value\" , legend = True , cmap = 'YlOrBr' , scheme = 'quantiles' , edgecolor = 'lightgray' ) Creating Spark DataFrame based on shapely objects \u00b6 Supported Shapely objects \u00b6 shapely object Available Point MultiPoint LineString MultiLinestring Polygon MultiPolygon To create Spark DataFrame based on mentioned Geometry types, please use GeometryType from geospark.sql.types module. Converting works for list or tuple with shapely objects. Schema for target table with integer id and geometry type can be defined as follow: from pyspark.sql.types import IntegerType , StructField , StructType from geospark.sql.types import GeometryType schema = StructType ( [ StructField ( \"id\" , IntegerType (), False ), StructField ( \"geom\" , GeometryType (), False ) ] ) Also Spark DataFrame with geometry type can be converted to list of shapely objects with collect method. Example usage for Shapely objects \u00b6 Point \u00b6 from shapely.geometry import Point data = [ [ 1 , Point ( 21.0 , 52.0 )], [ 1 , Point ( 23.0 , 42.0 )], [ 1 , Point ( 26.0 , 32.0 )] ] gdf = spark . createDataFrame ( data , schema ) gdf . show () +---+-------------+ | id| geom| +---+-------------+ | 1|POINT (21 52)| | 1|POINT (23 42)| | 1|POINT (26 32)| +---+-------------+ gdf . printSchema () root |-- id: integer (nullable = false) |-- geom: geometry (nullable = false) MultiPoint \u00b6 from shapely.geometry import MultiPoint data = [ [ 1 , MultiPoint ([[ 19.511463 , 51.765158 ], [ 19.446408 , 51.779752 ]])] ] gdf = spark . createDataFrame ( data , schema ) . show ( 1 , False ) +---+---------------------------------------------------------+ |id |geom | +---+---------------------------------------------------------+ |1 |MULTIPOINT ((19.511463 51.765158), (19.446408 51.779752))| +---+---------------------------------------------------------+ LineString \u00b6 from shapely.geometry import LineString line = [( 40 , 40 ), ( 30 , 30 ), ( 40 , 20 ), ( 30 , 10 )] data = [ [ 1 , LineString ( line )] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+--------------------------------+ |id |geom | +---+--------------------------------+ |1 |LINESTRING (10 10, 20 20, 10 40)| +---+--------------------------------+ MultiLineString \u00b6 from shapely.geometry import MultiLineString line1 = [( 10 , 10 ), ( 20 , 20 ), ( 10 , 40 )] line2 = [( 40 , 40 ), ( 30 , 30 ), ( 40 , 20 ), ( 30 , 10 )] data = [ [ 1 , MultiLineString ([ line1 , line2 ])] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+---------------------------------------------------------------------+ |id |geom | +---+---------------------------------------------------------------------+ |1 |MULTILINESTRING ((10 10, 20 20, 10 40), (40 40, 30 30, 40 20, 30 10))| +---+---------------------------------------------------------------------+ Polygon \u00b6 from shapely.geometry import Polygon polygon = Polygon ( [ [ 19.51121 , 51.76426 ], [ 19.51056 , 51.76583 ], [ 19.51216 , 51.76599 ], [ 19.51280 , 51.76448 ], [ 19.51121 , 51.76426 ] ] ) data = [ [ 1 , polygon ] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+--------------------------------------------------------------------------------------------------------+ |id |geom | +---+--------------------------------------------------------------------------------------------------------+ |1 |POLYGON ((19.51121 51.76426, 19.51056 51.76583, 19.51216 51.76599, 19.5128 51.76448, 19.51121 51.76426))| +---+--------------------------------------------------------------------------------------------------------+ MultiPolygon \u00b6 from shapely.geometry import MultiPolygon exterior_p1 = [( 0 , 0 ), ( 0 , 2 ), ( 2 , 2 ), ( 2 , 0 ), ( 0 , 0 )] interior_p1 = [( 1 , 1 ), ( 1 , 1.5 ), ( 1.5 , 1.5 ), ( 1.5 , 1 ), ( 1 , 1 )] exterior_p2 = [( 0 , 0 ), ( 1 , 0 ), ( 1 , 1 ), ( 0 , 1 ), ( 0 , 0 )] polygons = [ Polygon ( exterior_p1 , [ interior_p1 ]), Polygon ( exterior_p2 ) ] data = [ [ 1 , MultiPolygon ( polygons )] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+----------------------------------------------------------------------------------------------------------+ |id |geom | +---+----------------------------------------------------------------------------------------------------------+ |1 |MULTIPOLYGON (((0 0, 0 2, 2 2, 2 0, 0 0), (1 1, 1.5 1, 1.5 1.5, 1 1.5, 1 1)), ((0 0, 0 1, 1 1, 1 0, 0 0)))| +---+----------------------------------------------------------------------------------------------------------+ Supported versions \u00b6 Currently this python wrapper supports the following Spark, GeoSpark and Python versions: Apache Spark \u00b6 2.2 2.3 2.4 GeoSparkSQL \u00b6 1.3.1 1.2.0 1.1.3 Python \u00b6 3.6 3.7","title":"Spatial SQL in Python"},{"location":"archive/tutorial/geospark-sql-python/#spatial-sql-application-in-python","text":"","title":"Spatial SQL Application in Python"},{"location":"archive/tutorial/geospark-sql-python/#introduction","text":"GeoSPark provides a Python wrapper for its Spatial SQL / DataFrame interface. The official repository for GeoSpark can be found at https://github.com/DataSystemsLab/GeoSpark . This package allows users to use all GeoSparkSQL functions and transform it to Python Shapely geometry objects. Also it allows to create Spark DataFrame with GeoSpark UDT from Shapely geometry objects. Spark DataFrame can be converted to GeoPandas easily, in addition all fiona drivers for shape file are available to load data from files and convert them to Spark DataFrame. Please look at examples.","title":"Introduction"},{"location":"archive/tutorial/geospark-sql-python/#installation","text":"GeoSpark extends pyspark functions which depends on Python packages and Scala libraries. To see all dependencies please look at Dependencies section. https://pypi.org/project/pyspark/ . Package needs 2 jar files to work properly: geospark.jar geospark-sql.jar geo_wrapper.jar Note Since GeoSpark 1.3.0 it is possible also to use maven jars for GeoSparkSQL instead of geospark/jars/../geospark-sql jars files. This package automatically copies the newest GeoSpark jar files using function, please follow the example below. upload_jars from pyspark.sql import SparkSession from geospark.register import upload_jars from geospark.register import GeoSparkRegistrator upload_jars () spark = SparkSession . builder . \\ getOrCreate () GeoSparkRegistrator . registerAll ( spark ) Function upload_jars () uses findspark Python package to upload jar files to executor and nodes. To avoid copying all the time, jar files can be put in directory SPARK_HOME/jars or any other path specified in Spark config files.","title":"Installation"},{"location":"archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories","text":"Please use command below pip install geospark","title":"Installing from PyPi repositories"},{"location":"archive/tutorial/geospark-sql-python/#installing-from-wheel-file","text":"pipenv run python -m pip install dist/geospark-1.3.1-py3-none-any.whl or pip install dist/geospark-1.3.1-py3-none-any.whl","title":"Installing from wheel file"},{"location":"archive/tutorial/geospark-sql-python/#installing-from-source","text":"python3 setup.py install","title":"Installing from source"},{"location":"archive/tutorial/geospark-sql-python/#core-classes-and-methods","text":"GeoSparkRegistrator.registerAll(spark: pyspark.sql.SparkSession) -> bool This is the core of whole package. Class method registers all GeoSparkSQL functions (available for used GeoSparkSQL version). To check available functions please look at GeoSparkSQL section. :param spark: pyspark.sql.SparkSession, spark session instance upload_jars() -> NoReturn Function uses findspark Python module to upload newest GeoSpark jars to Spark executor and nodes. GeometryType() Class which handle serialization and deserialization between GeoSpark geometries and Shapely BaseGeometry types. KryoSerializer.getName -> str Class property which returns org.apache.spark.serializer.KryoSerializer string, which simplify using GeoSpark Serializers. GeoSparkKryoRegistrator.getName -> str Class property which returns org.datasyslab.geospark.serde.GeoSparkKryoRegistrator string, which simplify using GeoSpark Serializers.","title":"Core Classes and methods."},{"location":"archive/tutorial/geospark-sql-python/#writing-application","text":"Use KryoSerializer.getName and GeoSparkKryoRegistrator.getName class properties to reduce memory impact, reffering to GeoSpark docs . To do that use spark config as follows: . config ( \"spark.serializer\" , KryoSerializer . getName ) . config ( \"spark.kryo.registrator\" , GeoSparkKryoRegistrator . getName ) If jars was not uploaded manually please use function upload_jars() To turn on GeoSparkSQL function inside pyspark code use GeoSparkRegistrator.registerAll method on existing pyspark.sql.SparkSession instance ex. GeoSparkRegistrator.registerAll(spark) After that all the functions from GeoSparkSQL will be available, moreover using collect or toPandas methods on Spark DataFrame will return Shapely BaseGeometry objects. Based on GeoPandas DataFrame, Pandas DataFrame with shapely objects or Sequence with shapely objects, Spark DataFrame can be created using spark.createDataFrame method. To specify Schema with geometry inside please use GeometryType() instance (look at examples section to see that in practice).","title":"Writing Application"},{"location":"archive/tutorial/geospark-sql-python/#examples","text":"","title":"Examples"},{"location":"archive/tutorial/geospark-sql-python/#geosparksql","text":"All GeoSparkSQL functions (list depends on GeoSparkSQL version) are available in Python API. For documentation please look at GeoSpark website For example use GeoSparkSQL for Spatial Join. counties = spark . \\ read . \\ option ( \"delimiter\" , \"|\" ) . \\ option ( \"header\" , \"true\" ) . \\ csv ( \"counties.csv\" ) counties . createOrReplaceTempView ( \"county\" ) counties_geom = spark . sql ( \"SELECT county_code, st_geomFromWKT(geom) as geometry from county\" ) counties_geom . show ( 5 ) +-----------+--------------------+ |county_code| geometry| +-----------+--------------------+ | 1815|POLYGON ((21.6942...| | 1410|POLYGON ((22.7238...| | 1418|POLYGON ((21.1100...| | 1425|POLYGON ((20.9891...| | 1427|POLYGON ((19.5087...| +-----------+--------------------+ import geopandas as gpd points = gpd . read_file ( \"gis_osm_pois_free_1.shp\" ) points_geom = spark . createDataFrame ( points [[ \"fclass\" , \"geometry\" ]] ) points_geom . show ( 5 , False ) +---------+-----------------------------+ |fclass |geometry | +---------+-----------------------------+ |camp_site|POINT (15.3393145 52.3504247)| |chalet |POINT (14.8709625 52.691693) | |motel |POINT (15.0946636 52.3130396)| |atm |POINT (15.0732014 52.3141083)| |hotel |POINT (15.0696777 52.3143013)| +---------+-----------------------------+ points_geom . createOrReplaceTempView ( \"pois\" ) counties_geom . createOrReplaceTempView ( \"counties\" ) spatial_join_result = spark . sql ( \"\"\" SELECT c.county_code, p.fclass FROM pois AS p, counties AS c WHERE ST_Intersects(p.geometry, c.geometry) \"\"\" ) spatial_join_result . explain () == Physical Plan == *(2) Project [county_code#230, fclass#239] +- RangeJoin geometry#240: geometry, geometry#236: geometry, true :- Scan ExistingRDD[fclass#239,geometry#240] +- Project [county_code#230, st_geomfromwkt(geom#232) AS geometry#236] +- *(1) FileScan csv [county_code#230,geom#232] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/projects/geospark/counties.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<county_code:string,geom:string> Calculating Number of Pois within counties per fclass. pois_per_county = spatial_join_result . groupBy ( \"county_code\" , \"fclass\" ) . \\ count () pois_per_county . show ( 5 , False ) +-----------+---------+-----+ |county_code|fclass |count| +-----------+---------+-----+ |0805 |atm |6 | |0805 |bench |75 | |0803 |museum |9 | |0802 |fast_food|5 | |0862 |atm |20 | +-----------+---------+-----+","title":"GeoSparkSQL"},{"location":"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely","text":"geospark has implemented serializers and deserializers which allows to convert GeoSpark Geometry objects into Shapely BaseGeometry objects. Based on that it is possible to load the data with geopandas from file (look at Fiona possible drivers) and create Spark DataFrame based on GeoDataFrame object. Example, loading the data from shapefile using geopandas read_file method and create Spark DataFrame based on GeoDataFrame: import geopandas as gpd from pyspark.sql import SparkSession from geospark.register import GeoSparkRegistrator spark = SparkSession . builder . \\ getOrCreate () GeoSparkRegistrator . registerAll ( spark ) gdf = gpd . read_file ( \"gis_osm_pois_free_1.shp\" ) spark . createDataFrame ( gdf ) . show () +---------+----+-----------+--------------------+--------------------+ | osm_id|code| fclass| name| geometry| +---------+----+-----------+--------------------+--------------------+ | 26860257|2422| camp_site| de Kroon|POINT (15.3393145...| | 26860294|2406| chalet| Le\u015bne Ustronie|POINT (14.8709625...| | 29947493|2402| motel| null|POINT (15.0946636...| | 29947498|2602| atm| null|POINT (15.0732014...| | 29947499|2401| hotel| null|POINT (15.0696777...| | 29947505|2401| hotel| null|POINT (15.0155749...| +---------+----+-----------+--------------------+--------------------+ Reading data with Spark and converting to GeoPandas import geopandas as gpd from pyspark.sql import SparkSession from geospark.register import GeoSparkRegistrator spark = SparkSession . builder . \\ getOrCreate () GeoSparkRegistrator . registerAll ( spark ) counties = spark . \\ read . \\ option ( \"delimiter\" , \"|\" ) . \\ option ( \"header\" , \"true\" ) . \\ csv ( \"counties.csv\" ) counties . createOrReplaceTempView ( \"county\" ) counties_geom = spark . sql ( \"SELECT *, st_geomFromWKT(geom) as geometry from county\" ) df = counties_geom . toPandas () gdf = gpd . GeoDataFrame ( df , geometry = \"geometry\" ) gdf . plot ( figsize = ( 10 , 8 ), column = \"value\" , legend = True , cmap = 'YlOrBr' , scheme = 'quantiles' , edgecolor = 'lightgray' )","title":"Integration with GeoPandas and Shapely"},{"location":"archive/tutorial/geospark-sql-python/#creating-spark-dataframe-based-on-shapely-objects","text":"","title":"Creating Spark DataFrame based on shapely objects"},{"location":"archive/tutorial/geospark-sql-python/#supported-shapely-objects","text":"shapely object Available Point MultiPoint LineString MultiLinestring Polygon MultiPolygon To create Spark DataFrame based on mentioned Geometry types, please use GeometryType from geospark.sql.types module. Converting works for list or tuple with shapely objects. Schema for target table with integer id and geometry type can be defined as follow: from pyspark.sql.types import IntegerType , StructField , StructType from geospark.sql.types import GeometryType schema = StructType ( [ StructField ( \"id\" , IntegerType (), False ), StructField ( \"geom\" , GeometryType (), False ) ] ) Also Spark DataFrame with geometry type can be converted to list of shapely objects with collect method.","title":"Supported Shapely objects"},{"location":"archive/tutorial/geospark-sql-python/#example-usage-for-shapely-objects","text":"","title":"Example usage for Shapely objects"},{"location":"archive/tutorial/geospark-sql-python/#point","text":"from shapely.geometry import Point data = [ [ 1 , Point ( 21.0 , 52.0 )], [ 1 , Point ( 23.0 , 42.0 )], [ 1 , Point ( 26.0 , 32.0 )] ] gdf = spark . createDataFrame ( data , schema ) gdf . show () +---+-------------+ | id| geom| +---+-------------+ | 1|POINT (21 52)| | 1|POINT (23 42)| | 1|POINT (26 32)| +---+-------------+ gdf . printSchema () root |-- id: integer (nullable = false) |-- geom: geometry (nullable = false)","title":"Point"},{"location":"archive/tutorial/geospark-sql-python/#multipoint","text":"from shapely.geometry import MultiPoint data = [ [ 1 , MultiPoint ([[ 19.511463 , 51.765158 ], [ 19.446408 , 51.779752 ]])] ] gdf = spark . createDataFrame ( data , schema ) . show ( 1 , False ) +---+---------------------------------------------------------+ |id |geom | +---+---------------------------------------------------------+ |1 |MULTIPOINT ((19.511463 51.765158), (19.446408 51.779752))| +---+---------------------------------------------------------+","title":"MultiPoint"},{"location":"archive/tutorial/geospark-sql-python/#linestring","text":"from shapely.geometry import LineString line = [( 40 , 40 ), ( 30 , 30 ), ( 40 , 20 ), ( 30 , 10 )] data = [ [ 1 , LineString ( line )] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+--------------------------------+ |id |geom | +---+--------------------------------+ |1 |LINESTRING (10 10, 20 20, 10 40)| +---+--------------------------------+","title":"LineString"},{"location":"archive/tutorial/geospark-sql-python/#multilinestring","text":"from shapely.geometry import MultiLineString line1 = [( 10 , 10 ), ( 20 , 20 ), ( 10 , 40 )] line2 = [( 40 , 40 ), ( 30 , 30 ), ( 40 , 20 ), ( 30 , 10 )] data = [ [ 1 , MultiLineString ([ line1 , line2 ])] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+---------------------------------------------------------------------+ |id |geom | +---+---------------------------------------------------------------------+ |1 |MULTILINESTRING ((10 10, 20 20, 10 40), (40 40, 30 30, 40 20, 30 10))| +---+---------------------------------------------------------------------+","title":"MultiLineString"},{"location":"archive/tutorial/geospark-sql-python/#polygon","text":"from shapely.geometry import Polygon polygon = Polygon ( [ [ 19.51121 , 51.76426 ], [ 19.51056 , 51.76583 ], [ 19.51216 , 51.76599 ], [ 19.51280 , 51.76448 ], [ 19.51121 , 51.76426 ] ] ) data = [ [ 1 , polygon ] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+--------------------------------------------------------------------------------------------------------+ |id |geom | +---+--------------------------------------------------------------------------------------------------------+ |1 |POLYGON ((19.51121 51.76426, 19.51056 51.76583, 19.51216 51.76599, 19.5128 51.76448, 19.51121 51.76426))| +---+--------------------------------------------------------------------------------------------------------+","title":"Polygon"},{"location":"archive/tutorial/geospark-sql-python/#multipolygon","text":"from shapely.geometry import MultiPolygon exterior_p1 = [( 0 , 0 ), ( 0 , 2 ), ( 2 , 2 ), ( 2 , 0 ), ( 0 , 0 )] interior_p1 = [( 1 , 1 ), ( 1 , 1.5 ), ( 1.5 , 1.5 ), ( 1.5 , 1 ), ( 1 , 1 )] exterior_p2 = [( 0 , 0 ), ( 1 , 0 ), ( 1 , 1 ), ( 0 , 1 ), ( 0 , 0 )] polygons = [ Polygon ( exterior_p1 , [ interior_p1 ]), Polygon ( exterior_p2 ) ] data = [ [ 1 , MultiPolygon ( polygons )] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+----------------------------------------------------------------------------------------------------------+ |id |geom | +---+----------------------------------------------------------------------------------------------------------+ |1 |MULTIPOLYGON (((0 0, 0 2, 2 2, 2 0, 0 0), (1 1, 1.5 1, 1.5 1.5, 1 1.5, 1 1)), ((0 0, 0 1, 1 1, 1 0, 0 0)))| +---+----------------------------------------------------------------------------------------------------------+","title":"MultiPolygon"},{"location":"archive/tutorial/geospark-sql-python/#supported-versions","text":"Currently this python wrapper supports the following Spark, GeoSpark and Python versions:","title":"Supported versions"},{"location":"archive/tutorial/geospark-sql-python/#apache-spark","text":"2.2 2.3 2.4","title":"Apache Spark"},{"location":"archive/tutorial/geospark-sql-python/#geosparksql_1","text":"1.3.1 1.2.0 1.1.3","title":"GeoSparkSQL"},{"location":"archive/tutorial/geospark-sql-python/#python","text":"3.6 3.7","title":"Python"},{"location":"archive/tutorial/rdd/","text":"The page outlines the steps to create Spatial RDDs and run spatial queries using GeoSpark-core. The example code is written in Scala but also works for Java . Set up dependencies \u00b6 Read GeoSpark Maven Central coordinates Select the minimum dependencies : Add Apache Spark (only the Spark core) and GeoSpark (core). Add the dependencies in build.sbt or pom.xml. Note To enjoy the full functions of GeoSpark, we suggest you include the full dependencies : Apache Spark core , Apache SparkSQL , GeoSpark core , GeoSparkSQL , GeoSparkViz Initiate SparkContext \u00b6 val conf = new SparkConf () conf . setAppName ( \"GeoSparkRunnableExample\" ) // Change this to a proper name conf . setMaster ( \"local[*]\" ) // Delete this if run in cluster mode // Enable GeoSpark custom Kryo serializer conf . set ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) conf . set ( \"spark.kryo.registrator\" , classOf [ GeoSparkKryoRegistrator ]. getName ) val sc = new SparkContext ( conf ) Warning GeoSpark has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. If you add the GeoSpark full dependencies as suggested above, please use the following two lines to enable GeoSpark Kryo serializer instead: conf . set ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) conf . set ( \"spark.kryo.registrator\" , classOf [ GeoSparkVizKryoRegistrator ]. getName ) Create a SpatialRDD \u00b6 Create a typed SpatialRDD \u00b6 GeoSpark-core provides three special SpatialRDDs: PointRDD, PolygonRDD, and LineStringRDD . They can be loaded from CSV, TSV, WKT, WKB, Shapefiles, GeoJSON and NetCDF/HDF format. PointRDD from CSV/TSV Suppose we have a checkin.csv CSV file at Path /Download/checkin.csv as follows: -88.331492,32.324142,hotel -88.175933,32.360763,gas -88.388954,32.357073,bar -88.221102,32.35078,restaurant This file has three columns and corresponding offsets (Column IDs) are 0, 1, 2. Use the following code to create a PointRDD val pointRDDInputLocation = \"/Download/checkin.csv\" val pointRDDOffset = 0 // The point long/lat starts from Column 0 val pointRDDSplitter = FileDataSplitter . CSV val carryOtherAttributes = true // Carry Column 2 (hotel, gas, bar...) var objectRDD = new PointRDD ( sc , pointRDDInputLocation , pointRDDOffset , pointRDDSplitter , carryOtherAttributes ) If the data file is in TSV format, just simply use the following line to replace the old FileDataSplitter: val pointRDDSplitter = FileDataSplitter . TSV PolygonRDD/LineStringRDD from CSV/TSV In general, polygon and line string data is stored in WKT, WKB, GeoJSON and Shapefile formats instead of CSV/TSV because the geometries in a file may have different lengths. However, if all polygons / line strings in your CSV/TSV possess the same length, you can create PolygonRDD and LineStringRDD from these files. Suppose we have a checkinshape.csv CSV file at Path /Download/checkinshape.csv as follows: -88.331492,32.324142,-88.331492,32.324142,-88.331492,32.324142,-88.331492,32.324142,-88.331492,32.324142,hotel -88.175933,32.360763,-88.175933,32.360763,-88.175933,32.360763,-88.175933,32.360763,-88.175933,32.360763,gas -88.388954,32.357073,-88.388954,32.357073,-88.388954,32.357073,-88.388954,32.357073,-88.388954,32.357073,bar -88.221102,32.35078,-88.221102,32.35078,-88.221102,32.35078,-88.221102,32.35078,-88.221102,32.35078,restaurant This file has 11 columns and corresponding offsets (Column IDs) are 0 - 10. Column 0 - 9 are 5 coordinates (longitude/latitude pairs). In this file, all geometries have the same number of coordinates. The geometries can be polyons or line strings. Warning For polygon data, the last coordinate must be the same as the first coordinate because a polygon is a closed linear ring. Use the following code to create a PolygonRDD. val polygonRDDInputLocation = \"/Download/checkinshape.csv\" val polygonRDDStartOffset = 0 // The coordinates start from Column 0 val polygonRDDEndOffset = 9 // The coordinates end at Column 9 val polygonRDDSplitter = FileDataSplitter . CSV val carryOtherAttributes = true // Carry Column 10 (hotel, gas, bar...) var objectRDD = new PolygonRDD ( sc , polygonRDDInputLocation , polygonRDDStartOffset , polygonRDDEndOffset , polygonRDDSplitter , carryOtherAttributes ) If the data file is in TSV format, just simply use the following line to replace the old FileDataSplitter: val polygonRDDSplitter = FileDataSplitter . TSV The way to create a LineStringRDD is the same as PolygonRDD. Create a generic SpatialRDD (behavoir changed in v1.2.0) \u00b6 A generic SpatialRDD is not typed to a certain geometry type and open to more scenarios. It allows an input data file contains mixed types of geometries. For instance, a WKT file contains three types gemetries LineString , Polygon and MultiPolygon . From WKT/WKB Geometries in a WKT and WKB file always occupy a single column no matter how many coordinates they have. Therefore, creating a typed SpatialRDD is easy. Suppose we have a checkin.tsv WKT TSV file at Path /Download/checkin.tsv as follows: POINT (-88.331492 32.324142) hotel POINT (-88.175933 32.360763) gas POINT (-88.388954 32.357073) bar POINT (-88.221102 32.35078) restaurant This file has two columns and corresponding offsets (Column IDs) are 0, 1. Column 0 is the WKT string and Column 1 is the checkin business type. Use the following code to create a SpatialRDD val inputLocation = \"/Download/checkin.tsv\" val wktColumn = 0 // The WKT string starts from Column 0 val allowTopologyInvalidGeometries = true // Optional val skipSyntaxInvalidGeometries = false // Optional val spatialRDD = WktReader . readToGeometryRDD ( sparkSession . sparkContext , inputLocation , wktColumn , allowTopologyInvalidGeometries , skipSyntaxInvalidGeometries ) From GeoJSON Geometries in GeoJSON is similar to WKT/WKB. However, a GeoJSON file must be beaked into multiple lines. Suppose we have a polygon.json GeoJSON file at Path /Download/polygon.json as follows: { \"type\": \"Feature\", \"properties\": { \"STATEFP\": \"01\", \"COUNTYFP\": \"077\", \"TRACTCE\": \"011501\", \"BLKGRPCE\": \"5\", \"AFFGEOID\": \"1500000US010770115015\", \"GEOID\": \"010770115015\", \"NAME\": \"5\", \"LSAD\": \"BG\", \"ALAND\": 6844991, \"AWATER\": 32636 }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -87.621765, 34.873444 ], [ -87.617535, 34.873369 ], [ -87.6123, 34.873337 ], [ -87.604049, 34.873303 ], [ -87.604033, 34.872316 ], [ -87.60415, 34.867502 ], [ -87.604218, 34.865687 ], [ -87.604409, 34.858537 ], [ -87.604018, 34.851336 ], [ -87.603716, 34.844829 ], [ -87.603696, 34.844307 ], [ -87.603673, 34.841884 ], [ -87.60372, 34.841003 ], [ -87.603879, 34.838423 ], [ -87.603888, 34.837682 ], [ -87.603889, 34.83763 ], [ -87.613127, 34.833938 ], [ -87.616451, 34.832699 ], [ -87.621041, 34.831431 ], [ -87.621056, 34.831526 ], [ -87.62112, 34.831925 ], [ -87.621603, 34.8352 ], [ -87.62158, 34.836087 ], [ -87.621383, 34.84329 ], [ -87.621359, 34.844438 ], [ -87.62129, 34.846387 ], [ -87.62119, 34.85053 ], [ -87.62144, 34.865379 ], [ -87.621765, 34.873444 ] ] ] } }, { \"type\": \"Feature\", \"properties\": { \"STATEFP\": \"01\", \"COUNTYFP\": \"045\", \"TRACTCE\": \"021102\", \"BLKGRPCE\": \"4\", \"AFFGEOID\": \"1500000US010450211024\", \"GEOID\": \"010450211024\", \"NAME\": \"4\", \"LSAD\": \"BG\", \"ALAND\": 11360854, \"AWATER\": 0 }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -85.719017, 31.297901 ], [ -85.715626, 31.305203 ], [ -85.714271, 31.307096 ], [ -85.69999, 31.307552 ], [ -85.697419, 31.307951 ], [ -85.675603, 31.31218 ], [ -85.672733, 31.312876 ], [ -85.672275, 31.311977 ], [ -85.67145, 31.310988 ], [ -85.670622, 31.309524 ], [ -85.670729, 31.307622 ], [ -85.669876, 31.30666 ], [ -85.669796, 31.306224 ], [ -85.670356, 31.306178 ], [ -85.671664, 31.305583 ], [ -85.67177, 31.305299 ], [ -85.671878, 31.302764 ], [ -85.671344, 31.302123 ], [ -85.668276, 31.302076 ], [ -85.66566, 31.30093 ], [ -85.665687, 31.30022 ], [ -85.669183, 31.297677 ], [ -85.668703, 31.295638 ], [ -85.671985, 31.29314 ], [ -85.677177, 31.288211 ], [ -85.678452, 31.286376 ], [ -85.679236, 31.28285 ], [ -85.679195, 31.281426 ], [ -85.676865, 31.281049 ], [ -85.674661, 31.28008 ], [ -85.674377, 31.27935 ], [ -85.675714, 31.276882 ], [ -85.677938, 31.275168 ], [ -85.680348, 31.276814 ], [ -85.684032, 31.278848 ], [ -85.684387, 31.279082 ], [ -85.692398, 31.283499 ], [ -85.705032, 31.289718 ], [ -85.706755, 31.290476 ], [ -85.718102, 31.295204 ], [ -85.719132, 31.29689 ], [ -85.719017, 31.297901 ] ] ] } }, { \"type\": \"Feature\", \"properties\": { \"STATEFP\": \"01\", \"COUNTYFP\": \"055\", \"TRACTCE\": \"001300\", \"BLKGRPCE\": \"3\", \"AFFGEOID\": \"1500000US010550013003\", \"GEOID\": \"010550013003\", \"NAME\": \"3\", \"LSAD\": \"BG\", \"ALAND\": 1378742, \"AWATER\": 247387 }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -86.000685, 34.00537 ], [ -85.998837, 34.009768 ], [ -85.998012, 34.010398 ], [ -85.987865, 34.005426 ], [ -85.986656, 34.004552 ], [ -85.985, 34.002659 ], [ -85.98851, 34.001502 ], [ -85.987567, 33.999488 ], [ -85.988666, 33.99913 ], [ -85.992568, 33.999131 ], [ -85.993144, 33.999714 ], [ -85.994876, 33.995153 ], [ -85.998823, 33.989548 ], [ -85.999925, 33.994237 ], [ -86.000616, 34.000028 ], [ -86.000685, 34.00537 ] ] ] } }, { \"type\": \"Feature\", \"properties\": { \"STATEFP\": \"01\", \"COUNTYFP\": \"089\", \"TRACTCE\": \"001700\", \"BLKGRPCE\": \"2\", \"AFFGEOID\": \"1500000US010890017002\", \"GEOID\": \"010890017002\", \"NAME\": \"2\", \"LSAD\": \"BG\", \"ALAND\": 1040641, \"AWATER\": 0 }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -86.574172, 34.727375 ], [ -86.562684, 34.727131 ], [ -86.562797, 34.723865 ], [ -86.562957, 34.723168 ], [ -86.562336, 34.719766 ], [ -86.557381, 34.719143 ], [ -86.557352, 34.718322 ], [ -86.559921, 34.717363 ], [ -86.564827, 34.718513 ], [ -86.567582, 34.718565 ], [ -86.570572, 34.718577 ], [ -86.573618, 34.719377 ], [ -86.574172, 34.727375 ] ] ] } }, Use the following code to create a generic SpatialRDD: val inputLocation = \"/Download/polygon.json\" val allowTopologyInvalidGeometries = true // Optional val skipSyntaxInvalidGeometries = false // Optional val spatialRDD = GeoJsonReader . readToGeometryRDD ( sparkSession . sparkContext , inputLocation , allowTopologyInvalidGeometries , skipSyntaxInvalidGeometries ) Warning The way that GeoSpark reads JSON file is different from SparkSQL From Shapefile val shapefileInputLocation = \"/Download/myshapefile\" val spatialRDD = ShapefileReader . readToGeometryRDD ( sparkSession . sparkContext , shapefileInputLocation ) Note The file extensions of .shp, .shx, .dbf must be in lowercase. Assume you have a shape file called myShapefile , the file structure should be like this: - shapefile1 - shapefile2 - myshapefile - myshapefile.shp - myshapefile.shx - myshapefile.dbf - myshapefile... - ... If the file you are reading contains non-ASCII characters you'll need to explicitly set the encoding via geospark.global.charset system property before the call to ShapefileReader.readToGeometryRDD . Example: System . setProperty ( \"geospark.global.charset\" , \"utf8\" ) From SparkSQL DataFrame To create a generic SpatialRDD from CSV, TSV, WKT, WKB and GeoJSON input formats, you can use GeoSparkSQL. Make sure you include the full dependencies of GeoSpark. Read GeoSparkSQL API . We use checkin.csv CSV file as the example. You can create a generic SpatialRDD using the following steps: Load data in GeoSparkSQL. var df = sparkSession . read . format ( \"csv\" ). option ( \"header\" , \"false\" ). load ( csvPointInputLocation ) df . createOrReplaceTempView ( \"inputtable\" ) Create a Geometry type column in GeoSparkSQL var spatialDf = sparkSession . sql ( \"\"\" |SELECT ST_Point(CAST(inputtable._c0 AS Decimal(24,20)),CAST(inputtable._c1 AS Decimal(24,20))) AS checkin |FROM inputtable \"\"\" . stripMargin ) Use GeoSparkSQL DataFrame-RDD Adapter to convert a DataFrame to an SpatialRDD var spatialRDD = new SpatialRDD [ Geometry ] spatialRDD . rawSpatialRDD = Adapter . toRdd ( spatialDf ) For WKT/WKB/GeoJSON data, please use ST_GeomFromWKT / ST_GeomFromWKB / ST_GeomFromGeoJSON instead. Transform the Coordinate Reference System \u00b6 GeoSpark doesn't control the coordinate unit (degree-based or meter-based) of all geometries in an SpatialRDD. The unit of all related distances in GeoSpark is same as the unit of all geometries in an SpatialRDD. To convert Coordinate Reference System of an SpatialRDD, use the following code: val sourceCrsCode = \"epsg:4326\" // WGS84, the most common degree-based CRS val targetCrsCode = \"epsg:3857\" // The most common meter-based CRS objectRDD . CRSTransform ( sourceCrsCode , targetCrsCode ) Warning CRS transformation should be done right after creating each SpatialRDD, otherwise it will lead to wrong query results. For instace, use something like this: var objectRDD = new PointRDD ( sc , pointRDDInputLocation , pointRDDOffset , pointRDDSplitter , carryOtherAttributes ) objectRDD . CRSTransform ( \"epsg:4326\" , \"epsg:3857\" ) The details CRS information can be found on EPSG.io Read other attributes in an SpatialRDD \u00b6 Each SpatialRDD can carry non-spatial attributes such as price, age and name as long as the user sets carryOtherAttributes as TRUE . The other attributes are combined together to a string and stored in UserData field of each geometry. To retrieve the UserData field, use the following code: val rddWithOtherAttributes = objectRDD . rawSpatialRDD . rdd . map [ String ]( f => f . getUserData . asInstanceOf [ String ]) Write a Spatial Range Query \u00b6 A spatial range query takes as input a range query window and an SpatialRDD and returns all geometries that intersect / are fully covered by the query window. Assume you now have an SpatialRDD (typed or generic). You can use the following code to issue an Spatial Range Query on it. val rangeQueryWindow = new Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) val considerBoundaryIntersection = false // Only return gemeotries fully covered by the window val usingIndex = false var queryResult = RangeQuery . SpatialRangeQuery ( spatialRDD , rangeQueryWindow , considerBoundaryIntersection , usingIndex ) considerBoundaryIntersection can be set to TRUE to return all geometries intersect with query window. Note Spatial range query is equal to ST_Within and ST_Intersects in Spatial SQL. An example query is as follows: SELECT * FROM checkin WHERE ST_Intersects ( queryWindow , checkin . location ) Range query window \u00b6 Besides the rectangle (Envelope) type range query window, GeoSpark range query window can be Point/Polygon/LineString. The code to create a point is as follows: val geometryFactory = new GeometryFactory () val pointObject = geometryFactory . createPoint ( new Coordinate ( - 84.01 , 34.01 )) The code to create a polygon (with 4 vertexes) is as follows: val geometryFactory = new GeometryFactory () val coordinates = new Array [ Coordinate ]( 5 ) coordinates ( 0 ) = new Coordinate ( 0 , 0 ) coordinates ( 1 ) = new Coordinate ( 0 , 4 ) coordinates ( 2 ) = new Coordinate ( 4 , 4 ) coordinates ( 3 ) = new Coordinate ( 4 , 0 ) coordinates ( 4 ) = coordinates ( 0 ) // The last coordinate is the same as the first coordinate in order to compose a closed ring val polygonObject = geometryFactory . createPolygon ( coordinates ) The code to create a line string (with 4 vertexes) is as follows: val geometryFactory = new GeometryFactory () val coordinates = new Array [ Coordinate ]( 4 ) coordinates ( 0 ) = new Coordinate ( 0 , 0 ) coordinates ( 1 ) = new Coordinate ( 0 , 4 ) coordinates ( 2 ) = new Coordinate ( 4 , 4 ) coordinates ( 3 ) = new Coordinate ( 4 , 0 ) val linestringObject = geometryFactory . createLineString ( coordinates ) Use spatial indexes \u00b6 GeoSpark provides two types of spatial indexes, Quad-Tree and R-Tree. Once you specify an index type, GeoSpark will build a local tree index on each of the SpatialRDD partition. To utilize a spatial index in a spatial range query, use the following code: val rangeQueryWindow = new Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) val considerBoundaryIntersection = false // Only return gemeotries fully covered by the window val buildOnSpatialPartitionedRDD = false // Set to TRUE only if run join query spatialRDD . buildIndex ( IndexType . QUADTREE , buildOnSpatialPartitionedRDD ) val usingIndex = true var queryResult = RangeQuery . SpatialRangeQuery ( spatialRDD , rangeQueryWindow , considerBoundaryIntersection , usingIndex ) Tip Using an index might not be the best choice all the time because building index also takes time. A spatial index is very useful when your data is complex polygons and line strings. Output format \u00b6 The output format of the spatial range query is another SpatialRDD. Write a Spatial KNN Query \u00b6 A spatial K Nearnest Neighbor query takes as input a K, a query point and an SpatialRDD and finds the K geometries in the RDD which are the closest to he query point. Assume you now have an SpatialRDD (typed or generic). You can use the following code to issue an Spatial KNN Query on it. val geometryFactory = new GeometryFactory () val pointObject = geometryFactory . createPoint ( new Coordinate ( - 84.01 , 34.01 )) val K = 1000 // K Nearest Neighbors val usingIndex = false val result = KNNQuery . SpatialKnnQuery ( objectRDD , pointObject , K , usingIndex ) Note Spatial KNN query that returns 5 Nearest Neighbors is equal to the following statement in Spatial SQL SELECT ck . name , ck . rating , ST_Distance ( ck . location , myLocation ) AS distance FROM checkins ck ORDER BY distance DESC LIMIT 5 Query center geometry \u00b6 Besides the Point type, GeoSpark KNN query center can be Polygon and LineString. To learn how to create Polygon and LineString object, see Range query window . Use spatial indexes \u00b6 To utilize a spatial index in a spatial KNN query, use the following code: val geometryFactory = new GeometryFactory () val pointObject = geometryFactory . createPoint ( new Coordinate ( - 84.01 , 34.01 )) val K = 1000 // K Nearest Neighbors val buildOnSpatialPartitionedRDD = false // Set to TRUE only if run join query objectRDD . buildIndex ( IndexType . RTREE , buildOnSpatialPartitionedRDD ) val usingIndex = true val result = KNNQuery . SpatialKnnQuery ( objectRDD , pointObject , K , usingIndex ) Warning Only R-Tree index supports Spatial KNN query Output format \u00b6 The output format of the spatial KNN query is a list of geometries. The list has K geometry objects. Write a Spatial Join Query \u00b6 A spatial join query takes as input two Spatial RDD A and B. For each geometry in A, finds the geometries (from B) covered/intersected by it. A and B can be any geometry type and are not necessary to have the same geometry type. Assume you now have two SpatialRDDs (typed or generic). You can use the following code to issue an Spatial Join Query on them. val considerBoundaryIntersection = false // Only return gemeotries fully covered by each query window in queryWindowRDD val usingIndex = false objectRDD . analyze () objectRDD . spatialPartitioning ( GridType . KDBTREE ) queryWindowRDD . spatialPartitioning ( objectRDD . getPartitioner ) val result = JoinQuery . SpatialJoinQuery ( objectRDD , queryWindowRDD , usingIndex , considerBoundaryIntersection ) Note Spatial join query is equal to the following query in Spatial SQL: SELECT superhero . name FROM city , superhero WHERE ST_Contains ( city . geom , superhero . geom ); Find the super heros in each city Use spatial partitioning \u00b6 GeoSpark spatial partitioning method can significantly speed up the join query. Three spatial partitioning methods are available: KDB-Tree, Quad-Tree and R-Tree. Two SpatialRDD must be partitioned by the same way. If you first partition SpatialRDD A, then you must use the partitioner of A to partition B. objectRDD . spatialPartitioning ( GridType . KDBTREE ) queryWindowRDD . spatialPartitioning ( objectRDD . getPartitioner ) Or queryWindowRDD . spatialPartitioning ( GridType . KDBTREE ) objectRDD . spatialPartitioning ( queryWindowRDD . getPartitioner ) Use spatial indexes \u00b6 To utilize a spatial index in a spatial join query, use the following code: objectRDD . spatialPartitioning ( joinQueryPartitioningType ) queryWindowRDD . spatialPartitioning ( objectRDD . getPartitioner ) val buildOnSpatialPartitionedRDD = true // Set to TRUE only if run join query val usingIndex = true queryWindowRDD . buildIndex ( IndexType . QUADTREE , buildOnSpatialPartitionedRDD ) val result = JoinQuery . SpatialJoinQueryFlat ( objectRDD , queryWindowRDD , usingIndex , considerBoundaryIntersection ) The index should be built on either one of two SpatialRDDs. In general, you should build it on the larger SpatialRDD. Output format \u00b6 The output format of the spatial join query is a PairRDD. In this PairRDD, each object is a pair of two geometries. The left one is the geometry from objectRDD and the right one is the geometry from the queryWindowRDD. Point,Polygon Point,Polygon Point,Polygon Polygon,Polygon LineString,LineString Polygon,LineString ... Each object on the left is covered/intersected by the object on the right. Write a Distance Join Query \u00b6 A distance join query takes as input two Spatial RDD A and B and a distance. For each geometry in A, finds the geometries (from B) are within the given distance to it. A and B can be any geometry type and are not necessary to have the same geometry type. The unit of the distance is explained here . Assume you now have two SpatialRDDs (typed or generic). You can use the following code to issue an Distance Join Query on them. objectRddA . analyze () val circleRDD = new CircleRDD ( objectRddA , 0.1 ) // Create a CircleRDD using the given distance circleRDD . spatialPartitioning ( GridType . KDBTREE ) objectRddB . spatialPartitioning ( circleRDD . getPartitioner ) val considerBoundaryIntersection = false // Only return gemeotries fully covered by each query window in queryWindowRDD val usingIndex = false val result = JoinQuery . DistanceJoinQueryFlat ( objectRddB , circleRDD , usingIndex , considerBoundaryIntersection ) The rest part of the join query is same as the spatial join query. The details of spatial partitioning in join query is here . The details of using spatial indexes in join query is here . The output format of the distance join query is here . Note Distance join query is equal to the following query in Spatial SQL: SELECT superhero . name FROM city , superhero WHERE ST_Distance ( city . geom , superhero . geom ) <= 10 ; Find the super heros within 10 miles of each city Save to permanent storage \u00b6 You can always save an SpatialRDD back to some permanent storage such as HDFS and Amazon S3. You can save distributed SpatialRDD to WKT, GeoJSON and object files. Note Non-spatial attributes such as price, age and name will also be stored to permanent storage. Save an SpatialRDD (not indexed) \u00b6 Typed SpatialRDD and generic SpatialRDD can be saved to permanent storage. Save to distributed WKT text file Use the following code to save an SpatialRDD as a distributed WKT text file: objectRDD . rawSpatialRDD . saveAsTextFile ( \"hdfs://PATH\" ) objectRDD . saveAsWKT ( \"hdfs://PATH\" ) Save to distributed WKB text file Use the following code to save an SpatialRDD as a distributed WKB text file: objectRDD . saveAsWKB ( \"hdfs://PATH\" ) Save to distributed GeoJSON text file Use the following code to save an SpatialRDD as a distributed GeoJSON text file: objectRDD . saveAsGeoJSON ( \"hdfs://PATH\" ) Save to distributed object file Use the following code to save an SpatialRDD as a distributed object file: objectRDD . rawSpatialRDD . saveAsObjectFile ( \"hdfs://PATH\" ) Note Each object in a distributed object file is a byte array (not human-readable). This byte array is the serialized format of a Geometry or a SpatialIndex. Save an SpatialRDD (indexed) \u00b6 Indexed typed SpatialRDD and generic SpatialRDD can be saved to permanent storage. However, the indexed SpatialRDD has to be stored as a distributed object file. Save to distributed object file Use the following code to save an SpatialRDD as a distributed object file: objectRDD.indexedRawRDD.saveAsObjectFile(\"hdfs://PATH\") Save an SpatialRDD (spatialPartitioned W/O indexed) \u00b6 A spatial partitioned RDD can be saved to permanent storage but Spark is not able to maintain the same RDD partition Id of the original RDD. This will lead to wrong join query results. We are working on some solutions. Stay tuned! Reload a saved SpatialRDD \u00b6 You can easily reload an SpatialRDD that has been saved to a distributed object file . Load to a typed SpatialRDD Use the following code to reload the PointRDD/PolygonRDD/LineStringRDD: var savedRDD = new PointRDD ( sc . objectFile [ Point ]( \"hdfs://PATH\" )) var savedRDD = new PointRDD ( sc . objectFile [ Polygon ]( \"hdfs://PATH\" )) var savedRDD = new PointRDD ( sc . objectFile [ LineString ]( \"hdfs://PATH\" )) Load to a generic SpatialRDD Use the following code to reload the SpatialRDD: var savedRDD = new SpatialRDD [ Geometry ] savedRDD . rawSpatialRDD = sc . objectFile [ Geometry ]( \"hdfs://PATH\" ) Use the following code to reload the indexed SpatialRDD: var savedRDD = new SpatialRDD [ Geometry ] savedRDD . indexedRawRDD = sc . objectFile [ SpatialIndex ]( \"hdfs://PATH\" )","title":"Spatial RDD application"},{"location":"archive/tutorial/rdd/#set-up-dependencies","text":"Read GeoSpark Maven Central coordinates Select the minimum dependencies : Add Apache Spark (only the Spark core) and GeoSpark (core). Add the dependencies in build.sbt or pom.xml. Note To enjoy the full functions of GeoSpark, we suggest you include the full dependencies : Apache Spark core , Apache SparkSQL , GeoSpark core , GeoSparkSQL , GeoSparkViz","title":"Set up dependencies"},{"location":"archive/tutorial/rdd/#initiate-sparkcontext","text":"val conf = new SparkConf () conf . setAppName ( \"GeoSparkRunnableExample\" ) // Change this to a proper name conf . setMaster ( \"local[*]\" ) // Delete this if run in cluster mode // Enable GeoSpark custom Kryo serializer conf . set ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) conf . set ( \"spark.kryo.registrator\" , classOf [ GeoSparkKryoRegistrator ]. getName ) val sc = new SparkContext ( conf ) Warning GeoSpark has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. If you add the GeoSpark full dependencies as suggested above, please use the following two lines to enable GeoSpark Kryo serializer instead: conf . set ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) conf . set ( \"spark.kryo.registrator\" , classOf [ GeoSparkVizKryoRegistrator ]. getName )","title":"Initiate SparkContext"},{"location":"archive/tutorial/rdd/#create-a-spatialrdd","text":"","title":"Create a SpatialRDD"},{"location":"archive/tutorial/rdd/#create-a-typed-spatialrdd","text":"GeoSpark-core provides three special SpatialRDDs: PointRDD, PolygonRDD, and LineStringRDD . They can be loaded from CSV, TSV, WKT, WKB, Shapefiles, GeoJSON and NetCDF/HDF format.","title":"Create a typed SpatialRDD"},{"location":"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120","text":"A generic SpatialRDD is not typed to a certain geometry type and open to more scenarios. It allows an input data file contains mixed types of geometries. For instance, a WKT file contains three types gemetries LineString , Polygon and MultiPolygon .","title":"Create a generic SpatialRDD (behavoir changed in v1.2.0)"},{"location":"archive/tutorial/rdd/#transform-the-coordinate-reference-system","text":"GeoSpark doesn't control the coordinate unit (degree-based or meter-based) of all geometries in an SpatialRDD. The unit of all related distances in GeoSpark is same as the unit of all geometries in an SpatialRDD. To convert Coordinate Reference System of an SpatialRDD, use the following code: val sourceCrsCode = \"epsg:4326\" // WGS84, the most common degree-based CRS val targetCrsCode = \"epsg:3857\" // The most common meter-based CRS objectRDD . CRSTransform ( sourceCrsCode , targetCrsCode ) Warning CRS transformation should be done right after creating each SpatialRDD, otherwise it will lead to wrong query results. For instace, use something like this: var objectRDD = new PointRDD ( sc , pointRDDInputLocation , pointRDDOffset , pointRDDSplitter , carryOtherAttributes ) objectRDD . CRSTransform ( \"epsg:4326\" , \"epsg:3857\" ) The details CRS information can be found on EPSG.io","title":"Transform the Coordinate Reference System"},{"location":"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd","text":"Each SpatialRDD can carry non-spatial attributes such as price, age and name as long as the user sets carryOtherAttributes as TRUE . The other attributes are combined together to a string and stored in UserData field of each geometry. To retrieve the UserData field, use the following code: val rddWithOtherAttributes = objectRDD . rawSpatialRDD . rdd . map [ String ]( f => f . getUserData . asInstanceOf [ String ])","title":"Read other attributes in an SpatialRDD"},{"location":"archive/tutorial/rdd/#write-a-spatial-range-query","text":"A spatial range query takes as input a range query window and an SpatialRDD and returns all geometries that intersect / are fully covered by the query window. Assume you now have an SpatialRDD (typed or generic). You can use the following code to issue an Spatial Range Query on it. val rangeQueryWindow = new Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) val considerBoundaryIntersection = false // Only return gemeotries fully covered by the window val usingIndex = false var queryResult = RangeQuery . SpatialRangeQuery ( spatialRDD , rangeQueryWindow , considerBoundaryIntersection , usingIndex ) considerBoundaryIntersection can be set to TRUE to return all geometries intersect with query window. Note Spatial range query is equal to ST_Within and ST_Intersects in Spatial SQL. An example query is as follows: SELECT * FROM checkin WHERE ST_Intersects ( queryWindow , checkin . location )","title":"Write a Spatial Range Query"},{"location":"archive/tutorial/rdd/#range-query-window","text":"Besides the rectangle (Envelope) type range query window, GeoSpark range query window can be Point/Polygon/LineString. The code to create a point is as follows: val geometryFactory = new GeometryFactory () val pointObject = geometryFactory . createPoint ( new Coordinate ( - 84.01 , 34.01 )) The code to create a polygon (with 4 vertexes) is as follows: val geometryFactory = new GeometryFactory () val coordinates = new Array [ Coordinate ]( 5 ) coordinates ( 0 ) = new Coordinate ( 0 , 0 ) coordinates ( 1 ) = new Coordinate ( 0 , 4 ) coordinates ( 2 ) = new Coordinate ( 4 , 4 ) coordinates ( 3 ) = new Coordinate ( 4 , 0 ) coordinates ( 4 ) = coordinates ( 0 ) // The last coordinate is the same as the first coordinate in order to compose a closed ring val polygonObject = geometryFactory . createPolygon ( coordinates ) The code to create a line string (with 4 vertexes) is as follows: val geometryFactory = new GeometryFactory () val coordinates = new Array [ Coordinate ]( 4 ) coordinates ( 0 ) = new Coordinate ( 0 , 0 ) coordinates ( 1 ) = new Coordinate ( 0 , 4 ) coordinates ( 2 ) = new Coordinate ( 4 , 4 ) coordinates ( 3 ) = new Coordinate ( 4 , 0 ) val linestringObject = geometryFactory . createLineString ( coordinates )","title":"Range query window"},{"location":"archive/tutorial/rdd/#use-spatial-indexes","text":"GeoSpark provides two types of spatial indexes, Quad-Tree and R-Tree. Once you specify an index type, GeoSpark will build a local tree index on each of the SpatialRDD partition. To utilize a spatial index in a spatial range query, use the following code: val rangeQueryWindow = new Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) val considerBoundaryIntersection = false // Only return gemeotries fully covered by the window val buildOnSpatialPartitionedRDD = false // Set to TRUE only if run join query spatialRDD . buildIndex ( IndexType . QUADTREE , buildOnSpatialPartitionedRDD ) val usingIndex = true var queryResult = RangeQuery . SpatialRangeQuery ( spatialRDD , rangeQueryWindow , considerBoundaryIntersection , usingIndex ) Tip Using an index might not be the best choice all the time because building index also takes time. A spatial index is very useful when your data is complex polygons and line strings.","title":"Use spatial indexes"},{"location":"archive/tutorial/rdd/#output-format","text":"The output format of the spatial range query is another SpatialRDD.","title":"Output format"},{"location":"archive/tutorial/rdd/#write-a-spatial-knn-query","text":"A spatial K Nearnest Neighbor query takes as input a K, a query point and an SpatialRDD and finds the K geometries in the RDD which are the closest to he query point. Assume you now have an SpatialRDD (typed or generic). You can use the following code to issue an Spatial KNN Query on it. val geometryFactory = new GeometryFactory () val pointObject = geometryFactory . createPoint ( new Coordinate ( - 84.01 , 34.01 )) val K = 1000 // K Nearest Neighbors val usingIndex = false val result = KNNQuery . SpatialKnnQuery ( objectRDD , pointObject , K , usingIndex ) Note Spatial KNN query that returns 5 Nearest Neighbors is equal to the following statement in Spatial SQL SELECT ck . name , ck . rating , ST_Distance ( ck . location , myLocation ) AS distance FROM checkins ck ORDER BY distance DESC LIMIT 5","title":"Write a Spatial KNN Query"},{"location":"archive/tutorial/rdd/#query-center-geometry","text":"Besides the Point type, GeoSpark KNN query center can be Polygon and LineString. To learn how to create Polygon and LineString object, see Range query window .","title":"Query center geometry"},{"location":"archive/tutorial/rdd/#use-spatial-indexes_1","text":"To utilize a spatial index in a spatial KNN query, use the following code: val geometryFactory = new GeometryFactory () val pointObject = geometryFactory . createPoint ( new Coordinate ( - 84.01 , 34.01 )) val K = 1000 // K Nearest Neighbors val buildOnSpatialPartitionedRDD = false // Set to TRUE only if run join query objectRDD . buildIndex ( IndexType . RTREE , buildOnSpatialPartitionedRDD ) val usingIndex = true val result = KNNQuery . SpatialKnnQuery ( objectRDD , pointObject , K , usingIndex ) Warning Only R-Tree index supports Spatial KNN query","title":"Use spatial indexes"},{"location":"archive/tutorial/rdd/#output-format_1","text":"The output format of the spatial KNN query is a list of geometries. The list has K geometry objects.","title":"Output format"},{"location":"archive/tutorial/rdd/#write-a-spatial-join-query","text":"A spatial join query takes as input two Spatial RDD A and B. For each geometry in A, finds the geometries (from B) covered/intersected by it. A and B can be any geometry type and are not necessary to have the same geometry type. Assume you now have two SpatialRDDs (typed or generic). You can use the following code to issue an Spatial Join Query on them. val considerBoundaryIntersection = false // Only return gemeotries fully covered by each query window in queryWindowRDD val usingIndex = false objectRDD . analyze () objectRDD . spatialPartitioning ( GridType . KDBTREE ) queryWindowRDD . spatialPartitioning ( objectRDD . getPartitioner ) val result = JoinQuery . SpatialJoinQuery ( objectRDD , queryWindowRDD , usingIndex , considerBoundaryIntersection ) Note Spatial join query is equal to the following query in Spatial SQL: SELECT superhero . name FROM city , superhero WHERE ST_Contains ( city . geom , superhero . geom ); Find the super heros in each city","title":"Write a Spatial Join Query"},{"location":"archive/tutorial/rdd/#use-spatial-partitioning","text":"GeoSpark spatial partitioning method can significantly speed up the join query. Three spatial partitioning methods are available: KDB-Tree, Quad-Tree and R-Tree. Two SpatialRDD must be partitioned by the same way. If you first partition SpatialRDD A, then you must use the partitioner of A to partition B. objectRDD . spatialPartitioning ( GridType . KDBTREE ) queryWindowRDD . spatialPartitioning ( objectRDD . getPartitioner ) Or queryWindowRDD . spatialPartitioning ( GridType . KDBTREE ) objectRDD . spatialPartitioning ( queryWindowRDD . getPartitioner )","title":"Use spatial partitioning"},{"location":"archive/tutorial/rdd/#use-spatial-indexes_2","text":"To utilize a spatial index in a spatial join query, use the following code: objectRDD . spatialPartitioning ( joinQueryPartitioningType ) queryWindowRDD . spatialPartitioning ( objectRDD . getPartitioner ) val buildOnSpatialPartitionedRDD = true // Set to TRUE only if run join query val usingIndex = true queryWindowRDD . buildIndex ( IndexType . QUADTREE , buildOnSpatialPartitionedRDD ) val result = JoinQuery . SpatialJoinQueryFlat ( objectRDD , queryWindowRDD , usingIndex , considerBoundaryIntersection ) The index should be built on either one of two SpatialRDDs. In general, you should build it on the larger SpatialRDD.","title":"Use spatial indexes"},{"location":"archive/tutorial/rdd/#output-format_2","text":"The output format of the spatial join query is a PairRDD. In this PairRDD, each object is a pair of two geometries. The left one is the geometry from objectRDD and the right one is the geometry from the queryWindowRDD. Point,Polygon Point,Polygon Point,Polygon Polygon,Polygon LineString,LineString Polygon,LineString ... Each object on the left is covered/intersected by the object on the right.","title":"Output format"},{"location":"archive/tutorial/rdd/#write-a-distance-join-query","text":"A distance join query takes as input two Spatial RDD A and B and a distance. For each geometry in A, finds the geometries (from B) are within the given distance to it. A and B can be any geometry type and are not necessary to have the same geometry type. The unit of the distance is explained here . Assume you now have two SpatialRDDs (typed or generic). You can use the following code to issue an Distance Join Query on them. objectRddA . analyze () val circleRDD = new CircleRDD ( objectRddA , 0.1 ) // Create a CircleRDD using the given distance circleRDD . spatialPartitioning ( GridType . KDBTREE ) objectRddB . spatialPartitioning ( circleRDD . getPartitioner ) val considerBoundaryIntersection = false // Only return gemeotries fully covered by each query window in queryWindowRDD val usingIndex = false val result = JoinQuery . DistanceJoinQueryFlat ( objectRddB , circleRDD , usingIndex , considerBoundaryIntersection ) The rest part of the join query is same as the spatial join query. The details of spatial partitioning in join query is here . The details of using spatial indexes in join query is here . The output format of the distance join query is here . Note Distance join query is equal to the following query in Spatial SQL: SELECT superhero . name FROM city , superhero WHERE ST_Distance ( city . geom , superhero . geom ) <= 10 ; Find the super heros within 10 miles of each city","title":"Write a Distance Join Query"},{"location":"archive/tutorial/rdd/#save-to-permanent-storage","text":"You can always save an SpatialRDD back to some permanent storage such as HDFS and Amazon S3. You can save distributed SpatialRDD to WKT, GeoJSON and object files. Note Non-spatial attributes such as price, age and name will also be stored to permanent storage.","title":"Save to permanent storage"},{"location":"archive/tutorial/rdd/#save-an-spatialrdd-not-indexed","text":"Typed SpatialRDD and generic SpatialRDD can be saved to permanent storage.","title":"Save an SpatialRDD (not indexed)"},{"location":"archive/tutorial/rdd/#save-an-spatialrdd-indexed","text":"Indexed typed SpatialRDD and generic SpatialRDD can be saved to permanent storage. However, the indexed SpatialRDD has to be stored as a distributed object file.","title":"Save an SpatialRDD (indexed)"},{"location":"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed","text":"A spatial partitioned RDD can be saved to permanent storage but Spark is not able to maintain the same RDD partition Id of the original RDD. This will lead to wrong join query results. We are working on some solutions. Stay tuned!","title":"Save an SpatialRDD (spatialPartitioned W/O indexed)"},{"location":"archive/tutorial/rdd/#reload-a-saved-spatialrdd","text":"You can easily reload an SpatialRDD that has been saved to a distributed object file .","title":"Reload a saved SpatialRDD"},{"location":"archive/tutorial/sql/","text":"The page outlines the steps to manage spatial data using GeoSparkSQL. The example code is written in Scala but also works for Java . GeoSparkSQL supports SQL/MM Part3 Spatial SQL Standard. It includes four kinds of SQL operators as follows. All these operators can be directly called through: var myDataFrame = sparkSession . sql ( \"YOUR_SQL\" ) Detailed GeoSparkSQL APIs are available here: GeoSparkSQL API Set up dependencies \u00b6 Read GeoSpark Maven Central coordinates Select the minimum dependencies : Add Apache Spark core , Apache SparkSQL , GeoSpark core , GeoSparkSQL Add the dependencies in build.sbt or pom.xml. Note To enjoy the full functions of GeoSpark, we suggest you include the full dependencies : Apache Spark core , Apache SparkSQL , GeoSpark core , GeoSparkSQL , GeoSparkViz Initiate SparkSession \u00b6 Use the following code to initiate your SparkSession at the beginning: var sparkSession = SparkSession . builder () . master ( \"local[*]\" ) // Delete this if run in cluster mode . appName ( \"readTestScala\" ) // Change this to a proper name // Enable GeoSpark custom Kryo serializer . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) . config ( \"spark.kryo.registrator\" , classOf [ GeoSparkKryoRegistrator ]. getName ) . getOrCreate () Warning GeoSpark has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. If you add the GeoSpark full dependencies as suggested above, please use the following two lines to enable GeoSpark Kryo serializer instead: . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) . config ( \"spark.kryo.registrator\" , classOf [ GeoSparkVizKryoRegistrator ]. getName ) Register GeoSparkSQL \u00b6 Add the following line after your SparkSession declaration GeoSparkSQLRegistrator . registerAll ( sparkSession ) This function will register GeoSpark User Defined Type, User Defined Function and optimized join query strategy. Load data from files \u00b6 Assume we have a WKT file, namely usa-county.tsv , at Path /Download/usa-county.tsv as follows: POLYGON (..., ...) Cuming County POLYGON (..., ...) Wahkiakum County POLYGON (..., ...) De Baca County POLYGON (..., ...) Lancaster County The file may have many other columns. Use the following code to load the data and create a raw DataFrame: var rawDf = sparkSession . read . format ( \"csv\" ). option ( \"delimiter\" , \"\\t\" ). option ( \"header\" , \"false\" ). load ( \"/Download/usa-county.tsv\" ) rawDf . createOrReplaceTempView ( \"rawdf\" ) rawDf . show () The output will be like this: | _c0|_c1|_c2| _c3| _c4| _c5| _c6|_c7|_c8| _c9|_c10| _c11|_c12|_c13| _c14| _c15| _c16| _c17| +--------------------+---+---+--------+-----+-----------+--------------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+ |POLYGON ((-97.019...| 31|039|00835841|31039| Cuming| Cuming County| 06| H1|G4020|null| null|null| A|1477895811|10447360|+41.9158651|-096.7885168| |POLYGON ((-123.43...| 53|069|01513275|53069| Wahkiakum| Wahkiakum County| 06| H1|G4020|null| null|null| A| 682138871|61658258|+46.2946377|-123.4244583| |POLYGON ((-104.56...| 35|011|00933054|35011| De Baca| De Baca County| 06| H1|G4020|null| null|null| A|6015539696|29159492|+34.3592729|-104.3686961| |POLYGON ((-96.910...| 31|109|00835876|31109| Lancaster| Lancaster County| 06| H1|G4020| 339|30700|null| A|2169240202|22877180|+40.7835474|-096.6886584| Create a Geometry type column \u00b6 All geometrical operations in GeoSparkSQL are on Geometry type objects. Therefore, before any kind of queries, you need to create a Geometry type column on a DataFrame. var spatialDf = sparkSession . sql ( \"\"\" |SELECT ST_GeomFromWKT(_c0) AS countyshape, _c1, _c2 |FROM rawdf \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () You can select many other attributes to compose this spatialdDf . The output will be something like this: | countyshape|_c1|_c2| _c3| _c4| _c5| _c6|_c7|_c8| _c9|_c10| _c11|_c12|_c13| _c14| _c15| _c16| _c17| +--------------------+---+---+--------+-----+-----------+--------------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+ |POLYGON ((-97.019...| 31|039|00835841|31039| Cuming| Cuming County| 06| H1|G4020|null| null|null| A|1477895811|10447360|+41.9158651|-096.7885168| |POLYGON ((-123.43...| 53|069|01513275|53069| Wahkiakum| Wahkiakum County| 06| H1|G4020|null| null|null| A| 682138871|61658258|+46.2946377|-123.4244583| |POLYGON ((-104.56...| 35|011|00933054|35011| De Baca| De Baca County| 06| H1|G4020|null| null|null| A|6015539696|29159492|+34.3592729|-104.3686961| |POLYGON ((-96.910...| 31|109|00835876|31109| Lancaster| Lancaster County| 06| H1|G4020| 339|30700|null| A|2169240202|22877180|+40.7835474|-096.6886584| Although it looks same with the input, but actually the type of column countyshape has been changed to Geometry type. To verify this, use the following code to print the schema of the DataFrame: spatialDf . printSchema () The output will be like this: root |-- countyshape: geometry (nullable = false) |-- _c1: string (nullable = true) |-- _c2: string (nullable = true) |-- _c3: string (nullable = true) |-- _c4: string (nullable = true) |-- _c5: string (nullable = true) |-- _c6: string (nullable = true) |-- _c7: string (nullable = true) Note GeoSparkSQL provides more than 10 different functions to create a Geometry column, please read GeoSparkSQL constructor API . Load Shapefile and GeoJSON \u00b6 Shapefile and GeoJSON must be loaded by SpatialRDD and converted to DataFrame using Adapter. Please read Load SpatialRDD and DataFrame <-> RDD . Transform the Coordinate Reference System \u00b6 GeoSpark doesn't control the coordinate unit (degree-based or meter-based) of all geometries in a Geometry column. The unit of all related distances in GeoSparkSQL is same as the unit of all geometries in a Geometry column. To convert Coordinate Reference System of the Geometry column created before, use the following code: spatialDf = sparkSession . sql ( \"\"\" |SELECT ST_Transform(countyshape, \"epsg:4326\", \"epsg:3857\") AS newcountyshape, _c1, _c2, _c3, _c4, _c5, _c6, _c7 |FROM spatialdf \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () The first EPSG code EPSG:4326 in ST_Transform is the source CRS of the geometries. It is WGS84, the most common degree-based CRS. The second EPSG code EPSG:3857 in ST_Transform is the target CRS of the geometries. It is the most common meter-based CRS. This ST_Transform transform the CRS of these geomtries from EPSG:4326 to EPSG:3857. The details CRS information can be found on EPSG.io The coordinates of polygons have been changed. The output will be like this: +--------------------+---+---+--------+-----+-----------+--------------------+---+ | newcountyshape|_c1|_c2| _c3| _c4| _c5| _c6|_c7| +--------------------+---+---+--------+-----+-----------+--------------------+---+ |POLYGON ((-108001...| 31|039|00835841|31039| Cuming| Cuming County| 06| |POLYGON ((-137408...| 53|069|01513275|53069| Wahkiakum| Wahkiakum County| 06| |POLYGON ((-116403...| 35|011|00933054|35011| De Baca| De Baca County| 06| |POLYGON ((-107880...| 31|109|00835876|31109| Lancaster| Lancaster County| 06| Run spatial queries \u00b6 After creating a Geometry type column, you are able to run spatial queries. Range query \u00b6 Use ST_Contains , ST_Intersects , ST_Within to run a range query over a single column. The following example finds all counties that are within the given polygon: spatialDf = sparkSession . sql ( \"\"\" |SELECT * |FROM spatialdf |WHERE ST_Contains (ST_PolygonFromEnvelope(1.0,100.0,1000.0,1100.0), newcountyshape) \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () Note Read GeoSparkSQL constructor API to learn how to create a Geometry type query window KNN query \u00b6 Use ST_Distance to calculate the distance and rank the distance. The following code returns the 5 nearest neighbor of the given polygon. spatialDf = sparkSession . sql ( \"\"\" |SELECT countyname, ST_Distance(ST_PolygonFromEnvelope(1.0,100.0,1000.0,1100.0), newcountyshape) AS distance |FROM spatialdf |ORDER BY distance DESC |LIMIT 5 \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () Join query \u00b6 The details of a join query is available here Join query . Other queries \u00b6 There are lots of other functions can be combined with these queries. Please read GeoSparkSQL functions and GeoSparkSQL aggregate functions . Save to permanent storage \u00b6 To save a Spatial DataFrame to some permanent storage such as Hive tables and HDFS, you can simply convert each geometry in the Geometry type column back to a plain String and save the plain DataFrame to wherever you want. Use the following code to convert the Geometry column in a DataFrame back to a WKT string column: sparkSession . udf . register ( \"ST_SaveAsWKT\" , ( geometry : Geometry ) => ( geometry . toText )) var stringDf = sparkSession . sql ( \"\"\" |SELECT ST_SaveAsWKT(countyshape) |FROM polygondf \"\"\" . stripMargin ) Note We are working on providing more user-friendly output functions such as ST_SaveAsWKT and ST_SaveAsWKB . Stay tuned! To load the DataFrame back, you first use the regular method to load the saved string DataFrame from the permanent storage and use ST_GeomFromWKT to re-build the Geometry type column. Convert between DataFrame and SpatialRDD \u00b6 DataFrame to SpatialRDD \u00b6 Use GeoSparkSQL DataFrame-RDD Adapter to convert a DataFrame to an SpatialRDD GeoSpark 1.2.0+ var spatialRDD = Adapter . toSpatialRdd ( spatialDf , \"usacounty\" ) \"usacounty\" is the name of the geometry column Before GeoSpark 1.2.0 var spatialRDD = new SpatialRDD [ Geometry ] spatialRDD . rawSpatialRDD = Adapter . toRdd ( spatialDf ) Geometry must be the first column in the DataFrame Warning Only one Geometry type column is allowed per DataFrame. Note Before GeoSpark 1.2.0, other non-spatial columns need be brought to SpatialRDD using the UUIDs. Please read GeoSparkSQL constructor API . In GeoSpark 1.2.0+, all other non-spatial columns are automatically kept in SpatialRDD. SpatialRDD to DataFrame \u00b6 Use GeoSparkSQL DataFrame-RDD Adapter to convert a DataFrame to an SpatialRDD var spatialDf = Adapter . toDf ( spatialRDD , sparkSession ) All other attributes such as price and age will be also brought to the DataFrame as long as you specify carryOtherAttributes (see Read other attributes in an SpatialRDD ). SpatialPairRDD to DataFrame \u00b6 PairRDD is the result of a spatial join query or distance join query. GeoSparkSQL DataFrame-RDD Adapter can convert the result to a DataFrame: var joinResultDf = Adapter . toDf ( joinResultPairRDD , sparkSession ) All other attributes such as price and age will be also brought to the DataFrame as long as you specify carryOtherAttributes (see Read other attributes in an SpatialRDD ).","title":"Spatial SQL application"},{"location":"archive/tutorial/sql/#set-up-dependencies","text":"Read GeoSpark Maven Central coordinates Select the minimum dependencies : Add Apache Spark core , Apache SparkSQL , GeoSpark core , GeoSparkSQL Add the dependencies in build.sbt or pom.xml. Note To enjoy the full functions of GeoSpark, we suggest you include the full dependencies : Apache Spark core , Apache SparkSQL , GeoSpark core , GeoSparkSQL , GeoSparkViz","title":"Set up dependencies"},{"location":"archive/tutorial/sql/#initiate-sparksession","text":"Use the following code to initiate your SparkSession at the beginning: var sparkSession = SparkSession . builder () . master ( \"local[*]\" ) // Delete this if run in cluster mode . appName ( \"readTestScala\" ) // Change this to a proper name // Enable GeoSpark custom Kryo serializer . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) . config ( \"spark.kryo.registrator\" , classOf [ GeoSparkKryoRegistrator ]. getName ) . getOrCreate () Warning GeoSpark has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. If you add the GeoSpark full dependencies as suggested above, please use the following two lines to enable GeoSpark Kryo serializer instead: . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) . config ( \"spark.kryo.registrator\" , classOf [ GeoSparkVizKryoRegistrator ]. getName )","title":"Initiate SparkSession"},{"location":"archive/tutorial/sql/#register-geosparksql","text":"Add the following line after your SparkSession declaration GeoSparkSQLRegistrator . registerAll ( sparkSession ) This function will register GeoSpark User Defined Type, User Defined Function and optimized join query strategy.","title":"Register GeoSparkSQL"},{"location":"archive/tutorial/sql/#load-data-from-files","text":"Assume we have a WKT file, namely usa-county.tsv , at Path /Download/usa-county.tsv as follows: POLYGON (..., ...) Cuming County POLYGON (..., ...) Wahkiakum County POLYGON (..., ...) De Baca County POLYGON (..., ...) Lancaster County The file may have many other columns. Use the following code to load the data and create a raw DataFrame: var rawDf = sparkSession . read . format ( \"csv\" ). option ( \"delimiter\" , \"\\t\" ). option ( \"header\" , \"false\" ). load ( \"/Download/usa-county.tsv\" ) rawDf . createOrReplaceTempView ( \"rawdf\" ) rawDf . show () The output will be like this: | _c0|_c1|_c2| _c3| _c4| _c5| _c6|_c7|_c8| _c9|_c10| _c11|_c12|_c13| _c14| _c15| _c16| _c17| +--------------------+---+---+--------+-----+-----------+--------------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+ |POLYGON ((-97.019...| 31|039|00835841|31039| Cuming| Cuming County| 06| H1|G4020|null| null|null| A|1477895811|10447360|+41.9158651|-096.7885168| |POLYGON ((-123.43...| 53|069|01513275|53069| Wahkiakum| Wahkiakum County| 06| H1|G4020|null| null|null| A| 682138871|61658258|+46.2946377|-123.4244583| |POLYGON ((-104.56...| 35|011|00933054|35011| De Baca| De Baca County| 06| H1|G4020|null| null|null| A|6015539696|29159492|+34.3592729|-104.3686961| |POLYGON ((-96.910...| 31|109|00835876|31109| Lancaster| Lancaster County| 06| H1|G4020| 339|30700|null| A|2169240202|22877180|+40.7835474|-096.6886584|","title":"Load data from files"},{"location":"archive/tutorial/sql/#create-a-geometry-type-column","text":"All geometrical operations in GeoSparkSQL are on Geometry type objects. Therefore, before any kind of queries, you need to create a Geometry type column on a DataFrame. var spatialDf = sparkSession . sql ( \"\"\" |SELECT ST_GeomFromWKT(_c0) AS countyshape, _c1, _c2 |FROM rawdf \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () You can select many other attributes to compose this spatialdDf . The output will be something like this: | countyshape|_c1|_c2| _c3| _c4| _c5| _c6|_c7|_c8| _c9|_c10| _c11|_c12|_c13| _c14| _c15| _c16| _c17| +--------------------+---+---+--------+-----+-----------+--------------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+ |POLYGON ((-97.019...| 31|039|00835841|31039| Cuming| Cuming County| 06| H1|G4020|null| null|null| A|1477895811|10447360|+41.9158651|-096.7885168| |POLYGON ((-123.43...| 53|069|01513275|53069| Wahkiakum| Wahkiakum County| 06| H1|G4020|null| null|null| A| 682138871|61658258|+46.2946377|-123.4244583| |POLYGON ((-104.56...| 35|011|00933054|35011| De Baca| De Baca County| 06| H1|G4020|null| null|null| A|6015539696|29159492|+34.3592729|-104.3686961| |POLYGON ((-96.910...| 31|109|00835876|31109| Lancaster| Lancaster County| 06| H1|G4020| 339|30700|null| A|2169240202|22877180|+40.7835474|-096.6886584| Although it looks same with the input, but actually the type of column countyshape has been changed to Geometry type. To verify this, use the following code to print the schema of the DataFrame: spatialDf . printSchema () The output will be like this: root |-- countyshape: geometry (nullable = false) |-- _c1: string (nullable = true) |-- _c2: string (nullable = true) |-- _c3: string (nullable = true) |-- _c4: string (nullable = true) |-- _c5: string (nullable = true) |-- _c6: string (nullable = true) |-- _c7: string (nullable = true) Note GeoSparkSQL provides more than 10 different functions to create a Geometry column, please read GeoSparkSQL constructor API .","title":"Create a Geometry type column"},{"location":"archive/tutorial/sql/#load-shapefile-and-geojson","text":"Shapefile and GeoJSON must be loaded by SpatialRDD and converted to DataFrame using Adapter. Please read Load SpatialRDD and DataFrame <-> RDD .","title":"Load Shapefile and GeoJSON"},{"location":"archive/tutorial/sql/#transform-the-coordinate-reference-system","text":"GeoSpark doesn't control the coordinate unit (degree-based or meter-based) of all geometries in a Geometry column. The unit of all related distances in GeoSparkSQL is same as the unit of all geometries in a Geometry column. To convert Coordinate Reference System of the Geometry column created before, use the following code: spatialDf = sparkSession . sql ( \"\"\" |SELECT ST_Transform(countyshape, \"epsg:4326\", \"epsg:3857\") AS newcountyshape, _c1, _c2, _c3, _c4, _c5, _c6, _c7 |FROM spatialdf \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () The first EPSG code EPSG:4326 in ST_Transform is the source CRS of the geometries. It is WGS84, the most common degree-based CRS. The second EPSG code EPSG:3857 in ST_Transform is the target CRS of the geometries. It is the most common meter-based CRS. This ST_Transform transform the CRS of these geomtries from EPSG:4326 to EPSG:3857. The details CRS information can be found on EPSG.io The coordinates of polygons have been changed. The output will be like this: +--------------------+---+---+--------+-----+-----------+--------------------+---+ | newcountyshape|_c1|_c2| _c3| _c4| _c5| _c6|_c7| +--------------------+---+---+--------+-----+-----------+--------------------+---+ |POLYGON ((-108001...| 31|039|00835841|31039| Cuming| Cuming County| 06| |POLYGON ((-137408...| 53|069|01513275|53069| Wahkiakum| Wahkiakum County| 06| |POLYGON ((-116403...| 35|011|00933054|35011| De Baca| De Baca County| 06| |POLYGON ((-107880...| 31|109|00835876|31109| Lancaster| Lancaster County| 06|","title":"Transform the Coordinate Reference System"},{"location":"archive/tutorial/sql/#run-spatial-queries","text":"After creating a Geometry type column, you are able to run spatial queries.","title":"Run spatial queries"},{"location":"archive/tutorial/sql/#range-query","text":"Use ST_Contains , ST_Intersects , ST_Within to run a range query over a single column. The following example finds all counties that are within the given polygon: spatialDf = sparkSession . sql ( \"\"\" |SELECT * |FROM spatialdf |WHERE ST_Contains (ST_PolygonFromEnvelope(1.0,100.0,1000.0,1100.0), newcountyshape) \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () Note Read GeoSparkSQL constructor API to learn how to create a Geometry type query window","title":"Range query"},{"location":"archive/tutorial/sql/#knn-query","text":"Use ST_Distance to calculate the distance and rank the distance. The following code returns the 5 nearest neighbor of the given polygon. spatialDf = sparkSession . sql ( \"\"\" |SELECT countyname, ST_Distance(ST_PolygonFromEnvelope(1.0,100.0,1000.0,1100.0), newcountyshape) AS distance |FROM spatialdf |ORDER BY distance DESC |LIMIT 5 \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show ()","title":"KNN query"},{"location":"archive/tutorial/sql/#join-query","text":"The details of a join query is available here Join query .","title":"Join query"},{"location":"archive/tutorial/sql/#other-queries","text":"There are lots of other functions can be combined with these queries. Please read GeoSparkSQL functions and GeoSparkSQL aggregate functions .","title":"Other queries"},{"location":"archive/tutorial/sql/#save-to-permanent-storage","text":"To save a Spatial DataFrame to some permanent storage such as Hive tables and HDFS, you can simply convert each geometry in the Geometry type column back to a plain String and save the plain DataFrame to wherever you want. Use the following code to convert the Geometry column in a DataFrame back to a WKT string column: sparkSession . udf . register ( \"ST_SaveAsWKT\" , ( geometry : Geometry ) => ( geometry . toText )) var stringDf = sparkSession . sql ( \"\"\" |SELECT ST_SaveAsWKT(countyshape) |FROM polygondf \"\"\" . stripMargin ) Note We are working on providing more user-friendly output functions such as ST_SaveAsWKT and ST_SaveAsWKB . Stay tuned! To load the DataFrame back, you first use the regular method to load the saved string DataFrame from the permanent storage and use ST_GeomFromWKT to re-build the Geometry type column.","title":"Save to permanent storage"},{"location":"archive/tutorial/sql/#convert-between-dataframe-and-spatialrdd","text":"","title":"Convert between DataFrame and SpatialRDD"},{"location":"archive/tutorial/sql/#dataframe-to-spatialrdd","text":"Use GeoSparkSQL DataFrame-RDD Adapter to convert a DataFrame to an SpatialRDD GeoSpark 1.2.0+ var spatialRDD = Adapter . toSpatialRdd ( spatialDf , \"usacounty\" ) \"usacounty\" is the name of the geometry column Before GeoSpark 1.2.0 var spatialRDD = new SpatialRDD [ Geometry ] spatialRDD . rawSpatialRDD = Adapter . toRdd ( spatialDf ) Geometry must be the first column in the DataFrame Warning Only one Geometry type column is allowed per DataFrame. Note Before GeoSpark 1.2.0, other non-spatial columns need be brought to SpatialRDD using the UUIDs. Please read GeoSparkSQL constructor API . In GeoSpark 1.2.0+, all other non-spatial columns are automatically kept in SpatialRDD.","title":"DataFrame to SpatialRDD"},{"location":"archive/tutorial/sql/#spatialrdd-to-dataframe","text":"Use GeoSparkSQL DataFrame-RDD Adapter to convert a DataFrame to an SpatialRDD var spatialDf = Adapter . toDf ( spatialRDD , sparkSession ) All other attributes such as price and age will be also brought to the DataFrame as long as you specify carryOtherAttributes (see Read other attributes in an SpatialRDD ).","title":"SpatialRDD to DataFrame"},{"location":"archive/tutorial/sql/#spatialpairrdd-to-dataframe","text":"PairRDD is the result of a spatial join query or distance join query. GeoSparkSQL DataFrame-RDD Adapter can convert the result to a DataFrame: var joinResultDf = Adapter . toDf ( joinResultPairRDD , sparkSession ) All other attributes such as price and age will be also brought to the DataFrame as long as you specify carryOtherAttributes (see Read other attributes in an SpatialRDD ).","title":"SpatialPairRDD to DataFrame"},{"location":"archive/tutorial/viz/","text":"The page outlines the steps to visualize spatial data using GeoSparkViz. The example code is written in Scala but also works for Java . Starting from 1.2.0, GeoSparkViz provides the DataFrame support. This offers users a more flexible way to design beautiful map visualization effects including scatter plots and heat maps. In the meantime, GeoSparkViz RDD API remains the same. Note All GeoSparkViz SQL/DataFrame APIs are explained in GeoSparkViz API . Why scalable map visualization? \u00b6 Data visualization allows users to summarize, analyze and reason about data. Guaranteeing detailed and accurate geospatial map visualization (e.g., at multiple zoom levels) requires extremely high-resolution maps. Classic visualization solutions such as Google Maps, MapBox and ArcGIS suffer from limited computation resources and hence take a tremendous amount of time to generate maps for large-scale geospatial data. In big spatial data scenarios, these tools just crash or run forever. GeoSparkViz encapsulates the main steps of map visualization process, e.g., pixelize, aggregate, and render, into a set of massively parallelized GeoViz operators and the user can assemble any customized styles. Visualize SpatialRDD \u00b6 This tutorial mainly focuses on explaining SQL/DataFrame API. GeoSparkViz RDD example can be found in GeoSpark template project . Set up dependencies \u00b6 Read GeoSpark Maven Central coordinates Add Apache Spark core , Apache SparkSQL , GeoSpark core , GeoSparkSQL , GeoSparkViz Initiate SparkSession \u00b6 Use the following code to initiate your SparkSession at the beginning: This will register GeoSparkVizKryo serializer. var sparkSession = SparkSession . builder () . master ( \"local[*]\" ) // Delete this if run in cluster mode . appName ( \"readTestScala\" ) // Change this to a proper name // Enable GeoSpark custom Kryo serializer . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) . config ( \"spark.kryo.registrator\" , classOf [ GeoSparkVizKryoRegistrator ]. getName ) . getOrCreate () Register GeoSparkSQL and GeoSparkViz \u00b6 Add the following line after your SparkSession declaration GeoSparkSQLRegistrator . registerAll ( sparkSession ) GeoSparkVizRegistrator . registerAll ( sparkSession ) This will register all User Defined Tyeps, functions and optimizations in GeoSparkSQL and GeoSparkViz. Create Spatial DataFrame \u00b6 There is a DataFrame as follows: +----------+---------+ | _c0| _c1| +----------+---------+ |-88.331492|32.324142| |-88.175933|32.360763| |-88.388954|32.357073| |-88.221102| 32.35078| You first need to create a Geometry type column. CREATE OR REPLACE TEMP VIEW pointtable AS SELECT ST_Point ( cast ( pointtable . _c0 as Decimal ( 24 , 20 )), cast ( pointtable . _c1 as Decimal ( 24 , 20 ))) as shape FROM pointtable As you know, GeoSpark provides many different methods to load various spatial data formats. Please read Write an Spatial DataFrame application . Generate a single image \u00b6 In most cases, you just want to see a single image out of your spatial dataset. Pixelize spatial objects \u00b6 To put spatial objects on a map image, you first need to convert them to pixels. First, compute the spatial boundary of this column. CREATE OR REPLACE TEMP VIEW boundtable AS SELECT ST_Envelope_Aggr ( shape ) as bound FROM pointtable Then use ST_Pixelize to conver them to pixels. CREATE OR REPLACE TEMP VIEW pixels AS SELECT pixel , shape FROM pointtable LATERAL VIEW ST_Pixelize ( ST_Transform ( shape , 'epsg:4326' , 'epsg:3857' ), 256 , 256 , ( SELECT ST_Transform ( bound , 'epsg:4326' , 'epsg:3857' ) FROM boundtable )) AS pixel This will give you a 256*256 resolution image after you run ST_Render at the end of this tutorial. Warning We highly suggest that you should use ST_Transform to transfrom coordiantes to a visualization-specific coordinate sysmte such as epsg:3857. Otherwise you map may look distorted. Aggregate pixels \u00b6 Many objects may be pixelized to the same pixel locations. You now need to aggregate them based on either their spatial aggregation or spatial observations such as temperature or humidity. CREATE OR REPLACE TEMP VIEW pixelaggregates AS SELECT pixel , count ( * ) as weight FROM pixels GROUP BY pixel The weight indicates the degree of spatial aggregation or spatial observations. Later on, it will determine the color of this pixel. Colorize pixels \u00b6 Run the following command to assign colors for pixels based on their weights. CREATE OR REPLACE TEMP VIEW pixelaggregates AS SELECT pixel , ST_Colorize ( weight , ( SELECT max ( weight ) FROM pixelaggregates )) as color FROM pixelaggregates Please read ST_Colorize for a detailed API description. Render the image \u00b6 Use ST_Render to plot all pixels on a single image. CREATE OR REPLACE TEMP VIEW images AS SELECT ST_Render ( pixel , color ) AS image , ( SELECT ST_AsText ( bound ) FROM boundtable ) AS boundary FROM pixelaggregates This DataFrame will contain a Image type column which has only one image. Store the image on disk \u00b6 Fetch the image from the previous DataFrame var image = sparkSession.table(\"images\").take(1)(0)(0).asInstanceOf[ImageSerializableWrapper].getImage Use GeoSparkViz ImageGenerator to store this image on disk. var imageGenerator = new ImageGenerator imageGenerator . SaveRasterImageAsLocalFile ( image , System . getProperty ( \"user.dir\" ) + \"/target/points\" , ImageType . PNG ) Generate map tiles \u00b6 If you are a map tile professional, you may need to generate map tiles for different zoom levels and eventually create the map tile layer. Pixelization and pixel aggregation \u00b6 Please first do pixelization and pixel aggregation using the same commands in single image generation. In ST_Pixelize, you need specify a very high resolution. Create tile name \u00b6 Run the following command to compute the tile name for every pixels CREATE OR REPLACE TEMP VIEW pixelaggregates AS SELECT pixel , weight , ST_TileName ( pixel , 3 ) AS pid FROM pixelaggregates \"3\" is the zoom level for these map tiles. Colorize pixels \u00b6 Use the same command explained in single image generation to assign colors. Render map tiles \u00b6 You now need to group pixels by tiles and then render map tile images in parallel. CREATE OR REPLACE TEMP VIEW images AS SELECT ST_Render ( pixel , color ) AS image FROM pixelaggregates GROUP BY pid Store map tiles on disk \u00b6 You can use the same commands in single image generation to fetch all map tiles and store them one by one.","title":"Visualize Spatial DataFrame"},{"location":"archive/tutorial/viz/#why-scalable-map-visualization","text":"Data visualization allows users to summarize, analyze and reason about data. Guaranteeing detailed and accurate geospatial map visualization (e.g., at multiple zoom levels) requires extremely high-resolution maps. Classic visualization solutions such as Google Maps, MapBox and ArcGIS suffer from limited computation resources and hence take a tremendous amount of time to generate maps for large-scale geospatial data. In big spatial data scenarios, these tools just crash or run forever. GeoSparkViz encapsulates the main steps of map visualization process, e.g., pixelize, aggregate, and render, into a set of massively parallelized GeoViz operators and the user can assemble any customized styles.","title":"Why scalable map visualization?"},{"location":"archive/tutorial/viz/#visualize-spatialrdd","text":"This tutorial mainly focuses on explaining SQL/DataFrame API. GeoSparkViz RDD example can be found in GeoSpark template project .","title":"Visualize SpatialRDD"},{"location":"archive/tutorial/viz/#set-up-dependencies","text":"Read GeoSpark Maven Central coordinates Add Apache Spark core , Apache SparkSQL , GeoSpark core , GeoSparkSQL , GeoSparkViz","title":"Set up dependencies"},{"location":"archive/tutorial/viz/#initiate-sparksession","text":"Use the following code to initiate your SparkSession at the beginning: This will register GeoSparkVizKryo serializer. var sparkSession = SparkSession . builder () . master ( \"local[*]\" ) // Delete this if run in cluster mode . appName ( \"readTestScala\" ) // Change this to a proper name // Enable GeoSpark custom Kryo serializer . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) . config ( \"spark.kryo.registrator\" , classOf [ GeoSparkVizKryoRegistrator ]. getName ) . getOrCreate ()","title":"Initiate SparkSession"},{"location":"archive/tutorial/viz/#register-geosparksql-and-geosparkviz","text":"Add the following line after your SparkSession declaration GeoSparkSQLRegistrator . registerAll ( sparkSession ) GeoSparkVizRegistrator . registerAll ( sparkSession ) This will register all User Defined Tyeps, functions and optimizations in GeoSparkSQL and GeoSparkViz.","title":"Register GeoSparkSQL and GeoSparkViz"},{"location":"archive/tutorial/viz/#create-spatial-dataframe","text":"There is a DataFrame as follows: +----------+---------+ | _c0| _c1| +----------+---------+ |-88.331492|32.324142| |-88.175933|32.360763| |-88.388954|32.357073| |-88.221102| 32.35078| You first need to create a Geometry type column. CREATE OR REPLACE TEMP VIEW pointtable AS SELECT ST_Point ( cast ( pointtable . _c0 as Decimal ( 24 , 20 )), cast ( pointtable . _c1 as Decimal ( 24 , 20 ))) as shape FROM pointtable As you know, GeoSpark provides many different methods to load various spatial data formats. Please read Write an Spatial DataFrame application .","title":"Create Spatial DataFrame"},{"location":"archive/tutorial/viz/#generate-a-single-image","text":"In most cases, you just want to see a single image out of your spatial dataset.","title":"Generate a single image"},{"location":"archive/tutorial/viz/#pixelize-spatial-objects","text":"To put spatial objects on a map image, you first need to convert them to pixels. First, compute the spatial boundary of this column. CREATE OR REPLACE TEMP VIEW boundtable AS SELECT ST_Envelope_Aggr ( shape ) as bound FROM pointtable Then use ST_Pixelize to conver them to pixels. CREATE OR REPLACE TEMP VIEW pixels AS SELECT pixel , shape FROM pointtable LATERAL VIEW ST_Pixelize ( ST_Transform ( shape , 'epsg:4326' , 'epsg:3857' ), 256 , 256 , ( SELECT ST_Transform ( bound , 'epsg:4326' , 'epsg:3857' ) FROM boundtable )) AS pixel This will give you a 256*256 resolution image after you run ST_Render at the end of this tutorial. Warning We highly suggest that you should use ST_Transform to transfrom coordiantes to a visualization-specific coordinate sysmte such as epsg:3857. Otherwise you map may look distorted.","title":"Pixelize spatial objects"},{"location":"archive/tutorial/viz/#aggregate-pixels","text":"Many objects may be pixelized to the same pixel locations. You now need to aggregate them based on either their spatial aggregation or spatial observations such as temperature or humidity. CREATE OR REPLACE TEMP VIEW pixelaggregates AS SELECT pixel , count ( * ) as weight FROM pixels GROUP BY pixel The weight indicates the degree of spatial aggregation or spatial observations. Later on, it will determine the color of this pixel.","title":"Aggregate pixels"},{"location":"archive/tutorial/viz/#colorize-pixels","text":"Run the following command to assign colors for pixels based on their weights. CREATE OR REPLACE TEMP VIEW pixelaggregates AS SELECT pixel , ST_Colorize ( weight , ( SELECT max ( weight ) FROM pixelaggregates )) as color FROM pixelaggregates Please read ST_Colorize for a detailed API description.","title":"Colorize pixels"},{"location":"archive/tutorial/viz/#render-the-image","text":"Use ST_Render to plot all pixels on a single image. CREATE OR REPLACE TEMP VIEW images AS SELECT ST_Render ( pixel , color ) AS image , ( SELECT ST_AsText ( bound ) FROM boundtable ) AS boundary FROM pixelaggregates This DataFrame will contain a Image type column which has only one image.","title":"Render the image"},{"location":"archive/tutorial/viz/#store-the-image-on-disk","text":"Fetch the image from the previous DataFrame var image = sparkSession.table(\"images\").take(1)(0)(0).asInstanceOf[ImageSerializableWrapper].getImage Use GeoSparkViz ImageGenerator to store this image on disk. var imageGenerator = new ImageGenerator imageGenerator . SaveRasterImageAsLocalFile ( image , System . getProperty ( \"user.dir\" ) + \"/target/points\" , ImageType . PNG )","title":"Store the image on disk"},{"location":"archive/tutorial/viz/#generate-map-tiles","text":"If you are a map tile professional, you may need to generate map tiles for different zoom levels and eventually create the map tile layer.","title":"Generate map tiles"},{"location":"archive/tutorial/viz/#pixelization-and-pixel-aggregation","text":"Please first do pixelization and pixel aggregation using the same commands in single image generation. In ST_Pixelize, you need specify a very high resolution.","title":"Pixelization and pixel aggregation"},{"location":"archive/tutorial/viz/#create-tile-name","text":"Run the following command to compute the tile name for every pixels CREATE OR REPLACE TEMP VIEW pixelaggregates AS SELECT pixel , weight , ST_TileName ( pixel , 3 ) AS pid FROM pixelaggregates \"3\" is the zoom level for these map tiles.","title":"Create tile name"},{"location":"archive/tutorial/viz/#colorize-pixels_1","text":"Use the same command explained in single image generation to assign colors.","title":"Colorize pixels"},{"location":"archive/tutorial/viz/#render-map-tiles","text":"You now need to group pixels by tiles and then render map tile images in parallel. CREATE OR REPLACE TEMP VIEW images AS SELECT ST_Render ( pixel , color ) AS image FROM pixelaggregates GROUP BY pid","title":"Render map tiles"},{"location":"archive/tutorial/viz/#store-map-tiles-on-disk","text":"You can use the same commands in single image generation to fetch all map tiles and store them one by one.","title":"Store map tiles on disk"},{"location":"archive/tutorial/zeppelin/","text":"Starting from 1.2.0, GeoSpark provides a Helium visualization plugin tailored for Apache Zeppelin . This finally bridges the gap between GeoSpark and Zeppelin. Please read Install GeoSpark-Zeppelin to learn how to install this plugin in Zeppelin. GeoSpark-Zeppelin equips two approaches to visualize spatial data in Zeppelin. The first approach uses Zeppelin to plot all spatial objects on the map. The second one leverages GeoSparkViz to generate map images and overlay them on maps. Small-scale without GeoSparkViz \u00b6 Danger Zeppelin is just a front-end visualization framework. This approach is not scalable and will fail at large-scale geospatial data. Please scroll down to read GeoSparkViz solution. You can use Apache Zeppelin to plot a small number of spatial objects, such as 1000 points. Assume you already have a Spatial DataFrame, you need to convert the geometry column to WKT string column use the following command in your Zeppelin Spark notebook Scala paragraph: spark . sql ( \"\"\" |CREATE OR REPLACE TEMP VIEW wktpoint AS |SELECT ST_AsText(shape) as geom |FROM pointtable \"\"\" . stripMargin ) Then create an SQL paragraph to fetch the data % sql SELECT * FROM wktpoint Select the geometry column to visualize: Large-scale with GeoSparkViz \u00b6 GeoSparkViz is a distributed visualization system that allows you to visualize big spatial data at scale. Please read How to use GeoSparkViz . You can use GeoSpark-Zeppelin to ask Zeppelin to overlay GeoSparkViz images on a map background. This way, you can easily visualize 1 billion spatial objects or more (depends on your cluster size). First, encode images of GeoSparkViz DataFrame in Zeppelin Spark notebook Scala paragraph, spark.sql( \"\"\" |CREATE OR REPLACE TEMP VIEW images AS |SELECT ST_EncodeImage(image) AS image, (SELECT ST_AsText(bound) FROM boundtable) AS boundary |FROM images \"\"\".stripMargin) Then create an SQL paragraph to fetch the data % sql SELECT * , 'I am the map center!' FROM images Select the image and its geospatial boundary: Zeppelin Spark notebook demo \u00b6 We provide a full Zeppelin Spark notebook which demonstrates al functions. Please download GeoSpark-Zeppelin notebook template and test data - arealm.csv . You need to use Zeppelin to import this notebook JSON file and modify the input data path in the notebook.","title":"Run GeoSpark via Zeppelin"},{"location":"archive/tutorial/zeppelin/#small-scale-without-geosparkviz","text":"Danger Zeppelin is just a front-end visualization framework. This approach is not scalable and will fail at large-scale geospatial data. Please scroll down to read GeoSparkViz solution. You can use Apache Zeppelin to plot a small number of spatial objects, such as 1000 points. Assume you already have a Spatial DataFrame, you need to convert the geometry column to WKT string column use the following command in your Zeppelin Spark notebook Scala paragraph: spark . sql ( \"\"\" |CREATE OR REPLACE TEMP VIEW wktpoint AS |SELECT ST_AsText(shape) as geom |FROM pointtable \"\"\" . stripMargin ) Then create an SQL paragraph to fetch the data % sql SELECT * FROM wktpoint Select the geometry column to visualize:","title":"Small-scale without GeoSparkViz"},{"location":"archive/tutorial/zeppelin/#large-scale-with-geosparkviz","text":"GeoSparkViz is a distributed visualization system that allows you to visualize big spatial data at scale. Please read How to use GeoSparkViz . You can use GeoSpark-Zeppelin to ask Zeppelin to overlay GeoSparkViz images on a map background. This way, you can easily visualize 1 billion spatial objects or more (depends on your cluster size). First, encode images of GeoSparkViz DataFrame in Zeppelin Spark notebook Scala paragraph, spark.sql( \"\"\" |CREATE OR REPLACE TEMP VIEW images AS |SELECT ST_EncodeImage(image) AS image, (SELECT ST_AsText(bound) FROM boundtable) AS boundary |FROM images \"\"\".stripMargin) Then create an SQL paragraph to fetch the data % sql SELECT * , 'I am the map center!' FROM images Select the image and its geospatial boundary:","title":"Large-scale with GeoSparkViz"},{"location":"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo","text":"We provide a full Zeppelin Spark notebook which demonstrates al functions. Please download GeoSpark-Zeppelin notebook template and test data - arealm.csv . You need to use Zeppelin to import this notebook JSON file and modify the input data path in the notebook.","title":"Zeppelin Spark notebook demo"},{"location":"asf/asf/","text":"Copyright \u00b6 Apache Sedona, Apache Incubator, Apache, the Apache feather logo, and the Apache Incubator project logo are trademarks or registered trademarks of The Apache Software Foundation (ASF) .","title":"Foundation"},{"location":"asf/asf/#copyright","text":"Apache Sedona, Apache Incubator, Apache, the Apache feather logo, and the Apache Incubator project logo are trademarks or registered trademarks of The Apache Software Foundation (ASF) .","title":"Copyright"},{"location":"asf/disclaimer/","text":"Disclaimer \u00b6 Apache Sedona is an effort undergoing incubation at The Apache Software Foundation (ASF) , sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.","title":"Disclaimer"},{"location":"asf/disclaimer/#disclaimer","text":"Apache Sedona is an effort undergoing incubation at The Apache Software Foundation (ASF) , sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.","title":"Disclaimer"},{"location":"community/contact/","text":"Community \u00b6 Every volunteer project obtains its strength from the people involved in it. We invite you to participate as much or as little as you choose. You can participate in the community as follows: Use our project and provide a feedback. Provide us with the use-cases. Report bugs and submit patches. Contribute code and documentation. Feedback \u00b6 Feedback to improve Apache Sedona: Google Form Twitter \u00b6 Apache Sedona@Twitter Discord Server \u00b6 Join Apache Sedona community server ! Mailing list \u00b6 Get help using Sedona or contribute to the project on our mailing lists Sedona Mailing Lists : dev@sedona.apache.org : project development and general questions Please first subscribe and then post emails. To subscribe, please send an email (leave the subject and content blank) to dev-subscribe@sedona.apache.org Issue tracker \u00b6 Bug Reports \u00b6 Found bug? Enter an issue in the Sedona JIRA Before submitting an issue, please: Verify that the bug does in fact exist. Search the issue tracker to verify there is no existing issue reporting the bug you\u2019ve found. Consider tracking down the bug yourself in the Sedona\u2019s source and submitting a patch along with your bug report. This is a great time saver for the Sedona developers and helps ensure the bug will be fixed quickly. Feature Requests \u00b6 Enhancement requests for new features are also welcome. The more concrete and rationale the request is, the greater the chance it will be incorporated into future releases. Enter an issue in the Sedona JIRA or send an email to dev@sedona.apache.org","title":"Community"},{"location":"community/contact/#community","text":"Every volunteer project obtains its strength from the people involved in it. We invite you to participate as much or as little as you choose. You can participate in the community as follows: Use our project and provide a feedback. Provide us with the use-cases. Report bugs and submit patches. Contribute code and documentation.","title":"Community"},{"location":"community/contact/#feedback","text":"Feedback to improve Apache Sedona: Google Form","title":"Feedback"},{"location":"community/contact/#twitter","text":"Apache Sedona@Twitter","title":"Twitter"},{"location":"community/contact/#discord-server","text":"Join Apache Sedona community server !","title":"Discord Server"},{"location":"community/contact/#mailing-list","text":"Get help using Sedona or contribute to the project on our mailing lists Sedona Mailing Lists : dev@sedona.apache.org : project development and general questions Please first subscribe and then post emails. To subscribe, please send an email (leave the subject and content blank) to dev-subscribe@sedona.apache.org","title":"Mailing list"},{"location":"community/contact/#issue-tracker","text":"","title":"Issue tracker"},{"location":"community/contact/#bug-reports","text":"Found bug? Enter an issue in the Sedona JIRA Before submitting an issue, please: Verify that the bug does in fact exist. Search the issue tracker to verify there is no existing issue reporting the bug you\u2019ve found. Consider tracking down the bug yourself in the Sedona\u2019s source and submitting a patch along with your bug report. This is a great time saver for the Sedona developers and helps ensure the bug will be fixed quickly.","title":"Bug Reports"},{"location":"community/contact/#feature-requests","text":"Enhancement requests for new features are also welcome. The more concrete and rationale the request is, the greater the chance it will be incorporated into future releases. Enter an issue in the Sedona JIRA or send an email to dev@sedona.apache.org","title":"Feature Requests"},{"location":"community/contributor/","text":"Sedona has received numerous help from the community. This page lists the contributors and committers of Apache Sedona. People on this page are ordered by their last name. Committers \u00b6 A contributor who contributes enough code to Sedona will be promoted to a committer. A committer has the write access to Sedona main repository Project Management Committee (PMC) \u00b6 A committer will be promoted to a PMC member when the community thinks he/she is able to be in charge at least a major component of this project. Current Sedona PMC members are as follows: Name GitHub ID Apache ID Adam Binford Kimahriman kimahriman@apache.org Kanchan Chowdhury kanchanchy kanchanchy@apache.org Pawe\u0142 Koci\u0144ski Imbruced imbruced@apache.org Yitao Li yitao-li yitaoli@apache.org Netanel Malka netanel246 malka@apache.org Mohamed Sarwat Sarwat mosarwat@apache.org Kengo Seki sekikn sekikn@apache.org Sachio Wakai SW186000 swakai@apache.org Jinxuan Wu jinxuan jinxuanw@apache.org Jia Yu jiayuasu jiayu@apache.org Zongsi Zhang zongsizhang zongsizhang@apache.org Mentors \u00b6 Mentors from Apache Incubator help the project to turn into a good shape following the \"Apache\" way. Thank you, mentors! Name Apache id Felix Cheung felixcheung@apache.org Von Gosling vongosling@apache.org Jean-Baptiste Onofr\u00e9 jbonofre@apache.org George Percivall percivall@apache.org Sunil Govindan sunilg@apache.org Become a committer \u00b6 To get started contributing to Sedona, learn how to contribute \u2013 anyone can submit patches, documentation and examples to the project. The PMC regularly adds new committers from the active contributors, based on their contributions to Sedona. The qualifications for new committers include: Sustained contributions to Spark: Committers should have a history of major contributions to Sedona. Quality of contributions: Committers more than any other community member should submit simple, well-tested, and well-designed patches. In addition, they should show sufficient expertise to be able to review patches. Community involvement: Committers should have a constructive and friendly attitude in all community interactions. They should also be active on the dev mailing list & Gitter, and help mentor newer contributors and users. The PMC also adds new PMC members. PMC members are expected to carry out PMC responsibilities as described in Apache Guidance, including helping vote on releases, enforce Apache project trademarks, take responsibility for legal and license issues, and ensure the project follows Apache project mechanics. The PMC periodically adds committers to the PMC who have shown they understand and can help with these activities. Currently, Sedona makes committers PMC members automatically. Nominate a committer or PMC member \u00b6 Steps are as follows: 1. Call a vote (templates/committerVote.txt) 2. Close the vote. If the result is positive, invite the new committer. Call for a vote \u00b6 We do the vote and discussion on the private@sedona.apache.org to enable a frank discussion. Please read ASF Incubator New committer Discussion for notable items. Let the Vote thread run for one week. A positive result is achieved by Consensus Approval: at least 3 +1 votes and no vetoes. PMC vote template This is the email to commence a vote for a new PMC candidate. New PMC members need to be voted for by the existing PMC members and subsequently approved by the Board (or Incubator PMC for incubating projects). To: private@sedona.apache.org Subject: [VOTE] New PMC candidate: [New PMC NAME] [ add the reasons behind your nomination here ] Voting ends one week from today, or until at least 3 +1 votes are cast. See voting guidelines at https://incubator.apache.org/guides/ppmc.html Close a vote \u00b6 This email ends the vote and reports the result to the project. To: private@sedona.apache.org Subject: [VOTE][RESULT] New PMC candidate: [New PMC NAME] The vote has now closed: [paste the vote thread on https://lists.apache.org/list.html?private@sedona.apache.org]. The results are: Binding Votes: +1 [TOTAL BINDING +1 VOTES] 0 [TOTAL BINDING +0/-0 VOTES] -1 [TOTAL BINDING -1 VOTES] The vote is ***successful/not successful*** Send a notice to IPMC \u00b6 The nominating PPMC member should send a message to the IPMC ( private@incubator.apache.org ) with a reference to the vote result in the following form: To: private at incubator.apache.org CC: private at sedona.apache.org Subject: [NOTICE] New PMC NAME for Apache Sedona PPMC Body: New PMC NAME has been voted as a new member of the Apache Sedona PPMC. the vote thread is at: *link to the vote result thread* Note that there is a grace period of 72 hours from when the PPMC sends the NOTICE to the IPMC to when the PPMC should formally invite the proposed member. This is an important part of the overall process. Failure to do this can result in an embarassing situation for people involved. Send the invitation \u00b6 To: New PMC Email address CC: private@sedona.apache.org Dear NEW PMC NAME, In recognition of your demonstrated commitment to, and alignment with, the goals of the Apache Sedona project, the Sedona PPMC has voted to offer you membership in the Sedona PPMC (\"Podling Project Management Committee\"). Please let us know if you accept by replying to this email (including private@sedona.apache.org). The PPMC is the Incubator podling version of a project PMC (\"Project Management Committee\") that for every top-level project is tasked by the Apache Board of Directors with official oversight and binding votes in that project. When Sedona graduates from the Incubator to a top-level project, the project PMC is usually formed from the membership of the PPMC. Note that while participation in the PMC after graduation is not guaranteed, simply continuing your constructive and active participation is usually sufficient. As a PPMC member, and later as a PMC member, you are responsible for continuing the general project, code, and community oversight that you have exhibited so far. The votes of the PPMC are not legally binding; votes of the Incubator PMC are. However, many of the PPMC members are also Incubator PMC members, so they implicitly cast binding votes when we vote on PPMC issues. While this is an important legal distinction, it shouldn't enter your thinking when working on the PPMC - members should treat every decision as if it were legally binding for the ASF. Also, in day-to-day activities, the Incubator PMC member vs PPMC member distinction should be invisible -- we are peers. Finally, the PPMC (and assuming graduation, the PMC) is not meant to create a hierarchy within the committership or the community. In fact, a goal is to add all committers over time to the PPMC/PMC, as our belief is that those who do the work should get a binding vote. Therefore, in our day-to-day interactions with the rest of the community, we continue to interact as peers, where every reasonable opinion is considered, and all community members are invited to participate in our public voting. If there ever is a situation where the PMC/PPMC's view differs significantly from that of the rest of the community, this is a symptom of a problem that needs to be addressed. With the expectation of your acceptance, welcome! The Apache Sedona PPMC PMC Accept and ICLA instruction \u00b6 To: New PMC Email address Cc: private@sedona.apache.org Subject: Re: invitation to become Apache Sedona PMC Welcome. Here are the next steps in becoming a project committer. After that we will make an announcement to the dev@sedona.apache.org 1. You need to send a Contributor License Agreement to the ASF. Normally you would send an Individual CLA. If you also make contributions done in work time or using work resources, see the Corporate CLA. Ask us if you have any issues. https://www.apache.org/licenses/#clas. You need to choose a preferred ASF user name and alternatives. In order to ensure it is available you can view a list of taken IDs at https://people.apache.org/committer-index.html Please notify us when you have submitted the CLA and by what means you did so. This will enable us to monitor its progress. We will arrange for your Apache user account when the CLA has been recorded. 2. After that is done, please use your ASF email to subscribe to the dev@sedona.apache.org and private@sedona.apache.org by sending an email to dev-subscribe@sedona.apache.org and private-subscribe@sedona.apache.org. We generally discuss everything on the dev list and keep the private@sedona.apache.org list for occasional matters which must be private. The developer section of the website describes roles within the ASF and provides other resources: https://www.apache.org/foundation/how-it-works.html https://www.apache.org/dev/ The incubator also has some useful information for new committers in incubating projects: https://incubator.apache.org/guides/committer.html https://incubator.apache.org/guides/ppmc.html Just as before you became a committer, participation in any ASF community requires adherence to the ASF Code of Conduct: https://www.apache.org/foundation/policies/conduct.html Yours, The Apache Sedona PMC Create ASF account \u00b6 Once the ICLA has been filed, use the ASF New Account Request form to generate the request. Sedona mentors will request the account. Once Sedona graduates, the PMC chair will make the request. Add to the system \u00b6 Once the new PPMC subscribes to the Sedona mailing lists using his/her ASF account, one of the PPMC needs to add the new PPMC to the Whimsy system ( https://whimsy.apache.org/roster/ppmc/sedona ). PMC annoucement \u00b6 This is the email to announce the new committer to sedona-dev once the account has been created. To: dev@sedona.apache.org Subject: new committer: ###New PMC NAME The Podling Project Management Committee (PPMC) for Apache Sedona has invited New PMC NAME to become a committer and we are pleased to announce that they have accepted. ### add specific details here ### Being a committer enables easier contribution to the project since there is no need to go via the patch submission process. This should enable better productivity. A PMC member helps manage and guide the direction of the project. Committer Done Template \u00b6 After the committer account is established. To: New PMC Email CC: private@sedona.apache.org Subject: account request: New PMC NAME New PMC NAME, as you know, the ASF Infrastructure has set up your committer account with the username '####'. You have commit access to specific sections of the ASF repository, as follows: https://github.com/apache/incubator-sedona You need to link your ASF Account with your GitHub account. Here are the steps 1. Verify you have a Github ID enabled with 2FA * https://help.github.com/articles/securing-your-account-with-two-factor-authentication-2fa/ 2. Enter your Github ID into your Apache ID profile https://id.apache.org/ 3. Merge your Apache and GitHub accounts using * GitBox (Apache Account Linking utility) https://gitbox.apache.org/setup/ * You should see 3 green checks in GitBox. * Wait at least 30 minutes for an email inviting you to Apache GitHub Organization and accept invitation 4. After accepting the Github Invitation verify that you are a member of the team https://github.com/orgs/apache/teams/sedona-committers Optionally, if you want, please follow the instructions to set up your GitHub, SSH, svn password, svn configuration, email forwarding, etc. https://www.apache.org/dev/#committers Additionally, if you have been elected to the Sedona Podling Project Mgmt. Committee (PPMC): Verify you are part of the LDAP sedona ppmc https://whimsy.apache.org/roster/ppmc/sedona","title":"Project Management Committee"},{"location":"community/contributor/#committers","text":"A contributor who contributes enough code to Sedona will be promoted to a committer. A committer has the write access to Sedona main repository","title":"Committers"},{"location":"community/contributor/#project-management-committee-pmc","text":"A committer will be promoted to a PMC member when the community thinks he/she is able to be in charge at least a major component of this project. Current Sedona PMC members are as follows: Name GitHub ID Apache ID Adam Binford Kimahriman kimahriman@apache.org Kanchan Chowdhury kanchanchy kanchanchy@apache.org Pawe\u0142 Koci\u0144ski Imbruced imbruced@apache.org Yitao Li yitao-li yitaoli@apache.org Netanel Malka netanel246 malka@apache.org Mohamed Sarwat Sarwat mosarwat@apache.org Kengo Seki sekikn sekikn@apache.org Sachio Wakai SW186000 swakai@apache.org Jinxuan Wu jinxuan jinxuanw@apache.org Jia Yu jiayuasu jiayu@apache.org Zongsi Zhang zongsizhang zongsizhang@apache.org","title":"Project Management Committee (PMC)"},{"location":"community/contributor/#mentors","text":"Mentors from Apache Incubator help the project to turn into a good shape following the \"Apache\" way. Thank you, mentors! Name Apache id Felix Cheung felixcheung@apache.org Von Gosling vongosling@apache.org Jean-Baptiste Onofr\u00e9 jbonofre@apache.org George Percivall percivall@apache.org Sunil Govindan sunilg@apache.org","title":"Mentors"},{"location":"community/contributor/#become-a-committer","text":"To get started contributing to Sedona, learn how to contribute \u2013 anyone can submit patches, documentation and examples to the project. The PMC regularly adds new committers from the active contributors, based on their contributions to Sedona. The qualifications for new committers include: Sustained contributions to Spark: Committers should have a history of major contributions to Sedona. Quality of contributions: Committers more than any other community member should submit simple, well-tested, and well-designed patches. In addition, they should show sufficient expertise to be able to review patches. Community involvement: Committers should have a constructive and friendly attitude in all community interactions. They should also be active on the dev mailing list & Gitter, and help mentor newer contributors and users. The PMC also adds new PMC members. PMC members are expected to carry out PMC responsibilities as described in Apache Guidance, including helping vote on releases, enforce Apache project trademarks, take responsibility for legal and license issues, and ensure the project follows Apache project mechanics. The PMC periodically adds committers to the PMC who have shown they understand and can help with these activities. Currently, Sedona makes committers PMC members automatically.","title":"Become a committer"},{"location":"community/contributor/#nominate-a-committer-or-pmc-member","text":"Steps are as follows: 1. Call a vote (templates/committerVote.txt) 2. Close the vote. If the result is positive, invite the new committer.","title":"Nominate a committer or PMC member"},{"location":"community/contributor/#call-for-a-vote","text":"We do the vote and discussion on the private@sedona.apache.org to enable a frank discussion. Please read ASF Incubator New committer Discussion for notable items. Let the Vote thread run for one week. A positive result is achieved by Consensus Approval: at least 3 +1 votes and no vetoes.","title":"Call for a vote"},{"location":"community/contributor/#close-a-vote","text":"This email ends the vote and reports the result to the project. To: private@sedona.apache.org Subject: [VOTE][RESULT] New PMC candidate: [New PMC NAME] The vote has now closed: [paste the vote thread on https://lists.apache.org/list.html?private@sedona.apache.org]. The results are: Binding Votes: +1 [TOTAL BINDING +1 VOTES] 0 [TOTAL BINDING +0/-0 VOTES] -1 [TOTAL BINDING -1 VOTES] The vote is ***successful/not successful***","title":"Close a vote"},{"location":"community/contributor/#send-a-notice-to-ipmc","text":"The nominating PPMC member should send a message to the IPMC ( private@incubator.apache.org ) with a reference to the vote result in the following form: To: private at incubator.apache.org CC: private at sedona.apache.org Subject: [NOTICE] New PMC NAME for Apache Sedona PPMC Body: New PMC NAME has been voted as a new member of the Apache Sedona PPMC. the vote thread is at: *link to the vote result thread* Note that there is a grace period of 72 hours from when the PPMC sends the NOTICE to the IPMC to when the PPMC should formally invite the proposed member. This is an important part of the overall process. Failure to do this can result in an embarassing situation for people involved.","title":"Send a notice to IPMC"},{"location":"community/contributor/#send-the-invitation","text":"To: New PMC Email address CC: private@sedona.apache.org Dear NEW PMC NAME, In recognition of your demonstrated commitment to, and alignment with, the goals of the Apache Sedona project, the Sedona PPMC has voted to offer you membership in the Sedona PPMC (\"Podling Project Management Committee\"). Please let us know if you accept by replying to this email (including private@sedona.apache.org). The PPMC is the Incubator podling version of a project PMC (\"Project Management Committee\") that for every top-level project is tasked by the Apache Board of Directors with official oversight and binding votes in that project. When Sedona graduates from the Incubator to a top-level project, the project PMC is usually formed from the membership of the PPMC. Note that while participation in the PMC after graduation is not guaranteed, simply continuing your constructive and active participation is usually sufficient. As a PPMC member, and later as a PMC member, you are responsible for continuing the general project, code, and community oversight that you have exhibited so far. The votes of the PPMC are not legally binding; votes of the Incubator PMC are. However, many of the PPMC members are also Incubator PMC members, so they implicitly cast binding votes when we vote on PPMC issues. While this is an important legal distinction, it shouldn't enter your thinking when working on the PPMC - members should treat every decision as if it were legally binding for the ASF. Also, in day-to-day activities, the Incubator PMC member vs PPMC member distinction should be invisible -- we are peers. Finally, the PPMC (and assuming graduation, the PMC) is not meant to create a hierarchy within the committership or the community. In fact, a goal is to add all committers over time to the PPMC/PMC, as our belief is that those who do the work should get a binding vote. Therefore, in our day-to-day interactions with the rest of the community, we continue to interact as peers, where every reasonable opinion is considered, and all community members are invited to participate in our public voting. If there ever is a situation where the PMC/PPMC's view differs significantly from that of the rest of the community, this is a symptom of a problem that needs to be addressed. With the expectation of your acceptance, welcome! The Apache Sedona PPMC","title":"Send the invitation"},{"location":"community/contributor/#pmc-accept-and-icla-instruction","text":"To: New PMC Email address Cc: private@sedona.apache.org Subject: Re: invitation to become Apache Sedona PMC Welcome. Here are the next steps in becoming a project committer. After that we will make an announcement to the dev@sedona.apache.org 1. You need to send a Contributor License Agreement to the ASF. Normally you would send an Individual CLA. If you also make contributions done in work time or using work resources, see the Corporate CLA. Ask us if you have any issues. https://www.apache.org/licenses/#clas. You need to choose a preferred ASF user name and alternatives. In order to ensure it is available you can view a list of taken IDs at https://people.apache.org/committer-index.html Please notify us when you have submitted the CLA and by what means you did so. This will enable us to monitor its progress. We will arrange for your Apache user account when the CLA has been recorded. 2. After that is done, please use your ASF email to subscribe to the dev@sedona.apache.org and private@sedona.apache.org by sending an email to dev-subscribe@sedona.apache.org and private-subscribe@sedona.apache.org. We generally discuss everything on the dev list and keep the private@sedona.apache.org list for occasional matters which must be private. The developer section of the website describes roles within the ASF and provides other resources: https://www.apache.org/foundation/how-it-works.html https://www.apache.org/dev/ The incubator also has some useful information for new committers in incubating projects: https://incubator.apache.org/guides/committer.html https://incubator.apache.org/guides/ppmc.html Just as before you became a committer, participation in any ASF community requires adherence to the ASF Code of Conduct: https://www.apache.org/foundation/policies/conduct.html Yours, The Apache Sedona PMC","title":"PMC Accept and ICLA instruction"},{"location":"community/contributor/#create-asf-account","text":"Once the ICLA has been filed, use the ASF New Account Request form to generate the request. Sedona mentors will request the account. Once Sedona graduates, the PMC chair will make the request.","title":"Create ASF account"},{"location":"community/contributor/#add-to-the-system","text":"Once the new PPMC subscribes to the Sedona mailing lists using his/her ASF account, one of the PPMC needs to add the new PPMC to the Whimsy system ( https://whimsy.apache.org/roster/ppmc/sedona ).","title":"Add to the system"},{"location":"community/contributor/#pmc-annoucement","text":"This is the email to announce the new committer to sedona-dev once the account has been created. To: dev@sedona.apache.org Subject: new committer: ###New PMC NAME The Podling Project Management Committee (PPMC) for Apache Sedona has invited New PMC NAME to become a committer and we are pleased to announce that they have accepted. ### add specific details here ### Being a committer enables easier contribution to the project since there is no need to go via the patch submission process. This should enable better productivity. A PMC member helps manage and guide the direction of the project.","title":"PMC annoucement"},{"location":"community/contributor/#committer-done-template","text":"After the committer account is established. To: New PMC Email CC: private@sedona.apache.org Subject: account request: New PMC NAME New PMC NAME, as you know, the ASF Infrastructure has set up your committer account with the username '####'. You have commit access to specific sections of the ASF repository, as follows: https://github.com/apache/incubator-sedona You need to link your ASF Account with your GitHub account. Here are the steps 1. Verify you have a Github ID enabled with 2FA * https://help.github.com/articles/securing-your-account-with-two-factor-authentication-2fa/ 2. Enter your Github ID into your Apache ID profile https://id.apache.org/ 3. Merge your Apache and GitHub accounts using * GitBox (Apache Account Linking utility) https://gitbox.apache.org/setup/ * You should see 3 green checks in GitBox. * Wait at least 30 minutes for an email inviting you to Apache GitHub Organization and accept invitation 4. After accepting the Github Invitation verify that you are a member of the team https://github.com/orgs/apache/teams/sedona-committers Optionally, if you want, please follow the instructions to set up your GitHub, SSH, svn password, svn configuration, email forwarding, etc. https://www.apache.org/dev/#committers Additionally, if you have been elected to the Sedona Podling Project Mgmt. Committee (PPMC): Verify you are part of the LDAP sedona ppmc https://whimsy.apache.org/roster/ppmc/sedona","title":"Committer Done Template"},{"location":"community/develop/","text":"Develop Sedona \u00b6 Scala/Java developers \u00b6 IDE \u00b6 We recommend Intellij IDEA with Scala plugin installed. Import the project \u00b6 Choose Open Go to the Sedona root folder (not a submodule folder) and choose open The IDE might show errors The IDE usually has trouble understanding the complex project structure in Sedona. Fix errors by changing POM.xml You need to comment out the following lines in pom.xml at the root folder, as follows. Remember that you should NOT submit this change to Sedona. <!-- <parent>--> <!-- <groupId>org.apache</groupId>--> <!-- <artifactId>apache</artifactId>--> <!-- <version>23</version>--> <!-- <relativePath />--> <!-- </parent>--> Reload POM.xml Make sure you reload the POM.xml or reload the maven project. The IDE will ask you to remove some modules. Please select yes . The final project structure should be like this: Run unit tests \u00b6 Run all unit tests In a terminal, go to the Sedona root folder. Run mvn clean install . All tests will take more than 15 minutes. To only build the project jars, run mvn clean install -DskipTests . More details can be found on Compile Sedona Run a single unit test In the IDE, right-click a test case and run this test case. The IDE might tell you that the PATH does not exist as follows: Go to Edit Configuration Append the submodule folder to Working Directory . For example, incubator-sedona/sql . Re-run the test case. Do NOT right click the test case to re-run. Instead, click the button as shown in the figure below. Python developers \u00b6 More details to come. IDE \u00b6 We recommend PyCharm Import the project \u00b6 R developers \u00b6 More details to come. IDE \u00b6 We recommend RStudio Import the project \u00b6","title":"Develop"},{"location":"community/develop/#develop-sedona","text":"","title":"Develop Sedona"},{"location":"community/develop/#scalajava-developers","text":"","title":"Scala/Java developers"},{"location":"community/develop/#ide","text":"We recommend Intellij IDEA with Scala plugin installed.","title":"IDE"},{"location":"community/develop/#import-the-project","text":"","title":"Import the project"},{"location":"community/develop/#run-unit-tests","text":"","title":"Run unit tests"},{"location":"community/develop/#python-developers","text":"More details to come.","title":"Python developers"},{"location":"community/develop/#ide_1","text":"We recommend PyCharm","title":"IDE"},{"location":"community/develop/#import-the-project_1","text":"","title":"Import the project"},{"location":"community/develop/#r-developers","text":"More details to come.","title":"R developers"},{"location":"community/develop/#ide_2","text":"We recommend RStudio","title":"IDE"},{"location":"community/develop/#import-the-project_2","text":"","title":"Import the project"},{"location":"community/publication/","text":"Publication \u00b6 Apache Sedona was formerly called GeoSpark, initiated by Arizona State University Data Systems Lab . Key publications \u00b6 \"Spatial Data Management in Apache Spark: The GeoSpark Perspective and Beyond\" is the full research paper that talks about the entire GeoSpark ecosystem. Please cite this paper if your work mentions GeoSpark core system. \"GeoSparkViz: A Scalable Geospatial Data Visualization Framework in the Apache Spark Ecosystem\" is the full research paper that talks about map visualization system in GeoSpark. Please cite this paper if your work mentions GeoSpark visualization system. \"Building A Microscopic Road Network Traffic Simulator in Apache Spark\" is the full research paper that talks about the traffic simulator in GeoSpark. Please cite this paper if your work mentions GeoSparkSim traffic simulator. Third-party evaluation \u00b6 GeoSpark were evaluated by papers published on database top venues. It is worth noting that we do not have any collaboration with the authors. SIGMOD 2020 paper \"Architecting a Query Compiler for Spatial Workloads\" Ruby Y. Tahboub, Tiark Rompf (Purdue University). In Figure 16a, GeoSpark distance join query runs around 7x - 9x faster than Simba, a spatial extension on Spark, on 1 - 24 core machines. PVLDB 2018 paper \"How Good Are Modern Spatial Analytics Systems?\" Varun Pandey, Andreas Kipf, Thomas Neumann, Alfons Kemper (Technical University of Munich), quoted as follows: GeoSpark comes close to a complete spatial analytics system. It also exhibits the best performance in most cases. Full publications \u00b6 GeoSpark Ecosystem \u00b6 \"Spatial Data Management in Apache Spark: The GeoSpark Perspective and Beyond\" (research paper). Jia Yu, Zongsi Zhang, Mohamed Sarwat. Geoinformatica Journal 2019. \"A Demonstration of GeoSpark: A Cluster Computing Framework for Processing Big Spatial Data\" (demo paper). Jia Yu, Jinxuan Wu, Mohamed Sarwat. In Proceeding of IEEE International Conference on Data Engineering ICDE 2016, Helsinki, FI, May 2016 \"GeoSpark: A Cluster Computing Framework for Processing Large-Scale Spatial Data\" (short paper). Jia Yu, Jinxuan Wu, Mohamed Sarwat. In Proceeding of the ACM International Conference on Advances in Geographic Information Systems ACM SIGSPATIAL GIS 2015, Seattle, WA, USA November 2015 GeoSparkViz Visualization System \u00b6 \"GeoSparkViz in Action: A Data System with built-in support for Geospatial Visualization\" (demo paper) Jia Yu, Anique Tahir, and Mohamed Sarwat. In Proceedings of the International Conference on Data Engineering, ICDE, 2019 \"GeoSparkViz: A Scalable Geospatial Data Visualization Framework in the Apache Spark Ecosystem\" (research paper). Jia Yu, Zongsi Zhang, Mohamed Sarwat. In Proceedings of the International Conference on Scientific and Statistical Database Management, SSDBM 2018, Bolzano-Bozen, Italy July 2018 GeoSparkSim Traffic Simulator \u00b6 \"Dissecting GeoSparkSim: a scalable microscopic road network traffic simulator in Apache Spark\" (journal paper) Jia Yu, Zishan Fu, Mohamed Sarwat. Distributed Parallel Databases 38(4): 963-994 (2020) \"Demonstrating GeoSparkSim: A Scalable Microscopic Road Network Traffic Simulator Based on Apache Spark\" . Zishan Fu, Jia Yu, Mohamed Sarwat. International Symposium on Spatial and Temporal Databases, SSTD, 2019 \"Building A Microscopic Road Network Traffic Simulator in Apache Spark\" (research paper) Zishan Fu, Jia Yu, and Mohamed Sarwat. In Proceedings of the International Conference on Mobile Data Management, MDM, 2019 A Tutorial about Geospatial Data Management in Spark \u00b6 \"Geospatial Data Management in Apache Spark: A Tutorial\" (Tutorial) Jia Yu and Mohamed Sarwat. In Proceedings of the International Conference on Data Engineering, ICDE, 2019","title":"Publications"},{"location":"community/publication/#publication","text":"Apache Sedona was formerly called GeoSpark, initiated by Arizona State University Data Systems Lab .","title":"Publication"},{"location":"community/publication/#key-publications","text":"\"Spatial Data Management in Apache Spark: The GeoSpark Perspective and Beyond\" is the full research paper that talks about the entire GeoSpark ecosystem. Please cite this paper if your work mentions GeoSpark core system. \"GeoSparkViz: A Scalable Geospatial Data Visualization Framework in the Apache Spark Ecosystem\" is the full research paper that talks about map visualization system in GeoSpark. Please cite this paper if your work mentions GeoSpark visualization system. \"Building A Microscopic Road Network Traffic Simulator in Apache Spark\" is the full research paper that talks about the traffic simulator in GeoSpark. Please cite this paper if your work mentions GeoSparkSim traffic simulator.","title":"Key publications"},{"location":"community/publication/#third-party-evaluation","text":"GeoSpark were evaluated by papers published on database top venues. It is worth noting that we do not have any collaboration with the authors. SIGMOD 2020 paper \"Architecting a Query Compiler for Spatial Workloads\" Ruby Y. Tahboub, Tiark Rompf (Purdue University). In Figure 16a, GeoSpark distance join query runs around 7x - 9x faster than Simba, a spatial extension on Spark, on 1 - 24 core machines. PVLDB 2018 paper \"How Good Are Modern Spatial Analytics Systems?\" Varun Pandey, Andreas Kipf, Thomas Neumann, Alfons Kemper (Technical University of Munich), quoted as follows: GeoSpark comes close to a complete spatial analytics system. It also exhibits the best performance in most cases.","title":"Third-party evaluation"},{"location":"community/publication/#full-publications","text":"","title":"Full publications"},{"location":"community/publication/#geospark-ecosystem","text":"\"Spatial Data Management in Apache Spark: The GeoSpark Perspective and Beyond\" (research paper). Jia Yu, Zongsi Zhang, Mohamed Sarwat. Geoinformatica Journal 2019. \"A Demonstration of GeoSpark: A Cluster Computing Framework for Processing Big Spatial Data\" (demo paper). Jia Yu, Jinxuan Wu, Mohamed Sarwat. In Proceeding of IEEE International Conference on Data Engineering ICDE 2016, Helsinki, FI, May 2016 \"GeoSpark: A Cluster Computing Framework for Processing Large-Scale Spatial Data\" (short paper). Jia Yu, Jinxuan Wu, Mohamed Sarwat. In Proceeding of the ACM International Conference on Advances in Geographic Information Systems ACM SIGSPATIAL GIS 2015, Seattle, WA, USA November 2015","title":"GeoSpark Ecosystem"},{"location":"community/publication/#geosparkviz-visualization-system","text":"\"GeoSparkViz in Action: A Data System with built-in support for Geospatial Visualization\" (demo paper) Jia Yu, Anique Tahir, and Mohamed Sarwat. In Proceedings of the International Conference on Data Engineering, ICDE, 2019 \"GeoSparkViz: A Scalable Geospatial Data Visualization Framework in the Apache Spark Ecosystem\" (research paper). Jia Yu, Zongsi Zhang, Mohamed Sarwat. In Proceedings of the International Conference on Scientific and Statistical Database Management, SSDBM 2018, Bolzano-Bozen, Italy July 2018","title":"GeoSparkViz Visualization System"},{"location":"community/publication/#geosparksim-traffic-simulator","text":"\"Dissecting GeoSparkSim: a scalable microscopic road network traffic simulator in Apache Spark\" (journal paper) Jia Yu, Zishan Fu, Mohamed Sarwat. Distributed Parallel Databases 38(4): 963-994 (2020) \"Demonstrating GeoSparkSim: A Scalable Microscopic Road Network Traffic Simulator Based on Apache Spark\" . Zishan Fu, Jia Yu, Mohamed Sarwat. International Symposium on Spatial and Temporal Databases, SSTD, 2019 \"Building A Microscopic Road Network Traffic Simulator in Apache Spark\" (research paper) Zishan Fu, Jia Yu, and Mohamed Sarwat. In Proceedings of the International Conference on Mobile Data Management, MDM, 2019","title":"GeoSparkSim Traffic Simulator"},{"location":"community/publication/#a-tutorial-about-geospatial-data-management-in-spark","text":"\"Geospatial Data Management in Apache Spark: A Tutorial\" (Tutorial) Jia Yu and Mohamed Sarwat. In Proceedings of the International Conference on Data Engineering, ICDE, 2019","title":"A Tutorial about Geospatial Data Management in Spark"},{"location":"community/publish/","text":"Make a Sedona release \u00b6 This page is for Sedona PPMC to publish Sedona releases. You can read ASF guidelines: 1. ASF Incubator Distribution Guidelines: https://incubator.apache.org/guides/distribution.html 2. ASF Release Guidelines: https://infra.apache.org/release-publishing.html 3. ASF Incubator Release Votes Guidelines: https://issues.apache.org/jira/browse/LEGAL-469 Warning All scripts on this page should be run in your local Sedona Git repo under master branch via a single script file. 0. Prepare an empty script file \u00b6 In your local Sedona Git repo under master branch, run echo \"#!/bin/bash\" > create-release.sh chmod 777 create-release.sh Use your favourite GUI text editor to open create-release.sh . Then keep copying the scripts on this web page to replace all content in this script file. Do NOT directly copy/paste the scripts to your terminal because a bug in clipboard.js will create link breaks in such case. Each time when you copy content to this script file, run ./create-release.sh to execute it. 1. Check ASF copyright in all file headers \u00b6 Run the following script: #!/bin/bash wget -q https://dlcdn.apache.org//creadur/apache-rat- $RAT_VERSION /apache-rat-0.15-bin.tar.gz tar -xvf apache-rat-0.15-bin.tar.gz git clone --shared --branch master https://github.com/apache/incubator-sedona.git sedona-src java -jar apache-rat-0.15.jar -d sedona-src > report.txt Read the generated report.txt file and make sure all source code files have ASF header. Delete the generated report and cloned files #!/bin/bash rm -rf sedona-src rm report.txt 2. Update Sedona Python, R and Zeppelin versions \u00b6 Make sure the Sedona version in the following files are 1.3.1-incubating. Note that: Python and R versions cannot have \"incubating\" postfix. https://github.com/apache/incubator-sedona/blob/master/python/sedona/version.py https://github.com/apache/incubator-sedona/blob/master/R/DESCRIPTION https://github.com/apache/incubator-sedona/blob/master/zeppelin/package.json 3. Update mkdocs.yml \u00b6 Please change the following variables in mkdocs.yml to the version you want to publish. sedona_create_release.current_version sedona_create_release.current_rc sedona_create_release.current_git_tag sedona_create_release.current_snapshot Then compile the website by mkdocs serve . This will generate the scripts listed on this page in your local browser. You can also publish this website if needed. See the instruction at bottom. 4. Stage and upload release candidates \u00b6 #!/bin/bash source ~/.bashrc git checkout master git pull rm -f release.* rm -f pom.xml.* echo \"*****Step 1. Stage the Release Candidate to GitHub.\" mvn -q -B clean release:prepare -Dtag = sedona-1.3.1-incubating-rc1 -DreleaseVersion = 1 .3.1-incubating -DdevelopmentVersion = 1 .3.1-incubating-SNAPSHOT -DautoVersionSubmodules = true -Dresume = false -Darguments = \"-DskipTests\" rm -f release.* rm -f pom.xml.* echo \"Now the releases are staged. A tag and two commits have been created on Sedona GitHub repo\" echo \"*****Step 2: Upload the Release Candidate to https://repository.apache.org.\" # For Spark 3.0 and Scala 2.12 mvn -q org.apache.maven.plugins:maven-release-plugin:2.3.2:perform -DconnectionUrl = scm:git:https://github.com/apache/incubator-sedona.git -Dtag = sedona-1.3.1-incubating-rc1 -DautoVersionSubmodules = true -Dresume = false -Darguments = \"-DskipTests -Dscala=2.12\" # For Spark 3.0 and Scala 2.13 mvn -q org.apache.maven.plugins:maven-release-plugin:2.3.2:perform -DconnectionUrl = scm:git:https://github.com/apache/incubator-sedona.git -Dtag = sedona-1.3.1-incubating-rc1 -DautoVersionSubmodules = true -Dresume = false -Darguments = \"-DskipTests -Dscala=2.13\" echo \"*****Step 3: Upload Release Candidate on ASF SVN: https://dist.apache.org/repos/dist/dev/incubator/sedona\" echo \"Creating 1.3.1-incubating-rc1 folder on SVN...\" svn mkdir -m \"Adding folder\" https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1 echo \"Creating release files locally...\" echo \"Downloading source code...\" wget https://github.com/apache/incubator-sedona/archive/refs/tags/sedona-1.3.1-incubating-rc1.tar.gz tar -xvf sedona-1.3.1-incubating-rc1.tar.gz mkdir apache-sedona-1.3.1-incubating-src cp -r incubator-sedona-sedona-1.3.1-incubating-rc1/* apache-sedona-1.3.1-incubating-src/ tar czf apache-sedona-1.3.1-incubating-src.tar.gz apache-sedona-1.3.1-incubating-src rm sedona-1.3.1-incubating-rc1.tar.gz rm -rf incubator-sedona-sedona-1.3.1-incubating-rc1 echo \"Compiling the source code...\" mkdir apache-sedona-1.3.1-incubating-bin cd apache-sedona-1.3.1-incubating-src && mvn -q clean install -DskipTests -Dscala = 2 .12 && cd .. cp apache-sedona-1.3.1-incubating-src/core/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/sql/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/viz/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/python-adapter/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/flink/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cd apache-sedona-1.3.1-incubating-src && mvn -q clean install -DskipTests -Dscala = 2 .13 && cd .. cp apache-sedona-1.3.1-incubating-src/core/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/sql/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/viz/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/python-adapter/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/flink/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ tar czf apache-sedona-1.3.1-incubating-bin.tar.gz apache-sedona-1.3.1-incubating-bin shasum -a 512 apache-sedona-1.3.1-incubating-src.tar.gz > apache-sedona-1.3.1-incubating-src.tar.gz.sha512 shasum -a 512 apache-sedona-1.3.1-incubating-bin.tar.gz > apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 gpg -ab apache-sedona-1.3.1-incubating-src.tar.gz gpg -ab apache-sedona-1.3.1-incubating-bin.tar.gz echo \"Uploading local release files...\" svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-src.tar.gz https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-src.tar.gz svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-src.tar.gz.asc https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-src.tar.gz.asc svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-src.tar.gz.sha512 https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-src.tar.gz.sha512 svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-bin.tar.gz https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-bin.tar.gz svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-bin.tar.gz.asc https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-bin.tar.gz.asc svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 echo \"Removing local release files...\" rm apache-sedona-1.3.1-incubating-src.tar.gz rm apache-sedona-1.3.1-incubating-src.tar.gz.asc rm apache-sedona-1.3.1-incubating-src.tar.gz.sha512 rm apache-sedona-1.3.1-incubating-bin.tar.gz rm apache-sedona-1.3.1-incubating-bin.tar.gz.asc rm apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 rm -rf apache-sedona-1.3.1-incubating-src rm -rf apache-sedona-1.3.1-incubating-bin 5. Vote in dev sedona.apache.org \u00b6 Vote email \u00b6 Please add changes at the end if needed: Subject: [VOTE] Release Apache Sedona 1.3.1-incubating-rc1 Hi all, This is a call for vote on Apache Sedona 1.3.1-incubating-rc1. Please refer to the changes listed at the bottom of this email. Release notes: https://github.com/apache/incubator-sedona/blob/sedona-1.3.1-incubating-rc1/docs/setup/release-notes.md Build instructions: https://github.com/apache/incubator-sedona/blob/sedona-1.3.1-incubating-rc1/docs/setup/compile.md GitHub tag: https://github.com/apache/incubator-sedona/releases/tag/sedona-1.3.1-incubating-rc1 GPG public key to verify the Release: https://downloads.apache.org/incubator/sedona/KEYS Source code and binaries: https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/ The vote will be open for at least 72 hours or until at least 3 \"+1\" PMC votes are cast Instruction for checking items on the checklist: https://sedona.apache.org/community/vote/ We recommend you use this Jupyter notebook on MyBinder to perform this task: https://mybinder.org/v2/gh/jiayuasu/sedona-tools/HEAD?labpath=binder%2Fverify-release.ipynb **Please vote accordingly and you must provide your checklist for your vote**. [ ] +1 approve [ ] +0 no opinion [ ] -1 disapprove with the reason Checklist: [ ] Download links are valid. [ ] Checksums and PGP signatures are valid. [ ] DISCLAIMER is included. [ ] Source code artifacts have correct names matching the current release. For a detailed checklist please refer to: https://cwiki.apache.org/confluence/display/INCUBATOR/Incubator+Release+Checklist ------------ Changes according to the comments on the previous release Original comment (Permalink from https://lists.apache.org/list.html): Pass email \u00b6 Please count the votes and add the Permalink of the vote thread at the end. Subject: [RESULT][VOTE] Release Apache Sedona 1.3.1-incubating-rc1 Dear all, The vote closes now as 72hr have passed. The vote PASSES with +? (binding): NAME1, NAME2, NAME3 +? (non-binding): NAME4 No -1 votes The vote thread (Permalink from https://lists.apache.org/list.html): I will now bring the vote to general@incubator.apache.org to get approval by the IPMC. If this vote passes too, the release is accepted and will be published. 6. Vote in general incubator.apache.org \u00b6 Vote email \u00b6 Please add the permalink of Sedona Community vote thread Please add the permalink of Sedona Community vote result thread Please add changes at the end if needed. Subject: [VOTE] Release Apache Sedona 1.3.1-incubating-rc1 Hi all, This is a call for vote on Apache Sedona 1.3.1-incubating-rc1. Please refer to the changes listed at the bottom of this email. Sedona Community vote thread (Permalink from https://lists.apache.org/list.html): Sedona community vote result thread (Permalink from https://lists.apache.org/list.html): Release notes: https://github.com/apache/incubator-sedona/blob/sedona-1.3.1-incubating-rc1/docs/setup/release-notes.md Build instructions: https://github.com/apache/incubator-sedona/blob/sedona-1.3.1-incubating-rc1/docs/setup/compile.md GitHub tag: https://github.com/apache/incubator-sedona/releases/tag/sedona-1.3.1-incubating-rc1 GPG public key to verify the Release: https://downloads.apache.org/incubator/sedona/KEYS Source code and binaries: https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/ The vote will be open for at least 72 hours or until at least 3 \"+1\" PMC votes are cast Please vote accordingly: [ ] +1 approve [ ] +0 no opinion [ ] -1 disapprove with the reason Checklist for reference (because of DISCLAIMER-WIP, other checklist items are not blockers): [ ] Download links are valid. [ ] Checksums and PGP signatures are valid. [ ] DISCLAIMER is included. [ ] Source code artifacts have correct names matching the current release. For a detailed checklist please refer to: https://cwiki.apache.org/confluence/display/INCUBATOR/Incubator+Release+Checklist ------------ Changes according to the comments on the previous release Original comment (Permalink from https://lists.apache.org/list.html): Pass email \u00b6 Please count the votes and add the permalink of the vote thread. Subject: [RESULT][VOTE] Release Apache Sedona 1.3.1-incubating-rc1 Dear all, The vote closes now as 72hr have passed. The vote PASSES with +? (binding): NAME1, NAME2, NAME3 +? (non-binding): NAME4 No -1 votes The vote thread (Permalink from https://lists.apache.org/list.html): I will publish the release and make an annoucement once it is done. Announce email \u00b6 This email should be CCed to dev@sedona.apache.org Please add the permalink of the incubator vote thread Please add the permalink of the incubator vote result thread Subject: [ANNOUNCE] Apache Sedona 1.3.1-incubating released Dear all, We are happy to report that we have released Apache Sedona (incubating) 1.3.1-incubating. Thank you again for your help. Apache Sedona (incubating) is a cluster computing system for processing large-scale spatial data. Vote thread (Permalink from https://lists.apache.org/list.html): Vote result thread (Permalink from https://lists.apache.org/list.html): Website: http://sedona.apache.org/ Release notes: https://github.com/apache/incubator-sedona/blob/sedona-1.3.1-incubating/docs/setup/release-notes.md Download links: https://github.com/apache/incubator-sedona/releases/tag/sedona-1.3.1-incubating Additional resources: Get started: http://sedona.apache.org/setup/overview/ Tutorials: http://sedona.apache.org/tutorial/rdd/ Mailing list: dev@sedona.apache.org Twitter: https://twitter.com/ApacheSedona Gitter: https://gitter.im/apache/sedona Regards, Apache Sedona (incubating) Team 7. Failed vote \u00b6 If a vote failed, do the following: In the vote email, say that we will create another release candidate. Restart from Step 3 Update mkdocs.yml . Please increment the release candidate ID (e.g., 1.3.1-incubating-rc2 ) and update sedona_create_release.current_rc and sedona_create_release.current_git_tag in mkdocs.yml to generate the script listed on this webpage. 8. Release source code and Maven package \u00b6 Upload releases \u00b6 #!/bin/bash echo \"Move all files in https://dist.apache.org/repos/dist/dev/incubator/sedona to https://dist.apache.org/repos/dist/release/incubator/sedona, using svn\" svn mkdir -m \"Adding folder\" https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating wget https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-src.tar.gz wget https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-src.tar.gz.asc wget https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-src.tar.gz.sha512 wget https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-bin.tar.gz wget https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-bin.tar.gz.asc wget https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-src.tar.gz https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating/apache-sedona-1.3.1-incubating-src.tar.gz svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-src.tar.gz.asc https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating/apache-sedona-1.3.1-incubating-src.tar.gz.asc svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-src.tar.gz.sha512 https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating/apache-sedona-1.3.1-incubating-src.tar.gz.sha512 svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-bin.tar.gz https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating/apache-sedona-1.3.1-incubating-bin.tar.gz svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-bin.tar.gz.asc https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating/apache-sedona-1.3.1-incubating-bin.tar.gz.asc svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating/apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 rm apache-sedona-1.3.1-incubating-src.tar.gz rm apache-sedona-1.3.1-incubating-src.tar.gz.asc rm apache-sedona-1.3.1-incubating-src.tar.gz.sha512 rm apache-sedona-1.3.1-incubating-bin.tar.gz rm apache-sedona-1.3.1-incubating-bin.tar.gz.asc rm apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 echo \"Re-staging releases to https://repository.apache.org\" # For Spark 3.0 and Scala 2.12 mvn -q org.apache.maven.plugins:maven-release-plugin:2.3.2:perform -DconnectionUrl = scm:git:https://github.com/apache/incubator-sedona.git -Dtag = sedona-1.3.1-incubating-rc1 -DautoVersionSubmodules = true -Dresume = false -Darguments = \"-DskipTests\" # For Spark 3.0 and Scala 2.13 mvn -q org.apache.maven.plugins:maven-release-plugin:2.3.2:perform -DconnectionUrl = scm:git:https://github.com/apache/incubator-sedona.git -Dtag = sedona-1.3.1-incubating-rc1 -DautoVersionSubmodules = true -Dresume = false -Darguments = \"-DskipTests -Dscala=2.13\" Fix signature issues \u00b6 Please find the Sedona staging id on https://repository.apache.org under staging repository . Then run the following script. Replace admin , admind123 with your Apache ID username and Apache ID password. Replace stagingid with the correct id. #!/bin/bash username = admin password = admin123 stagingid = 1027 artifacts =( parent core-3.0_2.12 core-3.0_2.13 sql-3.0_2.12 sql-3.0_2.13 viz-3.0_2.12 viz-3.0_2.13 python-adapter-3.0_2.12 python-adapter-3.0_2.13 common flink_2.12 ) filenames =( .pom .jar -javadoc.jar ) echo \"Re-uploading signatures to fix *failureMessage Invalid Signature*\" for artifact in \" ${ artifacts [@] } \" ; do for filename in \" ${ filenames [@] } \" ; do if [ $artifact -eq 'parent' && $filename -ne '.pom' ] then continue fi wget https://repository.apache.org/service/local/repositories/orgapachesedona- $stagingid /content/org/apache/sedona/sedona- $artifact /1.3.1-incubating/sedona- ${ artifact } -1.3.1-incubating ${ filename } gpg -ab sedona- ${ artifact } -1.3.1-incubating ${ filename } curl -v -u $username : $password --upload-file sedona- ${ artifact } -1.3.1-incubating ${ filename } .asc https://repository.apache.org/service/local/repositories/orgapachesedona- $stagingid /content/org/apache/sedona/sedona- ${ artifact } /1.3.1-incubating/sedona- ${ artifact } -1.3.1-incubating ${ filename } .asc done done rm *.pom rm *.jar rm *.asc Manually close and release the package \u00b6 Click Close on the Sedona staging repo on https://repository.apache.org under staging repository Once the staging repo is closed, click Release on this repo. 9. Release Sedona Python and Zeppelin \u00b6 You must have the maintainer priviledge of https://pypi.org/project/apache-sedona/ and https://www.npmjs.com/package/apache-sedona #!/bin/bash git clone --shared --branch sedona-1.3.1-incubating-rc1 https://github.com/apache/incubator-sedona.git apache-sedona-1.3.1-incubating-src cd apache-sedona-1.3.1-incubating-src/python && python3 setup.py sdist bdist_wheel && twine upload dist/* && cd .. cd zeppelin && npm publish && cd .. rm -rf apache-sedona-1.3.1-incubating-src 10. Release Sedona R to CRAN. \u00b6 #!/bin/bash R CMD build . R CMD check --as-cran apache.sedona_*.tar.gz Then submit to CRAN using this web form . 11. Publish the doc website \u00b6 Add the download link to Download page and create a GitHub release. Run mkdocs build in Sedona root directory. Copy all content in the site folder. Check out GitHub incubator-sedona-website asf-site branch Use the copied content to replace all content in asf-site branch and upload to GitHub. Then sedona.apache.org will be automatically updated. You can also push the content to asf-staging branch. The staging website will be then updated: sedona.staged.apache.org Javadoc and Scaladoc \u00b6 Compile You should first compile the entire docs using mkdocs build to get the site folder. Javadoc: Use Intelij IDEA to generate Javadoc for core and viz module Scaladoc: Run scaladoc -d site/api/javadoc/sql/ sql/src/main/scala/org/apache/sedona/sql/utils/*.scala Copy Copy the generated Javadoc (Scaladoc should already be there) to the corresponding folders in site/api/javadoc Deploy Javadoc and Scaladoc with the project website Compile R html docs \u00b6 Make sure you install R, tree and curl on your Ubuntu machine. On Mac, just do brew install tree sudo apt install littler tree libcurl4-openssl-dev In the Sedona root directory, run the script below. This will create rdocs folder in Sedona /docs/api/rdocs #!/bin/bash Rscript generate-docs.R cd ./docs/api/rdocs && tree -H '.' -L 1 --noreport --charset utf-8 -o index.html && cd ../../../","title":"Make a release"},{"location":"community/publish/#make-a-sedona-release","text":"This page is for Sedona PPMC to publish Sedona releases. You can read ASF guidelines: 1. ASF Incubator Distribution Guidelines: https://incubator.apache.org/guides/distribution.html 2. ASF Release Guidelines: https://infra.apache.org/release-publishing.html 3. ASF Incubator Release Votes Guidelines: https://issues.apache.org/jira/browse/LEGAL-469 Warning All scripts on this page should be run in your local Sedona Git repo under master branch via a single script file.","title":"Make a Sedona release"},{"location":"community/publish/#0-prepare-an-empty-script-file","text":"In your local Sedona Git repo under master branch, run echo \"#!/bin/bash\" > create-release.sh chmod 777 create-release.sh Use your favourite GUI text editor to open create-release.sh . Then keep copying the scripts on this web page to replace all content in this script file. Do NOT directly copy/paste the scripts to your terminal because a bug in clipboard.js will create link breaks in such case. Each time when you copy content to this script file, run ./create-release.sh to execute it.","title":"0. Prepare an empty script file"},{"location":"community/publish/#1-check-asf-copyright-in-all-file-headers","text":"Run the following script: #!/bin/bash wget -q https://dlcdn.apache.org//creadur/apache-rat- $RAT_VERSION /apache-rat-0.15-bin.tar.gz tar -xvf apache-rat-0.15-bin.tar.gz git clone --shared --branch master https://github.com/apache/incubator-sedona.git sedona-src java -jar apache-rat-0.15.jar -d sedona-src > report.txt Read the generated report.txt file and make sure all source code files have ASF header. Delete the generated report and cloned files #!/bin/bash rm -rf sedona-src rm report.txt","title":"1. Check ASF copyright in all file headers"},{"location":"community/publish/#2-update-sedona-python-r-and-zeppelin-versions","text":"Make sure the Sedona version in the following files are 1.3.1-incubating. Note that: Python and R versions cannot have \"incubating\" postfix. https://github.com/apache/incubator-sedona/blob/master/python/sedona/version.py https://github.com/apache/incubator-sedona/blob/master/R/DESCRIPTION https://github.com/apache/incubator-sedona/blob/master/zeppelin/package.json","title":"2. Update Sedona Python, R and Zeppelin versions"},{"location":"community/publish/#3-update-mkdocsyml","text":"Please change the following variables in mkdocs.yml to the version you want to publish. sedona_create_release.current_version sedona_create_release.current_rc sedona_create_release.current_git_tag sedona_create_release.current_snapshot Then compile the website by mkdocs serve . This will generate the scripts listed on this page in your local browser. You can also publish this website if needed. See the instruction at bottom.","title":"3. Update mkdocs.yml"},{"location":"community/publish/#4-stage-and-upload-release-candidates","text":"#!/bin/bash source ~/.bashrc git checkout master git pull rm -f release.* rm -f pom.xml.* echo \"*****Step 1. Stage the Release Candidate to GitHub.\" mvn -q -B clean release:prepare -Dtag = sedona-1.3.1-incubating-rc1 -DreleaseVersion = 1 .3.1-incubating -DdevelopmentVersion = 1 .3.1-incubating-SNAPSHOT -DautoVersionSubmodules = true -Dresume = false -Darguments = \"-DskipTests\" rm -f release.* rm -f pom.xml.* echo \"Now the releases are staged. A tag and two commits have been created on Sedona GitHub repo\" echo \"*****Step 2: Upload the Release Candidate to https://repository.apache.org.\" # For Spark 3.0 and Scala 2.12 mvn -q org.apache.maven.plugins:maven-release-plugin:2.3.2:perform -DconnectionUrl = scm:git:https://github.com/apache/incubator-sedona.git -Dtag = sedona-1.3.1-incubating-rc1 -DautoVersionSubmodules = true -Dresume = false -Darguments = \"-DskipTests -Dscala=2.12\" # For Spark 3.0 and Scala 2.13 mvn -q org.apache.maven.plugins:maven-release-plugin:2.3.2:perform -DconnectionUrl = scm:git:https://github.com/apache/incubator-sedona.git -Dtag = sedona-1.3.1-incubating-rc1 -DautoVersionSubmodules = true -Dresume = false -Darguments = \"-DskipTests -Dscala=2.13\" echo \"*****Step 3: Upload Release Candidate on ASF SVN: https://dist.apache.org/repos/dist/dev/incubator/sedona\" echo \"Creating 1.3.1-incubating-rc1 folder on SVN...\" svn mkdir -m \"Adding folder\" https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1 echo \"Creating release files locally...\" echo \"Downloading source code...\" wget https://github.com/apache/incubator-sedona/archive/refs/tags/sedona-1.3.1-incubating-rc1.tar.gz tar -xvf sedona-1.3.1-incubating-rc1.tar.gz mkdir apache-sedona-1.3.1-incubating-src cp -r incubator-sedona-sedona-1.3.1-incubating-rc1/* apache-sedona-1.3.1-incubating-src/ tar czf apache-sedona-1.3.1-incubating-src.tar.gz apache-sedona-1.3.1-incubating-src rm sedona-1.3.1-incubating-rc1.tar.gz rm -rf incubator-sedona-sedona-1.3.1-incubating-rc1 echo \"Compiling the source code...\" mkdir apache-sedona-1.3.1-incubating-bin cd apache-sedona-1.3.1-incubating-src && mvn -q clean install -DskipTests -Dscala = 2 .12 && cd .. cp apache-sedona-1.3.1-incubating-src/core/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/sql/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/viz/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/python-adapter/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/flink/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cd apache-sedona-1.3.1-incubating-src && mvn -q clean install -DskipTests -Dscala = 2 .13 && cd .. cp apache-sedona-1.3.1-incubating-src/core/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/sql/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/viz/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/python-adapter/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ cp apache-sedona-1.3.1-incubating-src/flink/target/sedona-*1.3.1-incubating.jar apache-sedona-1.3.1-incubating-bin/ tar czf apache-sedona-1.3.1-incubating-bin.tar.gz apache-sedona-1.3.1-incubating-bin shasum -a 512 apache-sedona-1.3.1-incubating-src.tar.gz > apache-sedona-1.3.1-incubating-src.tar.gz.sha512 shasum -a 512 apache-sedona-1.3.1-incubating-bin.tar.gz > apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 gpg -ab apache-sedona-1.3.1-incubating-src.tar.gz gpg -ab apache-sedona-1.3.1-incubating-bin.tar.gz echo \"Uploading local release files...\" svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-src.tar.gz https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-src.tar.gz svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-src.tar.gz.asc https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-src.tar.gz.asc svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-src.tar.gz.sha512 https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-src.tar.gz.sha512 svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-bin.tar.gz https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-bin.tar.gz svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-bin.tar.gz.asc https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-bin.tar.gz.asc svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 echo \"Removing local release files...\" rm apache-sedona-1.3.1-incubating-src.tar.gz rm apache-sedona-1.3.1-incubating-src.tar.gz.asc rm apache-sedona-1.3.1-incubating-src.tar.gz.sha512 rm apache-sedona-1.3.1-incubating-bin.tar.gz rm apache-sedona-1.3.1-incubating-bin.tar.gz.asc rm apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 rm -rf apache-sedona-1.3.1-incubating-src rm -rf apache-sedona-1.3.1-incubating-bin","title":"4. Stage and upload release candidates"},{"location":"community/publish/#5-vote-in-dev-sedonaapacheorg","text":"","title":"5. Vote in dev sedona.apache.org"},{"location":"community/publish/#vote-email","text":"Please add changes at the end if needed: Subject: [VOTE] Release Apache Sedona 1.3.1-incubating-rc1 Hi all, This is a call for vote on Apache Sedona 1.3.1-incubating-rc1. Please refer to the changes listed at the bottom of this email. Release notes: https://github.com/apache/incubator-sedona/blob/sedona-1.3.1-incubating-rc1/docs/setup/release-notes.md Build instructions: https://github.com/apache/incubator-sedona/blob/sedona-1.3.1-incubating-rc1/docs/setup/compile.md GitHub tag: https://github.com/apache/incubator-sedona/releases/tag/sedona-1.3.1-incubating-rc1 GPG public key to verify the Release: https://downloads.apache.org/incubator/sedona/KEYS Source code and binaries: https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/ The vote will be open for at least 72 hours or until at least 3 \"+1\" PMC votes are cast Instruction for checking items on the checklist: https://sedona.apache.org/community/vote/ We recommend you use this Jupyter notebook on MyBinder to perform this task: https://mybinder.org/v2/gh/jiayuasu/sedona-tools/HEAD?labpath=binder%2Fverify-release.ipynb **Please vote accordingly and you must provide your checklist for your vote**. [ ] +1 approve [ ] +0 no opinion [ ] -1 disapprove with the reason Checklist: [ ] Download links are valid. [ ] Checksums and PGP signatures are valid. [ ] DISCLAIMER is included. [ ] Source code artifacts have correct names matching the current release. For a detailed checklist please refer to: https://cwiki.apache.org/confluence/display/INCUBATOR/Incubator+Release+Checklist ------------ Changes according to the comments on the previous release Original comment (Permalink from https://lists.apache.org/list.html):","title":"Vote email"},{"location":"community/publish/#pass-email","text":"Please count the votes and add the Permalink of the vote thread at the end. Subject: [RESULT][VOTE] Release Apache Sedona 1.3.1-incubating-rc1 Dear all, The vote closes now as 72hr have passed. The vote PASSES with +? (binding): NAME1, NAME2, NAME3 +? (non-binding): NAME4 No -1 votes The vote thread (Permalink from https://lists.apache.org/list.html): I will now bring the vote to general@incubator.apache.org to get approval by the IPMC. If this vote passes too, the release is accepted and will be published.","title":"Pass email"},{"location":"community/publish/#6-vote-in-general-incubatorapacheorg","text":"","title":"6. Vote in general incubator.apache.org"},{"location":"community/publish/#vote-email_1","text":"Please add the permalink of Sedona Community vote thread Please add the permalink of Sedona Community vote result thread Please add changes at the end if needed. Subject: [VOTE] Release Apache Sedona 1.3.1-incubating-rc1 Hi all, This is a call for vote on Apache Sedona 1.3.1-incubating-rc1. Please refer to the changes listed at the bottom of this email. Sedona Community vote thread (Permalink from https://lists.apache.org/list.html): Sedona community vote result thread (Permalink from https://lists.apache.org/list.html): Release notes: https://github.com/apache/incubator-sedona/blob/sedona-1.3.1-incubating-rc1/docs/setup/release-notes.md Build instructions: https://github.com/apache/incubator-sedona/blob/sedona-1.3.1-incubating-rc1/docs/setup/compile.md GitHub tag: https://github.com/apache/incubator-sedona/releases/tag/sedona-1.3.1-incubating-rc1 GPG public key to verify the Release: https://downloads.apache.org/incubator/sedona/KEYS Source code and binaries: https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/ The vote will be open for at least 72 hours or until at least 3 \"+1\" PMC votes are cast Please vote accordingly: [ ] +1 approve [ ] +0 no opinion [ ] -1 disapprove with the reason Checklist for reference (because of DISCLAIMER-WIP, other checklist items are not blockers): [ ] Download links are valid. [ ] Checksums and PGP signatures are valid. [ ] DISCLAIMER is included. [ ] Source code artifacts have correct names matching the current release. For a detailed checklist please refer to: https://cwiki.apache.org/confluence/display/INCUBATOR/Incubator+Release+Checklist ------------ Changes according to the comments on the previous release Original comment (Permalink from https://lists.apache.org/list.html):","title":"Vote email"},{"location":"community/publish/#pass-email_1","text":"Please count the votes and add the permalink of the vote thread. Subject: [RESULT][VOTE] Release Apache Sedona 1.3.1-incubating-rc1 Dear all, The vote closes now as 72hr have passed. The vote PASSES with +? (binding): NAME1, NAME2, NAME3 +? (non-binding): NAME4 No -1 votes The vote thread (Permalink from https://lists.apache.org/list.html): I will publish the release and make an annoucement once it is done.","title":"Pass email"},{"location":"community/publish/#announce-email","text":"This email should be CCed to dev@sedona.apache.org Please add the permalink of the incubator vote thread Please add the permalink of the incubator vote result thread Subject: [ANNOUNCE] Apache Sedona 1.3.1-incubating released Dear all, We are happy to report that we have released Apache Sedona (incubating) 1.3.1-incubating. Thank you again for your help. Apache Sedona (incubating) is a cluster computing system for processing large-scale spatial data. Vote thread (Permalink from https://lists.apache.org/list.html): Vote result thread (Permalink from https://lists.apache.org/list.html): Website: http://sedona.apache.org/ Release notes: https://github.com/apache/incubator-sedona/blob/sedona-1.3.1-incubating/docs/setup/release-notes.md Download links: https://github.com/apache/incubator-sedona/releases/tag/sedona-1.3.1-incubating Additional resources: Get started: http://sedona.apache.org/setup/overview/ Tutorials: http://sedona.apache.org/tutorial/rdd/ Mailing list: dev@sedona.apache.org Twitter: https://twitter.com/ApacheSedona Gitter: https://gitter.im/apache/sedona Regards, Apache Sedona (incubating) Team","title":"Announce email"},{"location":"community/publish/#7-failed-vote","text":"If a vote failed, do the following: In the vote email, say that we will create another release candidate. Restart from Step 3 Update mkdocs.yml . Please increment the release candidate ID (e.g., 1.3.1-incubating-rc2 ) and update sedona_create_release.current_rc and sedona_create_release.current_git_tag in mkdocs.yml to generate the script listed on this webpage.","title":"7. Failed vote"},{"location":"community/publish/#8-release-source-code-and-maven-package","text":"","title":"8. Release source code and Maven package"},{"location":"community/publish/#upload-releases","text":"#!/bin/bash echo \"Move all files in https://dist.apache.org/repos/dist/dev/incubator/sedona to https://dist.apache.org/repos/dist/release/incubator/sedona, using svn\" svn mkdir -m \"Adding folder\" https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating wget https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-src.tar.gz wget https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-src.tar.gz.asc wget https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-src.tar.gz.sha512 wget https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-bin.tar.gz wget https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-bin.tar.gz.asc wget https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1-incubating-rc1/apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-src.tar.gz https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating/apache-sedona-1.3.1-incubating-src.tar.gz svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-src.tar.gz.asc https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating/apache-sedona-1.3.1-incubating-src.tar.gz.asc svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-src.tar.gz.sha512 https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating/apache-sedona-1.3.1-incubating-src.tar.gz.sha512 svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-bin.tar.gz https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating/apache-sedona-1.3.1-incubating-bin.tar.gz svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-bin.tar.gz.asc https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating/apache-sedona-1.3.1-incubating-bin.tar.gz.asc svn import -m \"Adding file\" apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1-incubating/apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 rm apache-sedona-1.3.1-incubating-src.tar.gz rm apache-sedona-1.3.1-incubating-src.tar.gz.asc rm apache-sedona-1.3.1-incubating-src.tar.gz.sha512 rm apache-sedona-1.3.1-incubating-bin.tar.gz rm apache-sedona-1.3.1-incubating-bin.tar.gz.asc rm apache-sedona-1.3.1-incubating-bin.tar.gz.sha512 echo \"Re-staging releases to https://repository.apache.org\" # For Spark 3.0 and Scala 2.12 mvn -q org.apache.maven.plugins:maven-release-plugin:2.3.2:perform -DconnectionUrl = scm:git:https://github.com/apache/incubator-sedona.git -Dtag = sedona-1.3.1-incubating-rc1 -DautoVersionSubmodules = true -Dresume = false -Darguments = \"-DskipTests\" # For Spark 3.0 and Scala 2.13 mvn -q org.apache.maven.plugins:maven-release-plugin:2.3.2:perform -DconnectionUrl = scm:git:https://github.com/apache/incubator-sedona.git -Dtag = sedona-1.3.1-incubating-rc1 -DautoVersionSubmodules = true -Dresume = false -Darguments = \"-DskipTests -Dscala=2.13\"","title":"Upload releases"},{"location":"community/publish/#fix-signature-issues","text":"Please find the Sedona staging id on https://repository.apache.org under staging repository . Then run the following script. Replace admin , admind123 with your Apache ID username and Apache ID password. Replace stagingid with the correct id. #!/bin/bash username = admin password = admin123 stagingid = 1027 artifacts =( parent core-3.0_2.12 core-3.0_2.13 sql-3.0_2.12 sql-3.0_2.13 viz-3.0_2.12 viz-3.0_2.13 python-adapter-3.0_2.12 python-adapter-3.0_2.13 common flink_2.12 ) filenames =( .pom .jar -javadoc.jar ) echo \"Re-uploading signatures to fix *failureMessage Invalid Signature*\" for artifact in \" ${ artifacts [@] } \" ; do for filename in \" ${ filenames [@] } \" ; do if [ $artifact -eq 'parent' && $filename -ne '.pom' ] then continue fi wget https://repository.apache.org/service/local/repositories/orgapachesedona- $stagingid /content/org/apache/sedona/sedona- $artifact /1.3.1-incubating/sedona- ${ artifact } -1.3.1-incubating ${ filename } gpg -ab sedona- ${ artifact } -1.3.1-incubating ${ filename } curl -v -u $username : $password --upload-file sedona- ${ artifact } -1.3.1-incubating ${ filename } .asc https://repository.apache.org/service/local/repositories/orgapachesedona- $stagingid /content/org/apache/sedona/sedona- ${ artifact } /1.3.1-incubating/sedona- ${ artifact } -1.3.1-incubating ${ filename } .asc done done rm *.pom rm *.jar rm *.asc","title":"Fix signature issues"},{"location":"community/publish/#manually-close-and-release-the-package","text":"Click Close on the Sedona staging repo on https://repository.apache.org under staging repository Once the staging repo is closed, click Release on this repo.","title":"Manually close and release the package"},{"location":"community/publish/#9-release-sedona-python-and-zeppelin","text":"You must have the maintainer priviledge of https://pypi.org/project/apache-sedona/ and https://www.npmjs.com/package/apache-sedona #!/bin/bash git clone --shared --branch sedona-1.3.1-incubating-rc1 https://github.com/apache/incubator-sedona.git apache-sedona-1.3.1-incubating-src cd apache-sedona-1.3.1-incubating-src/python && python3 setup.py sdist bdist_wheel && twine upload dist/* && cd .. cd zeppelin && npm publish && cd .. rm -rf apache-sedona-1.3.1-incubating-src","title":"9. Release Sedona Python and Zeppelin"},{"location":"community/publish/#10-release-sedona-r-to-cran","text":"#!/bin/bash R CMD build . R CMD check --as-cran apache.sedona_*.tar.gz Then submit to CRAN using this web form .","title":"10. Release Sedona R to CRAN."},{"location":"community/publish/#11-publish-the-doc-website","text":"Add the download link to Download page and create a GitHub release. Run mkdocs build in Sedona root directory. Copy all content in the site folder. Check out GitHub incubator-sedona-website asf-site branch Use the copied content to replace all content in asf-site branch and upload to GitHub. Then sedona.apache.org will be automatically updated. You can also push the content to asf-staging branch. The staging website will be then updated: sedona.staged.apache.org","title":"11. Publish the doc website"},{"location":"community/publish/#javadoc-and-scaladoc","text":"","title":"Javadoc and Scaladoc"},{"location":"community/publish/#compile-r-html-docs","text":"Make sure you install R, tree and curl on your Ubuntu machine. On Mac, just do brew install tree sudo apt install littler tree libcurl4-openssl-dev In the Sedona root directory, run the script below. This will create rdocs folder in Sedona /docs/api/rdocs #!/bin/bash Rscript generate-docs.R cd ./docs/api/rdocs && tree -H '.' -L 1 --noreport --charset utf-8 -o index.html && cd ../../../","title":"Compile R html docs"},{"location":"community/release-manager/","text":"Become a release manager \u00b6 You only need to perform these steps if this is your first time being a release manager. 0. Software requirement \u00b6 JDK 8: brew install openjdk@8 Maven 3.X. Your Maven must point to JDK 8 (1.8). Check it by mvn --version Git and SVN If your Maven ( mvn --version ) points to other JDK versions, you must change it to JDK 8. Steps are as follows: Find all Java installed on your machine: /usr/libexec/java_home -V . You should see multiple JDK versions including JDK 8. Run whereis mvn to get the installation location of your Maven. The result is a symlink to the actual location. Open it in the terminal (with sudo if needed). It will be like this #!/bin/bash JAVA_HOME=\"${JAVA_HOME:-$(/usr/libexec/java_home)}\" exec \"/usr/local/Cellar/maven/3.6.3/libexec/bin/mvn\" \"$@\" Change JAVA_HOME:-$(/usr/libexec/java_home)} to JAVA_HOME:-$(/usr/libexec/java_home -v 1.8)} . The resulting content will be like this: #!/bin/bash JAVA_HOME=\"${JAVA_HOME:-$(/usr/libexec/java_home -v 1.8)}\" exec \"/usr/local/Cellar/maven/3.6.3/libexec/bin/mvn\" \"$@\" Run mvn --version again. It should now point to JDK 8. 1. Obtain Write Access to Sedona GitHub repo \u00b6 Verify you have a Github ID enabled with 2FA https://help.github.com/articles/securing-your-account-with-two-factor-authentication-2fa/ Enter your Github ID into your Apache ID profile https://id.apache.org/ Merge your Apache and GitHub accounts using GitBox (Apache Account Linking utility): https://gitbox.apache.org/setup/ You should see 5 green checks in GitBox Wait at least 30 minutes for an email inviting you to Apache GitHub Organization and accept invitation After accepting the Github Invitation, verify that you are a member of the team https://github.com/orgs/apache/teams/sedona-committers Additionally, if you have been elected to the Sedona PPMC, verify you are part of the LDAP Sedona PPMC https://whimsy.apache.org/roster/ppmc/sedona 2. Prepare Secret GPG key \u00b6 Install GNUGPG if it was not installed before. On Mac: brew install gnupg gnupg2 Generate a secret key. It must be RSA4096 (4096 bits long). Run gpg --full-generate-key . If not work, run gpg --default-new-key-algo rsa4096 --gen-key At the prompt, specify the kind of key you want: Select RSA , then press enter At the prompt, specify the key size you want: Enter 4096 At the prompt, enter the length of time the key should be valid: Press enter to make the key never expire. Verify that your selections are correct. Enter your user ID information: use your real name and Apache email address. Type a secure passphrase. Make sure you remember this because we will use it later. Use the gpg --list-secret-keys --keyid-format=long command to list the long form of the GPG keys. From the list of GPG keys, copy the long form of the GPG key ID you'd like to use (e.g., 3AA5C34371567BD2 ) Run gpg --export --armor 3AA5C34371567BD2 , substituting in the GPG key ID you'd like to use. Copy your GPG key, beginning with -----BEGIN PGP PUBLIC KEY BLOCK----- and ending with -----END PGP PUBLIC KEY BLOCK----- . There must be an empty line between -----BEGIN PGP PUBLIC KEY BLOCK----- and the actual key. Publish your armored key in major key servers: https://keyserver.pgp.com/ 3. Use SVN to update KEYS \u00b6 Use SVN to append your armored PGP public key to the KEYS files * https://dist.apache.org/repos/dist/dev/incubator/sedona/KEYS * https://dist.apache.org/repos/dist/release/incubator/sedona/KEYS Check out both KEYS files svn checkout https://dist.apache.org/repos/dist/dev/incubator/sedona/ sedona-dev --depth files svn checkout https://dist.apache.org/repos/dist/release/incubator/sedona/ sedona-release --depth files Use your favorite text editor to open sedona-dev/KEYS and sedona-release/KEYS . Paste your armored key to the end of both files. Note: There must be an empty line between -----BEGIN PGP PUBLIC KEY BLOCK----- and the actual key. Commit both KEYS. SVN might ask you to enter your ASF ID and password. Make sure you do it so SVN can always store your ID and password locally. svn commit -m \"Update KEYS\" sedona-dev/KEYS svn commit -m \"Update KEYS\" sedona-release/KEYS Then remove both svn folders rm -rf sedona-dev rm -rf sedona-release 4. Add GPG_TTY environment variable \u00b6 In your ~/.bashrc file, add the following content. Then restart your terminal. GPG_TTY = $( tty ) export GPG_TTY 5. Get GitHub personal access token (classic) \u00b6 You need to create a GitHub personal access token (classic). You can follow the instruction on GitHub . In short: On your GitHub interface -> Settings In the left sidebar, click Developer settings. In the left sidebar, under Personal access tokens, click Tokens (classic). Select Generate new token, then click Generate new token (classic). Give your token a descriptive name. To give your token an expiration, select the Expiration drop-down menu. Make sure you set the Expiration to No expiration . Select the scopes you'd like to grant this token. To use your token to access repositories from the command line, select repo and admin:org . Click Generate token . Please save your token somewhere because we will use it in the next step. 6. Set up credentials for Maven \u00b6 In your ~/.m2/settings.xml file, add the following content. Please create this file or .m2 folder if it does not exist. Please replace all capitalized text with your own ID and password. <settings> <servers> <server> <id>github</id> <username>YOUR_GITHUB_USERNAME</username> <password>YOUR_GITHUB_TOKEN</password> </server> <server> <id>apache.snapshots.https</id> <username>YOUR_ASF_ID</username> <password>YOUR_ASF_PASSWORD</password> </server> <server> <id>apache.releases.https</id> <username>YOUR_ASF_ID</username> <password>YOUR_ASF_PASSWORD</password> </server> </servers> <profiles> <profile> <id>gpg</id> <properties> <gpg.passphrase>YOUR_GPG_PASSPHRASE</gpg.passphrase> </properties> </profile> </profiles> <activeProfiles> <activeProfile>gpg</activeProfile> </activeProfiles> </settings>","title":"Become a release manager"},{"location":"community/release-manager/#become-a-release-manager","text":"You only need to perform these steps if this is your first time being a release manager.","title":"Become a release manager"},{"location":"community/release-manager/#0-software-requirement","text":"JDK 8: brew install openjdk@8 Maven 3.X. Your Maven must point to JDK 8 (1.8). Check it by mvn --version Git and SVN If your Maven ( mvn --version ) points to other JDK versions, you must change it to JDK 8. Steps are as follows: Find all Java installed on your machine: /usr/libexec/java_home -V . You should see multiple JDK versions including JDK 8. Run whereis mvn to get the installation location of your Maven. The result is a symlink to the actual location. Open it in the terminal (with sudo if needed). It will be like this #!/bin/bash JAVA_HOME=\"${JAVA_HOME:-$(/usr/libexec/java_home)}\" exec \"/usr/local/Cellar/maven/3.6.3/libexec/bin/mvn\" \"$@\" Change JAVA_HOME:-$(/usr/libexec/java_home)} to JAVA_HOME:-$(/usr/libexec/java_home -v 1.8)} . The resulting content will be like this: #!/bin/bash JAVA_HOME=\"${JAVA_HOME:-$(/usr/libexec/java_home -v 1.8)}\" exec \"/usr/local/Cellar/maven/3.6.3/libexec/bin/mvn\" \"$@\" Run mvn --version again. It should now point to JDK 8.","title":"0. Software requirement"},{"location":"community/release-manager/#1-obtain-write-access-to-sedona-github-repo","text":"Verify you have a Github ID enabled with 2FA https://help.github.com/articles/securing-your-account-with-two-factor-authentication-2fa/ Enter your Github ID into your Apache ID profile https://id.apache.org/ Merge your Apache and GitHub accounts using GitBox (Apache Account Linking utility): https://gitbox.apache.org/setup/ You should see 5 green checks in GitBox Wait at least 30 minutes for an email inviting you to Apache GitHub Organization and accept invitation After accepting the Github Invitation, verify that you are a member of the team https://github.com/orgs/apache/teams/sedona-committers Additionally, if you have been elected to the Sedona PPMC, verify you are part of the LDAP Sedona PPMC https://whimsy.apache.org/roster/ppmc/sedona","title":"1. Obtain Write Access to Sedona GitHub repo"},{"location":"community/release-manager/#2-prepare-secret-gpg-key","text":"Install GNUGPG if it was not installed before. On Mac: brew install gnupg gnupg2 Generate a secret key. It must be RSA4096 (4096 bits long). Run gpg --full-generate-key . If not work, run gpg --default-new-key-algo rsa4096 --gen-key At the prompt, specify the kind of key you want: Select RSA , then press enter At the prompt, specify the key size you want: Enter 4096 At the prompt, enter the length of time the key should be valid: Press enter to make the key never expire. Verify that your selections are correct. Enter your user ID information: use your real name and Apache email address. Type a secure passphrase. Make sure you remember this because we will use it later. Use the gpg --list-secret-keys --keyid-format=long command to list the long form of the GPG keys. From the list of GPG keys, copy the long form of the GPG key ID you'd like to use (e.g., 3AA5C34371567BD2 ) Run gpg --export --armor 3AA5C34371567BD2 , substituting in the GPG key ID you'd like to use. Copy your GPG key, beginning with -----BEGIN PGP PUBLIC KEY BLOCK----- and ending with -----END PGP PUBLIC KEY BLOCK----- . There must be an empty line between -----BEGIN PGP PUBLIC KEY BLOCK----- and the actual key. Publish your armored key in major key servers: https://keyserver.pgp.com/","title":"2. Prepare Secret GPG key"},{"location":"community/release-manager/#3-use-svn-to-update-keys","text":"Use SVN to append your armored PGP public key to the KEYS files * https://dist.apache.org/repos/dist/dev/incubator/sedona/KEYS * https://dist.apache.org/repos/dist/release/incubator/sedona/KEYS Check out both KEYS files svn checkout https://dist.apache.org/repos/dist/dev/incubator/sedona/ sedona-dev --depth files svn checkout https://dist.apache.org/repos/dist/release/incubator/sedona/ sedona-release --depth files Use your favorite text editor to open sedona-dev/KEYS and sedona-release/KEYS . Paste your armored key to the end of both files. Note: There must be an empty line between -----BEGIN PGP PUBLIC KEY BLOCK----- and the actual key. Commit both KEYS. SVN might ask you to enter your ASF ID and password. Make sure you do it so SVN can always store your ID and password locally. svn commit -m \"Update KEYS\" sedona-dev/KEYS svn commit -m \"Update KEYS\" sedona-release/KEYS Then remove both svn folders rm -rf sedona-dev rm -rf sedona-release","title":"3. Use SVN to update KEYS"},{"location":"community/release-manager/#4-add-gpg_tty-environment-variable","text":"In your ~/.bashrc file, add the following content. Then restart your terminal. GPG_TTY = $( tty ) export GPG_TTY","title":"4. Add GPG_TTY environment variable"},{"location":"community/release-manager/#5-get-github-personal-access-token-classic","text":"You need to create a GitHub personal access token (classic). You can follow the instruction on GitHub . In short: On your GitHub interface -> Settings In the left sidebar, click Developer settings. In the left sidebar, under Personal access tokens, click Tokens (classic). Select Generate new token, then click Generate new token (classic). Give your token a descriptive name. To give your token an expiration, select the Expiration drop-down menu. Make sure you set the Expiration to No expiration . Select the scopes you'd like to grant this token. To use your token to access repositories from the command line, select repo and admin:org . Click Generate token . Please save your token somewhere because we will use it in the next step.","title":"5. Get GitHub personal access token (classic)"},{"location":"community/release-manager/#6-set-up-credentials-for-maven","text":"In your ~/.m2/settings.xml file, add the following content. Please create this file or .m2 folder if it does not exist. Please replace all capitalized text with your own ID and password. <settings> <servers> <server> <id>github</id> <username>YOUR_GITHUB_USERNAME</username> <password>YOUR_GITHUB_TOKEN</password> </server> <server> <id>apache.snapshots.https</id> <username>YOUR_ASF_ID</username> <password>YOUR_ASF_PASSWORD</password> </server> <server> <id>apache.releases.https</id> <username>YOUR_ASF_ID</username> <password>YOUR_ASF_PASSWORD</password> </server> </servers> <profiles> <profile> <id>gpg</id> <properties> <gpg.passphrase>YOUR_GPG_PASSPHRASE</gpg.passphrase> </properties> </profile> </profiles> <activeProfiles> <activeProfile>gpg</activeProfile> </activeProfiles> </settings>","title":"6. Set up credentials for Maven"},{"location":"community/rule/","text":"Contributing to Apache Sedona \u00b6 The project welcomes contributions. You can contribute to Sedona code or documentation by making Pull Requests on Sedona GitHub Repo . The following sections brief the workflow of how to complete a contribution. Pick / Annouce a task using JIRA \u00b6 It is important to confirm that your contribution is acceptable. You should create a JIRA ticket or pick an existing ticket. A new JIRA ticket will be automatically sent to dev@sedona.apache.org Develop a code contribution \u00b6 Code contributions should include the following: Detailed documentations on classes and methods. Unit Tests to demonstrate code correctness and allow this to be maintained going forward. In the case of bug fixes the unit test should demonstrate the bug in the absence of the fix (if any). Unit Tests can be JUnit test or Scala test. Some Sedona functions need to be tested in both Scala and Java. Updates on corresponding Sedona documentation if necessary. Code contributions must include a Apache 2.0 license header at the top of each file. Develop a document contribution \u00b6 Documentation contributions should satisfy the following requirements: Detailed explanation with examples. Place a newly added document in a proper folder Change the mkdocs.yml if necessary Note Please read Compile the source code to learn how to compile Sedona website. Make a Pull Request \u00b6 After developing a contribution, the easiest and most visible way to submit a Pull Request (PR) to the GitHub repo . Please use the JIRA ticket ID in the PR name, such as \"[SEDONA-1] my subject\". When creating a PR, please answser the questions in the PR template. When a PR is submitted, GitHub Action will check the build correctness. Please check the PR status, and fix any reported problems. Review a Pull Request \u00b6 Every PR requires (1) at least 1 approval from a committer and (2) no disapproval from a committer. Everyone is welcome to review a PR but only the committer can make the final decision. Other reviewers, including community members and committers, may comment on the changes and suggest modifications. Changes can be added by simply pushing more commits to the same branch. Lively, polite, rapid technical debate is encouraged from everyone in the community even if the outcome may be a rejection of the entire change. Keep in mind that changes to more critical parts of Sedona, like Sedona core and spatial join algorithms, will be subjected to more review, and may require more testing and proof of its correctness than other changes. Sometimes, other changes will be merged which conflict with your pull request\u2019s changes. The PR can\u2019t be merged until the conflict is resolved. This can be resolved by resolving the conflicts by hand, then pushing the result to your branch. Code of Conduct \u00b6 Please read Apache Software Foundation Code of Conduct . We expect everyone who participates in the Apache community formally or informally, or claims any affiliation with the Foundation, in any Foundation-related activities and especially when representing the ASF in any role to honor this code of conduct.","title":"Rules"},{"location":"community/rule/#contributing-to-apache-sedona","text":"The project welcomes contributions. You can contribute to Sedona code or documentation by making Pull Requests on Sedona GitHub Repo . The following sections brief the workflow of how to complete a contribution.","title":"Contributing to Apache Sedona"},{"location":"community/rule/#pick-annouce-a-task-using-jira","text":"It is important to confirm that your contribution is acceptable. You should create a JIRA ticket or pick an existing ticket. A new JIRA ticket will be automatically sent to dev@sedona.apache.org","title":"Pick / Annouce a task using JIRA"},{"location":"community/rule/#develop-a-code-contribution","text":"Code contributions should include the following: Detailed documentations on classes and methods. Unit Tests to demonstrate code correctness and allow this to be maintained going forward. In the case of bug fixes the unit test should demonstrate the bug in the absence of the fix (if any). Unit Tests can be JUnit test or Scala test. Some Sedona functions need to be tested in both Scala and Java. Updates on corresponding Sedona documentation if necessary. Code contributions must include a Apache 2.0 license header at the top of each file.","title":"Develop a code contribution"},{"location":"community/rule/#develop-a-document-contribution","text":"Documentation contributions should satisfy the following requirements: Detailed explanation with examples. Place a newly added document in a proper folder Change the mkdocs.yml if necessary Note Please read Compile the source code to learn how to compile Sedona website.","title":"Develop a document contribution"},{"location":"community/rule/#make-a-pull-request","text":"After developing a contribution, the easiest and most visible way to submit a Pull Request (PR) to the GitHub repo . Please use the JIRA ticket ID in the PR name, such as \"[SEDONA-1] my subject\". When creating a PR, please answser the questions in the PR template. When a PR is submitted, GitHub Action will check the build correctness. Please check the PR status, and fix any reported problems.","title":"Make a Pull Request"},{"location":"community/rule/#review-a-pull-request","text":"Every PR requires (1) at least 1 approval from a committer and (2) no disapproval from a committer. Everyone is welcome to review a PR but only the committer can make the final decision. Other reviewers, including community members and committers, may comment on the changes and suggest modifications. Changes can be added by simply pushing more commits to the same branch. Lively, polite, rapid technical debate is encouraged from everyone in the community even if the outcome may be a rejection of the entire change. Keep in mind that changes to more critical parts of Sedona, like Sedona core and spatial join algorithms, will be subjected to more review, and may require more testing and proof of its correctness than other changes. Sometimes, other changes will be merged which conflict with your pull request\u2019s changes. The PR can\u2019t be merged until the conflict is resolved. This can be resolved by resolving the conflicts by hand, then pushing the result to your branch.","title":"Review a Pull Request"},{"location":"community/rule/#code-of-conduct","text":"Please read Apache Software Foundation Code of Conduct . We expect everyone who participates in the Apache community formally or informally, or claims any affiliation with the Foundation, in any Foundation-related activities and especially when representing the ASF in any role to honor this code of conduct.","title":"Code of Conduct"},{"location":"community/snapshot/","text":"Publish a SNAPSHOT version \u00b6 This step is to publish Maven SNAPSHOTs to https://repository.apache.org This is a good practice for a release manager to try out his/her credential setup. The detailed requirement is on ASF Infra website Warning All scripts on this page should be run in your local Sedona Git repo under master branch via a single script file. 0. Prepare an empty script file \u00b6 In your local Sedona Git repo under master branch, run echo \" \" > create-release.sh chmod 777 create-release.sh Use your favourite GUI text editor to open create-release.sh . Then keep copying the scripts on this web page to replace all content in this text file. Do NOT directly copy/paste the scripts to your terminal because a bug in clipboard.js will create link breaks in such case. Each time when you copy content to this script file, run ./create-release.sh to execute it. 1. Upload snapshot versions \u00b6 In your Sedona GitHub repo, run this script: #!/bin/bash source ~/.bashrc git checkout master git pull rm -f release.* rm -f pom.xml.* # Spark 3.0 and Scala 2.12 # Prepare the SNAPSHOTs mvn -q -B clean -Darguments = \"-DskipTests\" release:prepare -Dtag = sedona-1.3.1-incubating-rc1 -DreleaseVersion = 1 .3.1-incubating -DdevelopmentVersion = 1 .3.1-incubating-SNAPSHOT -DdryRun = true -DautoVersionSubmodules = true -Dresume = false # Deploy the SNAPSHOTs mvn -q deploy -DskipTests rm -f release.* rm -f pom.xml.* # Prepare for Spark 3.0 and Scala 2.13 # Prepare the SNAPSHOTs mvn -q -B clean -Darguments = \"-DskipTests -Dscala=2.13\" release:prepare -Dtag = sedona-1.3.1-incubating-rc1 -DreleaseVersion = 1 .3.1-incubating -DdevelopmentVersion = 1 .3.1-incubating-SNAPSHOT -DdryRun = true -DautoVersionSubmodules = true -Dresume = false # Deploy the SNAPSHOTs mvn -q deploy -DskipTests -Dscala = 2 .13 rm -f release.* rm -f pom.xml.*","title":"Publish a snapshot version"},{"location":"community/snapshot/#publish-a-snapshot-version","text":"This step is to publish Maven SNAPSHOTs to https://repository.apache.org This is a good practice for a release manager to try out his/her credential setup. The detailed requirement is on ASF Infra website Warning All scripts on this page should be run in your local Sedona Git repo under master branch via a single script file.","title":"Publish a SNAPSHOT version"},{"location":"community/snapshot/#0-prepare-an-empty-script-file","text":"In your local Sedona Git repo under master branch, run echo \" \" > create-release.sh chmod 777 create-release.sh Use your favourite GUI text editor to open create-release.sh . Then keep copying the scripts on this web page to replace all content in this text file. Do NOT directly copy/paste the scripts to your terminal because a bug in clipboard.js will create link breaks in such case. Each time when you copy content to this script file, run ./create-release.sh to execute it.","title":"0. Prepare an empty script file"},{"location":"community/snapshot/#1-upload-snapshot-versions","text":"In your Sedona GitHub repo, run this script: #!/bin/bash source ~/.bashrc git checkout master git pull rm -f release.* rm -f pom.xml.* # Spark 3.0 and Scala 2.12 # Prepare the SNAPSHOTs mvn -q -B clean -Darguments = \"-DskipTests\" release:prepare -Dtag = sedona-1.3.1-incubating-rc1 -DreleaseVersion = 1 .3.1-incubating -DdevelopmentVersion = 1 .3.1-incubating-SNAPSHOT -DdryRun = true -DautoVersionSubmodules = true -Dresume = false # Deploy the SNAPSHOTs mvn -q deploy -DskipTests rm -f release.* rm -f pom.xml.* # Prepare for Spark 3.0 and Scala 2.13 # Prepare the SNAPSHOTs mvn -q -B clean -Darguments = \"-DskipTests -Dscala=2.13\" release:prepare -Dtag = sedona-1.3.1-incubating-rc1 -DreleaseVersion = 1 .3.1-incubating -DdevelopmentVersion = 1 .3.1-incubating-SNAPSHOT -DdryRun = true -DautoVersionSubmodules = true -Dresume = false # Deploy the SNAPSHOTs mvn -q deploy -DskipTests -Dscala = 2 .13 rm -f release.* rm -f pom.xml.*","title":"1. Upload snapshot versions"},{"location":"community/vote/","text":"Vote a Sedona release \u00b6 This page is for Sedona community to vote a Sedona release. The script below is tested on MacOS. In order to vote a Sedona release, you must provide your checklist inlcuding the following minimum requirement: Download links are valid Checksums and PGP signatures are valid DISCLAIMER and NOTICE are included Source code artifacts have correct names matching the current release The project can compile from the source code To make your life easier, we have provided an online Jupyter notebook using MyBinder. Please click this button to open the notebook and verify the release: . Then you can vote +1 in the vote email. If you prefer to run the steps on your local machine, please read the steps below. If you can successfully finish the steps, you will pass the items mentioned above. Then you can vote +1 in the vote email and provide your checklist. Install necessary software \u00b6 GPG: On Mac brew install gnupg gnupg2 . You can check in a terminal gpg --version . JDK 1.8 or 1.11. Your Mac might have many different Java versions installed. You can try to use it but not sure if it can pass. You can check in a terminal java --version . Apache Maven 3.3.1+. On Mac brew install maven . You can check it in a terminal mvn -version . Python3 installed on your machine. MacOS comes with Python3 by default. You can check in a terminal python3 --version . You can skip this step if you installed these software before. Run the verify script \u00b6 Please replace SEDONA_CURRENT_RC and SEDONA_CURRENT_VERSION with the correct versions. Then paste the content in a script called verify.sh and re-direct the output to a file. To run a script, do the following: #!/bin/bash ## Change the permission of the script to executable chmod 777 verify.sh ## Run and redirect the output to a file ./verify.sh & > verify.out The content of the verify.sh script is as follows. If you copy the following content, a line break is automatically added to a long line of code. Please remove it in your local script. #!/bin/bash SEDONA_CURRENT_RC = 1 .3.1-incubating-rc1 SEDONA_CURRENT_VERSION = 1 .3.1-incubating ## Download a Sedona release wget -q https://downloads.apache.org/incubator/sedona/KEYS wget -q https://dist.apache.org/repos/dist/dev/incubator/sedona/ $SEDONA_CURRENT_RC /apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz wget -q https://dist.apache.org/repos/dist/dev/incubator/sedona/ $SEDONA_CURRENT_RC /apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz.asc wget -q https://dist.apache.org/repos/dist/dev/incubator/sedona/ $SEDONA_CURRENT_RC /apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz.sha512 wget -q https://dist.apache.org/repos/dist/dev/incubator/sedona/ $SEDONA_CURRENT_RC /apache-sedona- $SEDONA_CURRENT_VERSION -bin.tar.gz wget -q https://dist.apache.org/repos/dist/dev/incubator/sedona/ $SEDONA_CURRENT_RC /apache-sedona- $SEDONA_CURRENT_VERSION -bin.tar.gz.asc wget -q https://dist.apache.org/repos/dist/dev/incubator/sedona/ $SEDONA_CURRENT_RC /apache-sedona- $SEDONA_CURRENT_VERSION -bin.tar.gz.sha512 ## Verify the signature and checksum gpg --import KEYS gpg --verify apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz.asc gpg --verify apache-sedona- $SEDONA_CURRENT_VERSION -bin.tar.gz.asc shasum -a 512 apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz cat apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz.sha512 shasum -a 512 apache-sedona- $SEDONA_CURRENT_VERSION -bin.tar.gz cat apache-sedona- $SEDONA_CURRENT_VERSION -bin.tar.gz.sha512 ## Uncompress the source code folder tar -xvf apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz ## Compile the project from source ( cd apache-sedona- $SEDONA_CURRENT_VERSION -src ; mvn clean install -DskipTests ) If successful, in the output file, you should be able to see something similar to the following text. It should include Good signature from and the final 4 lines should be two pairs of checksum matching each other. gpg: key 3A79A47AC26FF4CD: \"Jia Yu <jiayu@apache.org>\" not changed gpg: key 6C883CA80E7FD299: \"PawelKocinski <imbruced@apache.org>\" not changed gpg: Total number processed: 2 gpg: unchanged: 2 gpg: assuming signed data in 'apache-sedona-1.2.0-incubating-src.tar.gz' gpg: Signature made Mon Apr 4 11:48:31 2022 PDT gpg: using RSA key 949DD6275C69AB954B1872FC6C883CA80E7FD299 gpg: issuer \"imbruced@apache.org\" gpg: Good signature from \"PawelKocinski <imbruced@apache.org>\" [unknown] gpg: WARNING: The key's User ID is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: 949D D627 5C69 AB95 4B18 72FC 6C88 3CA8 0E7F D299 gpg: assuming signed data in 'apache-sedona-1.2.0-incubating-bin.tar.gz' gpg: Signature made Mon Apr 4 11:48:42 2022 PDT gpg: using RSA key 949DD6275C69AB954B1872FC6C883CA80E7FD299 gpg: issuer \"imbruced@apache.org\" gpg: Good signature from \"PawelKocinski <imbruced@apache.org>\" [unknown] gpg: WARNING: The key's User ID is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: 949D D627 5C69 AB95 4B18 72FC 6C88 3CA8 0E7F D299 d3bdfd4d870838ebe63f21cb93634d2421ec1ac1b8184636206a5dc0d89a78a88257798b1f17371ad3cfcc3b1eb79c69e1410afdefeb4d9b52fc8bb5ea18dd2e apache-sedona-1.2.0-incubating-src.tar.gz d3bdfd4d870838ebe63f21cb93634d2421ec1ac1b8184636206a5dc0d89a78a88257798b1f17371ad3cfcc3b1eb79c69e1410afdefeb4d9b52fc8bb5ea18dd2e apache-sedona-1.2.0-incubating-src.tar.gz 64cea38dd3ca171ee4e2a7365dbce999773862f2a11599bd0f27e9551d740659a519a9b976b3e7b0826088010967093e6acc9462f7073e9737c24b007a2df846 apache-sedona-1.2.0-incubating-bin.tar.gz 64cea38dd3ca171ee4e2a7365dbce999773862f2a11599bd0f27e9551d740659a519a9b976b3e7b0826088010967093e6acc9462f7073e9737c24b007a2df846 apache-sedona-1.2.0-incubating-bin.tar.gz At the end of the output, you should also see the BUILD SUCCESS if you can compile the source code. If this step fails, you can contact Sedona PPMC and see if this is just because of your environment. Check files manually \u00b6 Check if the downloaded files have the correct version. In the unzipped source code folder, and check if DISCLAIMER and NOTICE files and included and up to date.","title":"Vote a release"},{"location":"community/vote/#vote-a-sedona-release","text":"This page is for Sedona community to vote a Sedona release. The script below is tested on MacOS. In order to vote a Sedona release, you must provide your checklist inlcuding the following minimum requirement: Download links are valid Checksums and PGP signatures are valid DISCLAIMER and NOTICE are included Source code artifacts have correct names matching the current release The project can compile from the source code To make your life easier, we have provided an online Jupyter notebook using MyBinder. Please click this button to open the notebook and verify the release: . Then you can vote +1 in the vote email. If you prefer to run the steps on your local machine, please read the steps below. If you can successfully finish the steps, you will pass the items mentioned above. Then you can vote +1 in the vote email and provide your checklist.","title":"Vote a Sedona release"},{"location":"community/vote/#install-necessary-software","text":"GPG: On Mac brew install gnupg gnupg2 . You can check in a terminal gpg --version . JDK 1.8 or 1.11. Your Mac might have many different Java versions installed. You can try to use it but not sure if it can pass. You can check in a terminal java --version . Apache Maven 3.3.1+. On Mac brew install maven . You can check it in a terminal mvn -version . Python3 installed on your machine. MacOS comes with Python3 by default. You can check in a terminal python3 --version . You can skip this step if you installed these software before.","title":"Install necessary software"},{"location":"community/vote/#run-the-verify-script","text":"Please replace SEDONA_CURRENT_RC and SEDONA_CURRENT_VERSION with the correct versions. Then paste the content in a script called verify.sh and re-direct the output to a file. To run a script, do the following: #!/bin/bash ## Change the permission of the script to executable chmod 777 verify.sh ## Run and redirect the output to a file ./verify.sh & > verify.out The content of the verify.sh script is as follows. If you copy the following content, a line break is automatically added to a long line of code. Please remove it in your local script. #!/bin/bash SEDONA_CURRENT_RC = 1 .3.1-incubating-rc1 SEDONA_CURRENT_VERSION = 1 .3.1-incubating ## Download a Sedona release wget -q https://downloads.apache.org/incubator/sedona/KEYS wget -q https://dist.apache.org/repos/dist/dev/incubator/sedona/ $SEDONA_CURRENT_RC /apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz wget -q https://dist.apache.org/repos/dist/dev/incubator/sedona/ $SEDONA_CURRENT_RC /apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz.asc wget -q https://dist.apache.org/repos/dist/dev/incubator/sedona/ $SEDONA_CURRENT_RC /apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz.sha512 wget -q https://dist.apache.org/repos/dist/dev/incubator/sedona/ $SEDONA_CURRENT_RC /apache-sedona- $SEDONA_CURRENT_VERSION -bin.tar.gz wget -q https://dist.apache.org/repos/dist/dev/incubator/sedona/ $SEDONA_CURRENT_RC /apache-sedona- $SEDONA_CURRENT_VERSION -bin.tar.gz.asc wget -q https://dist.apache.org/repos/dist/dev/incubator/sedona/ $SEDONA_CURRENT_RC /apache-sedona- $SEDONA_CURRENT_VERSION -bin.tar.gz.sha512 ## Verify the signature and checksum gpg --import KEYS gpg --verify apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz.asc gpg --verify apache-sedona- $SEDONA_CURRENT_VERSION -bin.tar.gz.asc shasum -a 512 apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz cat apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz.sha512 shasum -a 512 apache-sedona- $SEDONA_CURRENT_VERSION -bin.tar.gz cat apache-sedona- $SEDONA_CURRENT_VERSION -bin.tar.gz.sha512 ## Uncompress the source code folder tar -xvf apache-sedona- $SEDONA_CURRENT_VERSION -src.tar.gz ## Compile the project from source ( cd apache-sedona- $SEDONA_CURRENT_VERSION -src ; mvn clean install -DskipTests ) If successful, in the output file, you should be able to see something similar to the following text. It should include Good signature from and the final 4 lines should be two pairs of checksum matching each other. gpg: key 3A79A47AC26FF4CD: \"Jia Yu <jiayu@apache.org>\" not changed gpg: key 6C883CA80E7FD299: \"PawelKocinski <imbruced@apache.org>\" not changed gpg: Total number processed: 2 gpg: unchanged: 2 gpg: assuming signed data in 'apache-sedona-1.2.0-incubating-src.tar.gz' gpg: Signature made Mon Apr 4 11:48:31 2022 PDT gpg: using RSA key 949DD6275C69AB954B1872FC6C883CA80E7FD299 gpg: issuer \"imbruced@apache.org\" gpg: Good signature from \"PawelKocinski <imbruced@apache.org>\" [unknown] gpg: WARNING: The key's User ID is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: 949D D627 5C69 AB95 4B18 72FC 6C88 3CA8 0E7F D299 gpg: assuming signed data in 'apache-sedona-1.2.0-incubating-bin.tar.gz' gpg: Signature made Mon Apr 4 11:48:42 2022 PDT gpg: using RSA key 949DD6275C69AB954B1872FC6C883CA80E7FD299 gpg: issuer \"imbruced@apache.org\" gpg: Good signature from \"PawelKocinski <imbruced@apache.org>\" [unknown] gpg: WARNING: The key's User ID is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: 949D D627 5C69 AB95 4B18 72FC 6C88 3CA8 0E7F D299 d3bdfd4d870838ebe63f21cb93634d2421ec1ac1b8184636206a5dc0d89a78a88257798b1f17371ad3cfcc3b1eb79c69e1410afdefeb4d9b52fc8bb5ea18dd2e apache-sedona-1.2.0-incubating-src.tar.gz d3bdfd4d870838ebe63f21cb93634d2421ec1ac1b8184636206a5dc0d89a78a88257798b1f17371ad3cfcc3b1eb79c69e1410afdefeb4d9b52fc8bb5ea18dd2e apache-sedona-1.2.0-incubating-src.tar.gz 64cea38dd3ca171ee4e2a7365dbce999773862f2a11599bd0f27e9551d740659a519a9b976b3e7b0826088010967093e6acc9462f7073e9737c24b007a2df846 apache-sedona-1.2.0-incubating-bin.tar.gz 64cea38dd3ca171ee4e2a7365dbce999773862f2a11599bd0f27e9551d740659a519a9b976b3e7b0826088010967093e6acc9462f7073e9737c24b007a2df846 apache-sedona-1.2.0-incubating-bin.tar.gz At the end of the output, you should also see the BUILD SUCCESS if you can compile the source code. If this step fails, you can contact Sedona PPMC and see if this is just because of your environment.","title":"Run the verify script"},{"location":"community/vote/#check-files-manually","text":"Check if the downloaded files have the correct version. In the unzipped source code folder, and check if DISCLAIMER and NOTICE files and included and up to date.","title":"Check files manually"},{"location":"setup/cluster/","text":"Set up your Apache Spark cluster \u00b6 Download a Spark distribution from Spark download page . Preliminary \u00b6 Set up password-less SSH on your cluster. Each master-worker pair should have bi-directional password-less SSH. Make sure you have installed JRE 1.8 or later. Add the list of your workers' IP address in ./conf/slaves Besides the necessary Spark settings, you may need to add the following lines in Spark configuration files to avoid Sedona memory errors: In ./conf/spark-defaults.conf spark.driver.memory 10g spark.network.timeout 1000s spark.driver.maxResultSize 5g spark.driver.memory tells Spark to allocate enough memory for the driver program because Sedona needs to build global grid files (global index) on the driver program. If you have a large amount of data (normally, over 100 GB), set this parameter to 2~5 GB will be good. Otherwise, you may observe \"out of memory\" error. spark.network.timeout is the default timeout for all network interactions. Sometimes, spatial join query takes longer time to shuffle data. This will ensure Spark has enough patience to wait for the result. spark.driver.maxResultSize is the limit of total size of serialized results of all partitions for each Spark action. Sometimes, the result size of spatial queries is large. The \"Collect\" operation may throw errors. For more details of Spark parameters, please visit Spark Website . Start your cluster \u00b6 Go the root folder of the uncompressed Apache Spark folder. Start your spark cluster via a terminal ./sbin/start-all.sh","title":"Set up Spark cluser"},{"location":"setup/cluster/#set-up-your-apache-spark-cluster","text":"Download a Spark distribution from Spark download page .","title":"Set up your Apache Spark cluster"},{"location":"setup/cluster/#preliminary","text":"Set up password-less SSH on your cluster. Each master-worker pair should have bi-directional password-less SSH. Make sure you have installed JRE 1.8 or later. Add the list of your workers' IP address in ./conf/slaves Besides the necessary Spark settings, you may need to add the following lines in Spark configuration files to avoid Sedona memory errors: In ./conf/spark-defaults.conf spark.driver.memory 10g spark.network.timeout 1000s spark.driver.maxResultSize 5g spark.driver.memory tells Spark to allocate enough memory for the driver program because Sedona needs to build global grid files (global index) on the driver program. If you have a large amount of data (normally, over 100 GB), set this parameter to 2~5 GB will be good. Otherwise, you may observe \"out of memory\" error. spark.network.timeout is the default timeout for all network interactions. Sometimes, spatial join query takes longer time to shuffle data. This will ensure Spark has enough patience to wait for the result. spark.driver.maxResultSize is the limit of total size of serialized results of all partitions for each Spark action. Sometimes, the result size of spatial queries is large. The \"Collect\" operation may throw errors. For more details of Spark parameters, please visit Spark Website .","title":"Preliminary"},{"location":"setup/cluster/#start-your-cluster","text":"Go the root folder of the uncompressed Apache Spark folder. Start your spark cluster via a terminal ./sbin/start-all.sh","title":"Start your cluster"},{"location":"setup/compile/","text":"Compile Sedona source code \u00b6 Compile Scala / Java source code \u00b6 Sedona Scala/Java code is a project with four modules, core, sql, viz and python adapter. Each module is a Scala/Java mixed project which is managed by Apache Maven 3. Make sure your Linux/Mac machine has Java 1.8, Apache Maven 3.3.1+, and Python3. The compilation of Sedona is not tested on Windows machine. To compile all modules, please make sure you are in the root folder of all modules. Then enter the following command in the terminal: Without unit tests With unit tests With Geotools jars packaged mvn clean install -DskipTests This command will first delete the old binary files and compile all modules. This compilation will skip the unit tests. To compile a single module, please make sure you are in the folder of that module. Then enter the same command. mvn clean install The maven unit tests of all modules may take up to 30 minutes. mvn clean install -DskipTests -Dgeotools Geotools jars will be packaged into the produced fat jars. Note By default, this command will compile Sedona with Spark 3.0 and Scala 2.12 Compile with different targets \u00b6 Spark 3.0 + Scala 2.12 Spark 3.0 + Scala 2.13 mvn clean install -DskipTests -Dscala=2.12 mvn clean install -DskipTests -Dscala=2.13 Tip To get the Sedona Python-adapter jar with all GeoTools jars included, simply append -Dgeotools option. The command is like this: mvn clean install -DskipTests -Dscala=2.12 -Dspark=3.0 -Dgeotools Download staged jars \u00b6 Sedona uses GitHub action to automatically generate jars per commit. You can go here and download the jars by clicking the commit's Artifacts tag. Run Python test \u00b6 Set up the environment variable SPARK_HOME and PYTHONPATH For example, export SPARK_HOME=$PWD/spark-3.0.1-bin-hadoop2.7 export PYTHONPATH=$SPARK_HOME/python 2. Compile the Sedona Scala and Java code with -Dgeotools and then copy the sedona-python-adapter-1.3.0-incubating.jar to SPARK_HOME/jars/ folder. cp python-adapter/target/sedona-python-adapter-xxx.jar SPARK_HOME/jars/ 3. Install the following libraries sudo apt-get -y install python3-pip python-dev libgeos-dev sudo pip3 install -U setuptools sudo pip3 install -U wheel sudo pip3 install -U virtualenvwrapper sudo pip3 install -U pipenv 4. Set up pipenv to the desired Python version: 3.7, 3.8, or 3.9 cd python pipenv --python 3.7 5. Install the PySpark version and other dependency cd python pipenv install pyspark==3.0.1 pipenv install --dev 6. Run the Python tests cd python pipenv run pytest tests Compile the documentation \u00b6 The website is automatically built after each commit. The built website can be downloaded here: MkDocs website \u00b6 The source code of the documentation website is written in Markdown and then compiled by MkDocs. The website is built upon Material for MkDocs template . In the Sedona repository, MkDocs configuration file mkdocs.yml is in the root folder and all documentation source code is in docs folder. To compile the source code and test the website on your local machine, please read MkDocs Tutorial and Materials for MkDocs Tutorial . In short, you need to run: pip install mkdocs pip install mkdocs-material pip install mkdocs-macros-plugin pip install mkdocs-git-revision-date-localized-plugin After installing MkDocs and MkDocs-Material, run the command in Sedona root folder: mkdocs serve","title":"Compile the code"},{"location":"setup/compile/#compile-sedona-source-code","text":"","title":"Compile Sedona source code"},{"location":"setup/compile/#compile-scala-java-source-code","text":"Sedona Scala/Java code is a project with four modules, core, sql, viz and python adapter. Each module is a Scala/Java mixed project which is managed by Apache Maven 3. Make sure your Linux/Mac machine has Java 1.8, Apache Maven 3.3.1+, and Python3. The compilation of Sedona is not tested on Windows machine. To compile all modules, please make sure you are in the root folder of all modules. Then enter the following command in the terminal: Without unit tests With unit tests With Geotools jars packaged mvn clean install -DskipTests This command will first delete the old binary files and compile all modules. This compilation will skip the unit tests. To compile a single module, please make sure you are in the folder of that module. Then enter the same command. mvn clean install The maven unit tests of all modules may take up to 30 minutes. mvn clean install -DskipTests -Dgeotools Geotools jars will be packaged into the produced fat jars. Note By default, this command will compile Sedona with Spark 3.0 and Scala 2.12","title":"Compile Scala / Java source code"},{"location":"setup/compile/#compile-with-different-targets","text":"Spark 3.0 + Scala 2.12 Spark 3.0 + Scala 2.13 mvn clean install -DskipTests -Dscala=2.12 mvn clean install -DskipTests -Dscala=2.13 Tip To get the Sedona Python-adapter jar with all GeoTools jars included, simply append -Dgeotools option. The command is like this: mvn clean install -DskipTests -Dscala=2.12 -Dspark=3.0 -Dgeotools","title":"Compile with different targets"},{"location":"setup/compile/#download-staged-jars","text":"Sedona uses GitHub action to automatically generate jars per commit. You can go here and download the jars by clicking the commit's Artifacts tag.","title":"Download staged jars"},{"location":"setup/compile/#run-python-test","text":"Set up the environment variable SPARK_HOME and PYTHONPATH For example, export SPARK_HOME=$PWD/spark-3.0.1-bin-hadoop2.7 export PYTHONPATH=$SPARK_HOME/python 2. Compile the Sedona Scala and Java code with -Dgeotools and then copy the sedona-python-adapter-1.3.0-incubating.jar to SPARK_HOME/jars/ folder. cp python-adapter/target/sedona-python-adapter-xxx.jar SPARK_HOME/jars/ 3. Install the following libraries sudo apt-get -y install python3-pip python-dev libgeos-dev sudo pip3 install -U setuptools sudo pip3 install -U wheel sudo pip3 install -U virtualenvwrapper sudo pip3 install -U pipenv 4. Set up pipenv to the desired Python version: 3.7, 3.8, or 3.9 cd python pipenv --python 3.7 5. Install the PySpark version and other dependency cd python pipenv install pyspark==3.0.1 pipenv install --dev 6. Run the Python tests cd python pipenv run pytest tests","title":"Run Python test"},{"location":"setup/compile/#compile-the-documentation","text":"The website is automatically built after each commit. The built website can be downloaded here:","title":"Compile the documentation"},{"location":"setup/compile/#mkdocs-website","text":"The source code of the documentation website is written in Markdown and then compiled by MkDocs. The website is built upon Material for MkDocs template . In the Sedona repository, MkDocs configuration file mkdocs.yml is in the root folder and all documentation source code is in docs folder. To compile the source code and test the website on your local machine, please read MkDocs Tutorial and Materials for MkDocs Tutorial . In short, you need to run: pip install mkdocs pip install mkdocs-material pip install mkdocs-macros-plugin pip install mkdocs-git-revision-date-localized-plugin After installing MkDocs and MkDocs-Material, run the command in Sedona root folder: mkdocs serve","title":"MkDocs website"},{"location":"setup/databricks/","text":"Community edition (free-tier) \u00b6 You just need to install the Sedona jars and Sedona Python on Databricks using Databricks default web UI. Then everything will work. Advanced editions \u00b6 Sedona 1.0.1 & 1.1.0 is compiled against Spark 3.1 (~ Databricks DBR 9 LTS, DBR 7 is Spark 3.0) Sedona 1.1.1 is compiled against Spark 3.2 (~ DBR 10 & 11) In Spark 3.2, org.apache.spark.sql.catalyst.expressions.Generator class added a field nodePatterns . Any SQL functions that rely on Generator class may have issues if compiled for a runtime with a differing spark version. For Sedona, those functions are: * ST_MakeValid * ST_SubDivideExplode Sedona 1.1.1-incubating is overall the recommended version to use. It is generally backwards compatible with earlier Spark releases but you should be aware of what Spark version Sedona was compiled against versus which is being executed in case you hit issues. Databricks 10.x+ (Recommended) You need to use Sedona version 1.1.1-incubating or higher. In order to activate the Kryo serializer (this speeds up the serialization and deserialization of geometry types) you need to install the libraries via init script as described below. Databricks DBR 7.x - 9.x If you are using the commercial version of Databricks you can install the Sedona jars and Sedona Python using the Databricks default web UI. DBR 7 matches with Sedona 1.1.0-incubating and DBR 9 matches better with Sedona 1.1.1-incubating due to Databricks cherry-picking some Spark 3.2 private APIs. Install Sedona from the web UI \u00b6 1) From the Libraries tab install from Maven Coordinates org.apache.sedona:sedona-python-adapter-3.0_2.12:1.3.0-incubating org.datasyslab:geotools-wrapper:1.3.0-27.2 2) For enabling python support, from the Libraries tab install from PyPI apache-sedona 3) (Only for DBR up to 7.3 LTS) You can speed up the serialization of geometry types by adding to your spark configurations ( Cluster -> Edit -> Configuration -> Advanced options ) the following lines: spark.serializer org.apache.spark.serializer.KryoSerializer spark.kryo.registrator org.apache.sedona.core.serde.SedonaKryoRegistrator > For DBRs after 7.3, use the Init Script method described further down. Initialise \u00b6 After you have installed the libraries and started the cluster, you can initialize the Sedona ST_* functions and types by running from your code: (scala) import org . apache . sedona . sql . utils . SedonaSQLRegistrator SedonaSQLRegistrator . registerAll ( spark ) (or python) from sedona.register.geo_registrator import SedonaRegistrator SedonaRegistrator . registerAll ( spark ) Pure SQL environment \u00b6 In order to use the Sedona ST_* functions from SQL without having to register the Sedona functions from a python/scala cell, you need to install the Sedona libraries from the cluster init-scripts as follows. Install Sedona via init script (for DBRs > 7.3) \u00b6 Download the Sedona jars to a DBFS location. You can do that manually via UI or from a notebook by executing this code in a cell: %sh # Create JAR directory for Sedona mkdir -p /dbfs/FileStore/jars/sedona/1.3.0-incubating # Download the dependencies from Maven into DBFS curl -o /dbfs/FileStore/jars/sedona/1.3.0-incubating/geotools-wrapper-1.3.0-27.2.jar \"https://repo1.maven.org/maven2/org/datasyslab/geotools-wrapper/1.3.0-27.2/geotools-wrapper-1.3.0-27.2.jar\" curl -o /dbfs/FileStore/jars/sedona/1.3.0-incubating/sedona-python-adapter-3.0_2.12-1.3.0-incubating.jar \"https://repo1.maven.org/maven2/org/apache/sedona/sedona-python-adapter-3.0_2.12/1.3.0-incubating/sedona-python-adapter-3.0_2.12-1.3.0-incubating.jar\" curl -o /dbfs/FileStore/jars/sedona/1.3.0-incubating/sedona-viz-3.0_2.12-1.3.0-incubating.jar \"https://repo1.maven.org/maven2/org/apache/sedona/sedona-viz-3.0_2.12/1.3.0-incubating/sedona-viz-3.0_2.12-1.3.0-incubating.jar\" Create an init script in DBFS that loads the Sedona jars into the cluster's default jar directory. You can create that from any notebook by running: %sh # Create init script directory for Sedona mkdir -p /dbfs/FileStore/sedona/ # Create init script cat > /dbfs/FileStore/sedona/sedona-init.sh <<'EOF' #!/bin/bash # # File: sedona-init.sh # Author: Erni Durdevic # Created: 2021-11-01 # # On cluster startup, this script will copy the Sedona jars to the cluster's default jar directory. # In order to activate Sedona functions, remember to add to your spark configuration the Sedona extensions: \"spark.sql.extensions org.apache.sedona.viz.sql.SedonaVizExtensions,org.apache.sedona.sql.SedonaSqlExtensions\" cp /dbfs/FileStore/jars/sedona/1.3.0-incubating/*.jar /databricks/jars EOF From your cluster configuration ( Cluster -> Edit -> Configuration -> Advanced options -> Spark ) activate the Sedona functions and the kryo serializer by adding to the Spark Config spark.sql.extensions org.apache.sedona.viz.sql.SedonaVizExtensions,org.apache.sedona.sql.SedonaSqlExtensions spark.serializer org.apache.spark.serializer.KryoSerializer spark.kryo.registrator org.apache.sedona.core.serde.SedonaKryoRegistrator From your cluster configuration ( Cluster -> Edit -> Configuration -> Advanced options -> Init Scripts ) add the newly created init script dbfs:/FileStore/sedona/sedona-init.sh For enabling python support, from the Libraries tab install from PyPI apache-sedona Note: You need to install the Sedona libraries via init script because the libraries installed via UI are installed after the cluster has already started, and therefore the classes specified by the config spark.sql.extensions , spark.serializer , and spark.kryo.registrator are not available at startup time.","title":"Install on Databricks"},{"location":"setup/databricks/#community-edition-free-tier","text":"You just need to install the Sedona jars and Sedona Python on Databricks using Databricks default web UI. Then everything will work.","title":"Community edition (free-tier)"},{"location":"setup/databricks/#advanced-editions","text":"Sedona 1.0.1 & 1.1.0 is compiled against Spark 3.1 (~ Databricks DBR 9 LTS, DBR 7 is Spark 3.0) Sedona 1.1.1 is compiled against Spark 3.2 (~ DBR 10 & 11) In Spark 3.2, org.apache.spark.sql.catalyst.expressions.Generator class added a field nodePatterns . Any SQL functions that rely on Generator class may have issues if compiled for a runtime with a differing spark version. For Sedona, those functions are: * ST_MakeValid * ST_SubDivideExplode Sedona 1.1.1-incubating is overall the recommended version to use. It is generally backwards compatible with earlier Spark releases but you should be aware of what Spark version Sedona was compiled against versus which is being executed in case you hit issues.","title":"Advanced editions"},{"location":"setup/databricks/#install-sedona-from-the-web-ui","text":"1) From the Libraries tab install from Maven Coordinates org.apache.sedona:sedona-python-adapter-3.0_2.12:1.3.0-incubating org.datasyslab:geotools-wrapper:1.3.0-27.2 2) For enabling python support, from the Libraries tab install from PyPI apache-sedona 3) (Only for DBR up to 7.3 LTS) You can speed up the serialization of geometry types by adding to your spark configurations ( Cluster -> Edit -> Configuration -> Advanced options ) the following lines: spark.serializer org.apache.spark.serializer.KryoSerializer spark.kryo.registrator org.apache.sedona.core.serde.SedonaKryoRegistrator > For DBRs after 7.3, use the Init Script method described further down.","title":"Install Sedona from the web UI"},{"location":"setup/databricks/#initialise","text":"After you have installed the libraries and started the cluster, you can initialize the Sedona ST_* functions and types by running from your code: (scala) import org . apache . sedona . sql . utils . SedonaSQLRegistrator SedonaSQLRegistrator . registerAll ( spark ) (or python) from sedona.register.geo_registrator import SedonaRegistrator SedonaRegistrator . registerAll ( spark )","title":"Initialise"},{"location":"setup/databricks/#pure-sql-environment","text":"In order to use the Sedona ST_* functions from SQL without having to register the Sedona functions from a python/scala cell, you need to install the Sedona libraries from the cluster init-scripts as follows.","title":"Pure SQL environment"},{"location":"setup/databricks/#install-sedona-via-init-script-for-dbrs-73","text":"Download the Sedona jars to a DBFS location. You can do that manually via UI or from a notebook by executing this code in a cell: %sh # Create JAR directory for Sedona mkdir -p /dbfs/FileStore/jars/sedona/1.3.0-incubating # Download the dependencies from Maven into DBFS curl -o /dbfs/FileStore/jars/sedona/1.3.0-incubating/geotools-wrapper-1.3.0-27.2.jar \"https://repo1.maven.org/maven2/org/datasyslab/geotools-wrapper/1.3.0-27.2/geotools-wrapper-1.3.0-27.2.jar\" curl -o /dbfs/FileStore/jars/sedona/1.3.0-incubating/sedona-python-adapter-3.0_2.12-1.3.0-incubating.jar \"https://repo1.maven.org/maven2/org/apache/sedona/sedona-python-adapter-3.0_2.12/1.3.0-incubating/sedona-python-adapter-3.0_2.12-1.3.0-incubating.jar\" curl -o /dbfs/FileStore/jars/sedona/1.3.0-incubating/sedona-viz-3.0_2.12-1.3.0-incubating.jar \"https://repo1.maven.org/maven2/org/apache/sedona/sedona-viz-3.0_2.12/1.3.0-incubating/sedona-viz-3.0_2.12-1.3.0-incubating.jar\" Create an init script in DBFS that loads the Sedona jars into the cluster's default jar directory. You can create that from any notebook by running: %sh # Create init script directory for Sedona mkdir -p /dbfs/FileStore/sedona/ # Create init script cat > /dbfs/FileStore/sedona/sedona-init.sh <<'EOF' #!/bin/bash # # File: sedona-init.sh # Author: Erni Durdevic # Created: 2021-11-01 # # On cluster startup, this script will copy the Sedona jars to the cluster's default jar directory. # In order to activate Sedona functions, remember to add to your spark configuration the Sedona extensions: \"spark.sql.extensions org.apache.sedona.viz.sql.SedonaVizExtensions,org.apache.sedona.sql.SedonaSqlExtensions\" cp /dbfs/FileStore/jars/sedona/1.3.0-incubating/*.jar /databricks/jars EOF From your cluster configuration ( Cluster -> Edit -> Configuration -> Advanced options -> Spark ) activate the Sedona functions and the kryo serializer by adding to the Spark Config spark.sql.extensions org.apache.sedona.viz.sql.SedonaVizExtensions,org.apache.sedona.sql.SedonaSqlExtensions spark.serializer org.apache.spark.serializer.KryoSerializer spark.kryo.registrator org.apache.sedona.core.serde.SedonaKryoRegistrator From your cluster configuration ( Cluster -> Edit -> Configuration -> Advanced options -> Init Scripts ) add the newly created init script dbfs:/FileStore/sedona/sedona-init.sh For enabling python support, from the Libraries tab install from PyPI apache-sedona Note: You need to install the Sedona libraries via init script because the libraries installed via UI are installed after the cluster has already started, and therefore the classes specified by the config spark.sql.extensions , spark.serializer , and spark.kryo.registrator are not available at startup time.","title":"Install Sedona via init script (for DBRs &gt; 7.3)"},{"location":"setup/install-python/","text":"Click and play the interactive Sedona Python Jupyter Notebook immediately! Apache Sedona extends pyspark functions which depends on libraries: pyspark shapely attrs You need to install necessary packages if your system does not have them installed. See \"packages\" in our Pipfile . Install sedona \u00b6 Installing from PyPi repositories. You can find the latest Sedona Python on PyPi . There is an known issue in Sedona v1.0.1 and earlier versions . pip install apache-sedona Since Sedona v1.1.0, pyspark is an optional dependency of Sedona Python because spark comes pre-installed on many spark platforms. To install pyspark along with Sedona Python in one go, use the spark extra: pip install apache-sedona [ spark ] Installing from Sedona Python source Clone Sedona GitHub source code and run the following command cd python python3 setup.py install Prepare python-adapter jar \u00b6 Sedona Python needs one additional jar file called sedona-python-adapter to work properly. Please make sure you use the correct version for Spark and Scala. For Spark 3.0 + Scala 2.12, it is called sedona-python-adapter-3.0_2.12-1.3.0-incubating.jar You can get it using one of the following methods: Compile from the source within main project directory and copy it (in python-adapter/target folder) to SPARK_HOME/jars/ folder ( more details ) Download from GitHub release and copy it to SPARK_HOME/jars/ folder Call the Maven Central coordinate in your python program. For example, in PySparkSQL spark = SparkSession . \\ builder . \\ appName ( 'appName' ) . \\ config ( \"spark.serializer\" , KryoSerializer . getName ) . \\ config ( \"spark.kryo.registrator\" , SedonaKryoRegistrator . getName ) . \\ config ( 'spark.jars.packages' , 'org.apache.sedona:sedona-python-adapter-3.0_2.12:1.3.0-incubating,' 'org.datasyslab:geotools-wrapper:1.3.0-27.2' ) . \\ getOrCreate () Warning If you are going to use Sedona CRS transformation and ShapefileReader functions, you have to use Method 1 or 3. Because these functions internally use GeoTools libraries which are under LGPL license, Apache Sedona binary release cannot include them. Setup environment variables \u00b6 If you manually copy the python-adapter jar to SPARK_HOME/jars/ folder, you need to setup two environment variables SPARK_HOME. For example, run the command in your terminal export SPARK_HOME = ~/Downloads/spark-3.0.1-bin-hadoop2.7 PYTHONPATH. For example, run the command in your terminal export PYTHONPATH = $SPARK_HOME /python You can then play with Sedona Python Jupyter notebook .","title":"Install Sedona Python"},{"location":"setup/install-python/#install-sedona","text":"Installing from PyPi repositories. You can find the latest Sedona Python on PyPi . There is an known issue in Sedona v1.0.1 and earlier versions . pip install apache-sedona Since Sedona v1.1.0, pyspark is an optional dependency of Sedona Python because spark comes pre-installed on many spark platforms. To install pyspark along with Sedona Python in one go, use the spark extra: pip install apache-sedona [ spark ] Installing from Sedona Python source Clone Sedona GitHub source code and run the following command cd python python3 setup.py install","title":"Install sedona"},{"location":"setup/install-python/#prepare-python-adapter-jar","text":"Sedona Python needs one additional jar file called sedona-python-adapter to work properly. Please make sure you use the correct version for Spark and Scala. For Spark 3.0 + Scala 2.12, it is called sedona-python-adapter-3.0_2.12-1.3.0-incubating.jar You can get it using one of the following methods: Compile from the source within main project directory and copy it (in python-adapter/target folder) to SPARK_HOME/jars/ folder ( more details ) Download from GitHub release and copy it to SPARK_HOME/jars/ folder Call the Maven Central coordinate in your python program. For example, in PySparkSQL spark = SparkSession . \\ builder . \\ appName ( 'appName' ) . \\ config ( \"spark.serializer\" , KryoSerializer . getName ) . \\ config ( \"spark.kryo.registrator\" , SedonaKryoRegistrator . getName ) . \\ config ( 'spark.jars.packages' , 'org.apache.sedona:sedona-python-adapter-3.0_2.12:1.3.0-incubating,' 'org.datasyslab:geotools-wrapper:1.3.0-27.2' ) . \\ getOrCreate () Warning If you are going to use Sedona CRS transformation and ShapefileReader functions, you have to use Method 1 or 3. Because these functions internally use GeoTools libraries which are under LGPL license, Apache Sedona binary release cannot include them.","title":"Prepare python-adapter jar"},{"location":"setup/install-python/#setup-environment-variables","text":"If you manually copy the python-adapter jar to SPARK_HOME/jars/ folder, you need to setup two environment variables SPARK_HOME. For example, run the command in your terminal export SPARK_HOME = ~/Downloads/spark-3.0.1-bin-hadoop2.7 PYTHONPATH. For example, run the command in your terminal export PYTHONPATH = $SPARK_HOME /python You can then play with Sedona Python Jupyter notebook .","title":"Setup environment variables"},{"location":"setup/install-r/","text":"Introduction \u00b6 apache.sedona ( cran.r-project.org/package=apache.sedona ) is a sparklyr -based R interface for Apache Sedona . It presents what Apache Sedona has to offer through idiomatic frameworks and constructs in R (e.g., one can build spatial Spark SQL queries using Sedona UDFs in conjunction with a wide range of dplyr expressions), hence making Apache Sedona highly friendly for R users. Generally speaking, when working with Apache Sedona, one choose between the following two modes: Manipulating Sedona Spatial Resilient Distributed Datasets with spatial-RDD-related routines Querying geometric columns within Spatial dataframes with Sedona spatial UDFs While the former option enables more fine-grained control over low-level implementation details (e.g., which index to build for spatial queries, which data structure to use for spatial partitioning, etc), the latter is simpler and leads to a straightforward integration with dplyr , sparklyr , and other sparklyr extensions (e.g., one can build ML feature extractors with Sedona UDFs and connect them with ML pipelines using ml_*() family of functions in sparklyr , hence creating ML workflows capable of understanding spatial data). Because data from spatial RDDs can be imported into Spark dataframes as geometry columns and vice versa, one can switch between the abovementioned two modes fairly easily. At the moment apache.sedona consists of the following components: R interface for Spatial-RDD-related functionalities Reading/writing spatial data in WKT, WKB, and GeoJSON formats Shapefile reader Spatial partition, index, join, KNN query, and range query operations Visualization routines dplyr -integration for Sedona spatial UDTs and UDFs See SQL APIs for the list of available UDFs Functions importing data from spatial RDDs to Spark dataframes and vice versa Connect to Spark \u00b6 To ensure Sedona serialization routines, UDTs, and UDFs are properly registered when creating a Spark session, one simply needs to attach apache.sedona before instantiating a Spark conneciton. apache.sedona will take care of the rest. For example, library ( sparklyr ) library ( apache.sedona ) spark_home <- \"/usr/lib/spark\" # NOTE: replace this with your $SPARK_HOME directory sc <- spark_connect ( master = \"yarn\" , spark_home = spark_home ) will create a Sedona-capable Spark connection in YARN client mode, and library ( sparklyr ) library ( apache.sedona ) sc <- spark_connect ( master = \"local\" ) will create a Sedona-capable Spark connection to an Apache Spark instance running locally. In sparklyr , one can easily inspect the Spark connection object to sanity-check it has been properly initialized with all Sedona-related dependencies, e.g., print ( sc $ extensions $ packages ) ## [1] \"org.apache.sedona:sedona-core-3.0_2.12:1.3.0-incubating\" ## [2] \"org.apache.sedona:sedona-sql-3.0_2.12:1.3.0-incubating\" ## [3] \"org.apache.sedona:sedona-viz-3.0_2.12:1.3.0-incubating\" ## [4] \"org.datasyslab:geotools-wrapper:1.3.0-27.2\" ## [5] \"org.datasyslab:sernetcdf:0.1.0\" ## [6] \"org.locationtech.jts:jts-core:1.18.0\" ## [7] \"org.wololo:jts2geojson:0.14.3\" and spark_session ( sc ) %>% invoke ( \"%>%\" , list ( \"conf\" ), list ( \"get\" , \"spark.kryo.registrator\" )) %>% print () ## [1] \"org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator\" For more information about connecting to Spark with sparklyr , see https://therinspark.com/connections.html and ?sparklyr::spark_connect . Also see Initiate Spark Context and Initiate Spark Session for minimum and recommended dependencies for Apache Sedona.","title":"Install Sedona R"},{"location":"setup/install-r/#introduction","text":"apache.sedona ( cran.r-project.org/package=apache.sedona ) is a sparklyr -based R interface for Apache Sedona . It presents what Apache Sedona has to offer through idiomatic frameworks and constructs in R (e.g., one can build spatial Spark SQL queries using Sedona UDFs in conjunction with a wide range of dplyr expressions), hence making Apache Sedona highly friendly for R users. Generally speaking, when working with Apache Sedona, one choose between the following two modes: Manipulating Sedona Spatial Resilient Distributed Datasets with spatial-RDD-related routines Querying geometric columns within Spatial dataframes with Sedona spatial UDFs While the former option enables more fine-grained control over low-level implementation details (e.g., which index to build for spatial queries, which data structure to use for spatial partitioning, etc), the latter is simpler and leads to a straightforward integration with dplyr , sparklyr , and other sparklyr extensions (e.g., one can build ML feature extractors with Sedona UDFs and connect them with ML pipelines using ml_*() family of functions in sparklyr , hence creating ML workflows capable of understanding spatial data). Because data from spatial RDDs can be imported into Spark dataframes as geometry columns and vice versa, one can switch between the abovementioned two modes fairly easily. At the moment apache.sedona consists of the following components: R interface for Spatial-RDD-related functionalities Reading/writing spatial data in WKT, WKB, and GeoJSON formats Shapefile reader Spatial partition, index, join, KNN query, and range query operations Visualization routines dplyr -integration for Sedona spatial UDTs and UDFs See SQL APIs for the list of available UDFs Functions importing data from spatial RDDs to Spark dataframes and vice versa","title":"Introduction"},{"location":"setup/install-r/#connect-to-spark","text":"To ensure Sedona serialization routines, UDTs, and UDFs are properly registered when creating a Spark session, one simply needs to attach apache.sedona before instantiating a Spark conneciton. apache.sedona will take care of the rest. For example, library ( sparklyr ) library ( apache.sedona ) spark_home <- \"/usr/lib/spark\" # NOTE: replace this with your $SPARK_HOME directory sc <- spark_connect ( master = \"yarn\" , spark_home = spark_home ) will create a Sedona-capable Spark connection in YARN client mode, and library ( sparklyr ) library ( apache.sedona ) sc <- spark_connect ( master = \"local\" ) will create a Sedona-capable Spark connection to an Apache Spark instance running locally. In sparklyr , one can easily inspect the Spark connection object to sanity-check it has been properly initialized with all Sedona-related dependencies, e.g., print ( sc $ extensions $ packages ) ## [1] \"org.apache.sedona:sedona-core-3.0_2.12:1.3.0-incubating\" ## [2] \"org.apache.sedona:sedona-sql-3.0_2.12:1.3.0-incubating\" ## [3] \"org.apache.sedona:sedona-viz-3.0_2.12:1.3.0-incubating\" ## [4] \"org.datasyslab:geotools-wrapper:1.3.0-27.2\" ## [5] \"org.datasyslab:sernetcdf:0.1.0\" ## [6] \"org.locationtech.jts:jts-core:1.18.0\" ## [7] \"org.wololo:jts2geojson:0.14.3\" and spark_session ( sc ) %>% invoke ( \"%>%\" , list ( \"conf\" ), list ( \"get\" , \"spark.kryo.registrator\" )) %>% print () ## [1] \"org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator\" For more information about connecting to Spark with sparklyr , see https://therinspark.com/connections.html and ?sparklyr::spark_connect . Also see Initiate Spark Context and Initiate Spark Session for minimum and recommended dependencies for Apache Sedona.","title":"Connect to Spark"},{"location":"setup/install-scala/","text":"Before starting the Sedona journey, you need to make sure your Apache Spark cluster is ready. There are two ways to use a Scala or Java library with Apache Spark. You can user either one to run Sedona. Spark interactive Scala or SQL shell: easy to start, good for new learners to try simple functions Self-contained Scala / Java project: a steep learning curve of package management, but good for large projects Spark Scala shell \u00b6 Download Sedona jar automatically \u00b6 Have your Spark cluster ready. Run Spark shell with --packages option. This command will automatically download Sedona jars from Maven Central. ./bin/spark-shell --packages MavenCoordiantes Local mode: test Sedona without setting up a cluster ./bin/spark-shell --packages org.apache.sedona:sedona-python-adapter-3.0_2.12:1.3.0-incubating,org.apache.sedona:sedona-viz-3.0_2.12:1.3.0-incubating,org.datasyslab:geotools-wrapper:1.3.0-27.2 Cluster mode: you need to specify Spark Master IP ./bin/spark-shell --master spark://localhost:7077 --packages org.apache.sedona:sedona-python-adapter-3.0_2.12:1.3.0-incubating,org.apache.sedona:sedona-viz-3.0_2.12:1.3.0-incubating,org.datasyslab:geotools-wrapper:1.3.0-27.2 Download Sedona jar manually \u00b6 Have your Spark cluster ready. Download Sedona jars: Download the pre-compiled jars from Sedona Releases Download / Git clone Sedona source code and compile the code by yourself (see Compile Sedona ) Run Spark shell with --jars option. ./bin/spark-shell --jars /Path/To/SedonaJars.jar Local mode: test Sedona without setting up a cluster ./bin/spark-shell --jars org.apache.sedona:sedona-python-adapter-3.0_2.12:1.3.0-incubating,org.apache.sedona:sedona-viz-3.0_2.12:1.3.0-incubating,org.datasyslab:geotools-wrapper:1.3.0-27.2 Cluster mode: you need to specify Spark Master IP ./bin/spark-shell --master spark://localhost:7077 --jars org.apache.sedona:sedona-python-adapter-3.0_2.12:1.3.0-incubating,org.apache.sedona:sedona-viz-3.0_2.12:1.3.0-incubating,org.datasyslab:geotools-wrapper:1.3.0-27.2 Spark SQL shell \u00b6 Please see Use Sedona in a pure SQL environment Self-contained Spark projects \u00b6 A self-contained project allows you to create multiple Scala / Java files and write complex logics in one place. To use Sedona in your self-contained Spark project, you just need to add Sedona as a dependency in your POM.xml or build.sbt. To add Sedona as dependencies, please read Sedona Maven Central coordinates Use Sedona Template project to start: Sedona Template Project Compile your project using SBT. Make sure you obtain the fat jar which packages all dependencies. Submit your compiled fat jar to Spark cluster. Make sure you are in the root folder of Spark distribution. Then run the following command: ./bin/spark-submit --master spark://YOUR-IP:7077 /Path/To/YourJar.jar Note The detailed explanation of spark-submit is available on Spark website .","title":"Install Sedona Scala/Java"},{"location":"setup/install-scala/#spark-scala-shell","text":"","title":"Spark Scala shell"},{"location":"setup/install-scala/#download-sedona-jar-automatically","text":"Have your Spark cluster ready. Run Spark shell with --packages option. This command will automatically download Sedona jars from Maven Central. ./bin/spark-shell --packages MavenCoordiantes Local mode: test Sedona without setting up a cluster ./bin/spark-shell --packages org.apache.sedona:sedona-python-adapter-3.0_2.12:1.3.0-incubating,org.apache.sedona:sedona-viz-3.0_2.12:1.3.0-incubating,org.datasyslab:geotools-wrapper:1.3.0-27.2 Cluster mode: you need to specify Spark Master IP ./bin/spark-shell --master spark://localhost:7077 --packages org.apache.sedona:sedona-python-adapter-3.0_2.12:1.3.0-incubating,org.apache.sedona:sedona-viz-3.0_2.12:1.3.0-incubating,org.datasyslab:geotools-wrapper:1.3.0-27.2","title":"Download Sedona jar automatically"},{"location":"setup/install-scala/#download-sedona-jar-manually","text":"Have your Spark cluster ready. Download Sedona jars: Download the pre-compiled jars from Sedona Releases Download / Git clone Sedona source code and compile the code by yourself (see Compile Sedona ) Run Spark shell with --jars option. ./bin/spark-shell --jars /Path/To/SedonaJars.jar Local mode: test Sedona without setting up a cluster ./bin/spark-shell --jars org.apache.sedona:sedona-python-adapter-3.0_2.12:1.3.0-incubating,org.apache.sedona:sedona-viz-3.0_2.12:1.3.0-incubating,org.datasyslab:geotools-wrapper:1.3.0-27.2 Cluster mode: you need to specify Spark Master IP ./bin/spark-shell --master spark://localhost:7077 --jars org.apache.sedona:sedona-python-adapter-3.0_2.12:1.3.0-incubating,org.apache.sedona:sedona-viz-3.0_2.12:1.3.0-incubating,org.datasyslab:geotools-wrapper:1.3.0-27.2","title":"Download Sedona jar manually"},{"location":"setup/install-scala/#spark-sql-shell","text":"Please see Use Sedona in a pure SQL environment","title":"Spark SQL shell"},{"location":"setup/install-scala/#self-contained-spark-projects","text":"A self-contained project allows you to create multiple Scala / Java files and write complex logics in one place. To use Sedona in your self-contained Spark project, you just need to add Sedona as a dependency in your POM.xml or build.sbt. To add Sedona as dependencies, please read Sedona Maven Central coordinates Use Sedona Template project to start: Sedona Template Project Compile your project using SBT. Make sure you obtain the fat jar which packages all dependencies. Submit your compiled fat jar to Spark cluster. Make sure you are in the root folder of Spark distribution. Then run the following command: ./bin/spark-submit --master spark://YOUR-IP:7077 /Path/To/YourJar.jar Note The detailed explanation of spark-submit is available on Spark website .","title":"Self-contained Spark projects"},{"location":"setup/maven-coordinates/","text":"Maven Coordinates \u00b6 Sedona Spark has four modules: sedona-core, sedona-sql, sedona-viz, sedona-python-adapter . sedona-python-adapter is a fat jar of sedona-core, sedona-sql and python adapter code. If you want to use SedonaViz, you will include one more jar: sedona-viz . Sedona Flink has four modules : sedona-core, sedona-sql, sedona-python-adapter, sedona-flink . sedona-python-adapter is a fat jar of sedona-core, sedona-sql . Use Sedona fat jars \u00b6 Warning For Scala/Java/Python/R users, this is the most common way to use Sedona in your environment. Do not use separate Sedona jars othwerwise you will get dependency conflicts. sedona-python-adapter already contains all you need. The optional GeoTools library is required only if you want to use CRS transformation and ShapefileReader. This wrapper library is a re-distriution of GeoTools official jars. The only purpose of this library is to bring GeoTools jars from OSGEO repository to Maven Central. This libary is under GNU Lesser General Public License (LGPL) license so we cannot package it in Sedona official release. Sedona with Apache Spark Spark 3.0+ and Scala 2.12 Spark 3.0 and Scala 2.13 <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-python-adapter-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-viz-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <!-- Optional: https://mvnrepository.com/artifact/org.datasyslab/geotools-wrapper --> <dependency> <groupId> org.datasyslab </groupId> <artifactId> geotools-wrapper </artifactId> <version> 1.3.0-27.2 </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-python-adapter-3.0_2.13 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-viz-3.0_2.13 </artifactId> <version> 1.3.0-incubating </version> </dependency> <!-- Optional: https://mvnrepository.com/artifact/org.datasyslab/geotools-wrapper --> <dependency> <groupId> org.datasyslab </groupId> <artifactId> geotools-wrapper </artifactId> <version> 1.3.0-27.2 </version> </dependency> Sedona with Apache Flink Flink 1.12+ and Scala 2.12 <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-python-adapter-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-flink_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <!-- Optional: https://mvnrepository.com/artifact/org.datasyslab/geotools-wrapper --> <dependency> <groupId> org.datasyslab </groupId> <artifactId> geotools-wrapper </artifactId> <version> 1.3.0-27.2 </version> </dependency> netCDF-Java 5.4.2 \u00b6 For Scala / Java API, it is required only if you want to read HDF/NetCDF files. HDF/NetCDF function is only supported in Spark RDD with Java/Scala API. The current function is deprecated and more mature support will be released soon. Under BSD 3-clause (compatible with Apache 2.0 license) Add HDF/NetCDF dependency Sedona 1.3.1+ Before Sedona 1.3.1 Add unidata repo to your POM.xml <repositories> <repository> <id>unidata-all</id> <name>Unidata All</name> <url>https://artifacts.unidata.ucar.edu/repository/unidata-all/</url> </repository> </repositories> Then add cdm-core to your POM dependency. <dependency> <groupId> edu.ucar </groupId> <artifactId> cdm-core </artifactId> <version> 5.4.2 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.datasyslab/sernetcdf --> <dependency> <groupId> org.datasyslab </groupId> <artifactId> sernetcdf </artifactId> <version> 0.1.0 </version> </dependency> Use Sedona and third-party jars separately \u00b6 For Scala and Java users , if by any chance you don't want to use an uber jar that includes every dependency, you can use the following jars instead. Otherwise, please do not continue reading this section. Sedona with Apache Spark Spark 3.0+ and Scala 2.12 Spark 3.0+ and Scala 2.13 <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-core-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-sql-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-viz-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-core-3.0_2.13 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-sql-3.0_2.13 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-viz-3.0_2.13 </artifactId> <version> 1.3.0-incubating </version> </dependency> Sedona with Apache Flink Flink 1.12+ and Scala 2.12 <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-core-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-sql-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-flink-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> LocationTech JTS-core 1.18.0+ \u00b6 Under Eclipse Public License 2.0 (\"EPL\") or the Eclipse Distribution License 1.0 (a BSD Style License) <!-- https://mvnrepository.com/artifact/org.locationtech.jts/jts-core --> <dependency> <groupId> org.locationtech.jts </groupId> <artifactId> jts-core </artifactId> <version> 1.18.0 </version> </dependency> jts2geojson 0.16.1+ \u00b6 Under MIT License. Please make sure you exclude jts and jackson from this library. <!-- https://mvnrepository.com/artifact/org.wololo/jts2geojson --> <dependency> <groupId> org.wololo </groupId> <artifactId> jts2geojson </artifactId> <version> 0.16.1 </version> <exclusions> <exclusion> <groupId> org.locationtech.jts </groupId> <artifactId> jts-core </artifactId> </exclusion> <exclusion> <groupId> com.fasterxml.jackson.core </groupId> <artifactId> * </artifactId> </exclusion> </exclusions> </dependency> GeoTools 24.0+ \u00b6 GeoTools library is required only if you want to use CRS transformation and ShapefileReader. This wrapper library is a re-distriution of GeoTools official jars. The only purpose of this library is to bring GeoTools jars from OSGEO repository to Maven Central. This libary is under GNU Lesser General Public License (LGPL) license so we cannot package it in Sedona official release. <!-- https://mvnrepository.com/artifact/org.datasyslab/geotools-wrapper --> <dependency> <groupId> org.datasyslab </groupId> <artifactId> geotools-wrapper </artifactId> <version> 1.3.0-27.2 </version> </dependency> netCDF-Java 5.4.2 \u00b6 For Scala / Java API, it is required only if you want to read HDF/NetCDF files. HDF/NetCDF function is only supported in Spark RDD with Java/Scala API. The current function is deprecated and more mature support will be released soon. Under BSD 3-clause (compatible with Apache 2.0 license) Add HDF/NetCDF dependency Sedona 1.3.1+ Before Sedona 1.3.1 Add unidata repo to your POM.xml <repositories> <repository> <id>unidata-all</id> <name>Unidata All</name> <url>https://artifacts.unidata.ucar.edu/repository/unidata-all/</url> </repository> </repositories> Then add cdm-core to your POM dependency. <dependency> <groupId> edu.ucar </groupId> <artifactId> cdm-core </artifactId> <version> 5.4.2 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.datasyslab/sernetcdf --> <dependency> <groupId> org.datasyslab </groupId> <artifactId> sernetcdf </artifactId> <version> 0.1.0 </version> </dependency> SNAPSHOT versions \u00b6 Sometimes Sedona has a SNAPSHOT version for the upcoming release. It follows the same naming conversion but has \"SNAPSHOT\" as suffix in the version. For example, {{ no such element: dict object['current_snapshot'] }} In order to download SNAPSHOTs, you need to add the following repositories in your POM.XML or build.sbt build.sbt \u00b6 resolvers += \"Apache Software Foundation Snapshots\" at \" https://repository.apache.org/content/groups/snapshots \" POM.XML \u00b6 <repositories> <repository> <id> snapshots-repo </id> <url> https://repository.apache.org/content/groups/snapshots </url> <releases><enabled> false </enabled></releases> <snapshots><enabled> true </enabled></snapshots> </repository> </repositories>","title":"Maven Central coordinate"},{"location":"setup/maven-coordinates/#maven-coordinates","text":"Sedona Spark has four modules: sedona-core, sedona-sql, sedona-viz, sedona-python-adapter . sedona-python-adapter is a fat jar of sedona-core, sedona-sql and python adapter code. If you want to use SedonaViz, you will include one more jar: sedona-viz . Sedona Flink has four modules : sedona-core, sedona-sql, sedona-python-adapter, sedona-flink . sedona-python-adapter is a fat jar of sedona-core, sedona-sql .","title":"Maven Coordinates"},{"location":"setup/maven-coordinates/#use-sedona-fat-jars","text":"Warning For Scala/Java/Python/R users, this is the most common way to use Sedona in your environment. Do not use separate Sedona jars othwerwise you will get dependency conflicts. sedona-python-adapter already contains all you need. The optional GeoTools library is required only if you want to use CRS transformation and ShapefileReader. This wrapper library is a re-distriution of GeoTools official jars. The only purpose of this library is to bring GeoTools jars from OSGEO repository to Maven Central. This libary is under GNU Lesser General Public License (LGPL) license so we cannot package it in Sedona official release. Sedona with Apache Spark Spark 3.0+ and Scala 2.12 Spark 3.0 and Scala 2.13 <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-python-adapter-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-viz-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <!-- Optional: https://mvnrepository.com/artifact/org.datasyslab/geotools-wrapper --> <dependency> <groupId> org.datasyslab </groupId> <artifactId> geotools-wrapper </artifactId> <version> 1.3.0-27.2 </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-python-adapter-3.0_2.13 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-viz-3.0_2.13 </artifactId> <version> 1.3.0-incubating </version> </dependency> <!-- Optional: https://mvnrepository.com/artifact/org.datasyslab/geotools-wrapper --> <dependency> <groupId> org.datasyslab </groupId> <artifactId> geotools-wrapper </artifactId> <version> 1.3.0-27.2 </version> </dependency> Sedona with Apache Flink Flink 1.12+ and Scala 2.12 <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-python-adapter-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-flink_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <!-- Optional: https://mvnrepository.com/artifact/org.datasyslab/geotools-wrapper --> <dependency> <groupId> org.datasyslab </groupId> <artifactId> geotools-wrapper </artifactId> <version> 1.3.0-27.2 </version> </dependency>","title":"Use Sedona fat jars"},{"location":"setup/maven-coordinates/#netcdf-java-542","text":"For Scala / Java API, it is required only if you want to read HDF/NetCDF files. HDF/NetCDF function is only supported in Spark RDD with Java/Scala API. The current function is deprecated and more mature support will be released soon. Under BSD 3-clause (compatible with Apache 2.0 license) Add HDF/NetCDF dependency Sedona 1.3.1+ Before Sedona 1.3.1 Add unidata repo to your POM.xml <repositories> <repository> <id>unidata-all</id> <name>Unidata All</name> <url>https://artifacts.unidata.ucar.edu/repository/unidata-all/</url> </repository> </repositories> Then add cdm-core to your POM dependency. <dependency> <groupId> edu.ucar </groupId> <artifactId> cdm-core </artifactId> <version> 5.4.2 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.datasyslab/sernetcdf --> <dependency> <groupId> org.datasyslab </groupId> <artifactId> sernetcdf </artifactId> <version> 0.1.0 </version> </dependency>","title":"netCDF-Java 5.4.2"},{"location":"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately","text":"For Scala and Java users , if by any chance you don't want to use an uber jar that includes every dependency, you can use the following jars instead. Otherwise, please do not continue reading this section. Sedona with Apache Spark Spark 3.0+ and Scala 2.12 Spark 3.0+ and Scala 2.13 <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-core-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-sql-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-viz-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-core-3.0_2.13 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-sql-3.0_2.13 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-viz-3.0_2.13 </artifactId> <version> 1.3.0-incubating </version> </dependency> Sedona with Apache Flink Flink 1.12+ and Scala 2.12 <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-core-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-sql-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency> <dependency> <groupId> org.apache.sedona </groupId> <artifactId> sedona-flink-3.0_2.12 </artifactId> <version> 1.3.0-incubating </version> </dependency>","title":"Use Sedona and third-party jars separately"},{"location":"setup/maven-coordinates/#locationtech-jts-core-1180","text":"Under Eclipse Public License 2.0 (\"EPL\") or the Eclipse Distribution License 1.0 (a BSD Style License) <!-- https://mvnrepository.com/artifact/org.locationtech.jts/jts-core --> <dependency> <groupId> org.locationtech.jts </groupId> <artifactId> jts-core </artifactId> <version> 1.18.0 </version> </dependency>","title":"LocationTech JTS-core 1.18.0+"},{"location":"setup/maven-coordinates/#jts2geojson-0161","text":"Under MIT License. Please make sure you exclude jts and jackson from this library. <!-- https://mvnrepository.com/artifact/org.wololo/jts2geojson --> <dependency> <groupId> org.wololo </groupId> <artifactId> jts2geojson </artifactId> <version> 0.16.1 </version> <exclusions> <exclusion> <groupId> org.locationtech.jts </groupId> <artifactId> jts-core </artifactId> </exclusion> <exclusion> <groupId> com.fasterxml.jackson.core </groupId> <artifactId> * </artifactId> </exclusion> </exclusions> </dependency>","title":"jts2geojson 0.16.1+"},{"location":"setup/maven-coordinates/#geotools-240","text":"GeoTools library is required only if you want to use CRS transformation and ShapefileReader. This wrapper library is a re-distriution of GeoTools official jars. The only purpose of this library is to bring GeoTools jars from OSGEO repository to Maven Central. This libary is under GNU Lesser General Public License (LGPL) license so we cannot package it in Sedona official release. <!-- https://mvnrepository.com/artifact/org.datasyslab/geotools-wrapper --> <dependency> <groupId> org.datasyslab </groupId> <artifactId> geotools-wrapper </artifactId> <version> 1.3.0-27.2 </version> </dependency>","title":"GeoTools 24.0+"},{"location":"setup/maven-coordinates/#netcdf-java-542_1","text":"For Scala / Java API, it is required only if you want to read HDF/NetCDF files. HDF/NetCDF function is only supported in Spark RDD with Java/Scala API. The current function is deprecated and more mature support will be released soon. Under BSD 3-clause (compatible with Apache 2.0 license) Add HDF/NetCDF dependency Sedona 1.3.1+ Before Sedona 1.3.1 Add unidata repo to your POM.xml <repositories> <repository> <id>unidata-all</id> <name>Unidata All</name> <url>https://artifacts.unidata.ucar.edu/repository/unidata-all/</url> </repository> </repositories> Then add cdm-core to your POM dependency. <dependency> <groupId> edu.ucar </groupId> <artifactId> cdm-core </artifactId> <version> 5.4.2 </version> </dependency> <!-- https://mvnrepository.com/artifact/org.datasyslab/sernetcdf --> <dependency> <groupId> org.datasyslab </groupId> <artifactId> sernetcdf </artifactId> <version> 0.1.0 </version> </dependency>","title":"netCDF-Java 5.4.2"},{"location":"setup/maven-coordinates/#snapshot-versions","text":"Sometimes Sedona has a SNAPSHOT version for the upcoming release. It follows the same naming conversion but has \"SNAPSHOT\" as suffix in the version. For example, {{ no such element: dict object['current_snapshot'] }} In order to download SNAPSHOTs, you need to add the following repositories in your POM.XML or build.sbt","title":"SNAPSHOT versions"},{"location":"setup/maven-coordinates/#buildsbt","text":"resolvers += \"Apache Software Foundation Snapshots\" at \" https://repository.apache.org/content/groups/snapshots \"","title":"build.sbt"},{"location":"setup/maven-coordinates/#pomxml","text":"<repositories> <repository> <id> snapshots-repo </id> <url> https://repository.apache.org/content/groups/snapshots </url> <releases><enabled> false </enabled></releases> <snapshots><enabled> true </enabled></snapshots> </repository> </repositories>","title":"POM.XML"},{"location":"setup/modules/","text":"Sedona modules for Apache Spark \u00b6 Name API Introduction Core RDD SpatialRDDs and Query Operators. SQL SQL/DataFrame SQL interfaces for Sedona core. Viz RDD, SQL/DataFrame Visualization for Spatial RDD and DataFrame Zeppelin Apache Zeppelin Plugin for Apache Zeppelin 0.8.1+ API availability \u00b6 Core/RDD DataFrame/SQL Viz RDD/SQL Scala/Java \u2705 \u2705 \u2705 Python \u2705 \u2705 SQL only R \u2705 \u2705 \u2705","title":"Modules"},{"location":"setup/modules/#sedona-modules-for-apache-spark","text":"Name API Introduction Core RDD SpatialRDDs and Query Operators. SQL SQL/DataFrame SQL interfaces for Sedona core. Viz RDD, SQL/DataFrame Visualization for Spatial RDD and DataFrame Zeppelin Apache Zeppelin Plugin for Apache Zeppelin 0.8.1+","title":"Sedona modules for Apache Spark"},{"location":"setup/modules/#api-availability","text":"Core/RDD DataFrame/SQL Viz RDD/SQL Scala/Java \u2705 \u2705 \u2705 Python \u2705 \u2705 SQL only R \u2705 \u2705 \u2705","title":"API availability"},{"location":"setup/overview/","text":"Download statistics \u00b6 Maven PyPI CRAN Apache Sedona 80k/month Archived GeoSpark releases 300k/month What can Sedona do? \u00b6 Distributed spatial datasets \u00b6 Spatial RDD on Spark Spatial DataFrame/SQL on Spark Spatial DataStream on Flink Spatial Table/SQL on Flink Complex spatial objects \u00b6 Vector geometries / trajectories Raster images with Map Algebra Various input formats: CSV, TSV, WKT, WKB, GeoJSON, Shapefile, GeoTIFF, NetCDF/HDF Distributed spatial queries \u00b6 Spatial query: range query, range join query, distance join query, K Nearest Neighbor query Spatial index: R-Tree, Quad-Tree Rich spatial analytics tools \u00b6 Coordinate Reference System / Spatial Reference System Transformation High resolution map generation: Visualize Spatial DataFrame/RDD Apache Zeppelin integration Support Scala, Java, Python, R","title":"Overview"},{"location":"setup/overview/#download-statistics","text":"Maven PyPI CRAN Apache Sedona 80k/month Archived GeoSpark releases 300k/month","title":"Download statistics"},{"location":"setup/overview/#what-can-sedona-do","text":"","title":"What can Sedona do?"},{"location":"setup/overview/#distributed-spatial-datasets","text":"Spatial RDD on Spark Spatial DataFrame/SQL on Spark Spatial DataStream on Flink Spatial Table/SQL on Flink","title":"Distributed spatial datasets"},{"location":"setup/overview/#complex-spatial-objects","text":"Vector geometries / trajectories Raster images with Map Algebra Various input formats: CSV, TSV, WKT, WKB, GeoJSON, Shapefile, GeoTIFF, NetCDF/HDF","title":"Complex spatial objects"},{"location":"setup/overview/#distributed-spatial-queries","text":"Spatial query: range query, range join query, distance join query, K Nearest Neighbor query Spatial index: R-Tree, Quad-Tree","title":"Distributed spatial queries"},{"location":"setup/overview/#rich-spatial-analytics-tools","text":"Coordinate Reference System / Spatial Reference System Transformation High resolution map generation: Visualize Spatial DataFrame/RDD Apache Zeppelin integration Support Scala, Java, Python, R","title":"Rich spatial analytics tools"},{"location":"setup/platform/","text":"Sedona binary releases are compiled by Java 1.8 and Scala 2.11/2.12 and tested in the following environments: Warning Support of Spark 2.X and Scala 2.11 was removed in Sedona 1.3.0+ although some parts of the source code might still be compatible. Sedona 1.3.0+ release binary for both Scala 2.12 and 2.13. Sedona Scala/Java Sedona Python Sedona R Spark 2.4 Spark 3.0 Spark 3.1 Spark 3.2 Spark 3.3 Scala 2.11 not tested not tested not tested not tested not tested Scala 2.12 not tested \u2705 \u2705 \u2705 \u2705 Scala 2.13 not tested not tested not tested not tested \u2705 Spark 2.4 (Scala 2.11) Spark 3.0 (Scala 2.12) Spark 3.1 (Scala 2.12) Spark 3.2 (Scala 2.12) Spark 3.3 (Scala 2.12) Python 3.7 not tested \u2705 \u2705 \u2705 \u2705 Python 3.8 not tested not tested not tested not tested \u2705 Python 3.9 not tested not tested not tested not tested \u2705 Python 3.10 not tested not tested not tested not tested \u2705 Spark 2.4 Spark 3.0 Spark 3.1 Spark 3.2 Spark 3.3 Scala 2.11 not tested not tested not tested not tested not tested Scala 2.12 not tested \u2705 \u2705 \u2705 \u2705","title":"Language wrappers"},{"location":"setup/release-notes/","text":"Warning Support of Spark 2.X and Scala 2.11 was removed in Sedona 1.3.0+ although some parts of the source code might still be compatible. Sedona 1.3.0+ releases binary for both Scala 2.12 and 2.13. Sedona 1.3.1 \u00b6 This version is a minor release on Sedoma 1.3.0 line. It fixes a few critical bugs in 1.3.0. We suggest all 1.3.0 users to migrate to this version. Bug fixes \u00b6 SEDONA-204 - Init value in X/Y/Z max should be -Double.MAX SEDONA-206 - Performance regression of ST_Transform in 1.3.0-incubating SEDONA-210 - 1.3.0-incubating doesn't work with Scala 2.12 sbt projects SEDONA-211 - Enforce release managers to use JDK 8 SEDONA-201 - Implement ST_MLineFromText and ST_MPolyFromText methods New Feature \u00b6 SEDONA-196 - Add ST_Force3D to Sedona SEDONA-197 - Add ST_ZMin, ST_ZMax to Sedona SEDONA-199 - Add ST_NDims to Sedona Improvement \u00b6 SEDONA-194 - Merge org.datasyslab.sernetcdf into Sedona SEDONA-208 - Use Spark RuntimeConfig in SedonaConf Sedona 1.3.0 \u00b6 This version is a major release on Sedona 1.3.0 line and consists of 50 PRs. It includes many new functions, optimization and bug fixes. Highlights \u00b6 Sedona on Spark in this release is compiled against Spark 3.3. Sedona on Flink in this release is compiled against Flink 1.14. Scala 2.11 support is removed. Spark 2.X support is removed. Python 3.10 support is added. Aggregators in Flink are added Correctness fixes for corner cases in range join and distance join. Native GeoParquet read and write ( https://sedona.apache.org/tutorial/sql/#load-geoparquet ). df = spark.read.format(\"geoparquet\").option(\"fieldGeometry\", \"myGeometryColumn\").load(\"PATH/TO/MYFILE.parquet\") df.write.format(\"geoparquet\").save(\"PATH/TO/MYFILE.parquet\") DataFrame style API ( https://sedona.apache.org/tutorial/sql/#dataframe-style-api ) df.select(ST_Point(min_value, max_value).as(\"point\")) Allow WKT format CRS in ST_Transform ST_Transform(geom, \"srcWktString\", \"tgtWktString\") GEOGCS[\"WGS 84\", DATUM[\"WGS_1984\", SPHEROID[\"WGS 84\",6378137,298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\",0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\",0.0174532925199433, AUTHORITY[\"EPSG\",\"9122\"]], AUTHORITY[\"EPSG\",\"4326\"]] Bug fixes \u00b6 SEDONA-119 - ST_Touches join query returns true for polygons whose interiors intersect SEDONA-136 - Enable testAsEWKT for Flink SEDONA-137 - Fix ST_Buffer for Flink to work SEDONA-138 - Fix ST_GeoHash for Flink to work SEDONA-153 - Python Serialization Fails with Nulls SEDONA-158 - Fix wrong description about ST_GeometryN in the API docs SEDONA-169 - Fix ST_RemovePoint in accordance with the API document SEDONA-178 - Correctness issue in distance join queries SEDONA-182 - ST_AsText should not return SRID SEDONA-186 - collecting result rows of a spatial join query with SELECT * fails with serde error SEDONA-188 - Python warns about missing jars even when some are found SEDONA-193 - ST_AsBinary produces EWKB by mistake New Features \u00b6 SEDONA-94 - GeoParquet Support For Sedona SEDONA-125 - Allows customized CRS in ST_Transform SEDONA-166 - Provide Type-safe DataFrame Style API SEDONA-168 - Add ST_Normalize to Apache Sedona SEDONA-171 - Add ST_SetPoint to Apache Sedona Improvement \u00b6 SEDONA-121 - Add equivalent constructors left over from Spark to Flink SEDONA-132 - Create common module for SQL functions SEDONA-133 - Allow user-defined schemas in Adapter.toDf() SEDONA-139 - Fix wrong argument order in Flink unit tests SEDONA-140 - Update Sedona Dependencies in R Package SEDONA-143 - Add missing unit tests for the Flink predicates SEDONA-144 - Add ST_AsGeoJSON to the Flink API SEDONA-145 - Fix ST_AsEWKT to reserve the Z coordinate SEDONA-146 - Add missing output funtions to the Flink API SEDONA-147 - Add SRID functions to the Flink API SEDONA-148 - Add boolean functions to the Flink API SEDONA-149 - Add Python 3.10 support SEDONA-151 - Add ST aggregators to Sedona Flink SEDONA-152 - Add reader/writer functions for GML and KML SEDONA-154 - Add measurement functions to the Flink API SEDONA-157 - Add coordinate accessors to the Flink API SEDONA-159 - Add Nth accessor functions to the Flink API SEDONA-160 - Fix geoparquetIOTests.scala to cleanup after test SEDONA-161 - Add ST_Boundary to the Flink API SEDONA-162 - Add ST_Envelope to the Flink API SEDONA-163 - Better handle of unsupported types in shapefile reader SEDONA-164 - Add geometry count functions to the Flink API SEDONA-165 - Upgrade Apache Rat to 0.14 SEDONA-170 - Add ST_AddPoint and ST_RemovePoint to the Flink API SEDONA-172 - Add ST_LineFromMultiPoint to Apache Sedona SEDONA-176 - Make ST_Contains conform with OGC standard, and add ST_Covers and ST_CoveredBy functions. SEDONA-177 - Support spatial predicates other than INTERSECTS and COVERS/COVERED_BY in RangeQuery.SpatialRangeQuery and JoinQuery.SpatialJoinQuery SEDONA-181 - Build fails with java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ SEDONA-189 - Prepare geometries in broadcast join SEDONA-192 - Null handling in predicates SEDONA-195 - Add wkt validation and an optional srid to ST_GeomFromWKT/ST_GeomFromText Task \u00b6 SEDONA-150 - Drop Spark 2.4 and Scala 2.11 support Sedona 1.2.1 \u00b6 This version is a maintenance release on Sedona 1.2.0 line. It includes bug fixes. Sedona on Spark is now compiled against Spark 3.3, instead of Spark 3.2. SQL (for Spark) \u00b6 Bug fixes: SEDONA-104 : Bug in reading band values of GeoTiff images SEDONA-118 : Fix the wrong result in ST_Within SEDONA-123 : Fix the check for invalid lat/lon in ST_GeoHash Improvement: SEDONA-96 : Refactor ST_MakeValid to use GeometryFixer SEDONA-108 : Write support for GeoTiff images SEDONA-122 : Overload ST_GeomFromWKB for BYTES column SEDONA-127 : Add null safety to ST_GeomFromWKT/WKB/Text SEDONA-129 : Support Spark 3.3 SEDONA-135 : Consolidate and upgrade hadoop dependency New features: SEDONA-107 : Add St_Reverse function SEDONA-105 : Add ST_PointOnSurface function SEDONA-95 : Add ST_Disjoint predicate SEDONA-112 : Add ST_AsEWKT SEDONA-106 : Add ST_LineFromText SEDONA-117 : Add RS_AppendNormalizedDifference SEDONA-97 : Add ST_Force_2D SEDONA-98 : Add ST_IsEmpty SEDONA-116 : Add ST_YMax and ST_Ymin SEDONA-115 : Add ST_XMax and ST_Min SEDONA-120 : Add ST_BuildArea SEDONA-113 : Add ST_PointN SEDONA-124 : Add ST_CollectionExtract SEDONA-109 : Add ST_OrderingEquals Flink \u00b6 New features: SEDONA-107 : Add St_Reverse function SEDONA-105 : Add ST_PointOnSurface function SEDONA-95 : Add ST_Disjoint predicate SEDONA-112 : Add ST_AsEWKT SEDONA-97 : Add ST_Force_2D SEDONA-98 : Add ST_IsEmpty SEDONA-116 : Add ST_YMax and ST_Ymin SEDONA-115 : Add ST_XMax and ST_Min SEDONA-120 : Add ST_BuildArea SEDONA-113 : Add ST_PointN SEDONA-110 : Add ST_GeomFromGeoHash SEDONA-121 : More ST constructors to Flink SEDONA-122 : Overload ST_GeomFromWKB for BYTES column Sedona 1.2.0 \u00b6 This version is a major release on Sedona 1.2.0 line. It includes bug fixes and new features: Sedona with Apache Flink. RDD \u00b6 Bug fix: SEDONA-18 : Fix an error reading Shapefile SEDONA-73 : Exclude scala-library from scala-collection-compat Improvement: SEDONA-77 : Refactor Format readers and spatial partitioning functions to be standalone libraries. So they can be used by Flink and others. SQL \u00b6 New features: SEDONA-4 : Handle nulls in SQL functions SEDONA-65 : Create ST_Difference function SEDONA-68 Add St_Collect function. SEDONA-82 : Create ST_SymmDifference function SEDONA-75 : Add support for \"3D\" geometries: Preserve Z coordinates on geometries when serializing, ST_AsText , ST_Z, ST_3DDistance SEDONA-86 : Support empty geometries in ST_AsBinary and ST_AsEWKB SEDONA-90 : Add ST_Union SEDONA-100 : Add st_multi function Bug fix: SEDONA-89 : GeometryUDT equals should test equivalence of the other object Flink \u00b6 Major update: SEDONA-80 : Geospatial stream processing support in Flink Table API SEDONA-85 : ST_Geohash function in Flink SEDONA-87 : Support Flink Table and DataStream conversion SEDONA-93 : Add ST_GeomFromGeoJSON Sedona 1.1.1 \u00b6 This version is a maintenance release on Sedona 1.1.X line. It includes bug fixes and a few new functions. Global \u00b6 New feature: SEDONA-73 : Scala source code supports Scala 2.13 SQL \u00b6 Bug fix: SEDONA-67 : Support Spark 3.2 New features: SEDONA-43 : Add ST_GeoHash and ST_GeomFromGeoHash SEDONA-45 : Add ST_MakePolygon SEDONA-71 : Add ST_AsBinary, ST_AsEWKB, ST_SRID, ST_SetSRID Sedona 1.1.0 \u00b6 This version is a major release on Sedona 1.1.0 line. It includes bug fixes and new features: R language API, Raster data and Map algebra support Global \u00b6 Dependency upgrade: SEDONA-30 : Use Geotools-wrapper 1.1.0-24.1 to include geotools GeoTiff libraries. Improvement on join queries in core and SQL: SEDONA-63 : Skip empty partitions in NestedLoopJudgement SEDONA-64 : Broadcast dedupParams to improve performance Behavior change: SEDONA-62 : Ignore HDF test in order to avoid NASA copyright issue Core \u00b6 Bug fix: SEDONA-41 : Fix rangeFilter bug when the leftCoveredByRight para is false SEDONA-53 : Fix SpatialKnnQuery NullPointerException SQL \u00b6 Major update: SEDONA-30 : Add GeoTiff raster I/O and Map Algebra function New function: SEDONA-27 : Add ST_Subdivide and ST_SubdivideExplode functions Bug fix: SEDONA-56 : Fix broadcast join with Adapter Query Engine enabled SEDONA-22 , SEDONA-60 : Fix join queries in SparkSQL when one side has no rows or only one row Viz \u00b6 N/A Python \u00b6 Improvement: SEDONA-59 : Make pyspark dependency of Sedona Python optional Bug fix: SEDONA-50 : Remove problematic logging conf that leads to errors on Databricks Fix the issue: Spark dependency in setup.py was configured to be < v3.1.0 by mistake. R \u00b6 Major update: SEDONA-31 : Add R interface for Sedona Sedona 1.0.1 \u00b6 This version is a maintenance release on Sedona 1.0.0 line. It includes bug fixes, some new features, one API change Known issue \u00b6 In Sedona v1.0.1 and eariler versions, the Spark dependency in setup.py was configured to be < v3.1.0 by mistake . When you install Sedona Python (apache-sedona v1.0.1) from Pypi, pip might unstall PySpark 3.1.1 and install PySpark 3.0.2 on your machine. Three ways to fix this: After install apache-sedona v1.0.1, unstall PySpark 3.0.2 and reinstall PySpark 3.1.1 Ask pip not to install Sedona dependencies: pip install --no-deps apache-sedona Install Sedona from the latest setup.py (on GitHub) manually. Global \u00b6 Dependency upgrade: SEDONA-16 : Use a GeoTools Maven Central wrapper to fix failed Jupyter notebook examples SEDONA-29 : upgrade to Spark 3.1.1 SEDONA-33 : jts2geojson version from 0.14.3 to 0.16.1 Core \u00b6 Bug fix: SEDONA-35 : Address user-data mutability issue with Adapter.toDF() SQL \u00b6 Bug fix: SEDONA-14 : Saving dataframe to CSV or Parquet fails due to unknown type SEDONA-15 : Add ST_MinimumBoundingRadius and ST_MinimumBoundingCircle functions SEDONA-19 : Global indexing does not work with SQL joins SEDONA-20 : Case object GeometryUDT and GeometryUDT instance not equal in Spark 3.0.2 New function: SEDONA-21 : allows Sedona to be used in pure SQL environment SEDONA-24 : Add ST_LineSubString and ST_LineInterpolatePoint SEDONA-26 : Add broadcast join support Viz \u00b6 Improvement: SEDONA-32 : Speed up ST_Render API change: SEDONA-29 : Upgrade to Spark 3.1.1 and fix ST_Pixelize Python \u00b6 Bug fix: SEDONA-19 : Global indexing does not work with SQL joins Sedona 1.0.0 \u00b6 This version is the first Sedona release since it joins the Apache Incubator. It includes new functions, bug fixes, and API changes . Global \u00b6 Key dependency upgrade: SEDONA-1 : upgrade to JTS 1.18 upgrade to GeoTools 24.0 upgrade to jts2geojson 0.14.3 Key dependency packaging strategy change: JTS, GeoTools, jts2geojson are no longer packaged in Sedona jars. End users need to add them manually. See here . Key compilation target change: SEDONA-3 : Paths and class names have been changed to Apache Sedona SEDONA-7 : build the source code for Spark 2.4, 3.0, Scala 2.11, 2.12, Python 3.7, 3.8, 3.9. See here . Sedona-core \u00b6 Bug fix: PR 443 : read multiple Shape Files by multiPartitions PR 451 ( API change ): modify CRSTransform to ignore datum shift New function: SEDONA-8 : spatialRDD.flipCoordinates() API / behavior change: PR 488 : JoinQuery.SpatialJoinQuery/DistanceJoinQuery now returns <Geometry, List> instead of <Geometry, HashSet> because we can no longer use HashSet in Sedona for duplicates removal. All original duplicates in both input RDDs will be preserved in the output. Sedona-sql \u00b6 Bug fix: SEDONA-8 ( API change ): ST_Transform slow due to lock contention. See here PR 427 : ST_Point and ST_PolygonFromEnvelope now allows Double type New function: PR 499 : ST_Azimuth, ST_X, ST_Y, ST_StartPoint, ST_Boundary, ST_EndPoint, ST_ExteriorRing, ST_GeometryN, ST_InteriorRingN, ST_Dump, ST_DumpPoints, ST_IsClosed, ST_NumInteriorRings, ST_AddPoint, ST_RemovePoint, ST_IsRing PR 459 : ST_LineMerge PR 460 : ST_NumGeometries PR 469 : ST_AsGeoJSON SEDONA-8 : ST_FlipCoordinates Behavior change: PR 480 : Aggregate Functions rewrite for new Aggregator API. The functions can be used as typed functions in code and enable compilation-time type check. API change: SEDONA-11 : Adapter.toDf() will directly generate a geometry type column. ST_GeomFromWKT is no longer needed. Sedona-viz \u00b6 API change: Drop the function which can generate SVG vector images because the required library has an incompatible license and the SVG image is not good at plotting big data Sedona Python \u00b6 API/Behavior change: Python-to-Sedona adapter is moved to a separate module. To use Sedona Python, see here New function: PR 448 : Add support for partition number in spatialPartitioning function spatial_rdd.spatialPartitioning(grid_type, NUM_PARTITION) GeoSpark legacy release notes \u00b6 v1.3.1 \u00b6 This version includes the official release of GeoSpark Python wrapper. It also contains a number of bug fixes and new functions. The tutorial section provides some articles to explain the usage of GeoSpark Python wrapper. GeoSpark Core Bug fix: Issue # 344 and PR # 365 : GeoJSON reader cannot handle \"id\" Issue # 420 and PR # 421 : Cannot handle null value in geojson properties PR # 422 : Use HTTPS to resolve dependencies in Maven Build New functions: Issue # 399 and PR # 401 : saveAsWKB PR # 402 : saveAsWKT GeoSpark SQL New functions: PR # 359 : ST_NPoints PR # 373 : ST_GeometryType PR # 398 : ST_SimplifyPreserveTopology PR # 406 : ST_MakeValid PR # 416 : ST_Intersection_aggr Performance: Issue # 345 and PR # 346 : the performance issue of Adapter.toDF() function Bug fix: Issue # 395 and PR # 396 : Fix the geometry col bug in Adapter GeoSpark Viz Bug fix: Issue # 378 and PR # 379 : Classpath issue when integrating GeoSparkViz with s3 GeoSpark Python Add new GeoSpark python wrapper for RDD and SQL APIs Contributors (12) Mariano Gonzalez Pawe\u0142 Koci\u0144ski Semen Komissarov Jonathan Leitschuh Netanel Malka Keivan Shahida Sachio Wakai Hui Wang Wrussia Jia Yu Harry Zhu Ilya Zverev v1.3.0 \u00b6 This release has been skipped due to a bug in GeoSpark Python wrapper. v1.2.0 \u00b6 This version contains numerous bug fixes, new functions, and new GeoSpark module. License change From MIT to Apache License 2.0 GeoSpark Core Bug fix: Issue # 224 load GeoJSON non-spatial attributes. Issue # 228 Shapefiel Reader fails to handle UNDEFINED type. Issue # 320 Read CSV ArrayIndexOutOfBoundsException New functions: PR # 270 # 298 Add GeoJSON Reader to load GeoJSON with all attributes. See GeoSpark doc for an example. PR # 314 Add WktReader and WkbReader. Their usage is simialr to GeoJSON reader. GeoSpark SQL Bug fix: Issue # 244 JTS side location conflict Issue # 245 Drop ST_Circle in 1.2.0 Issue # 288 ST_isValid fails Issue # 321 ST_Point doesn't accept null user data PR # 284 ST_Union_Aggr bug PR # 331 Adapter doesn't handle null values New SQL functions: ST_IsValid ST_PrecisionReduce ST_Touches ST_Overlaps ST_Equals ST_Crosses ST_IsSimple ST_AsText Behavior / API change: GeoSpark Adapter will automatically carry all attributes between DataFrame and RDD. No need to use UUID in SQL ST functions to pass values. Please read GeoSpark doc . GeoSpark Viz Bug fix: Issue # 231 Pixel NullPointException Issue # 234 OutOfMemory for large images New functions Add the DataFrame support. Please read GeoSpark doc ST_Pixelize ST_TileName ST_Colorize ST_EncodeImage ST_Render Behavior / API change GeoSparkViz Maven coordinate changed. You need to specify Spark version. Please read GeoSpark Maven coordinate GeoSpark-Zeppelin New functions Add the support of connecting GeoSpark and Zeppelin Add the support of connecting GeoSparkViz and Zeppelin Contributors (13) Anton Peniaziev, Avshalom Orenstein, Jia Yu, Jordan Perr-Sauer, JulienPeloton, Sergii Mikhtoniuk, Netanel Malka, Rishabh Mishra, sagar1993, Shi-Hao Liu, Serhuela, tociek, Wrussia v1.1.3 \u00b6 This version contains a critical bug fix for GeoSpark-core RDD API. GeoSpark Core Fixed Issue # 222 : geometry toString() method has cumulative non-spatial attributes. See PR # 223 GeoSpark SQL None GeoSpark Viz None v1.1.2 \u00b6 This version contains several bug fixes and several small improvements. GeoSpark Core Added WKB input format support (Issue # 2 , 213 ): See PR # 203 , 216 . Thanks for the patch from Lucas C.! Added empty constructors for typed SpatialRDDs. This is especially useful when the users want to load a persisted RDD from disk and assemble a typed SpatialRDD by themselves. See PR # 211 Fixed Issue # 214 : duplicated geometry parts when print each Geometry in a SpatialRDD to a String using toString() method. See PR # 216 GeoSpark SQL Added ST_GeomFromWKB expression (Issue # 2 ): See PR # 203 . Thanks for the patch from Lucas C.! Fixed Issue # 193 : IllegalArgumentException in RangeJoin: Number of partitions must be >= 0. See PR # 207 Fixed Issue # 204 : Wrong ST_Intersection result. See PR # 205 [For Developer] Separate the expression catalog and the udf registrator to simplify the steps of merging patches among different Spark versions. See PR # 209 GeoSpark Viz None v1.1.1 \u00b6 This release has been skipped due to wrong Maven Central configuration. v1.1.0 \u00b6 This version adds very efficient R-Tree and Quad-Tree index serializers and supports Apache Spark and SparkSQL 2.3. See Maven Central coordinate to locate the particular version. GeoSpark Core Fixed Issue # 185 : CRStransform throws Exception for Bursa wolf parameters. See PR # 189 . Fixed Issue # 190 : Shapefile reader doesn't support Chinese characters (\u4e2d\u6587\u5b57\u7b26). See PR # 192 . Add R-Tree and Quad-Tree index serializer. GeoSpark custom index serializer has around 2 times smaller index size and faster serialization than Apache Spark kryo serializer. See PR # 177 . GeoSpark SQL Fixed Issue # 194 : doesn't support Spark 2.3. Fixed Issue # 188 :ST_ConvexHull should accept any type of geometry as an input. See PR # 189 . Add ST_Intersection function. See Issue # 110 and PR # 189 . GeoSpark Viz Fixed Issue # 154 : GeoSpark kryp serializer and GeoSparkViz conflict. See PR # 178 v1.0.1 \u00b6 GeoSpark Core Fixed Issue # 170 GeoSpark SQL Fixed Issue # 171 Added the support of SparkSQL 2.2. GeoSpark-SQL for Spark 2.1 is published separately ( Maven Coordinates ). GeoSpark Viz None v1.0.0 \u00b6 GeoSpark Core Add GeoSparkConf class to read GeoSparkConf from SparkConf GeoSpark SQL Initial release: fully supports SQL/MM-Part3 Spatial SQL standard GeoSpark Viz Republish GeoSpark Viz under \"GeoSparkViz\" folder. All \"Babylon\" strings have been replaced to \"GeoSparkViz\" v0.9.1 (GeoSpark-core) \u00b6 Bug fixes : Fixed \"Missing values when reading Shapefile\": Issue #141 Performance improvement : Solved Issue #91 , #103 , #104 , #125 , #150 . Add GeoSpark customized Kryo Serializer to significantly reduce memory footprint. This serializer which follows Shapefile compression rule takes less memory than the default Kryo. See PR 139 . Delete the duplicate removal by using Reference Point concept. This eliminates one data shuffle but still guarantees the accuracy. See PR 131 . New Functionalities added : SpatialJoinQueryFlat/DistanceJoinQueryFlat returns the join query in a flat way following database iteration model: Each row has fixed two members [Polygon, Point]. This API is more efficient for unbalanced length of join results. The left and right shapes in Range query, Distance query, Range join query, Distance join query can be switched. The index side in Range query, Distance query, Range join query, Distance join query can be switched. The generic SpatialRdd supports heterogenous geometries Add KDB-Tree spatial partitioning method which is more balanced than Quad-Tree Range query, Distance query, Range join query, Distance join query, KNN query supports heterogenous inputs. v0.8.2 (GeoSpark-core) \u00b6 Bug fixes : Fix the shapefile RDD null pointer bug when running in cluster mode. See Issue https://github.com/DataSystemsLab/GeoSpark/issues/115 New function added : Provide granular control to SpatialRDD sampling utils. SpatialRDD has a setter and getter for a parameter called \"sampleNumber\". The user can manually specify the sample size for spatial partitioning. v0.8.1 (GeoSpark-core) \u00b6 Bug fixes : (1) Fix the blank DBF attribute error when load DBF along with SHX file. (2) Allow user to call CRS transformation function at any time. Previously, it was only allowed in GeoSpark constructors v0.8.0 (GeoSpark-core) \u00b6 New input format added : GeoSpark is able to load and query ESRI ShapeFile (.shp, .shx, .dbf) from local disk and HDFS! Users first need to build a Shapefile RDD by giving Spark Context and an input path then call ShapefileRDD.getSpatialRDD to retrieve Spatial RDD. ( Scala Example , Java Example ) Join Query Performance enhancement 1 : GeoSpark provides a new Quad-Tree Spatial Partitioning method to speed up Join Query. Users need to pass GridType.QUADTREE parameter to RDD1.spatialPartitioning() function. Then users need to use RDD1.partitionTree in RDD2.spatialPartitioning() function. This Quad-Tree partitioning method (1) avoids overflowed spatial objects when partitioning spatial objects. (2) checking a spatial object against the Quad-Tree grids is completed in a log complexity tree search. ( Scala Example , Java Example ) Join Query Performance enhancement 2 : Internally, GeoSpark uses zipPartitions instead of CoGroup to join two Spatial RDD so that the incurred shuffle overhead decreases. SpatialRDD Initialization Performance enhancement : GeoSpark uses mapPartition instead of flatMapToPair to generate Spatial Objects. This will speed up the calculation. API changed : Since it chooses mapPartition API in mappers, GeoSpark no longer supports the old user supplified format mapper. However, if you are using your own format mapper for old GeoSpark version, you just need to add one more loop to fit in GeoSpark 0.8.0. Please see GeoSpark user supplied format mapper examples Alternative SpatialRDD constructor added : GeoSpark no longer forces users to provide StorageLevel parameter in their SpatialRDD constructors. This will siginicantly accelerate all Spatial RDD initialization. If he only needs Spatial Range Query and KNN query, the user can totally remove this parameter from their constructors. If he needs Spatial Join Query or Distance Join Query but he knows his dataset boundary and approximate total count, the user can also remove StorageLevel parameter and append a Envelope type dataset boundary and an approxmiate total count as additional parameters. If he needs Spatial Join Query or Distance Join Query but knows nothing about his dataset , the user still has to pass StorageLevel parameter. Bug fix : Fix bug Issue #97 and Issue #100 . v0.1 - v0.7 \u00b6 Version Summary 0.7.0 Coordinate Reference System (CRS) Transformation (aka. Coordinate projection) added: GeoSpark allows users to transform the original CRS (e.g., degree based coordinates such as EPSG:4326 and WGS84) to any other CRS (e.g., meter based coordinates such as EPSG:3857) so that it can accurately process both geographic data and geometrical data. Please specify your desired CRS in GeoSpark Spatial RDD constructor ( Example ); Unnecessary dependencies removed : NetCDF/HDF support depends on SerNetCDF . SetNetCDF becomes optional dependency to reduce fat jar size; Default JDK/JRE change to JDK/JRE 1.8 : To satisfy CRS transformation requirement, GeoSpark is compiled by JDK 1.8 by default; Bug fix : fix a small format bug when output spatial RDD to disk. 0.6.2 New input format added: Add a new input format mapper called EarthdataHDFPointMapper so that GeoSpark can load, query and save NASA Petabytes NetCDF/HDF Earth Data ( Scala Example , Java Example ); Bug fix: Print UserData attribute when output Spatial RDDs as GeoJSON or regular text file 0.6.1 Bug fixes: Fix typos LineString DistanceJoin API 0.6.0 Major updates: (1) DistanceJoin is merged into JoinQuery. GeoSpark now supports complete DistanceJoin between Points, Polygons, and LineStrings. (2) Add Refine Phase to Spatial Range and Join Query. Use real polygon coordinates instead of its MBR to filter the final results. API changes: All spatial range and join queries now take a parameter called ConsiderBoundaryIntersection . This will tell GeoSpark whether returns the objects intersect with windows. 0.5.3 Bug fix: Fix Issue #69 : Now, if two objects have the same coordinates but different non-spatial attributes (UserData), GeoSpark treats them as different objects. 0.5.2 Bug fix: Fix Issue #58 and Issue #60 ; Performance enhancement: (1) Deprecate all old Spatial RDD constructors. See the JavaDoc here . (2) Recommend the new SRDD constructors which take an additional RDD storage level and automatically cache rawSpatialRDD to accelerate internal SRDD analyze step 0.5.1 Bug fix: (1) GeoSpark: Fix inaccurate KNN result when K is large (2) GeoSpark: Replace incompatible Spark API call Issue #55 ; (3) Babylon: Remove JPG output format temporarily due to the lack of OpenJDK support 0.5.0 Major updates: We are pleased to announce the initial version of Babylon a large-scale in-memory geospatial visualization system extending GeoSpark. Babylon and GeoSpark are integrated together. You can just import GeoSpark and enjoy! More details are available here: Babylon GeoSpatial Visualization 0.4.0 Major updates: ( Example ) 1. Refactor constrcutor API usage. 2. Simplify Spatial Join Query API. 3. Add native support for LineStringRDD; Functionality enhancement: 1. Release the persist function back to users. 2. Add more exception explanations. 0.3.2 Functionality enhancement: 1. JTSplus Spatial Objects now carry the original input data. Each object stores \"UserData\" and provides getter and setter. 2. Add a new SpatialRDD constructor to transform a regular data RDD to a spatial partitioned SpatialRDD. 0.3.1 Bug fix: Support Apache Spark 2.X version, fix a bug which results in inaccurate results when doing join query, add more unit test cases 0.3 Major updates: Significantly shorten query time on spatial join for skewed data; Support load balanced spatial partitioning methods (also serve as the global index); Optimize code for iterative spatial data mining 0.2 Improve code structure and refactor API 0.1 Support spatial range, join and Knn GeoSpark-Viz (old) \u00b6 Version Summary 0.2.2 Add the support of new output storage : Now the user is able to output gigapixel or megapixel resolution images (image tiles or stitched single image) to HDFS and Amazon S3. Please use the new ImageGenerator not the BabylonImageGenerator class. 0.2.1 Performance enhancement : significantly accelerate single image generation pipeline. Bug fix :fix a bug in scatter plot parallel rendering. 0.2.0 API updates for Issue #80 : 1. Babylon now has two different OverlayOperators for raster image and vector image: RasterOverlayOperator and VectorOverlayOperator; 2. Babylon merged old SparkImageGenerator and NativeJavaGenerator into a new BabylonImageGenerator which has neat APIs; New feature: Babylon can use Scatter Plot to visualize NASA Petabytes NetCDF/HDF format Earth Data. ( Scala Example , Java Example ) 0.1.1 Major updates: Babylon supports vector image and outputs SVG image format 0.1.0 Major updates: Babylon initial version supports raster images","title":"Release notes"},{"location":"setup/release-notes/#sedona-131","text":"This version is a minor release on Sedoma 1.3.0 line. It fixes a few critical bugs in 1.3.0. We suggest all 1.3.0 users to migrate to this version.","title":"Sedona 1.3.1"},{"location":"setup/release-notes/#bug-fixes","text":"SEDONA-204 - Init value in X/Y/Z max should be -Double.MAX SEDONA-206 - Performance regression of ST_Transform in 1.3.0-incubating SEDONA-210 - 1.3.0-incubating doesn't work with Scala 2.12 sbt projects SEDONA-211 - Enforce release managers to use JDK 8 SEDONA-201 - Implement ST_MLineFromText and ST_MPolyFromText methods","title":"Bug fixes"},{"location":"setup/release-notes/#new-feature","text":"SEDONA-196 - Add ST_Force3D to Sedona SEDONA-197 - Add ST_ZMin, ST_ZMax to Sedona SEDONA-199 - Add ST_NDims to Sedona","title":"New Feature"},{"location":"setup/release-notes/#improvement","text":"SEDONA-194 - Merge org.datasyslab.sernetcdf into Sedona SEDONA-208 - Use Spark RuntimeConfig in SedonaConf","title":"Improvement"},{"location":"setup/release-notes/#sedona-130","text":"This version is a major release on Sedona 1.3.0 line and consists of 50 PRs. It includes many new functions, optimization and bug fixes.","title":"Sedona 1.3.0"},{"location":"setup/release-notes/#highlights","text":"Sedona on Spark in this release is compiled against Spark 3.3. Sedona on Flink in this release is compiled against Flink 1.14. Scala 2.11 support is removed. Spark 2.X support is removed. Python 3.10 support is added. Aggregators in Flink are added Correctness fixes for corner cases in range join and distance join. Native GeoParquet read and write ( https://sedona.apache.org/tutorial/sql/#load-geoparquet ). df = spark.read.format(\"geoparquet\").option(\"fieldGeometry\", \"myGeometryColumn\").load(\"PATH/TO/MYFILE.parquet\") df.write.format(\"geoparquet\").save(\"PATH/TO/MYFILE.parquet\") DataFrame style API ( https://sedona.apache.org/tutorial/sql/#dataframe-style-api ) df.select(ST_Point(min_value, max_value).as(\"point\")) Allow WKT format CRS in ST_Transform ST_Transform(geom, \"srcWktString\", \"tgtWktString\") GEOGCS[\"WGS 84\", DATUM[\"WGS_1984\", SPHEROID[\"WGS 84\",6378137,298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\",0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\",0.0174532925199433, AUTHORITY[\"EPSG\",\"9122\"]], AUTHORITY[\"EPSG\",\"4326\"]]","title":"Highlights"},{"location":"setup/release-notes/#bug-fixes_1","text":"SEDONA-119 - ST_Touches join query returns true for polygons whose interiors intersect SEDONA-136 - Enable testAsEWKT for Flink SEDONA-137 - Fix ST_Buffer for Flink to work SEDONA-138 - Fix ST_GeoHash for Flink to work SEDONA-153 - Python Serialization Fails with Nulls SEDONA-158 - Fix wrong description about ST_GeometryN in the API docs SEDONA-169 - Fix ST_RemovePoint in accordance with the API document SEDONA-178 - Correctness issue in distance join queries SEDONA-182 - ST_AsText should not return SRID SEDONA-186 - collecting result rows of a spatial join query with SELECT * fails with serde error SEDONA-188 - Python warns about missing jars even when some are found SEDONA-193 - ST_AsBinary produces EWKB by mistake","title":"Bug fixes"},{"location":"setup/release-notes/#new-features","text":"SEDONA-94 - GeoParquet Support For Sedona SEDONA-125 - Allows customized CRS in ST_Transform SEDONA-166 - Provide Type-safe DataFrame Style API SEDONA-168 - Add ST_Normalize to Apache Sedona SEDONA-171 - Add ST_SetPoint to Apache Sedona","title":"New Features"},{"location":"setup/release-notes/#improvement_1","text":"SEDONA-121 - Add equivalent constructors left over from Spark to Flink SEDONA-132 - Create common module for SQL functions SEDONA-133 - Allow user-defined schemas in Adapter.toDf() SEDONA-139 - Fix wrong argument order in Flink unit tests SEDONA-140 - Update Sedona Dependencies in R Package SEDONA-143 - Add missing unit tests for the Flink predicates SEDONA-144 - Add ST_AsGeoJSON to the Flink API SEDONA-145 - Fix ST_AsEWKT to reserve the Z coordinate SEDONA-146 - Add missing output funtions to the Flink API SEDONA-147 - Add SRID functions to the Flink API SEDONA-148 - Add boolean functions to the Flink API SEDONA-149 - Add Python 3.10 support SEDONA-151 - Add ST aggregators to Sedona Flink SEDONA-152 - Add reader/writer functions for GML and KML SEDONA-154 - Add measurement functions to the Flink API SEDONA-157 - Add coordinate accessors to the Flink API SEDONA-159 - Add Nth accessor functions to the Flink API SEDONA-160 - Fix geoparquetIOTests.scala to cleanup after test SEDONA-161 - Add ST_Boundary to the Flink API SEDONA-162 - Add ST_Envelope to the Flink API SEDONA-163 - Better handle of unsupported types in shapefile reader SEDONA-164 - Add geometry count functions to the Flink API SEDONA-165 - Upgrade Apache Rat to 0.14 SEDONA-170 - Add ST_AddPoint and ST_RemovePoint to the Flink API SEDONA-172 - Add ST_LineFromMultiPoint to Apache Sedona SEDONA-176 - Make ST_Contains conform with OGC standard, and add ST_Covers and ST_CoveredBy functions. SEDONA-177 - Support spatial predicates other than INTERSECTS and COVERS/COVERED_BY in RangeQuery.SpatialRangeQuery and JoinQuery.SpatialJoinQuery SEDONA-181 - Build fails with java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ SEDONA-189 - Prepare geometries in broadcast join SEDONA-192 - Null handling in predicates SEDONA-195 - Add wkt validation and an optional srid to ST_GeomFromWKT/ST_GeomFromText","title":"Improvement"},{"location":"setup/release-notes/#task","text":"SEDONA-150 - Drop Spark 2.4 and Scala 2.11 support","title":"Task"},{"location":"setup/release-notes/#sedona-121","text":"This version is a maintenance release on Sedona 1.2.0 line. It includes bug fixes. Sedona on Spark is now compiled against Spark 3.3, instead of Spark 3.2.","title":"Sedona 1.2.1"},{"location":"setup/release-notes/#sql-for-spark","text":"Bug fixes: SEDONA-104 : Bug in reading band values of GeoTiff images SEDONA-118 : Fix the wrong result in ST_Within SEDONA-123 : Fix the check for invalid lat/lon in ST_GeoHash Improvement: SEDONA-96 : Refactor ST_MakeValid to use GeometryFixer SEDONA-108 : Write support for GeoTiff images SEDONA-122 : Overload ST_GeomFromWKB for BYTES column SEDONA-127 : Add null safety to ST_GeomFromWKT/WKB/Text SEDONA-129 : Support Spark 3.3 SEDONA-135 : Consolidate and upgrade hadoop dependency New features: SEDONA-107 : Add St_Reverse function SEDONA-105 : Add ST_PointOnSurface function SEDONA-95 : Add ST_Disjoint predicate SEDONA-112 : Add ST_AsEWKT SEDONA-106 : Add ST_LineFromText SEDONA-117 : Add RS_AppendNormalizedDifference SEDONA-97 : Add ST_Force_2D SEDONA-98 : Add ST_IsEmpty SEDONA-116 : Add ST_YMax and ST_Ymin SEDONA-115 : Add ST_XMax and ST_Min SEDONA-120 : Add ST_BuildArea SEDONA-113 : Add ST_PointN SEDONA-124 : Add ST_CollectionExtract SEDONA-109 : Add ST_OrderingEquals","title":"SQL (for Spark)"},{"location":"setup/release-notes/#flink","text":"New features: SEDONA-107 : Add St_Reverse function SEDONA-105 : Add ST_PointOnSurface function SEDONA-95 : Add ST_Disjoint predicate SEDONA-112 : Add ST_AsEWKT SEDONA-97 : Add ST_Force_2D SEDONA-98 : Add ST_IsEmpty SEDONA-116 : Add ST_YMax and ST_Ymin SEDONA-115 : Add ST_XMax and ST_Min SEDONA-120 : Add ST_BuildArea SEDONA-113 : Add ST_PointN SEDONA-110 : Add ST_GeomFromGeoHash SEDONA-121 : More ST constructors to Flink SEDONA-122 : Overload ST_GeomFromWKB for BYTES column","title":"Flink"},{"location":"setup/release-notes/#sedona-120","text":"This version is a major release on Sedona 1.2.0 line. It includes bug fixes and new features: Sedona with Apache Flink.","title":"Sedona 1.2.0"},{"location":"setup/release-notes/#rdd","text":"Bug fix: SEDONA-18 : Fix an error reading Shapefile SEDONA-73 : Exclude scala-library from scala-collection-compat Improvement: SEDONA-77 : Refactor Format readers and spatial partitioning functions to be standalone libraries. So they can be used by Flink and others.","title":"RDD"},{"location":"setup/release-notes/#sql","text":"New features: SEDONA-4 : Handle nulls in SQL functions SEDONA-65 : Create ST_Difference function SEDONA-68 Add St_Collect function. SEDONA-82 : Create ST_SymmDifference function SEDONA-75 : Add support for \"3D\" geometries: Preserve Z coordinates on geometries when serializing, ST_AsText , ST_Z, ST_3DDistance SEDONA-86 : Support empty geometries in ST_AsBinary and ST_AsEWKB SEDONA-90 : Add ST_Union SEDONA-100 : Add st_multi function Bug fix: SEDONA-89 : GeometryUDT equals should test equivalence of the other object","title":"SQL"},{"location":"setup/release-notes/#flink_1","text":"Major update: SEDONA-80 : Geospatial stream processing support in Flink Table API SEDONA-85 : ST_Geohash function in Flink SEDONA-87 : Support Flink Table and DataStream conversion SEDONA-93 : Add ST_GeomFromGeoJSON","title":"Flink"},{"location":"setup/release-notes/#sedona-111","text":"This version is a maintenance release on Sedona 1.1.X line. It includes bug fixes and a few new functions.","title":"Sedona 1.1.1"},{"location":"setup/release-notes/#global","text":"New feature: SEDONA-73 : Scala source code supports Scala 2.13","title":"Global"},{"location":"setup/release-notes/#sql_1","text":"Bug fix: SEDONA-67 : Support Spark 3.2 New features: SEDONA-43 : Add ST_GeoHash and ST_GeomFromGeoHash SEDONA-45 : Add ST_MakePolygon SEDONA-71 : Add ST_AsBinary, ST_AsEWKB, ST_SRID, ST_SetSRID","title":"SQL"},{"location":"setup/release-notes/#sedona-110","text":"This version is a major release on Sedona 1.1.0 line. It includes bug fixes and new features: R language API, Raster data and Map algebra support","title":"Sedona 1.1.0"},{"location":"setup/release-notes/#global_1","text":"Dependency upgrade: SEDONA-30 : Use Geotools-wrapper 1.1.0-24.1 to include geotools GeoTiff libraries. Improvement on join queries in core and SQL: SEDONA-63 : Skip empty partitions in NestedLoopJudgement SEDONA-64 : Broadcast dedupParams to improve performance Behavior change: SEDONA-62 : Ignore HDF test in order to avoid NASA copyright issue","title":"Global"},{"location":"setup/release-notes/#core","text":"Bug fix: SEDONA-41 : Fix rangeFilter bug when the leftCoveredByRight para is false SEDONA-53 : Fix SpatialKnnQuery NullPointerException","title":"Core"},{"location":"setup/release-notes/#sql_2","text":"Major update: SEDONA-30 : Add GeoTiff raster I/O and Map Algebra function New function: SEDONA-27 : Add ST_Subdivide and ST_SubdivideExplode functions Bug fix: SEDONA-56 : Fix broadcast join with Adapter Query Engine enabled SEDONA-22 , SEDONA-60 : Fix join queries in SparkSQL when one side has no rows or only one row","title":"SQL"},{"location":"setup/release-notes/#viz","text":"N/A","title":"Viz"},{"location":"setup/release-notes/#python","text":"Improvement: SEDONA-59 : Make pyspark dependency of Sedona Python optional Bug fix: SEDONA-50 : Remove problematic logging conf that leads to errors on Databricks Fix the issue: Spark dependency in setup.py was configured to be < v3.1.0 by mistake.","title":"Python"},{"location":"setup/release-notes/#r","text":"Major update: SEDONA-31 : Add R interface for Sedona","title":"R"},{"location":"setup/release-notes/#sedona-101","text":"This version is a maintenance release on Sedona 1.0.0 line. It includes bug fixes, some new features, one API change","title":"Sedona 1.0.1"},{"location":"setup/release-notes/#known-issue","text":"In Sedona v1.0.1 and eariler versions, the Spark dependency in setup.py was configured to be < v3.1.0 by mistake . When you install Sedona Python (apache-sedona v1.0.1) from Pypi, pip might unstall PySpark 3.1.1 and install PySpark 3.0.2 on your machine. Three ways to fix this: After install apache-sedona v1.0.1, unstall PySpark 3.0.2 and reinstall PySpark 3.1.1 Ask pip not to install Sedona dependencies: pip install --no-deps apache-sedona Install Sedona from the latest setup.py (on GitHub) manually.","title":"Known issue"},{"location":"setup/release-notes/#global_2","text":"Dependency upgrade: SEDONA-16 : Use a GeoTools Maven Central wrapper to fix failed Jupyter notebook examples SEDONA-29 : upgrade to Spark 3.1.1 SEDONA-33 : jts2geojson version from 0.14.3 to 0.16.1","title":"Global"},{"location":"setup/release-notes/#core_1","text":"Bug fix: SEDONA-35 : Address user-data mutability issue with Adapter.toDF()","title":"Core"},{"location":"setup/release-notes/#sql_3","text":"Bug fix: SEDONA-14 : Saving dataframe to CSV or Parquet fails due to unknown type SEDONA-15 : Add ST_MinimumBoundingRadius and ST_MinimumBoundingCircle functions SEDONA-19 : Global indexing does not work with SQL joins SEDONA-20 : Case object GeometryUDT and GeometryUDT instance not equal in Spark 3.0.2 New function: SEDONA-21 : allows Sedona to be used in pure SQL environment SEDONA-24 : Add ST_LineSubString and ST_LineInterpolatePoint SEDONA-26 : Add broadcast join support","title":"SQL"},{"location":"setup/release-notes/#viz_1","text":"Improvement: SEDONA-32 : Speed up ST_Render API change: SEDONA-29 : Upgrade to Spark 3.1.1 and fix ST_Pixelize","title":"Viz"},{"location":"setup/release-notes/#python_1","text":"Bug fix: SEDONA-19 : Global indexing does not work with SQL joins","title":"Python"},{"location":"setup/release-notes/#sedona-100","text":"This version is the first Sedona release since it joins the Apache Incubator. It includes new functions, bug fixes, and API changes .","title":"Sedona 1.0.0"},{"location":"setup/release-notes/#global_3","text":"Key dependency upgrade: SEDONA-1 : upgrade to JTS 1.18 upgrade to GeoTools 24.0 upgrade to jts2geojson 0.14.3 Key dependency packaging strategy change: JTS, GeoTools, jts2geojson are no longer packaged in Sedona jars. End users need to add them manually. See here . Key compilation target change: SEDONA-3 : Paths and class names have been changed to Apache Sedona SEDONA-7 : build the source code for Spark 2.4, 3.0, Scala 2.11, 2.12, Python 3.7, 3.8, 3.9. See here .","title":"Global"},{"location":"setup/release-notes/#sedona-core","text":"Bug fix: PR 443 : read multiple Shape Files by multiPartitions PR 451 ( API change ): modify CRSTransform to ignore datum shift New function: SEDONA-8 : spatialRDD.flipCoordinates() API / behavior change: PR 488 : JoinQuery.SpatialJoinQuery/DistanceJoinQuery now returns <Geometry, List> instead of <Geometry, HashSet> because we can no longer use HashSet in Sedona for duplicates removal. All original duplicates in both input RDDs will be preserved in the output.","title":"Sedona-core"},{"location":"setup/release-notes/#sedona-sql","text":"Bug fix: SEDONA-8 ( API change ): ST_Transform slow due to lock contention. See here PR 427 : ST_Point and ST_PolygonFromEnvelope now allows Double type New function: PR 499 : ST_Azimuth, ST_X, ST_Y, ST_StartPoint, ST_Boundary, ST_EndPoint, ST_ExteriorRing, ST_GeometryN, ST_InteriorRingN, ST_Dump, ST_DumpPoints, ST_IsClosed, ST_NumInteriorRings, ST_AddPoint, ST_RemovePoint, ST_IsRing PR 459 : ST_LineMerge PR 460 : ST_NumGeometries PR 469 : ST_AsGeoJSON SEDONA-8 : ST_FlipCoordinates Behavior change: PR 480 : Aggregate Functions rewrite for new Aggregator API. The functions can be used as typed functions in code and enable compilation-time type check. API change: SEDONA-11 : Adapter.toDf() will directly generate a geometry type column. ST_GeomFromWKT is no longer needed.","title":"Sedona-sql"},{"location":"setup/release-notes/#sedona-viz","text":"API change: Drop the function which can generate SVG vector images because the required library has an incompatible license and the SVG image is not good at plotting big data","title":"Sedona-viz"},{"location":"setup/release-notes/#sedona-python","text":"API/Behavior change: Python-to-Sedona adapter is moved to a separate module. To use Sedona Python, see here New function: PR 448 : Add support for partition number in spatialPartitioning function spatial_rdd.spatialPartitioning(grid_type, NUM_PARTITION)","title":"Sedona Python"},{"location":"setup/release-notes/#geospark-legacy-release-notes","text":"","title":"GeoSpark legacy release notes"},{"location":"setup/release-notes/#v131","text":"This version includes the official release of GeoSpark Python wrapper. It also contains a number of bug fixes and new functions. The tutorial section provides some articles to explain the usage of GeoSpark Python wrapper. GeoSpark Core Bug fix: Issue # 344 and PR # 365 : GeoJSON reader cannot handle \"id\" Issue # 420 and PR # 421 : Cannot handle null value in geojson properties PR # 422 : Use HTTPS to resolve dependencies in Maven Build New functions: Issue # 399 and PR # 401 : saveAsWKB PR # 402 : saveAsWKT GeoSpark SQL New functions: PR # 359 : ST_NPoints PR # 373 : ST_GeometryType PR # 398 : ST_SimplifyPreserveTopology PR # 406 : ST_MakeValid PR # 416 : ST_Intersection_aggr Performance: Issue # 345 and PR # 346 : the performance issue of Adapter.toDF() function Bug fix: Issue # 395 and PR # 396 : Fix the geometry col bug in Adapter GeoSpark Viz Bug fix: Issue # 378 and PR # 379 : Classpath issue when integrating GeoSparkViz with s3 GeoSpark Python Add new GeoSpark python wrapper for RDD and SQL APIs Contributors (12) Mariano Gonzalez Pawe\u0142 Koci\u0144ski Semen Komissarov Jonathan Leitschuh Netanel Malka Keivan Shahida Sachio Wakai Hui Wang Wrussia Jia Yu Harry Zhu Ilya Zverev","title":"v1.3.1"},{"location":"setup/release-notes/#v130","text":"This release has been skipped due to a bug in GeoSpark Python wrapper.","title":"v1.3.0"},{"location":"setup/release-notes/#v120","text":"This version contains numerous bug fixes, new functions, and new GeoSpark module. License change From MIT to Apache License 2.0 GeoSpark Core Bug fix: Issue # 224 load GeoJSON non-spatial attributes. Issue # 228 Shapefiel Reader fails to handle UNDEFINED type. Issue # 320 Read CSV ArrayIndexOutOfBoundsException New functions: PR # 270 # 298 Add GeoJSON Reader to load GeoJSON with all attributes. See GeoSpark doc for an example. PR # 314 Add WktReader and WkbReader. Their usage is simialr to GeoJSON reader. GeoSpark SQL Bug fix: Issue # 244 JTS side location conflict Issue # 245 Drop ST_Circle in 1.2.0 Issue # 288 ST_isValid fails Issue # 321 ST_Point doesn't accept null user data PR # 284 ST_Union_Aggr bug PR # 331 Adapter doesn't handle null values New SQL functions: ST_IsValid ST_PrecisionReduce ST_Touches ST_Overlaps ST_Equals ST_Crosses ST_IsSimple ST_AsText Behavior / API change: GeoSpark Adapter will automatically carry all attributes between DataFrame and RDD. No need to use UUID in SQL ST functions to pass values. Please read GeoSpark doc . GeoSpark Viz Bug fix: Issue # 231 Pixel NullPointException Issue # 234 OutOfMemory for large images New functions Add the DataFrame support. Please read GeoSpark doc ST_Pixelize ST_TileName ST_Colorize ST_EncodeImage ST_Render Behavior / API change GeoSparkViz Maven coordinate changed. You need to specify Spark version. Please read GeoSpark Maven coordinate GeoSpark-Zeppelin New functions Add the support of connecting GeoSpark and Zeppelin Add the support of connecting GeoSparkViz and Zeppelin Contributors (13) Anton Peniaziev, Avshalom Orenstein, Jia Yu, Jordan Perr-Sauer, JulienPeloton, Sergii Mikhtoniuk, Netanel Malka, Rishabh Mishra, sagar1993, Shi-Hao Liu, Serhuela, tociek, Wrussia","title":"v1.2.0"},{"location":"setup/release-notes/#v113","text":"This version contains a critical bug fix for GeoSpark-core RDD API. GeoSpark Core Fixed Issue # 222 : geometry toString() method has cumulative non-spatial attributes. See PR # 223 GeoSpark SQL None GeoSpark Viz None","title":"v1.1.3"},{"location":"setup/release-notes/#v112","text":"This version contains several bug fixes and several small improvements. GeoSpark Core Added WKB input format support (Issue # 2 , 213 ): See PR # 203 , 216 . Thanks for the patch from Lucas C.! Added empty constructors for typed SpatialRDDs. This is especially useful when the users want to load a persisted RDD from disk and assemble a typed SpatialRDD by themselves. See PR # 211 Fixed Issue # 214 : duplicated geometry parts when print each Geometry in a SpatialRDD to a String using toString() method. See PR # 216 GeoSpark SQL Added ST_GeomFromWKB expression (Issue # 2 ): See PR # 203 . Thanks for the patch from Lucas C.! Fixed Issue # 193 : IllegalArgumentException in RangeJoin: Number of partitions must be >= 0. See PR # 207 Fixed Issue # 204 : Wrong ST_Intersection result. See PR # 205 [For Developer] Separate the expression catalog and the udf registrator to simplify the steps of merging patches among different Spark versions. See PR # 209 GeoSpark Viz None","title":"v1.1.2"},{"location":"setup/release-notes/#v111","text":"This release has been skipped due to wrong Maven Central configuration.","title":"v1.1.1"},{"location":"setup/release-notes/#v110","text":"This version adds very efficient R-Tree and Quad-Tree index serializers and supports Apache Spark and SparkSQL 2.3. See Maven Central coordinate to locate the particular version. GeoSpark Core Fixed Issue # 185 : CRStransform throws Exception for Bursa wolf parameters. See PR # 189 . Fixed Issue # 190 : Shapefile reader doesn't support Chinese characters (\u4e2d\u6587\u5b57\u7b26). See PR # 192 . Add R-Tree and Quad-Tree index serializer. GeoSpark custom index serializer has around 2 times smaller index size and faster serialization than Apache Spark kryo serializer. See PR # 177 . GeoSpark SQL Fixed Issue # 194 : doesn't support Spark 2.3. Fixed Issue # 188 :ST_ConvexHull should accept any type of geometry as an input. See PR # 189 . Add ST_Intersection function. See Issue # 110 and PR # 189 . GeoSpark Viz Fixed Issue # 154 : GeoSpark kryp serializer and GeoSparkViz conflict. See PR # 178","title":"v1.1.0"},{"location":"setup/release-notes/#v101","text":"GeoSpark Core Fixed Issue # 170 GeoSpark SQL Fixed Issue # 171 Added the support of SparkSQL 2.2. GeoSpark-SQL for Spark 2.1 is published separately ( Maven Coordinates ). GeoSpark Viz None","title":"v1.0.1"},{"location":"setup/release-notes/#v100","text":"GeoSpark Core Add GeoSparkConf class to read GeoSparkConf from SparkConf GeoSpark SQL Initial release: fully supports SQL/MM-Part3 Spatial SQL standard GeoSpark Viz Republish GeoSpark Viz under \"GeoSparkViz\" folder. All \"Babylon\" strings have been replaced to \"GeoSparkViz\"","title":"v1.0.0"},{"location":"setup/release-notes/#v091-geospark-core","text":"Bug fixes : Fixed \"Missing values when reading Shapefile\": Issue #141 Performance improvement : Solved Issue #91 , #103 , #104 , #125 , #150 . Add GeoSpark customized Kryo Serializer to significantly reduce memory footprint. This serializer which follows Shapefile compression rule takes less memory than the default Kryo. See PR 139 . Delete the duplicate removal by using Reference Point concept. This eliminates one data shuffle but still guarantees the accuracy. See PR 131 . New Functionalities added : SpatialJoinQueryFlat/DistanceJoinQueryFlat returns the join query in a flat way following database iteration model: Each row has fixed two members [Polygon, Point]. This API is more efficient for unbalanced length of join results. The left and right shapes in Range query, Distance query, Range join query, Distance join query can be switched. The index side in Range query, Distance query, Range join query, Distance join query can be switched. The generic SpatialRdd supports heterogenous geometries Add KDB-Tree spatial partitioning method which is more balanced than Quad-Tree Range query, Distance query, Range join query, Distance join query, KNN query supports heterogenous inputs.","title":"v0.9.1 (GeoSpark-core)"},{"location":"setup/release-notes/#v082-geospark-core","text":"Bug fixes : Fix the shapefile RDD null pointer bug when running in cluster mode. See Issue https://github.com/DataSystemsLab/GeoSpark/issues/115 New function added : Provide granular control to SpatialRDD sampling utils. SpatialRDD has a setter and getter for a parameter called \"sampleNumber\". The user can manually specify the sample size for spatial partitioning.","title":"v0.8.2 (GeoSpark-core)"},{"location":"setup/release-notes/#v081-geospark-core","text":"Bug fixes : (1) Fix the blank DBF attribute error when load DBF along with SHX file. (2) Allow user to call CRS transformation function at any time. Previously, it was only allowed in GeoSpark constructors","title":"v0.8.1 (GeoSpark-core)"},{"location":"setup/release-notes/#v080-geospark-core","text":"New input format added : GeoSpark is able to load and query ESRI ShapeFile (.shp, .shx, .dbf) from local disk and HDFS! Users first need to build a Shapefile RDD by giving Spark Context and an input path then call ShapefileRDD.getSpatialRDD to retrieve Spatial RDD. ( Scala Example , Java Example ) Join Query Performance enhancement 1 : GeoSpark provides a new Quad-Tree Spatial Partitioning method to speed up Join Query. Users need to pass GridType.QUADTREE parameter to RDD1.spatialPartitioning() function. Then users need to use RDD1.partitionTree in RDD2.spatialPartitioning() function. This Quad-Tree partitioning method (1) avoids overflowed spatial objects when partitioning spatial objects. (2) checking a spatial object against the Quad-Tree grids is completed in a log complexity tree search. ( Scala Example , Java Example ) Join Query Performance enhancement 2 : Internally, GeoSpark uses zipPartitions instead of CoGroup to join two Spatial RDD so that the incurred shuffle overhead decreases. SpatialRDD Initialization Performance enhancement : GeoSpark uses mapPartition instead of flatMapToPair to generate Spatial Objects. This will speed up the calculation. API changed : Since it chooses mapPartition API in mappers, GeoSpark no longer supports the old user supplified format mapper. However, if you are using your own format mapper for old GeoSpark version, you just need to add one more loop to fit in GeoSpark 0.8.0. Please see GeoSpark user supplied format mapper examples Alternative SpatialRDD constructor added : GeoSpark no longer forces users to provide StorageLevel parameter in their SpatialRDD constructors. This will siginicantly accelerate all Spatial RDD initialization. If he only needs Spatial Range Query and KNN query, the user can totally remove this parameter from their constructors. If he needs Spatial Join Query or Distance Join Query but he knows his dataset boundary and approximate total count, the user can also remove StorageLevel parameter and append a Envelope type dataset boundary and an approxmiate total count as additional parameters. If he needs Spatial Join Query or Distance Join Query but knows nothing about his dataset , the user still has to pass StorageLevel parameter. Bug fix : Fix bug Issue #97 and Issue #100 .","title":"v0.8.0 (GeoSpark-core)"},{"location":"setup/release-notes/#v01-v07","text":"Version Summary 0.7.0 Coordinate Reference System (CRS) Transformation (aka. Coordinate projection) added: GeoSpark allows users to transform the original CRS (e.g., degree based coordinates such as EPSG:4326 and WGS84) to any other CRS (e.g., meter based coordinates such as EPSG:3857) so that it can accurately process both geographic data and geometrical data. Please specify your desired CRS in GeoSpark Spatial RDD constructor ( Example ); Unnecessary dependencies removed : NetCDF/HDF support depends on SerNetCDF . SetNetCDF becomes optional dependency to reduce fat jar size; Default JDK/JRE change to JDK/JRE 1.8 : To satisfy CRS transformation requirement, GeoSpark is compiled by JDK 1.8 by default; Bug fix : fix a small format bug when output spatial RDD to disk. 0.6.2 New input format added: Add a new input format mapper called EarthdataHDFPointMapper so that GeoSpark can load, query and save NASA Petabytes NetCDF/HDF Earth Data ( Scala Example , Java Example ); Bug fix: Print UserData attribute when output Spatial RDDs as GeoJSON or regular text file 0.6.1 Bug fixes: Fix typos LineString DistanceJoin API 0.6.0 Major updates: (1) DistanceJoin is merged into JoinQuery. GeoSpark now supports complete DistanceJoin between Points, Polygons, and LineStrings. (2) Add Refine Phase to Spatial Range and Join Query. Use real polygon coordinates instead of its MBR to filter the final results. API changes: All spatial range and join queries now take a parameter called ConsiderBoundaryIntersection . This will tell GeoSpark whether returns the objects intersect with windows. 0.5.3 Bug fix: Fix Issue #69 : Now, if two objects have the same coordinates but different non-spatial attributes (UserData), GeoSpark treats them as different objects. 0.5.2 Bug fix: Fix Issue #58 and Issue #60 ; Performance enhancement: (1) Deprecate all old Spatial RDD constructors. See the JavaDoc here . (2) Recommend the new SRDD constructors which take an additional RDD storage level and automatically cache rawSpatialRDD to accelerate internal SRDD analyze step 0.5.1 Bug fix: (1) GeoSpark: Fix inaccurate KNN result when K is large (2) GeoSpark: Replace incompatible Spark API call Issue #55 ; (3) Babylon: Remove JPG output format temporarily due to the lack of OpenJDK support 0.5.0 Major updates: We are pleased to announce the initial version of Babylon a large-scale in-memory geospatial visualization system extending GeoSpark. Babylon and GeoSpark are integrated together. You can just import GeoSpark and enjoy! More details are available here: Babylon GeoSpatial Visualization 0.4.0 Major updates: ( Example ) 1. Refactor constrcutor API usage. 2. Simplify Spatial Join Query API. 3. Add native support for LineStringRDD; Functionality enhancement: 1. Release the persist function back to users. 2. Add more exception explanations. 0.3.2 Functionality enhancement: 1. JTSplus Spatial Objects now carry the original input data. Each object stores \"UserData\" and provides getter and setter. 2. Add a new SpatialRDD constructor to transform a regular data RDD to a spatial partitioned SpatialRDD. 0.3.1 Bug fix: Support Apache Spark 2.X version, fix a bug which results in inaccurate results when doing join query, add more unit test cases 0.3 Major updates: Significantly shorten query time on spatial join for skewed data; Support load balanced spatial partitioning methods (also serve as the global index); Optimize code for iterative spatial data mining 0.2 Improve code structure and refactor API 0.1 Support spatial range, join and Knn","title":"v0.1 - v0.7"},{"location":"setup/release-notes/#geospark-viz-old","text":"Version Summary 0.2.2 Add the support of new output storage : Now the user is able to output gigapixel or megapixel resolution images (image tiles or stitched single image) to HDFS and Amazon S3. Please use the new ImageGenerator not the BabylonImageGenerator class. 0.2.1 Performance enhancement : significantly accelerate single image generation pipeline. Bug fix :fix a bug in scatter plot parallel rendering. 0.2.0 API updates for Issue #80 : 1. Babylon now has two different OverlayOperators for raster image and vector image: RasterOverlayOperator and VectorOverlayOperator; 2. Babylon merged old SparkImageGenerator and NativeJavaGenerator into a new BabylonImageGenerator which has neat APIs; New feature: Babylon can use Scatter Plot to visualize NASA Petabytes NetCDF/HDF format Earth Data. ( Scala Example , Java Example ) 0.1.1 Major updates: Babylon supports vector image and outputs SVG image format 0.1.0 Major updates: Babylon initial version supports raster images","title":"GeoSpark-Viz (old)"},{"location":"setup/zeppelin/","text":"Install Sedona-Zeppelin \u00b6 Warning Known issue : due to an issue in Leaflet JS, Sedona can only plot each geometry (point, line string and polygon) as a point on Zeppelin map. To enjoy the scalable and full-fleged visualization, please use SedonaViz to plot scatter plots and heat maps on Zeppelin map. Compatibility \u00b6 Apache Spark 2.3+ Apache Zeppelin 0.8.1+ Sedona 1.0.0+: Sedona-core, Sedona-SQL, Sedona-Viz Installation \u00b6 Note You only need to do Step 1 and 2 only if you cannot see Apache-sedona or GeoSpark Zeppelin in Zeppelin Helium package list. Create Helium folder (optional) \u00b6 Create a folder called helium in Zeppelin root folder. Add Sedona-Zeppelin description (optional) \u00b6 Create a file called sedona-zeppelin.json in this folder and put the following content in this file. You need to change the artifact path! { \"type\": \"VISUALIZATION\", \"name\": \"sedona-zeppelin\", \"description\": \"Zeppelin visualization support for Sedona\", \"artifact\": \"/Absolute/Path/incubator-sedona/zeppelin\", \"license\": \"BSD-2-Clause\", \"icon\": \"<i class='fa fa-globe'></i>\" } Enable Sedona-Zeppelin \u00b6 Restart Zeppelin then open Zeppelin Helium interface and enable Sedona-Zeppelin. Add Sedona dependencies in Zeppelin Spark Interpreter \u00b6 Visualize SedonaSQL results \u00b6 Display SedonaViz results \u00b6 Now, you are good to go! Please read Sedona-Zeppelin tutorial for a hands-on tutorial.","title":"Install Sedona-Zeppelin"},{"location":"setup/zeppelin/#install-sedona-zeppelin","text":"Warning Known issue : due to an issue in Leaflet JS, Sedona can only plot each geometry (point, line string and polygon) as a point on Zeppelin map. To enjoy the scalable and full-fleged visualization, please use SedonaViz to plot scatter plots and heat maps on Zeppelin map.","title":"Install Sedona-Zeppelin"},{"location":"setup/zeppelin/#compatibility","text":"Apache Spark 2.3+ Apache Zeppelin 0.8.1+ Sedona 1.0.0+: Sedona-core, Sedona-SQL, Sedona-Viz","title":"Compatibility"},{"location":"setup/zeppelin/#installation","text":"Note You only need to do Step 1 and 2 only if you cannot see Apache-sedona or GeoSpark Zeppelin in Zeppelin Helium package list.","title":"Installation"},{"location":"setup/zeppelin/#create-helium-folder-optional","text":"Create a folder called helium in Zeppelin root folder.","title":"Create Helium folder (optional)"},{"location":"setup/zeppelin/#add-sedona-zeppelin-description-optional","text":"Create a file called sedona-zeppelin.json in this folder and put the following content in this file. You need to change the artifact path! { \"type\": \"VISUALIZATION\", \"name\": \"sedona-zeppelin\", \"description\": \"Zeppelin visualization support for Sedona\", \"artifact\": \"/Absolute/Path/incubator-sedona/zeppelin\", \"license\": \"BSD-2-Clause\", \"icon\": \"<i class='fa fa-globe'></i>\" }","title":"Add Sedona-Zeppelin description (optional)"},{"location":"setup/zeppelin/#enable-sedona-zeppelin","text":"Restart Zeppelin then open Zeppelin Helium interface and enable Sedona-Zeppelin.","title":"Enable Sedona-Zeppelin"},{"location":"setup/zeppelin/#add-sedona-dependencies-in-zeppelin-spark-interpreter","text":"","title":"Add Sedona dependencies in Zeppelin Spark Interpreter"},{"location":"setup/zeppelin/#visualize-sedonasql-results","text":"","title":"Visualize SedonaSQL results"},{"location":"setup/zeppelin/#display-sedonaviz-results","text":"Now, you are good to go! Please read Sedona-Zeppelin tutorial for a hands-on tutorial.","title":"Display SedonaViz results"},{"location":"setup/flink/install-scala/","text":"Before starting the Sedona journey, you need to make sure your Apache Flink cluster is ready. Then you can create a self-contained Scala / Java project. A self-contained project allows you to create multiple Scala / Java files and write complex logics in one place. To use Sedona in your self-contained Flink project, you just need to add Sedona as a dependency in your POM.xml or build.sbt. To add Sedona as dependencies, please read Sedona Maven Central coordinates Read Sedona Flink guide and use Sedona Template project to start: Sedona Template Project Compile your project using Maven. Make sure you obtain the fat jar which packages all dependencies. Submit your compiled fat jar to Flink cluster. Make sure you are in the root folder of Flink distribution. Then run the following command: ./bin/flink run /Path/To/YourJar.jar","title":"Install Sedona Scala/Java"},{"location":"setup/flink/modules/","text":"Sedona modules for Apache Flink \u00b6 Name Introduction Core Spatial query algorithms, data readers/writers SQL Spatial SQL function implementation Flink Spatial Table and DataStream implementation API availability \u00b6 DataStream Table Scala/Java \u2705 \u2705 Python no no R no no","title":"Modules"},{"location":"setup/flink/modules/#sedona-modules-for-apache-flink","text":"Name Introduction Core Spatial query algorithms, data readers/writers SQL Spatial SQL function implementation Flink Spatial Table and DataStream implementation","title":"Sedona modules for Apache Flink"},{"location":"setup/flink/modules/#api-availability","text":"DataStream Table Scala/Java \u2705 \u2705 Python no no R no no","title":"API availability"},{"location":"setup/flink/platform/","text":"Sedona Flink binary releases are compiled by Java 1.8 and Scala 2.12/2.11, and tested in the following environments: Sedona Scala/Java Flink 1.12 Flink 1.13 Flink 1.14 Scala 2.12 \u2705 \u2705 \u2705 Scala 2.11 \u2705 \u2705 \u2705","title":"Language wrappers"},{"location":"tutorial/Advanced-Tutorial-Tune-your-Application/","text":"Advanced tutorial: Tune your Sedona RDD application \u00b6 Before getting into this advanced tutorial, please make sure that you have tried several Sedona functions on your local machine. Pick a proper Sedona version \u00b6 The versions of Sedona have three levels: X.X.X (i.e., 0.8.1) The first level means that this version contains big structure redesign which may bring big changes in APIs and performance. The second level (i.e., 0.8) indicates that this version contains significant performance enhancement, big new features and API changes. An old Sedona user who wants to pick this version needs to be careful about the API changes. Before you move to this version, please read Sedona version release notes and make sure you are ready to accept the API changes. The third level (i.e., 0.8.1) tells that this version only contains bug fixes, some small new features and slight performance enhancement. This version will not contain any API changes. Moving to this version is safe. We highly suggest all Sedona users that stay at the same level move to the latest version in this level. Choose a proper Spatial RDD constructor \u00b6 Sedona provides a number of constructors for each SpatialRDD (PointRDD, PolygonRDD and LineStringRDD). In general, you have two options to start with. Initialize a SpatialRDD from your data source such as HDFS and S3. A typical example is as follows: public PointRDD ( JavaSparkContext sparkContext , String InputLocation , Integer Offset , FileDataSplitter splitter , boolean carryInputData , Integer partitions , StorageLevel newLevel ) Initialize a SpatialRDD from an existing RDD. A typical example is as follows: public PointRDD ( JavaRDD < Point > rawSpatialRDD , StorageLevel newLevel ) You may notice that these constructors all take as input a \"StorageLevel\" parameter. This is to tell Apache Spark cache the \"rawSpatialRDD\", one attribute of SpatialRDD. The reason why Sedona does this is that Sedona wants to calculate the dataset boundary and approximate total count using several Apache Spark \"Action\"s. These information are useful when doing Spatial Join Query and Distance Join Query. However, in some cases, you may know well about your datasets. If so, you can manually provide these information by calling this kind of Spatial RDD constructors: public PointRDD ( JavaSparkContext sparkContext , String InputLocation , Integer Offset , FileDataSplitter splitter , boolean carryInputData , Integer partitions , Envelope datasetBoundary , Integer approximateTotalCount ) { Manually providing the dataset boundary and approximate total count helps Sedona avoiding several slow \"Action\"s during initialization. Cache the Spatial RDD that is repeatedly used \u00b6 Each SpatialRDD (PointRDD, PolygonRDD and LineStringRDD) possesses four RDD attributes. They are: rawSpatialRDD: The RDD generated by SpatialRDD constructors. spatialPartitionedRDD: The RDD generated by spatial partition a rawSpatialRDD. Note that: this RDD has replicated spatial objects. indexedRawRDD: The RDD generated by indexing a rawSpatialRDD. indexedRDD: The RDD generated by indexing a spatialPartitionedRDD. Note that: this RDD has replicated spatial objects. These four RDDs don't co-exist so you don't need to worry about the memory issue. These four RDDs are invoked in different queries: Spatial Range Query / KNN Query, no index: rawSpatialRDD is used. Spatial Range Query / KNN Query, use index: indexedRawRDD is used. Spatial Join Query / Distance Join Query, no index: spatialPartitionedRDD is used. Spatial Join Query / Distance Join Query, use index: indexed RDD is used. Therefore, if you use one of the queries above many times, you'd better cache the associated RDD into memory. There are several possible use cases: In Spatial Data Mining such as Spatial Autocorrelation and Spatial Co-location Pattern Mining, you may need to use Spatial Join / Spatial Self-join iteratively in order to calculate the adjacency matrix. If so, please cache the spatialPartitionedRDD/indexedRDD which is queries many times. In Spark RDD sharing applications such as Livy and Spark Job Server , many users may do Spatial Range Query / KNN Query on the same Spatial RDD with different query predicates. You'd better cache the rawSpatialRDD/indexedRawRDD. Be aware of Spatial RDD partitions \u00b6 Sometimes users complain that the execution time is slow in some cases. As the first step, you should always consider increasing the number of your SpatialRDD partitions (2 - 8 times more than the original number). You can do this when you initialize a SpatialRDD. This may significantly improve your performance. After that, you may consider tuning some other parameters in Apache Spark. For example, you may use Kyro serializer or change the RDD fraction that is cached into memory.","title":"Tune RDD application"},{"location":"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application","text":"Before getting into this advanced tutorial, please make sure that you have tried several Sedona functions on your local machine.","title":"Advanced tutorial: Tune your Sedona RDD application"},{"location":"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version","text":"The versions of Sedona have three levels: X.X.X (i.e., 0.8.1) The first level means that this version contains big structure redesign which may bring big changes in APIs and performance. The second level (i.e., 0.8) indicates that this version contains significant performance enhancement, big new features and API changes. An old Sedona user who wants to pick this version needs to be careful about the API changes. Before you move to this version, please read Sedona version release notes and make sure you are ready to accept the API changes. The third level (i.e., 0.8.1) tells that this version only contains bug fixes, some small new features and slight performance enhancement. This version will not contain any API changes. Moving to this version is safe. We highly suggest all Sedona users that stay at the same level move to the latest version in this level.","title":"Pick a proper Sedona version"},{"location":"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor","text":"Sedona provides a number of constructors for each SpatialRDD (PointRDD, PolygonRDD and LineStringRDD). In general, you have two options to start with. Initialize a SpatialRDD from your data source such as HDFS and S3. A typical example is as follows: public PointRDD ( JavaSparkContext sparkContext , String InputLocation , Integer Offset , FileDataSplitter splitter , boolean carryInputData , Integer partitions , StorageLevel newLevel ) Initialize a SpatialRDD from an existing RDD. A typical example is as follows: public PointRDD ( JavaRDD < Point > rawSpatialRDD , StorageLevel newLevel ) You may notice that these constructors all take as input a \"StorageLevel\" parameter. This is to tell Apache Spark cache the \"rawSpatialRDD\", one attribute of SpatialRDD. The reason why Sedona does this is that Sedona wants to calculate the dataset boundary and approximate total count using several Apache Spark \"Action\"s. These information are useful when doing Spatial Join Query and Distance Join Query. However, in some cases, you may know well about your datasets. If so, you can manually provide these information by calling this kind of Spatial RDD constructors: public PointRDD ( JavaSparkContext sparkContext , String InputLocation , Integer Offset , FileDataSplitter splitter , boolean carryInputData , Integer partitions , Envelope datasetBoundary , Integer approximateTotalCount ) { Manually providing the dataset boundary and approximate total count helps Sedona avoiding several slow \"Action\"s during initialization.","title":"Choose a proper Spatial RDD constructor"},{"location":"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used","text":"Each SpatialRDD (PointRDD, PolygonRDD and LineStringRDD) possesses four RDD attributes. They are: rawSpatialRDD: The RDD generated by SpatialRDD constructors. spatialPartitionedRDD: The RDD generated by spatial partition a rawSpatialRDD. Note that: this RDD has replicated spatial objects. indexedRawRDD: The RDD generated by indexing a rawSpatialRDD. indexedRDD: The RDD generated by indexing a spatialPartitionedRDD. Note that: this RDD has replicated spatial objects. These four RDDs don't co-exist so you don't need to worry about the memory issue. These four RDDs are invoked in different queries: Spatial Range Query / KNN Query, no index: rawSpatialRDD is used. Spatial Range Query / KNN Query, use index: indexedRawRDD is used. Spatial Join Query / Distance Join Query, no index: spatialPartitionedRDD is used. Spatial Join Query / Distance Join Query, use index: indexed RDD is used. Therefore, if you use one of the queries above many times, you'd better cache the associated RDD into memory. There are several possible use cases: In Spatial Data Mining such as Spatial Autocorrelation and Spatial Co-location Pattern Mining, you may need to use Spatial Join / Spatial Self-join iteratively in order to calculate the adjacency matrix. If so, please cache the spatialPartitionedRDD/indexedRDD which is queries many times. In Spark RDD sharing applications such as Livy and Spark Job Server , many users may do Spatial Range Query / KNN Query on the same Spatial RDD with different query predicates. You'd better cache the rawSpatialRDD/indexedRawRDD.","title":"Cache the Spatial RDD that is repeatedly used"},{"location":"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions","text":"Sometimes users complain that the execution time is slow in some cases. As the first step, you should always consider increasing the number of your SpatialRDD partitions (2 - 8 times more than the original number). You can do this when you initialize a SpatialRDD. This may significantly improve your performance. After that, you may consider tuning some other parameters in Apache Spark. For example, you may use Kyro serializer or change the RDD fraction that is cached into memory.","title":"Be aware of Spatial RDD partitions"},{"location":"tutorial/benchmark/","text":"Benchmark \u00b6 We welcome people to use Sedona for benchmark purpose. To achieve the best performance or enjoy all features of Sedona, Please always use the latest version or state the version used in your benchmark so that we can trace back to the issues. Please consider using Sedona core instead of Sedona SQL. Due to the limitation of SparkSQL (for instance, not support clustered index), we are not able to expose all features to SparkSQL. Please open Sedona kryo serializer to reduce the memory footprint.","title":"Benchmark"},{"location":"tutorial/benchmark/#benchmark","text":"We welcome people to use Sedona for benchmark purpose. To achieve the best performance or enjoy all features of Sedona, Please always use the latest version or state the version used in your benchmark so that we can trace back to the issues. Please consider using Sedona core instead of Sedona SQL. Due to the limitation of SparkSQL (for instance, not support clustered index), we are not able to expose all features to SparkSQL. Please open Sedona kryo serializer to reduce the memory footprint.","title":"Benchmark"},{"location":"tutorial/core-python/","text":"Spatial RDD Applications in Python \u00b6 Introduction \u00b6 Sedona provides a Python wrapper on Sedona core Java/Scala library. Sedona SpatialRDDs (and other classes when it was necessary) have implemented meta classes which allow to use overloaded functions, methods and constructors to be the most similar to Java/Scala API as possible. Apache Sedona core provides five special SpatialRDDs: PointRDD PolygonRDD LineStringRDD CircleRDD RectangleRDD All of them can be imported from sedona.core.SpatialRDD module sedona has written serializers which convert Sedona SpatialRDD to Python objects. Converting will produce GeoData objects which have 2 attributes: geom: shapely.geometry.BaseGeometry userData: str geom attribute holds geometry representation as shapely objects. userData is string representation of other attributes separated by \"\\t\" GeoData has one method to get user data. getUserData() -> str Note This tutorial is based on Sedona Core Jupyter Notebook example . You can interact with Sedona Python Jupyter notebook immediately on Binder. Click and wait for a few minutes. Then select a notebook and enjoy! Installation \u00b6 Please read Quick start to install Sedona Python. Apache Sedona Serializers \u00b6 Sedona has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. conf . set ( \"spark.serializer\" , KryoSerializer . getName ) conf . set ( \"spark.kryo.registrator\" , SedonaKryoRegistrator . getName ) sc = SparkContext ( conf = conf ) Create a SpatialRDD \u00b6 Create a typed SpatialRDD \u00b6 Apache Sedona core provides three special SpatialRDDs: PointRDD PolygonRDD LineStringRDD CircleRDD RectangleRDD They can be loaded from CSV, TSV, WKT, WKB, Shapefiles, GeoJSON formats. To pass the format to SpatialRDD constructor please use FileDataSplitter enumeration. sedona SpatialRDDs (and other classes when it was necessary) have implemented meta classes which allow to use overloaded functions how Scala/Java Apache Sedona API allows. ex. from pyspark import StorageLevel from sedona.core.SpatialRDD import PointRDD from sedona.core.enums import FileDataSplitter input_location = \"checkin.csv\" offset = 0 # The point long/lat starts from Column 0 splitter = FileDataSplitter . CSV # FileDataSplitter enumeration carry_other_attributes = True # Carry Column 2 (hotel, gas, bar...) level = StorageLevel . MEMORY_ONLY # Storage level from pyspark s_epsg = \"epsg:4326\" # Source epsg code t_epsg = \"epsg:5070\" # target epsg code point_rdd = PointRDD ( sc , input_location , offset , splitter , carry_other_attributes ) point_rdd = PointRDD ( sc , input_location , splitter , carry_other_attributes , level , s_epsg , t_epsg ) point_rdd = PointRDD ( sparkContext = sc , InputLocation = input_location , Offset = offset , splitter = splitter , carryInputData = carry_other_attributes ) From SparkSQL DataFrame To create spatialRDD from other formats you can use adapter between Spark DataFrame and SpatialRDD Load data in SedonaSQL. csv_point_input_location = \"/tests/resources/county_small.tsv\" df = spark . read . \\ format ( \"csv\" ) . \\ option ( \"delimiter\" , \" \\t \" ) . \\ option ( \"header\" , \"false\" ) . \\ load ( csv_point_input_location ) df . createOrReplaceTempView ( \"counties\" ) Create a Geometry type column in SedonaSQL spatial_df = spark . sql ( \"\"\" SELECT ST_GeomFromWKT(_c0) as geom, _c6 as county_name FROM counties \"\"\" ) spatial_df . printSchema () root |-- geom: geometry (nullable = false) |-- county_name: string (nullable = true) Use SedonaSQL DataFrame-RDD Adapter to convert a DataFrame to an SpatialRDD Note that, you have to name your column geometry from sedona.utils.adapter import Adapter spatial_rdd = Adapter . toSpatialRdd ( spatial_df ) spatial_rdd . analyze () spatial_rdd . boundaryEnvelope <sedona.core.geom_types.Envelope object at 0x7f1e5f29fe10> or pass Geometry column name as a second argument spatial_rdd = Adapter . toSpatialRdd ( spatial_df , \"geom\" ) For WKT/WKB/GeoJSON data, please use ST_GeomFromWKT / ST_GeomFromWKB / ST_GeomFromGeoJSON instead. Read other attributes in an SpatialRDD \u00b6 Each SpatialRDD can carry non-spatial attributes such as price, age and name as long as the user sets carryOtherAttributes as TRUE . The other attributes are combined together to a string and stored in UserData field of each geometry. To retrieve the UserData field, use the following code: rdd_with_other_attributes = object_rdd . rawSpatialRDD . map ( lambda x : x . getUserData ()) Write a Spatial Range Query \u00b6 from sedona.core.geom.envelope import Envelope from sedona.core.spatialOperator import RangeQuery range_query_window = Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) consider_boundary_intersection = False ## Only return gemeotries fully covered by the window using_index = False query_result = RangeQuery . SpatialRangeQuery ( spatial_rdd , range_query_window , consider_boundary_intersection , using_index ) Note Please use RangeQueryRaw from the same module if you want to avoid jvm python serde while converting to Spatial DataFrame It takes the same parameters as RangeQuery but returns reference to jvm rdd which can be converted to dataframe without python - jvm serde using Adapter. Example: from sedona.core.geom.envelope import Envelope from sedona.core.spatialOperator import RangeQueryRaw from sedona.utils.adapter import Adapter range_query_window = Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) consider_boundary_intersection = False ## Only return gemeotries fully covered by the window using_index = False query_result = RangeQueryRaw . SpatialRangeQuery ( spatial_rdd , range_query_window , consider_boundary_intersection , using_index ) gdf = Adapter . toDf ( query_result , spark , [ \"col1\" , ... , \"coln\" ]) Range query window \u00b6 Besides the rectangle (Envelope) type range query window, Apache Sedona range query window can be Point Polygon LineString To create shapely geometries please follow Shapely official docs Use spatial indexes \u00b6 Sedona provides two types of spatial indexes, Quad-Tree R-Tree Once you specify an index type, Sedona will build a local tree index on each of the SpatialRDD partition. To utilize a spatial index in a spatial range query, use the following code: from sedona.core.geom.envelope import Envelope from sedona.core.enums import IndexType from sedona.core.spatialOperator import RangeQuery range_query_window = Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) consider_boundary_intersection = False ## Only return gemeotries fully covered by the window build_on_spatial_partitioned_rdd = False ## Set to TRUE only if run join query spatial_rdd . buildIndex ( IndexType . QUADTREE , build_on_spatial_partitioned_rdd ) using_index = True query_result = RangeQuery . SpatialRangeQuery ( spatial_rdd , range_query_window , consider_boundary_intersection , using_index ) Output format \u00b6 The output format of the spatial range query is another RDD which consists of GeoData objects. SpatialRangeQuery result can be used as RDD with map or other spark RDD funtions. Also it can be used as Python objects when using collect method. Example: query_result . map ( lambda x : x . geom . length ) . collect () [ 1.5900840000000045, 1.5906639999999896, 1.1110299999999995, 1.1096700000000084, 1.1415619999999933, 1.1386399999999952, 1.1415619999999933, 1.1418860000000137, 1.1392780000000045, ... ] Or transformed to GeoPandas GeoDataFrame import geopandas as gpd gpd . GeoDataFrame ( query_result . map ( lambda x : [ x . geom , x . userData ]) . collect (), columns = [ \"geom\" , \"user_data\" ], geometry = \"geom\" ) Write a Spatial KNN Query \u00b6 A spatial K Nearnest Neighbor query takes as input a K, a query point and an SpatialRDD and finds the K geometries in the RDD which are the closest to he query point. Assume you now have an SpatialRDD (typed or generic). You can use the following code to issue an Spatial KNN Query on it. from sedona.core.spatialOperator import KNNQuery from shapely.geometry import Point point = Point ( - 84.01 , 34.01 ) k = 1000 ## K Nearest Neighbors using_index = False result = KNNQuery . SpatialKnnQuery ( object_rdd , point , k , using_index ) Query center geometry \u00b6 Besides the Point type, Apache Sedona KNN query center can be Polygon LineString To create Polygon or Linestring object please follow Shapely official docs Use spatial indexes \u00b6 To utilize a spatial index in a spatial KNN query, use the following code: from sedona.core.spatialOperator import KNNQuery from sedona.core.enums import IndexType from shapely.geometry import Point point = Point ( - 84.01 , 34.01 ) k = 5 ## K Nearest Neighbors build_on_spatial_partitioned_rdd = False ## Set to TRUE only if run join query spatial_rdd . buildIndex ( IndexType . RTREE , build_on_spatial_partitioned_rdd ) using_index = True result = KNNQuery . SpatialKnnQuery ( spatial_rdd , point , k , using_index ) Warning Only R-Tree index supports Spatial KNN query Output format \u00b6 The output format of the spatial KNN query is a list of GeoData objects. The list has K GeoData objects. Example: >> result [ GeoData , GeoData , GeoData , GeoData , GeoData ] Write a Spatial Join Query \u00b6 A spatial join query takes as input two Spatial RDD A and B. For each geometry in A, finds the geometries (from B) covered/intersected by it. A and B can be any geometry type and are not necessary to have the same geometry type. Assume you now have two SpatialRDDs (typed or generic). You can use the following code to issue an Spatial Join Query on them. from sedona.core.enums import GridType from sedona.core.spatialOperator import JoinQuery consider_boundary_intersection = False ## Only return geometries fully covered by each query window in queryWindowRDD using_index = False object_rdd . analyze () object_rdd . spatialPartitioning ( GridType . KDBTREE ) query_window_rdd . spatialPartitioning ( object_rdd . getPartitioner ()) result = JoinQuery . SpatialJoinQuery ( object_rdd , query_window_rdd , using_index , consider_boundary_intersection ) Result of SpatialJoinQuery is RDD which consists of GeoData instance and list of GeoData instances which spatially intersects or are covered by GeoData. result . collect ()) [ [GeoData, [GeoData, GeoData, GeoData, GeoData]], [GeoData, [GeoData, GeoData, GeoData]], [GeoData, [GeoData]], [GeoData, [GeoData, GeoData]], ... [GeoData, [GeoData, GeoData]] ] Use spatial partitioning \u00b6 Apache Sedona spatial partitioning method can significantly speed up the join query. Three spatial partitioning methods are available: KDB-Tree, Quad-Tree and R-Tree. Two SpatialRDD must be partitioned by the same way. If you first partition SpatialRDD A, then you must use the partitioner of A to partition B. object_rdd . spatialPartitioning ( GridType . KDBTREE ) query_window_rdd . spatialPartitioning ( object_rdd . getPartitioner ()) Or query_window_rdd . spatialPartitioning ( GridType . KDBTREE ) object_rdd . spatialPartitioning ( query_window_rdd . getPartitioner ()) Use spatial indexes \u00b6 To utilize a spatial index in a spatial join query, use the following code: from sedona.core.enums import GridType from sedona.core.enums import IndexType from sedona.core.spatialOperator import JoinQuery object_rdd . spatialPartitioning ( GridType . KDBTREE ) query_window_rdd . spatialPartitioning ( object_rdd . getPartitioner ()) build_on_spatial_partitioned_rdd = True ## Set to TRUE only if run join query using_index = True query_window_rdd . buildIndex ( IndexType . QUADTREE , build_on_spatial_partitioned_rdd ) result = JoinQuery . SpatialJoinQueryFlat ( object_rdd , query_window_rdd , using_index , True ) The index should be built on either one of two SpatialRDDs. In general, you should build it on the larger SpatialRDD. Output format \u00b6 The output format of the spatial join query is a PairRDD. In this PairRDD, each object is a pair of two GeoData objects. The left one is the GeoData from object_rdd and the right one is the GeoData from the query_window_rdd. Point,Polygon Point,Polygon Point,Polygon Polygon,Polygon LineString,LineString Polygon,LineString ... example result . collect () [ [GeoData, GeoData], [GeoData, GeoData], [GeoData, GeoData], [GeoData, GeoData], ... [GeoData, GeoData], [GeoData, GeoData] ] Each object on the left is covered/intersected by the object on the right. Write a Distance Join Query \u00b6 !!!warning RDD distance joins are only reliable for points. For other geometry types, please use Spatial SQL. A distance join query takes two spatial RDD assuming that we have two SpatialRDD's: object_rdd spatial_rdd And finds the geometries (from spatial_rdd) are within given distance to it. spatial_rdd and object_rdd can be any geometry type (point, line, polygon) and are not necessary to have the same geometry type You can use the following code to issue an Distance Join Query on them. from sedona.core.SpatialRDD import CircleRDD from sedona.core.enums import GridType from sedona.core.spatialOperator import JoinQuery object_rdd . analyze () circle_rdd = CircleRDD ( object_rdd , 0.1 ) ## Create a CircleRDD using the given distance circle_rdd . analyze () circle_rdd . spatialPartitioning ( GridType . KDBTREE ) spatial_rdd . spatialPartitioning ( circle_rdd . getPartitioner ()) consider_boundary_intersection = False ## Only return gemeotries fully covered by each query window in queryWindowRDD using_index = False result = JoinQuery . DistanceJoinQueryFlat ( spatial_rdd , circle_rdd , using_index , consider_boundary_intersection ) Note Please use JoinQueryRaw from the same module for methods spatialJoin DistanceJoinQueryFlat SpatialJoinQueryFlat For better performance while converting to dataframe with adapter. That approach allows to avoid costly serialization between Python and jvm and in result operating on python object instead of native geometries. Example: from sedona.core.SpatialRDD import CircleRDD from sedona.core.enums import GridType from sedona.core.spatialOperator import JoinQueryRaw object_rdd . analyze () circle_rdd = CircleRDD ( object_rdd , 0.1 ) ## Create a CircleRDD using the given distance circle_rdd . analyze () circle_rdd . spatialPartitioning ( GridType . KDBTREE ) spatial_rdd . spatialPartitioning ( circle_rdd . getPartitioner ()) consider_boundary_intersection = False ## Only return gemeotries fully covered by each query window in queryWindowRDD using_index = False result = JoinQueryRaw . DistanceJoinQueryFlat ( spatial_rdd , circle_rdd , using_index , consider_boundary_intersection ) gdf = Adapter . toDf ( result , [ \"left_col1\" , ... , \"lefcoln\" ], [ \"rightcol1\" , ... , \"rightcol2\" ], spark ) Output format \u00b6 Result for this query is RDD which holds two GeoData objects within list of lists. Example: result . collect () [[GeoData, GeoData], [GeoData, GeoData] ...] It is possible to do some RDD operation on result data ex. Getting polygon centroid. result . map ( lambda x : x [ 0 ] . geom . centroid ) . collect () [ <shapely.geometry.point.Point at 0x7efee2d28128>, <shapely.geometry.point.Point at 0x7efee2d280b8>, <shapely.geometry.point.Point at 0x7efee2d28fd0>, <shapely.geometry.point.Point at 0x7efee2d28080>, ... ] Save to permanent storage \u00b6 You can always save an SpatialRDD back to some permanent storage such as HDFS and Amazon S3. You can save distributed SpatialRDD to WKT, GeoJSON and object files. Note Non-spatial attributes such as price, age and name will also be stored to permanent storage. Save an SpatialRDD (not indexed) \u00b6 Typed SpatialRDD and generic SpatialRDD can be saved to permanent storage. Save to distributed WKT text file Use the following code to save an SpatialRDD as a distributed WKT text file: object_rdd . rawSpatialRDD . saveAsTextFile ( \"hdfs://PATH\" ) object_rdd . saveAsWKT ( \"hdfs://PATH\" ) Save to distributed WKB text file Use the following code to save an SpatialRDD as a distributed WKB text file: object_rdd . saveAsWKB ( \"hdfs://PATH\" ) Save to distributed GeoJSON text file Use the following code to save an SpatialRDD as a distributed GeoJSON text file: object_rdd . saveAsGeoJSON ( \"hdfs://PATH\" ) Save to distributed object file Use the following code to save an SpatialRDD as a distributed object file: object_rdd . rawJvmSpatialRDD . saveAsObjectFile ( \"hdfs://PATH\" ) Note Each object in a distributed object file is a byte array (not human-readable). This byte array is the serialized format of a Geometry or a SpatialIndex. Save an SpatialRDD (indexed) \u00b6 Indexed typed SpatialRDD and generic SpatialRDD can be saved to permanent storage. However, the indexed SpatialRDD has to be stored as a distributed object file. Save to distributed object file Use the following code to save an SpatialRDD as a distributed object file: object_rdd . indexedRawRDD . saveAsObjectFile ( \"hdfs://PATH\" ) Save an SpatialRDD (spatialPartitioned W/O indexed) \u00b6 A spatial partitioned RDD can be saved to permanent storage but Spark is not able to maintain the same RDD partition Id of the original RDD. This will lead to wrong join query results. We are working on some solutions. Stay tuned! Reload a saved SpatialRDD \u00b6 You can easily reload an SpatialRDD that has been saved to a distributed object file . Load to a typed SpatialRDD Use the following code to reload the PointRDD/PolygonRDD/LineStringRDD: from sedona.core.formatMapper.disc_utils import load_spatial_rdd_from_disc , GeoType polygon_rdd = load_spatial_rdd_from_disc ( sc , \"hdfs://PATH\" , GeoType . POLYGON ) point_rdd = load_spatial_rdd_from_disc ( sc , \"hdfs://PATH\" , GeoType . POINT ) linestring_rdd = load_spatial_rdd_from_disc ( sc , \"hdfs://PATH\" , GeoType . LINESTRING ) Load to a generic SpatialRDD Use the following code to reload the SpatialRDD: saved_rdd = load_spatial_rdd_from_disc ( sc , \"hdfs://PATH\" , GeoType . GEOMETRY ) Use the following code to reload the indexed SpatialRDD: saved_rdd = SpatialRDD () saved_rdd . indexedRawRDD = load_spatial_index_rdd_from_disc ( sc , \"hdfs://PATH\" ) Read from other Geometry files \u00b6 All below methods will return SpatialRDD object which can be used with Spatial functions such as Spatial Join etc. Read from WKT file \u00b6 from sedona.core.formatMapper import WktReader WktReader . readToGeometryRDD ( sc , wkt_geometries_location , 0 , True , False ) <sedona.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2fbf250> Read from WKB file \u00b6 from sedona.core.formatMapper import WkbReader WkbReader . readToGeometryRDD ( sc , wkb_geometries_location , 0 , True , False ) <sedona.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2eece50> Read from GeoJson file \u00b6 from sedona.core.formatMapper import GeoJsonReader GeoJsonReader . readToGeometryRDD ( sc , geo_json_file_location ) <sedona.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2eecb90> Read from Shapefile \u00b6 from sedona.core.formatMapper.shapefileParser import ShapefileReader ShapefileReader . readToGeometryRDD ( sc , shape_file_location ) <sedona.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2ee0710> Tips \u00b6 When you use Sedona functions such as JoinQuery.spatialJoin JoinQuery.DistanceJoinQueryFlat JoinQuery.SpatialJoinQueryFlat RangeQuery.SpatialRangeQuery For better performance when converting to dataframe you can use JoinQueryRaw and RangeQueryRaw from the same module and adapter to convert to Spatial DataFrame. Example, JoinQueryRaw: from sedona.core.SpatialRDD import CircleRDD from sedona.core.enums import GridType from sedona.core.spatialOperator import JoinQueryRaw object_rdd . analyze () circle_rdd = CircleRDD ( object_rdd , 0.1 ) ## Create a CircleRDD using the given distance circle_rdd . analyze () circle_rdd . spatialPartitioning ( GridType . KDBTREE ) spatial_rdd . spatialPartitioning ( circle_rdd . getPartitioner ()) consider_boundary_intersection = False ## Only return gemeotries fully covered by each query window in queryWindowRDD using_index = False result = JoinQueryRaw . DistanceJoinQueryFlat ( spatial_rdd , circle_rdd , using_index , consider_boundary_intersection ) gdf = Adapter . toDf ( result , [ \"left_col1\" , ... , \"lefcoln\" ], [ \"rightcol1\" , ... , \"rightcol2\" ], spark ) and RangeQueryRaw from sedona.core.geom.envelope import Envelope from sedona.core.spatialOperator import RangeQueryRaw from sedona.utils.adapter import Adapter range_query_window = Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) consider_boundary_intersection = False ## Only return gemeotries fully covered by the window using_index = False query_result = RangeQueryRaw . SpatialRangeQuery ( spatial_rdd , range_query_window , consider_boundary_intersection , using_index ) gdf = Adapter . toDf ( query_result , spark , [ \"col1\" , ... , \"coln\" ])","title":"Python"},{"location":"tutorial/core-python/#spatial-rdd-applications-in-python","text":"","title":"Spatial RDD Applications in Python"},{"location":"tutorial/core-python/#introduction","text":"Sedona provides a Python wrapper on Sedona core Java/Scala library. Sedona SpatialRDDs (and other classes when it was necessary) have implemented meta classes which allow to use overloaded functions, methods and constructors to be the most similar to Java/Scala API as possible. Apache Sedona core provides five special SpatialRDDs: PointRDD PolygonRDD LineStringRDD CircleRDD RectangleRDD All of them can be imported from sedona.core.SpatialRDD module sedona has written serializers which convert Sedona SpatialRDD to Python objects. Converting will produce GeoData objects which have 2 attributes: geom: shapely.geometry.BaseGeometry userData: str geom attribute holds geometry representation as shapely objects. userData is string representation of other attributes separated by \"\\t\" GeoData has one method to get user data. getUserData() -> str Note This tutorial is based on Sedona Core Jupyter Notebook example . You can interact with Sedona Python Jupyter notebook immediately on Binder. Click and wait for a few minutes. Then select a notebook and enjoy!","title":"Introduction"},{"location":"tutorial/core-python/#installation","text":"Please read Quick start to install Sedona Python.","title":"Installation"},{"location":"tutorial/core-python/#apache-sedona-serializers","text":"Sedona has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. conf . set ( \"spark.serializer\" , KryoSerializer . getName ) conf . set ( \"spark.kryo.registrator\" , SedonaKryoRegistrator . getName ) sc = SparkContext ( conf = conf )","title":"Apache Sedona Serializers"},{"location":"tutorial/core-python/#create-a-spatialrdd","text":"","title":"Create a SpatialRDD"},{"location":"tutorial/core-python/#create-a-typed-spatialrdd","text":"Apache Sedona core provides three special SpatialRDDs: PointRDD PolygonRDD LineStringRDD CircleRDD RectangleRDD They can be loaded from CSV, TSV, WKT, WKB, Shapefiles, GeoJSON formats. To pass the format to SpatialRDD constructor please use FileDataSplitter enumeration. sedona SpatialRDDs (and other classes when it was necessary) have implemented meta classes which allow to use overloaded functions how Scala/Java Apache Sedona API allows. ex. from pyspark import StorageLevel from sedona.core.SpatialRDD import PointRDD from sedona.core.enums import FileDataSplitter input_location = \"checkin.csv\" offset = 0 # The point long/lat starts from Column 0 splitter = FileDataSplitter . CSV # FileDataSplitter enumeration carry_other_attributes = True # Carry Column 2 (hotel, gas, bar...) level = StorageLevel . MEMORY_ONLY # Storage level from pyspark s_epsg = \"epsg:4326\" # Source epsg code t_epsg = \"epsg:5070\" # target epsg code point_rdd = PointRDD ( sc , input_location , offset , splitter , carry_other_attributes ) point_rdd = PointRDD ( sc , input_location , splitter , carry_other_attributes , level , s_epsg , t_epsg ) point_rdd = PointRDD ( sparkContext = sc , InputLocation = input_location , Offset = offset , splitter = splitter , carryInputData = carry_other_attributes )","title":"Create a typed SpatialRDD"},{"location":"tutorial/core-python/#read-other-attributes-in-an-spatialrdd","text":"Each SpatialRDD can carry non-spatial attributes such as price, age and name as long as the user sets carryOtherAttributes as TRUE . The other attributes are combined together to a string and stored in UserData field of each geometry. To retrieve the UserData field, use the following code: rdd_with_other_attributes = object_rdd . rawSpatialRDD . map ( lambda x : x . getUserData ())","title":"Read other attributes in an SpatialRDD"},{"location":"tutorial/core-python/#write-a-spatial-range-query","text":"from sedona.core.geom.envelope import Envelope from sedona.core.spatialOperator import RangeQuery range_query_window = Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) consider_boundary_intersection = False ## Only return gemeotries fully covered by the window using_index = False query_result = RangeQuery . SpatialRangeQuery ( spatial_rdd , range_query_window , consider_boundary_intersection , using_index ) Note Please use RangeQueryRaw from the same module if you want to avoid jvm python serde while converting to Spatial DataFrame It takes the same parameters as RangeQuery but returns reference to jvm rdd which can be converted to dataframe without python - jvm serde using Adapter. Example: from sedona.core.geom.envelope import Envelope from sedona.core.spatialOperator import RangeQueryRaw from sedona.utils.adapter import Adapter range_query_window = Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) consider_boundary_intersection = False ## Only return gemeotries fully covered by the window using_index = False query_result = RangeQueryRaw . SpatialRangeQuery ( spatial_rdd , range_query_window , consider_boundary_intersection , using_index ) gdf = Adapter . toDf ( query_result , spark , [ \"col1\" , ... , \"coln\" ])","title":"Write a Spatial Range Query"},{"location":"tutorial/core-python/#range-query-window","text":"Besides the rectangle (Envelope) type range query window, Apache Sedona range query window can be Point Polygon LineString To create shapely geometries please follow Shapely official docs","title":"Range query window"},{"location":"tutorial/core-python/#use-spatial-indexes","text":"Sedona provides two types of spatial indexes, Quad-Tree R-Tree Once you specify an index type, Sedona will build a local tree index on each of the SpatialRDD partition. To utilize a spatial index in a spatial range query, use the following code: from sedona.core.geom.envelope import Envelope from sedona.core.enums import IndexType from sedona.core.spatialOperator import RangeQuery range_query_window = Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) consider_boundary_intersection = False ## Only return gemeotries fully covered by the window build_on_spatial_partitioned_rdd = False ## Set to TRUE only if run join query spatial_rdd . buildIndex ( IndexType . QUADTREE , build_on_spatial_partitioned_rdd ) using_index = True query_result = RangeQuery . SpatialRangeQuery ( spatial_rdd , range_query_window , consider_boundary_intersection , using_index )","title":"Use spatial indexes"},{"location":"tutorial/core-python/#output-format","text":"The output format of the spatial range query is another RDD which consists of GeoData objects. SpatialRangeQuery result can be used as RDD with map or other spark RDD funtions. Also it can be used as Python objects when using collect method. Example: query_result . map ( lambda x : x . geom . length ) . collect () [ 1.5900840000000045, 1.5906639999999896, 1.1110299999999995, 1.1096700000000084, 1.1415619999999933, 1.1386399999999952, 1.1415619999999933, 1.1418860000000137, 1.1392780000000045, ... ] Or transformed to GeoPandas GeoDataFrame import geopandas as gpd gpd . GeoDataFrame ( query_result . map ( lambda x : [ x . geom , x . userData ]) . collect (), columns = [ \"geom\" , \"user_data\" ], geometry = \"geom\" )","title":"Output format"},{"location":"tutorial/core-python/#write-a-spatial-knn-query","text":"A spatial K Nearnest Neighbor query takes as input a K, a query point and an SpatialRDD and finds the K geometries in the RDD which are the closest to he query point. Assume you now have an SpatialRDD (typed or generic). You can use the following code to issue an Spatial KNN Query on it. from sedona.core.spatialOperator import KNNQuery from shapely.geometry import Point point = Point ( - 84.01 , 34.01 ) k = 1000 ## K Nearest Neighbors using_index = False result = KNNQuery . SpatialKnnQuery ( object_rdd , point , k , using_index )","title":"Write a Spatial KNN Query"},{"location":"tutorial/core-python/#query-center-geometry","text":"Besides the Point type, Apache Sedona KNN query center can be Polygon LineString To create Polygon or Linestring object please follow Shapely official docs","title":"Query center geometry"},{"location":"tutorial/core-python/#use-spatial-indexes_1","text":"To utilize a spatial index in a spatial KNN query, use the following code: from sedona.core.spatialOperator import KNNQuery from sedona.core.enums import IndexType from shapely.geometry import Point point = Point ( - 84.01 , 34.01 ) k = 5 ## K Nearest Neighbors build_on_spatial_partitioned_rdd = False ## Set to TRUE only if run join query spatial_rdd . buildIndex ( IndexType . RTREE , build_on_spatial_partitioned_rdd ) using_index = True result = KNNQuery . SpatialKnnQuery ( spatial_rdd , point , k , using_index ) Warning Only R-Tree index supports Spatial KNN query","title":"Use spatial indexes"},{"location":"tutorial/core-python/#output-format_1","text":"The output format of the spatial KNN query is a list of GeoData objects. The list has K GeoData objects. Example: >> result [ GeoData , GeoData , GeoData , GeoData , GeoData ]","title":"Output format"},{"location":"tutorial/core-python/#write-a-spatial-join-query","text":"A spatial join query takes as input two Spatial RDD A and B. For each geometry in A, finds the geometries (from B) covered/intersected by it. A and B can be any geometry type and are not necessary to have the same geometry type. Assume you now have two SpatialRDDs (typed or generic). You can use the following code to issue an Spatial Join Query on them. from sedona.core.enums import GridType from sedona.core.spatialOperator import JoinQuery consider_boundary_intersection = False ## Only return geometries fully covered by each query window in queryWindowRDD using_index = False object_rdd . analyze () object_rdd . spatialPartitioning ( GridType . KDBTREE ) query_window_rdd . spatialPartitioning ( object_rdd . getPartitioner ()) result = JoinQuery . SpatialJoinQuery ( object_rdd , query_window_rdd , using_index , consider_boundary_intersection ) Result of SpatialJoinQuery is RDD which consists of GeoData instance and list of GeoData instances which spatially intersects or are covered by GeoData. result . collect ()) [ [GeoData, [GeoData, GeoData, GeoData, GeoData]], [GeoData, [GeoData, GeoData, GeoData]], [GeoData, [GeoData]], [GeoData, [GeoData, GeoData]], ... [GeoData, [GeoData, GeoData]] ]","title":"Write a Spatial Join Query"},{"location":"tutorial/core-python/#use-spatial-partitioning","text":"Apache Sedona spatial partitioning method can significantly speed up the join query. Three spatial partitioning methods are available: KDB-Tree, Quad-Tree and R-Tree. Two SpatialRDD must be partitioned by the same way. If you first partition SpatialRDD A, then you must use the partitioner of A to partition B. object_rdd . spatialPartitioning ( GridType . KDBTREE ) query_window_rdd . spatialPartitioning ( object_rdd . getPartitioner ()) Or query_window_rdd . spatialPartitioning ( GridType . KDBTREE ) object_rdd . spatialPartitioning ( query_window_rdd . getPartitioner ())","title":"Use spatial partitioning"},{"location":"tutorial/core-python/#use-spatial-indexes_2","text":"To utilize a spatial index in a spatial join query, use the following code: from sedona.core.enums import GridType from sedona.core.enums import IndexType from sedona.core.spatialOperator import JoinQuery object_rdd . spatialPartitioning ( GridType . KDBTREE ) query_window_rdd . spatialPartitioning ( object_rdd . getPartitioner ()) build_on_spatial_partitioned_rdd = True ## Set to TRUE only if run join query using_index = True query_window_rdd . buildIndex ( IndexType . QUADTREE , build_on_spatial_partitioned_rdd ) result = JoinQuery . SpatialJoinQueryFlat ( object_rdd , query_window_rdd , using_index , True ) The index should be built on either one of two SpatialRDDs. In general, you should build it on the larger SpatialRDD.","title":"Use spatial indexes"},{"location":"tutorial/core-python/#output-format_2","text":"The output format of the spatial join query is a PairRDD. In this PairRDD, each object is a pair of two GeoData objects. The left one is the GeoData from object_rdd and the right one is the GeoData from the query_window_rdd. Point,Polygon Point,Polygon Point,Polygon Polygon,Polygon LineString,LineString Polygon,LineString ... example result . collect () [ [GeoData, GeoData], [GeoData, GeoData], [GeoData, GeoData], [GeoData, GeoData], ... [GeoData, GeoData], [GeoData, GeoData] ] Each object on the left is covered/intersected by the object on the right.","title":"Output format"},{"location":"tutorial/core-python/#write-a-distance-join-query","text":"!!!warning RDD distance joins are only reliable for points. For other geometry types, please use Spatial SQL. A distance join query takes two spatial RDD assuming that we have two SpatialRDD's: object_rdd spatial_rdd And finds the geometries (from spatial_rdd) are within given distance to it. spatial_rdd and object_rdd can be any geometry type (point, line, polygon) and are not necessary to have the same geometry type You can use the following code to issue an Distance Join Query on them. from sedona.core.SpatialRDD import CircleRDD from sedona.core.enums import GridType from sedona.core.spatialOperator import JoinQuery object_rdd . analyze () circle_rdd = CircleRDD ( object_rdd , 0.1 ) ## Create a CircleRDD using the given distance circle_rdd . analyze () circle_rdd . spatialPartitioning ( GridType . KDBTREE ) spatial_rdd . spatialPartitioning ( circle_rdd . getPartitioner ()) consider_boundary_intersection = False ## Only return gemeotries fully covered by each query window in queryWindowRDD using_index = False result = JoinQuery . DistanceJoinQueryFlat ( spatial_rdd , circle_rdd , using_index , consider_boundary_intersection ) Note Please use JoinQueryRaw from the same module for methods spatialJoin DistanceJoinQueryFlat SpatialJoinQueryFlat For better performance while converting to dataframe with adapter. That approach allows to avoid costly serialization between Python and jvm and in result operating on python object instead of native geometries. Example: from sedona.core.SpatialRDD import CircleRDD from sedona.core.enums import GridType from sedona.core.spatialOperator import JoinQueryRaw object_rdd . analyze () circle_rdd = CircleRDD ( object_rdd , 0.1 ) ## Create a CircleRDD using the given distance circle_rdd . analyze () circle_rdd . spatialPartitioning ( GridType . KDBTREE ) spatial_rdd . spatialPartitioning ( circle_rdd . getPartitioner ()) consider_boundary_intersection = False ## Only return gemeotries fully covered by each query window in queryWindowRDD using_index = False result = JoinQueryRaw . DistanceJoinQueryFlat ( spatial_rdd , circle_rdd , using_index , consider_boundary_intersection ) gdf = Adapter . toDf ( result , [ \"left_col1\" , ... , \"lefcoln\" ], [ \"rightcol1\" , ... , \"rightcol2\" ], spark )","title":"Write a Distance Join Query"},{"location":"tutorial/core-python/#output-format_3","text":"Result for this query is RDD which holds two GeoData objects within list of lists. Example: result . collect () [[GeoData, GeoData], [GeoData, GeoData] ...] It is possible to do some RDD operation on result data ex. Getting polygon centroid. result . map ( lambda x : x [ 0 ] . geom . centroid ) . collect () [ <shapely.geometry.point.Point at 0x7efee2d28128>, <shapely.geometry.point.Point at 0x7efee2d280b8>, <shapely.geometry.point.Point at 0x7efee2d28fd0>, <shapely.geometry.point.Point at 0x7efee2d28080>, ... ]","title":"Output format"},{"location":"tutorial/core-python/#save-to-permanent-storage","text":"You can always save an SpatialRDD back to some permanent storage such as HDFS and Amazon S3. You can save distributed SpatialRDD to WKT, GeoJSON and object files. Note Non-spatial attributes such as price, age and name will also be stored to permanent storage.","title":"Save to permanent storage"},{"location":"tutorial/core-python/#save-an-spatialrdd-not-indexed","text":"Typed SpatialRDD and generic SpatialRDD can be saved to permanent storage.","title":"Save an SpatialRDD (not indexed)"},{"location":"tutorial/core-python/#save-an-spatialrdd-indexed","text":"Indexed typed SpatialRDD and generic SpatialRDD can be saved to permanent storage. However, the indexed SpatialRDD has to be stored as a distributed object file.","title":"Save an SpatialRDD (indexed)"},{"location":"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed","text":"A spatial partitioned RDD can be saved to permanent storage but Spark is not able to maintain the same RDD partition Id of the original RDD. This will lead to wrong join query results. We are working on some solutions. Stay tuned!","title":"Save an SpatialRDD (spatialPartitioned W/O indexed)"},{"location":"tutorial/core-python/#reload-a-saved-spatialrdd","text":"You can easily reload an SpatialRDD that has been saved to a distributed object file .","title":"Reload a saved SpatialRDD"},{"location":"tutorial/core-python/#read-from-other-geometry-files","text":"All below methods will return SpatialRDD object which can be used with Spatial functions such as Spatial Join etc.","title":"Read from other Geometry files"},{"location":"tutorial/core-python/#read-from-wkt-file","text":"from sedona.core.formatMapper import WktReader WktReader . readToGeometryRDD ( sc , wkt_geometries_location , 0 , True , False ) <sedona.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2fbf250>","title":"Read from WKT file"},{"location":"tutorial/core-python/#read-from-wkb-file","text":"from sedona.core.formatMapper import WkbReader WkbReader . readToGeometryRDD ( sc , wkb_geometries_location , 0 , True , False ) <sedona.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2eece50>","title":"Read from WKB file"},{"location":"tutorial/core-python/#read-from-geojson-file","text":"from sedona.core.formatMapper import GeoJsonReader GeoJsonReader . readToGeometryRDD ( sc , geo_json_file_location ) <sedona.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2eecb90>","title":"Read from GeoJson file"},{"location":"tutorial/core-python/#read-from-shapefile","text":"from sedona.core.formatMapper.shapefileParser import ShapefileReader ShapefileReader . readToGeometryRDD ( sc , shape_file_location ) <sedona.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f8fd2ee0710>","title":"Read from Shapefile"},{"location":"tutorial/core-python/#tips","text":"When you use Sedona functions such as JoinQuery.spatialJoin JoinQuery.DistanceJoinQueryFlat JoinQuery.SpatialJoinQueryFlat RangeQuery.SpatialRangeQuery For better performance when converting to dataframe you can use JoinQueryRaw and RangeQueryRaw from the same module and adapter to convert to Spatial DataFrame. Example, JoinQueryRaw: from sedona.core.SpatialRDD import CircleRDD from sedona.core.enums import GridType from sedona.core.spatialOperator import JoinQueryRaw object_rdd . analyze () circle_rdd = CircleRDD ( object_rdd , 0.1 ) ## Create a CircleRDD using the given distance circle_rdd . analyze () circle_rdd . spatialPartitioning ( GridType . KDBTREE ) spatial_rdd . spatialPartitioning ( circle_rdd . getPartitioner ()) consider_boundary_intersection = False ## Only return gemeotries fully covered by each query window in queryWindowRDD using_index = False result = JoinQueryRaw . DistanceJoinQueryFlat ( spatial_rdd , circle_rdd , using_index , consider_boundary_intersection ) gdf = Adapter . toDf ( result , [ \"left_col1\" , ... , \"lefcoln\" ], [ \"rightcol1\" , ... , \"rightcol2\" ], spark ) and RangeQueryRaw from sedona.core.geom.envelope import Envelope from sedona.core.spatialOperator import RangeQueryRaw from sedona.utils.adapter import Adapter range_query_window = Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) consider_boundary_intersection = False ## Only return gemeotries fully covered by the window using_index = False query_result = RangeQueryRaw . SpatialRangeQuery ( spatial_rdd , range_query_window , consider_boundary_intersection , using_index ) gdf = Adapter . toDf ( query_result , spark , [ \"col1\" , ... , \"coln\" ])","title":"Tips"},{"location":"tutorial/demo/","text":"Scala and Java Examples \u00b6 Scala and Java Examples contains template projects for RDD, SQL and Viz. The template projects have been configured properly. Note that, although the template projects are written in Scala, the same APIs can be used in Java as well. Folder structure \u00b6 The folder structure of this repository is as follows. rdd-colocation-mining: a scala template shows how to use Sedona RDD API in Spatial Data Mining sql: a scala template shows how to use Sedona DataFrame and SQL API viz: a scala template shows how to use Sedona Viz RDD and SQL API Compile and package \u00b6 Prerequisites \u00b6 Please make sure you have the following software installed on your local machine: For Scala: Scala 2.12, SBT For Java: JDK 1.8, Apache Maven 3 Compile \u00b6 Run a terminal command sbt assembly within the folder of each template Submit your fat jar to Spark \u00b6 After running the command mentioned above, you are able to see a fat jar in ./target folder. Please take it and use ./bin/spark-submit to submit this jar. To run the jar in this way, you need to: Either change Spark Master Address in template projects or simply delete it. Currently, they are hard coded to local[*] which means run locally with all cores. Change the dependency packaging scope of Apache Spark from \"compile\" to \"provided\". This is a common packaging strategy in Maven and SBT which means do not package Spark into your fat jar. Otherwise, this may lead to a huge jar and version conflicts! Make sure the dependency versions in build.sbt are consistent with your Spark version. Run template projects locally \u00b6 We highly suggest you use IDEs to run template projects on your local machine. For Scala, we recommend IntelliJ IDEA with Scala plug-in. For Java, we recommend IntelliJ IDEA and Eclipse. With the help of IDEs, you don't have to prepare anything (even don't need to download and set up Spark!). As long as you have Scala and Java, everything works properly! Scala \u00b6 Import the Scala template project as SBT project. Then run the Main file in this project.","title":"Scala/Java"},{"location":"tutorial/demo/#scala-and-java-examples","text":"Scala and Java Examples contains template projects for RDD, SQL and Viz. The template projects have been configured properly. Note that, although the template projects are written in Scala, the same APIs can be used in Java as well.","title":"Scala and Java Examples"},{"location":"tutorial/demo/#folder-structure","text":"The folder structure of this repository is as follows. rdd-colocation-mining: a scala template shows how to use Sedona RDD API in Spatial Data Mining sql: a scala template shows how to use Sedona DataFrame and SQL API viz: a scala template shows how to use Sedona Viz RDD and SQL API","title":"Folder structure"},{"location":"tutorial/demo/#compile-and-package","text":"","title":"Compile and package"},{"location":"tutorial/demo/#prerequisites","text":"Please make sure you have the following software installed on your local machine: For Scala: Scala 2.12, SBT For Java: JDK 1.8, Apache Maven 3","title":"Prerequisites"},{"location":"tutorial/demo/#compile","text":"Run a terminal command sbt assembly within the folder of each template","title":"Compile"},{"location":"tutorial/demo/#submit-your-fat-jar-to-spark","text":"After running the command mentioned above, you are able to see a fat jar in ./target folder. Please take it and use ./bin/spark-submit to submit this jar. To run the jar in this way, you need to: Either change Spark Master Address in template projects or simply delete it. Currently, they are hard coded to local[*] which means run locally with all cores. Change the dependency packaging scope of Apache Spark from \"compile\" to \"provided\". This is a common packaging strategy in Maven and SBT which means do not package Spark into your fat jar. Otherwise, this may lead to a huge jar and version conflicts! Make sure the dependency versions in build.sbt are consistent with your Spark version.","title":"Submit your fat jar to Spark"},{"location":"tutorial/demo/#run-template-projects-locally","text":"We highly suggest you use IDEs to run template projects on your local machine. For Scala, we recommend IntelliJ IDEA with Scala plug-in. For Java, we recommend IntelliJ IDEA and Eclipse. With the help of IDEs, you don't have to prepare anything (even don't need to download and set up Spark!). As long as you have Scala and Java, everything works properly!","title":"Run template projects locally"},{"location":"tutorial/demo/#scala","text":"Import the Scala template project as SBT project. Then run the Main file in this project.","title":"Scala"},{"location":"tutorial/jupyter-notebook/","text":"Python Jupyter Notebook Examples \u00b6 Click and play the interactive Sedona Python Jupyter Notebook immediately! Sedona Python provides a number of Jupyter Notebook examples . Please use the following steps to run Jupyter notebook with Pipenv on your machine Clone Sedona GitHub repo or download the source code Install Sedona Python from PyPi or GitHub source: Read Install Sedona Python to learn. Prepare python-adapter jar: Read Install Sedona Python to learn. Setup pipenv python version. For Spark 3.0, Sedona supports 3.7 - 3.9 cd binder pipenv --python 3 .8 Install dependencies cd binder pipenv install Install jupyter notebook kernel for pipenv pipenv install ipykernel pipenv shell In the pipenv shell, do python -m ipykernel install --user --name = apache-sedona Setup environment variables SPARK_HOME and PYTHONPATH if you didn't do it before. Read Install Sedona Python to learn. Launch jupyter notebook: jupyter notebook Select Sedona notebook. In your notebook, Kernel -> Change Kernel. Your kernel should now be an option.","title":"Python"},{"location":"tutorial/jupyter-notebook/#python-jupyter-notebook-examples","text":"Click and play the interactive Sedona Python Jupyter Notebook immediately! Sedona Python provides a number of Jupyter Notebook examples . Please use the following steps to run Jupyter notebook with Pipenv on your machine Clone Sedona GitHub repo or download the source code Install Sedona Python from PyPi or GitHub source: Read Install Sedona Python to learn. Prepare python-adapter jar: Read Install Sedona Python to learn. Setup pipenv python version. For Spark 3.0, Sedona supports 3.7 - 3.9 cd binder pipenv --python 3 .8 Install dependencies cd binder pipenv install Install jupyter notebook kernel for pipenv pipenv install ipykernel pipenv shell In the pipenv shell, do python -m ipykernel install --user --name = apache-sedona Setup environment variables SPARK_HOME and PYTHONPATH if you didn't do it before. Read Install Sedona Python to learn. Launch jupyter notebook: jupyter notebook Select Sedona notebook. In your notebook, Kernel -> Change Kernel. Your kernel should now be an option.","title":"Python Jupyter Notebook Examples"},{"location":"tutorial/python-vector-osm/","text":"Example of spark + sedona + hdfs with slave nodes and OSM vector data consults \u00b6 from IPython.display import display, HTML from pyspark.sql import SparkSession from pyspark import StorageLevel import pandas as pd from pyspark.sql.types import StructType, StructField,StringType, LongType, IntegerType, DoubleType, ArrayType from pyspark.sql.functions import regexp_replace from sedona.register import SedonaRegistrator from sedona.utils import SedonaKryoRegistrator, KryoSerializer from pyspark.sql.functions import col, split, expr from pyspark.sql.functions import udf, lit from sedona.utils import SedonaKryoRegistrator, KryoSerializer from pyspark.sql.functions import col, split, expr from pyspark.sql.functions import udf, lit, flatten from pywebhdfs.webhdfs import PyWebHdfsClient from datetime import date from pyspark.sql.functions import monotonically_increasing_id import json Registering spark session, adding node executor configurations and sedona registrator \u00b6 spark = SparkSession.\\ builder.\\ appName(\"Overpass-API\").\\ enableHiveSupport().\\ master(\"local[*]\").\\ master(\"spark://spark-master:7077\").\\ config(\"spark.executor.memory\", \"15G\").\\ config(\"spark.driver.maxResultSize\", \"135G\").\\ config(\"spark.sql.shuffle.partitions\", \"500\").\\ config(' spark.sql.adaptive.coalescePartitions.enabled', True).\\ config('spark.sql.adaptive.enabled', True).\\ config('spark.sql.adaptive.coalescePartitions.initialPartitionNum', 125).\\ config(\"spark.sql.execution.arrow.pyspark.enabled\", True).\\ config(\"spark.sql.execution.arrow.fallback.enabled\", True).\\ config('spark.kryoserializer.buffer.max', 2047).\\ config(\"spark.serializer\", KryoSerializer.getName).\\ config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName).\\ config(\"spark.jars.packages\", \"org.apache.sedona:sedona-python-adapter-3.0_2.12:1.1.0-incubating,org.datasyslab:geotools-wrapper:1.1.0-25.2\") .\\ enableHiveSupport().\\ getOrCreate() SedonaRegistrator.registerAll(spark) sc = spark.sparkContext Connecting to Overpass API to search and downloading data for saving into HDFS \u00b6 import requests import json overpass_url = \"http://overpass-api.de/api/interpreter\" overpass_query = \"\"\" [out:json]; area[name = \"Foz do Igua\u00e7u\"]; way(area)[\"highway\"~\"\"]; out geom; >; out skel qt; \"\"\" response = requests.get(overpass_url, params={'data': overpass_query}) data = response.json() hdfs = PyWebHdfsClient(host='179.106.229.159',port='50070', user_name='root') file_name = \"foz_roads_osm.json\" hdfs.delete_file_dir(file_name) hdfs.create_file(file_name, json.dumps(data)) Connecting spark sedona with saved hdfs file \u00b6 path = \"hdfs://776faf4d6a1e:8020/\"+file_name df = spark.read.json(path, multiLine = \"true\") Consulting and organizing data for analisis \u00b6 from pyspark.sql.functions import explode, arrays_zip df.createOrReplaceTempView(\"df\") tb = spark.sql(\"select *, size(elements) total_nodes from df\") tb.show(5) isolate_total_nodes = tb.select(\"total_nodes\").toPandas() total_nodes = isolate_total_nodes[\"total_nodes\"].iloc[0] print(total_nodes) isolate_ids = tb.select(\"elements.id\").toPandas() ids = pd.DataFrame(isolate_ids[\"id\"].iloc[0]).drop_duplicates() print(ids[0].iloc[1]) formatted_df = tb\\ .withColumn(\"id\", explode(\"elements.id\")) formatted_df.show(5) formatted_df = tb\\ .withColumn(\"new\", arrays_zip(\"elements.id\", \"elements.geometry\", \"elements.nodes\", \"elements.tags\"))\\ .withColumn(\"new\", explode(\"new\")) formatted_df.show(5) # formatted_df.printSchema() formatted_df = formatted_df.select(\"new.0\",\"new.1\",\"new.2\",\"new.3.maxspeed\",\"new.3.incline\",\"new.3.surface\", \"new.3.name\", \"total_nodes\") formatted_df = formatted_df.withColumnRenamed(\"0\",\"id\").withColumnRenamed(\"1\",\"geom\").withColumnRenamed(\"2\",\"nodes\").withColumnRenamed(\"3\",\"tags\") formatted_df.createOrReplaceTempView(\"formatted_df\") formatted_df.show(5) # TODO atualizar daqui para baixo para considerar a linha inteira na l\u00f3gica points_tb = spark.sql(\"select geom, id from formatted_df where geom IS NOT NULL\") points_tb = points_tb\\ .withColumn(\"new\", arrays_zip(\"geom.lat\", \"geom.lon\"))\\ .withColumn(\"new\", explode(\"new\")) points_tb = points_tb.select(\"new.0\",\"new.1\", \"id\") points_tb = points_tb.withColumnRenamed(\"0\",\"lat\").withColumnRenamed(\"1\",\"lon\") points_tb.printSchema() points_tb.createOrReplaceTempView(\"points_tb\") points_tb.show(5) coordinates_tb = spark.sql(\"select (select collect_list(CONCAT(p1.lat,',',p1.lon)) from points_tb p1 where p1.id = p2.id group by p1.id) as coordinates, p2.id, p2.maxspeed, p2.incline, p2.surface, p2.name, p2.nodes, p2.total_nodes from formatted_df p2\") coordinates_tb.createOrReplaceTempView(\"coordinates_tb\") coordinates_tb.show(5) roads_tb = spark.sql(\"SELECT ST_LineStringFromText(REPLACE(REPLACE(CAST(coordinates as string),'[',''),']',''), ',') as geom, id, maxspeed, incline, surface, name, nodes, total_nodes FROM coordinates_tb WHERE coordinates IS NOT NULL\") roads_tb.createOrReplaceTempView(\"roads_tb\") roads_tb.show(5)","title":"Example of spark + sedona + hdfs with slave nodes and OSM vector data consults"},{"location":"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults","text":"from IPython.display import display, HTML from pyspark.sql import SparkSession from pyspark import StorageLevel import pandas as pd from pyspark.sql.types import StructType, StructField,StringType, LongType, IntegerType, DoubleType, ArrayType from pyspark.sql.functions import regexp_replace from sedona.register import SedonaRegistrator from sedona.utils import SedonaKryoRegistrator, KryoSerializer from pyspark.sql.functions import col, split, expr from pyspark.sql.functions import udf, lit from sedona.utils import SedonaKryoRegistrator, KryoSerializer from pyspark.sql.functions import col, split, expr from pyspark.sql.functions import udf, lit, flatten from pywebhdfs.webhdfs import PyWebHdfsClient from datetime import date from pyspark.sql.functions import monotonically_increasing_id import json","title":"Example of spark + sedona + hdfs with slave nodes and OSM vector data consults"},{"location":"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator","text":"spark = SparkSession.\\ builder.\\ appName(\"Overpass-API\").\\ enableHiveSupport().\\ master(\"local[*]\").\\ master(\"spark://spark-master:7077\").\\ config(\"spark.executor.memory\", \"15G\").\\ config(\"spark.driver.maxResultSize\", \"135G\").\\ config(\"spark.sql.shuffle.partitions\", \"500\").\\ config(' spark.sql.adaptive.coalescePartitions.enabled', True).\\ config('spark.sql.adaptive.enabled', True).\\ config('spark.sql.adaptive.coalescePartitions.initialPartitionNum', 125).\\ config(\"spark.sql.execution.arrow.pyspark.enabled\", True).\\ config(\"spark.sql.execution.arrow.fallback.enabled\", True).\\ config('spark.kryoserializer.buffer.max', 2047).\\ config(\"spark.serializer\", KryoSerializer.getName).\\ config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName).\\ config(\"spark.jars.packages\", \"org.apache.sedona:sedona-python-adapter-3.0_2.12:1.1.0-incubating,org.datasyslab:geotools-wrapper:1.1.0-25.2\") .\\ enableHiveSupport().\\ getOrCreate() SedonaRegistrator.registerAll(spark) sc = spark.sparkContext","title":"Registering spark session, adding node executor configurations and sedona registrator"},{"location":"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs","text":"import requests import json overpass_url = \"http://overpass-api.de/api/interpreter\" overpass_query = \"\"\" [out:json]; area[name = \"Foz do Igua\u00e7u\"]; way(area)[\"highway\"~\"\"]; out geom; >; out skel qt; \"\"\" response = requests.get(overpass_url, params={'data': overpass_query}) data = response.json() hdfs = PyWebHdfsClient(host='179.106.229.159',port='50070', user_name='root') file_name = \"foz_roads_osm.json\" hdfs.delete_file_dir(file_name) hdfs.create_file(file_name, json.dumps(data))","title":"Connecting to Overpass API to search and downloading data for saving into HDFS"},{"location":"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file","text":"path = \"hdfs://776faf4d6a1e:8020/\"+file_name df = spark.read.json(path, multiLine = \"true\")","title":"Connecting spark sedona with saved hdfs file"},{"location":"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis","text":"from pyspark.sql.functions import explode, arrays_zip df.createOrReplaceTempView(\"df\") tb = spark.sql(\"select *, size(elements) total_nodes from df\") tb.show(5) isolate_total_nodes = tb.select(\"total_nodes\").toPandas() total_nodes = isolate_total_nodes[\"total_nodes\"].iloc[0] print(total_nodes) isolate_ids = tb.select(\"elements.id\").toPandas() ids = pd.DataFrame(isolate_ids[\"id\"].iloc[0]).drop_duplicates() print(ids[0].iloc[1]) formatted_df = tb\\ .withColumn(\"id\", explode(\"elements.id\")) formatted_df.show(5) formatted_df = tb\\ .withColumn(\"new\", arrays_zip(\"elements.id\", \"elements.geometry\", \"elements.nodes\", \"elements.tags\"))\\ .withColumn(\"new\", explode(\"new\")) formatted_df.show(5) # formatted_df.printSchema() formatted_df = formatted_df.select(\"new.0\",\"new.1\",\"new.2\",\"new.3.maxspeed\",\"new.3.incline\",\"new.3.surface\", \"new.3.name\", \"total_nodes\") formatted_df = formatted_df.withColumnRenamed(\"0\",\"id\").withColumnRenamed(\"1\",\"geom\").withColumnRenamed(\"2\",\"nodes\").withColumnRenamed(\"3\",\"tags\") formatted_df.createOrReplaceTempView(\"formatted_df\") formatted_df.show(5) # TODO atualizar daqui para baixo para considerar a linha inteira na l\u00f3gica points_tb = spark.sql(\"select geom, id from formatted_df where geom IS NOT NULL\") points_tb = points_tb\\ .withColumn(\"new\", arrays_zip(\"geom.lat\", \"geom.lon\"))\\ .withColumn(\"new\", explode(\"new\")) points_tb = points_tb.select(\"new.0\",\"new.1\", \"id\") points_tb = points_tb.withColumnRenamed(\"0\",\"lat\").withColumnRenamed(\"1\",\"lon\") points_tb.printSchema() points_tb.createOrReplaceTempView(\"points_tb\") points_tb.show(5) coordinates_tb = spark.sql(\"select (select collect_list(CONCAT(p1.lat,',',p1.lon)) from points_tb p1 where p1.id = p2.id group by p1.id) as coordinates, p2.id, p2.maxspeed, p2.incline, p2.surface, p2.name, p2.nodes, p2.total_nodes from formatted_df p2\") coordinates_tb.createOrReplaceTempView(\"coordinates_tb\") coordinates_tb.show(5) roads_tb = spark.sql(\"SELECT ST_LineStringFromText(REPLACE(REPLACE(CAST(coordinates as string),'[',''),']',''), ',') as geom, id, maxspeed, incline, surface, name, nodes, total_nodes FROM coordinates_tb WHERE coordinates IS NOT NULL\") roads_tb.createOrReplaceTempView(\"roads_tb\") roads_tb.show(5)","title":"Consulting and organizing data for analisis"},{"location":"tutorial/raster/","text":"Starting from v1.1.0 , Sedona SQL supports raster data sources and raster operators in DataFrame and SQL. Raster support is available in all Sedona language bindings including Scala, Java, Python and R . Initial setup \u00b6 Set up dependencies Initiate Spark session Register SedonaSQL API docs \u00b6 IO of raster data in DataFrame Map algebra in DataFrame Tutorials \u00b6 Python Jupyter Notebook","title":"Raster data - Map Algebra"},{"location":"tutorial/raster/#initial-setup","text":"Set up dependencies Initiate Spark session Register SedonaSQL","title":"Initial setup"},{"location":"tutorial/raster/#api-docs","text":"IO of raster data in DataFrame Map algebra in DataFrame","title":"API docs"},{"location":"tutorial/raster/#tutorials","text":"Python Jupyter Notebook","title":"Tutorials"},{"location":"tutorial/rdd-r/","text":"Spatial RDD applications in R language \u00b6 What are SpatialRDD s? \u00b6 SpatialRDDs are basic building blocks of distributed spatial data in Apache Sedona. A SpatialRDD can be partitioned and indexed using well-known spatial data structures to facilitate range queries, KNN queries, and other low-level operations. One can also export records from SpatailRDD s into regular Spark dataframes, making them accessible through Spark SQL and through the dplyr interface of sparklyr . Creating a SpatialRDD \u00b6 NOTE: this section is largely based on Spatial RDD Scala tutorial , except for examples have been written in R instead of Scala to reflect usages of apache.sedona . Currently SpatialRDD s can be created in apache.sedona by reading a file in a supported geospatial format, or by extracting data from a Spark SQL query. For example, the following code will import data from arealm-small.csv into a SpatialRDD : pt_rdd <- sedona_read_dsv_to_typed_rdd ( sc , location = \"arealm-small.csv\" , delimiter = \",\" , type = \"point\" , first_spatial_col_index = 1 , has_non_spatial_attrs = TRUE ) . Records from the example arealm-small.csv file look like the following: testattribute0,-88.331492,32.324142,testattribute1,testattribute2 testattribute0,-88.175933,32.360763,testattribute1,testattribute2 testattribute0,-88.388954,32.357073,testattribute1,testattribute2 As one can see from the above, each record is comma-separated and consists of a 2-dimensional coordinate starting at the 2 nd column and ending at the 3 rd column. All other columns contain non-spatial attributes. Because column indexes are 0-based, we need to specify first_spatial_col_index = 1 in the example above to ensure each record is parsed correctly. In addition to formats such as CSV and TSV, currently apache.sedona also supports reading files in WKT (Well-Known Text), WKB (Well-Known Binary), and GeoJSON formats. See ?apache.sedona::sedona_read_wkt , ?apache.sedona::sedona_read_wkb , and ?apache.sedona::sedona_read_geojson for details. One can also run to_spatial_rdd() to extract a SpatailRDD from a Spark SQL query, e.g., library ( sparklyr ) library ( apache.sedona ) library ( dplyr ) sc <- spark_connect ( master = \"local\" ) sdf <- tbl ( sc , sql ( \"SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `geom`, \\\"point\\\" AS `type`\" ) ) spatial_rdd <- sdf %>% to_spatial_rdd ( spatial_col = \"geom\" ) print ( spatial_rdd ) ## $.jobj ## <jobj[70]> ## org.apache.sedona.core.spatialRDD.SpatialRDD ## org.apache.sedona.core.spatialRDD.SpatialRDD@422afc5a ## ## ... will extract a spatial column named \"geom\" from the Sedona spatial SQL query above and store it in a SpatialRDD object.","title":"R"},{"location":"tutorial/rdd-r/#spatial-rdd-applications-in-r-language","text":"","title":"Spatial RDD applications in R language"},{"location":"tutorial/rdd-r/#what-are-spatialrdds","text":"SpatialRDDs are basic building blocks of distributed spatial data in Apache Sedona. A SpatialRDD can be partitioned and indexed using well-known spatial data structures to facilitate range queries, KNN queries, and other low-level operations. One can also export records from SpatailRDD s into regular Spark dataframes, making them accessible through Spark SQL and through the dplyr interface of sparklyr .","title":"What are SpatialRDDs?"},{"location":"tutorial/rdd-r/#creating-a-spatialrdd","text":"NOTE: this section is largely based on Spatial RDD Scala tutorial , except for examples have been written in R instead of Scala to reflect usages of apache.sedona . Currently SpatialRDD s can be created in apache.sedona by reading a file in a supported geospatial format, or by extracting data from a Spark SQL query. For example, the following code will import data from arealm-small.csv into a SpatialRDD : pt_rdd <- sedona_read_dsv_to_typed_rdd ( sc , location = \"arealm-small.csv\" , delimiter = \",\" , type = \"point\" , first_spatial_col_index = 1 , has_non_spatial_attrs = TRUE ) . Records from the example arealm-small.csv file look like the following: testattribute0,-88.331492,32.324142,testattribute1,testattribute2 testattribute0,-88.175933,32.360763,testattribute1,testattribute2 testattribute0,-88.388954,32.357073,testattribute1,testattribute2 As one can see from the above, each record is comma-separated and consists of a 2-dimensional coordinate starting at the 2 nd column and ending at the 3 rd column. All other columns contain non-spatial attributes. Because column indexes are 0-based, we need to specify first_spatial_col_index = 1 in the example above to ensure each record is parsed correctly. In addition to formats such as CSV and TSV, currently apache.sedona also supports reading files in WKT (Well-Known Text), WKB (Well-Known Binary), and GeoJSON formats. See ?apache.sedona::sedona_read_wkt , ?apache.sedona::sedona_read_wkb , and ?apache.sedona::sedona_read_geojson for details. One can also run to_spatial_rdd() to extract a SpatailRDD from a Spark SQL query, e.g., library ( sparklyr ) library ( apache.sedona ) library ( dplyr ) sc <- spark_connect ( master = \"local\" ) sdf <- tbl ( sc , sql ( \"SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `geom`, \\\"point\\\" AS `type`\" ) ) spatial_rdd <- sdf %>% to_spatial_rdd ( spatial_col = \"geom\" ) print ( spatial_rdd ) ## $.jobj ## <jobj[70]> ## org.apache.sedona.core.spatialRDD.SpatialRDD ## org.apache.sedona.core.spatialRDD.SpatialRDD@422afc5a ## ## ... will extract a spatial column named \"geom\" from the Sedona spatial SQL query above and store it in a SpatialRDD object.","title":"Creating a SpatialRDD"},{"location":"tutorial/rdd/","text":"The page outlines the steps to create Spatial RDDs and run spatial queries using Sedona-core. The example code is written in Scala but also works for Java . Set up dependencies \u00b6 Read Sedona Maven Central coordinates Select the minimum dependencies : Add Apache Spark (only the Spark core) and Sedona (core). Add the dependencies in build.sbt or pom.xml. Note To enjoy the full functions of Sedona, we suggest you include the full dependencies : Apache Spark core , Apache SparkSQL , Sedona-core, Sedona-SQL, Sedona-Viz. Please see RDD example project Initiate SparkContext \u00b6 val conf = new SparkConf () conf . setAppName ( \"SedonaRunnableExample\" ) // Change this to a proper name conf . setMaster ( \"local[*]\" ) // Delete this if run in cluster mode // Enable Sedona custom Kryo serializer conf . set ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) // org.apache.spark.serializer.KryoSerializer conf . set ( \"spark.kryo.registrator\" , classOf [ SedonaKryoRegistrator ]. getName ) // org.apache.sedona.core.serde.SedonaKryoRegistrator val sc = new SparkContext ( conf ) Warning Sedona has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. If you add the Sedona full dependencies as suggested above, please use the following two lines to enable Sedona Kryo serializer instead: conf . set ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) // org.apache.spark.serializer.KryoSerializer conf . set ( \"spark.kryo.registrator\" , classOf [ SedonaVizKryoRegistrator ]. getName ) // org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator Create a SpatialRDD \u00b6 Create a typed SpatialRDD \u00b6 Sedona-core provides three special SpatialRDDs: PointRDD, PolygonRDD, and LineStringRDD . They can be loaded from CSV, TSV, WKT, WKB, Shapefiles, GeoJSON and NetCDF/HDF format. PointRDD from CSV/TSV Suppose we have a checkin.csv CSV file at Path /Download/checkin.csv as follows: -88.331492,32.324142,hotel -88.175933,32.360763,gas -88.388954,32.357073,bar -88.221102,32.35078,restaurant This file has three columns and corresponding offsets (Column IDs) are 0, 1, 2. Use the following code to create a PointRDD val pointRDDInputLocation = \"/Download/checkin.csv\" val pointRDDOffset = 0 // The point long/lat starts from Column 0 val pointRDDSplitter = FileDataSplitter . CSV val carryOtherAttributes = true // Carry Column 2 (hotel, gas, bar...) var objectRDD = new PointRDD ( sc , pointRDDInputLocation , pointRDDOffset , pointRDDSplitter , carryOtherAttributes ) If the data file is in TSV format, just simply use the following line to replace the old FileDataSplitter: val pointRDDSplitter = FileDataSplitter . TSV PolygonRDD/LineStringRDD from CSV/TSV In general, polygon and line string data is stored in WKT, WKB, GeoJSON and Shapefile formats instead of CSV/TSV because the geometries in a file may have different lengths. However, if all polygons / line strings in your CSV/TSV possess the same length, you can create PolygonRDD and LineStringRDD from these files. Suppose we have a checkinshape.csv CSV file at Path /Download/checkinshape.csv as follows: -88.331492,32.324142,-88.331492,32.324142,-88.331492,32.324142,-88.331492,32.324142,-88.331492,32.324142,hotel -88.175933,32.360763,-88.175933,32.360763,-88.175933,32.360763,-88.175933,32.360763,-88.175933,32.360763,gas -88.388954,32.357073,-88.388954,32.357073,-88.388954,32.357073,-88.388954,32.357073,-88.388954,32.357073,bar -88.221102,32.35078,-88.221102,32.35078,-88.221102,32.35078,-88.221102,32.35078,-88.221102,32.35078,restaurant This file has 11 columns and corresponding offsets (Column IDs) are 0 - 10. Column 0 - 9 are 5 coordinates (longitude/latitude pairs). In this file, all geometries have the same number of coordinates. The geometries can be polyons or line strings. Warning For polygon data, the last coordinate must be the same as the first coordinate because a polygon is a closed linear ring. Use the following code to create a PolygonRDD. val polygonRDDInputLocation = \"/Download/checkinshape.csv\" val polygonRDDStartOffset = 0 // The coordinates start from Column 0 val polygonRDDEndOffset = 9 // The coordinates end at Column 9 val polygonRDDSplitter = FileDataSplitter . CSV val carryOtherAttributes = true // Carry Column 10 (hotel, gas, bar...) var objectRDD = new PolygonRDD ( sc , polygonRDDInputLocation , polygonRDDStartOffset , polygonRDDEndOffset , polygonRDDSplitter , carryOtherAttributes ) If the data file is in TSV format, just simply use the following line to replace the old FileDataSplitter: val polygonRDDSplitter = FileDataSplitter . TSV The way to create a LineStringRDD is the same as PolygonRDD. Create a generic SpatialRDD \u00b6 A generic SpatialRDD is not typed to a certain geometry type and open to more scenarios. It allows an input data file contains mixed types of geometries. For instance, a WKT file contains three types gemetries LineString , Polygon and MultiPolygon . From WKT/WKB Geometries in a WKT and WKB file always occupy a single column no matter how many coordinates they have. Therefore, creating a typed SpatialRDD is easy. Suppose we have a checkin.tsv WKT TSV file at Path /Download/checkin.tsv as follows: POINT (-88.331492 32.324142) hotel POINT (-88.175933 32.360763) gas POINT (-88.388954 32.357073) bar POINT (-88.221102 32.35078) restaurant This file has two columns and corresponding offsets (Column IDs) are 0, 1. Column 0 is the WKT string and Column 1 is the checkin business type. Use the following code to create a SpatialRDD val inputLocation = \"/Download/checkin.tsv\" val wktColumn = 0 // The WKT string starts from Column 0 val allowTopologyInvalidGeometries = true // Optional val skipSyntaxInvalidGeometries = false // Optional val spatialRDD = WktReader . readToGeometryRDD ( sparkSession . sparkContext , inputLocation , wktColumn , allowTopologyInvalidGeometries , skipSyntaxInvalidGeometries ) From GeoJSON Geometries in GeoJSON is similar to WKT/WKB. However, a GeoJSON file must be beaked into multiple lines. Suppose we have a polygon.json GeoJSON file at Path /Download/polygon.json as follows: { \"type\": \"Feature\", \"properties\": { \"STATEFP\": \"01\", \"COUNTYFP\": \"077\", \"TRACTCE\": \"011501\", \"BLKGRPCE\": \"5\", \"AFFGEOID\": \"1500000US010770115015\", \"GEOID\": \"010770115015\", \"NAME\": \"5\", \"LSAD\": \"BG\", \"ALAND\": 6844991, \"AWATER\": 32636 }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -87.621765, 34.873444 ], [ -87.617535, 34.873369 ], [ -87.6123, 34.873337 ], [ -87.604049, 34.873303 ], [ -87.604033, 34.872316 ], [ -87.60415, 34.867502 ], [ -87.604218, 34.865687 ], [ -87.604409, 34.858537 ], [ -87.604018, 34.851336 ], [ -87.603716, 34.844829 ], [ -87.603696, 34.844307 ], [ -87.603673, 34.841884 ], [ -87.60372, 34.841003 ], [ -87.603879, 34.838423 ], [ -87.603888, 34.837682 ], [ -87.603889, 34.83763 ], [ -87.613127, 34.833938 ], [ -87.616451, 34.832699 ], [ -87.621041, 34.831431 ], [ -87.621056, 34.831526 ], [ -87.62112, 34.831925 ], [ -87.621603, 34.8352 ], [ -87.62158, 34.836087 ], [ -87.621383, 34.84329 ], [ -87.621359, 34.844438 ], [ -87.62129, 34.846387 ], [ -87.62119, 34.85053 ], [ -87.62144, 34.865379 ], [ -87.621765, 34.873444 ] ] ] } }, { \"type\": \"Feature\", \"properties\": { \"STATEFP\": \"01\", \"COUNTYFP\": \"045\", \"TRACTCE\": \"021102\", \"BLKGRPCE\": \"4\", \"AFFGEOID\": \"1500000US010450211024\", \"GEOID\": \"010450211024\", \"NAME\": \"4\", \"LSAD\": \"BG\", \"ALAND\": 11360854, \"AWATER\": 0 }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -85.719017, 31.297901 ], [ -85.715626, 31.305203 ], [ -85.714271, 31.307096 ], [ -85.69999, 31.307552 ], [ -85.697419, 31.307951 ], [ -85.675603, 31.31218 ], [ -85.672733, 31.312876 ], [ -85.672275, 31.311977 ], [ -85.67145, 31.310988 ], [ -85.670622, 31.309524 ], [ -85.670729, 31.307622 ], [ -85.669876, 31.30666 ], [ -85.669796, 31.306224 ], [ -85.670356, 31.306178 ], [ -85.671664, 31.305583 ], [ -85.67177, 31.305299 ], [ -85.671878, 31.302764 ], [ -85.671344, 31.302123 ], [ -85.668276, 31.302076 ], [ -85.66566, 31.30093 ], [ -85.665687, 31.30022 ], [ -85.669183, 31.297677 ], [ -85.668703, 31.295638 ], [ -85.671985, 31.29314 ], [ -85.677177, 31.288211 ], [ -85.678452, 31.286376 ], [ -85.679236, 31.28285 ], [ -85.679195, 31.281426 ], [ -85.676865, 31.281049 ], [ -85.674661, 31.28008 ], [ -85.674377, 31.27935 ], [ -85.675714, 31.276882 ], [ -85.677938, 31.275168 ], [ -85.680348, 31.276814 ], [ -85.684032, 31.278848 ], [ -85.684387, 31.279082 ], [ -85.692398, 31.283499 ], [ -85.705032, 31.289718 ], [ -85.706755, 31.290476 ], [ -85.718102, 31.295204 ], [ -85.719132, 31.29689 ], [ -85.719017, 31.297901 ] ] ] } }, { \"type\": \"Feature\", \"properties\": { \"STATEFP\": \"01\", \"COUNTYFP\": \"055\", \"TRACTCE\": \"001300\", \"BLKGRPCE\": \"3\", \"AFFGEOID\": \"1500000US010550013003\", \"GEOID\": \"010550013003\", \"NAME\": \"3\", \"LSAD\": \"BG\", \"ALAND\": 1378742, \"AWATER\": 247387 }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -86.000685, 34.00537 ], [ -85.998837, 34.009768 ], [ -85.998012, 34.010398 ], [ -85.987865, 34.005426 ], [ -85.986656, 34.004552 ], [ -85.985, 34.002659 ], [ -85.98851, 34.001502 ], [ -85.987567, 33.999488 ], [ -85.988666, 33.99913 ], [ -85.992568, 33.999131 ], [ -85.993144, 33.999714 ], [ -85.994876, 33.995153 ], [ -85.998823, 33.989548 ], [ -85.999925, 33.994237 ], [ -86.000616, 34.000028 ], [ -86.000685, 34.00537 ] ] ] } }, { \"type\": \"Feature\", \"properties\": { \"STATEFP\": \"01\", \"COUNTYFP\": \"089\", \"TRACTCE\": \"001700\", \"BLKGRPCE\": \"2\", \"AFFGEOID\": \"1500000US010890017002\", \"GEOID\": \"010890017002\", \"NAME\": \"2\", \"LSAD\": \"BG\", \"ALAND\": 1040641, \"AWATER\": 0 }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -86.574172, 34.727375 ], [ -86.562684, 34.727131 ], [ -86.562797, 34.723865 ], [ -86.562957, 34.723168 ], [ -86.562336, 34.719766 ], [ -86.557381, 34.719143 ], [ -86.557352, 34.718322 ], [ -86.559921, 34.717363 ], [ -86.564827, 34.718513 ], [ -86.567582, 34.718565 ], [ -86.570572, 34.718577 ], [ -86.573618, 34.719377 ], [ -86.574172, 34.727375 ] ] ] } }, Use the following code to create a generic SpatialRDD: val inputLocation = \"/Download/polygon.json\" val allowTopologyInvalidGeometries = true // Optional val skipSyntaxInvalidGeometries = false // Optional val spatialRDD = GeoJsonReader . readToGeometryRDD ( sparkSession . sparkContext , inputLocation , allowTopologyInvalidGeometries , skipSyntaxInvalidGeometries ) Warning The way that Sedona reads JSON file is different from SparkSQL From Shapefile val shapefileInputLocation = \"/Download/myshapefile\" val spatialRDD = ShapefileReader . readToGeometryRDD ( sparkSession . sparkContext , shapefileInputLocation ) Note The file extensions of .shp, .shx, .dbf must be in lowercase. Assume you have a shape file called myShapefile , the file structure should be like this: - shapefile1 - shapefile2 - myshapefile - myshapefile.shp - myshapefile.shx - myshapefile.dbf - myshapefile... - ... If the file you are reading contains non-ASCII characters you'll need to explicitly set the encoding via sedona.global.charset system property before the call to ShapefileReader.readToGeometryRDD . Example: System . setProperty ( \"sedona.global.charset\" , \"utf8\" ) From SparkSQL DataFrame To create a generic SpatialRDD from CSV, TSV, WKT, WKB and GeoJSON input formats, you can use SedonaSQL. Make sure you include the full dependencies of Sedona. Read SedonaSQL API . We use checkin.csv CSV file as the example. You can create a generic SpatialRDD using the following steps: Load data in SedonaSQL. var df = sparkSession . read . format ( \"csv\" ). option ( \"header\" , \"false\" ). load ( csvPointInputLocation ) df . createOrReplaceTempView ( \"inputtable\" ) Create a Geometry type column in SedonaSQL var spatialDf = sparkSession . sql ( \"\"\" |SELECT ST_Point(CAST(inputtable._c0 AS Decimal(24,20)),CAST(inputtable._c1 AS Decimal(24,20))) AS checkin |FROM inputtable \"\"\" . stripMargin ) Use SedonaSQL DataFrame-RDD Adapter to convert a DataFrame to an SpatialRDD var spatialRDD = Adapter . toSpatialRdd ( spatialDf , \"checkin\" ) \"checkin\" is the name of the geometry column For WKT/WKB/GeoJSON data, please use ST_GeomFromWKT / ST_GeomFromWKB / ST_GeomFromGeoJSON instead. Transform the Coordinate Reference System \u00b6 Sedona doesn't control the coordinate unit (degree-based or meter-based) of all geometries in an SpatialRDD. The unit of all related distances in Sedona is same as the unit of all geometries in an SpatialRDD. To convert Coordinate Reference System of an SpatialRDD, use the following code: val sourceCrsCode = \"epsg:4326\" // WGS84, the most common degree-based CRS val targetCrsCode = \"epsg:3857\" // The most common meter-based CRS objectRDD . CRSTransform ( sourceCrsCode , targetCrsCode , false ) false in CRSTransform(sourceCrsCode, targetCrsCode, false) means that it will not tolerate Datum shift. If you want it to be lenient, use true instead. Warning CRS transformation should be done right after creating each SpatialRDD, otherwise it will lead to wrong query results. For instace, use something like this: var objectRDD = new PointRDD ( sc , pointRDDInputLocation , pointRDDOffset , pointRDDSplitter , carryOtherAttributes ) objectRDD . CRSTransform ( \"epsg:4326\" , \"epsg:3857\" , false ) The details CRS information can be found on EPSG.io Read other attributes in an SpatialRDD \u00b6 Each SpatialRDD can carry non-spatial attributes such as price, age and name as long as the user sets carryOtherAttributes as TRUE . The other attributes are combined together to a string and stored in UserData field of each geometry. To retrieve the UserData field, use the following code: val rddWithOtherAttributes = objectRDD . rawSpatialRDD . rdd . map [ String ]( f => f . getUserData . asInstanceOf [ String ]) Write a Spatial Range Query \u00b6 A spatial range query takes as input a range query window and an SpatialRDD and returns all geometries that have specified relationship with the query window. Assume you now have an SpatialRDD (typed or generic). You can use the following code to issue an Spatial Range Query on it. val rangeQueryWindow = new Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) val spatialPredicate = SpatialPredicate . COVERED_BY // Only return gemeotries fully covered by the window val usingIndex = false var queryResult = RangeQuery . SpatialRangeQuery ( spatialRDD , rangeQueryWindow , spatialPredicate , usingIndex ) spatialPredicate can be set to SpatialPredicate.INTERSECTS to return all geometries intersect with query window. Supported spatial predicates are: CONTAINS : geometry is completely inside the query window INTERSECTS : geometry have at least one point in common with the query window WITHIN : geometry is completely within the query window (no touching edges) COVERS : query window has no point outside of the geometry COVERED_BY : geometry has no point outside of the query window OVERLAPS : geometry and the query window spatially overlap CROSSES : geometry and the query window spatially cross TOUCHES : the only points shared between geometry and the query window are on the boundary of geometry and the query window EQUALS : geometry and the query window are spatially equal Note Spatial range query is equivalent with a SELECT query with spatial predicate as search condition in Spatial SQL. An example query is as follows: SELECT * FROM checkin WHERE ST_Intersects ( checkin . location , queryWindow ) Range query window \u00b6 Besides the rectangle (Envelope) type range query window, Sedona range query window can be Point/Polygon/LineString. The code to create a point is as follows: val geometryFactory = new GeometryFactory () val pointObject = geometryFactory . createPoint ( new Coordinate ( - 84.01 , 34.01 )) The code to create a polygon (with 4 vertexes) is as follows: val geometryFactory = new GeometryFactory () val coordinates = new Array [ Coordinate ]( 5 ) coordinates ( 0 ) = new Coordinate ( 0 , 0 ) coordinates ( 1 ) = new Coordinate ( 0 , 4 ) coordinates ( 2 ) = new Coordinate ( 4 , 4 ) coordinates ( 3 ) = new Coordinate ( 4 , 0 ) coordinates ( 4 ) = coordinates ( 0 ) // The last coordinate is the same as the first coordinate in order to compose a closed ring val polygonObject = geometryFactory . createPolygon ( coordinates ) The code to create a line string (with 4 vertexes) is as follows: val geometryFactory = new GeometryFactory () val coordinates = new Array [ Coordinate ]( 4 ) coordinates ( 0 ) = new Coordinate ( 0 , 0 ) coordinates ( 1 ) = new Coordinate ( 0 , 4 ) coordinates ( 2 ) = new Coordinate ( 4 , 4 ) coordinates ( 3 ) = new Coordinate ( 4 , 0 ) val linestringObject = geometryFactory . createLineString ( coordinates ) Use spatial indexes \u00b6 Sedona provides two types of spatial indexes, Quad-Tree and R-Tree. Once you specify an index type, Sedona will build a local tree index on each of the SpatialRDD partition. To utilize a spatial index in a spatial range query, use the following code: val rangeQueryWindow = new Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) val spatialPredicate = SpatialPredicate . COVERED_BY // Only return gemeotries fully covered by the window val buildOnSpatialPartitionedRDD = false // Set to TRUE only if run join query spatialRDD . buildIndex ( IndexType . QUADTREE , buildOnSpatialPartitionedRDD ) val usingIndex = true var queryResult = RangeQuery . SpatialRangeQuery ( spatialRDD , rangeQueryWindow , spatialPredicate , usingIndex ) Tip Using an index might not be the best choice all the time because building index also takes time. A spatial index is very useful when your data is complex polygons and line strings. Output format \u00b6 The output format of the spatial range query is another SpatialRDD. Write a Spatial KNN Query \u00b6 A spatial K Nearnest Neighbor query takes as input a K, a query point and an SpatialRDD and finds the K geometries in the RDD which are the closest to he query point. Assume you now have an SpatialRDD (typed or generic). You can use the following code to issue an Spatial KNN Query on it. val geometryFactory = new GeometryFactory () val pointObject = geometryFactory . createPoint ( new Coordinate ( - 84.01 , 34.01 )) val K = 1000 // K Nearest Neighbors val usingIndex = false val result = KNNQuery . SpatialKnnQuery ( objectRDD , pointObject , K , usingIndex ) Note Spatial KNN query that returns 5 Nearest Neighbors is equal to the following statement in Spatial SQL SELECT ck . name , ck . rating , ST_Distance ( ck . location , myLocation ) AS distance FROM checkins ck ORDER BY distance DESC LIMIT 5 Query center geometry \u00b6 Besides the Point type, Sedona KNN query center can be Polygon and LineString. To learn how to create Polygon and LineString object, see Range query window . Use spatial indexes \u00b6 To utilize a spatial index in a spatial KNN query, use the following code: val geometryFactory = new GeometryFactory () val pointObject = geometryFactory . createPoint ( new Coordinate ( - 84.01 , 34.01 )) val K = 1000 // K Nearest Neighbors val buildOnSpatialPartitionedRDD = false // Set to TRUE only if run join query objectRDD . buildIndex ( IndexType . RTREE , buildOnSpatialPartitionedRDD ) val usingIndex = true val result = KNNQuery . SpatialKnnQuery ( objectRDD , pointObject , K , usingIndex ) Warning Only R-Tree index supports Spatial KNN query Output format \u00b6 The output format of the spatial KNN query is a list of geometries. The list has K geometry objects. Write a Spatial Join Query \u00b6 A spatial join query takes as input two Spatial RDD A and B. For each geometry in A, finds the geometries (from B) covered/intersected by it. A and B can be any geometry type and are not necessary to have the same geometry type. Assume you now have two SpatialRDDs (typed or generic). You can use the following code to issue an Spatial Join Query on them. val spatialPredicate = SpatialPredicate . COVERED_BY // Only return gemeotries fully covered by each query window in queryWindowRDD val usingIndex = false objectRDD . analyze () objectRDD . spatialPartitioning ( GridType . KDBTREE ) queryWindowRDD . spatialPartitioning ( objectRDD . getPartitioner ) val result = JoinQuery . SpatialJoinQuery ( objectRDD , queryWindowRDD , usingIndex , spatialPredicate ) Note Spatial join query is equal to the following query in Spatial SQL: SELECT superhero . name FROM city , superhero WHERE ST_Contains ( city . geom , superhero . geom ); Find the super heros in each city Use spatial partitioning \u00b6 Sedona spatial partitioning method can significantly speed up the join query. Three spatial partitioning methods are available: KDB-Tree, Quad-Tree and R-Tree. Two SpatialRDD must be partitioned by the same way. If you first partition SpatialRDD A, then you must use the partitioner of A to partition B. objectRDD . spatialPartitioning ( GridType . KDBTREE ) queryWindowRDD . spatialPartitioning ( objectRDD . getPartitioner ) Or queryWindowRDD . spatialPartitioning ( GridType . KDBTREE ) objectRDD . spatialPartitioning ( queryWindowRDD . getPartitioner ) Use spatial indexes \u00b6 To utilize a spatial index in a spatial join query, use the following code: objectRDD . spatialPartitioning ( joinQueryPartitioningType ) queryWindowRDD . spatialPartitioning ( objectRDD . getPartitioner ) val buildOnSpatialPartitionedRDD = true // Set to TRUE only if run join query val usingIndex = true queryWindowRDD . buildIndex ( IndexType . QUADTREE , buildOnSpatialPartitionedRDD ) val result = JoinQuery . SpatialJoinQueryFlat ( objectRDD , queryWindowRDD , usingIndex , spatialPredicate ) The index should be built on either one of two SpatialRDDs. In general, you should build it on the larger SpatialRDD. Output format \u00b6 The output format of the spatial join query is a PairRDD. In this PairRDD, each object is a pair of two geometries. The left one is the geometry from objectRDD and the right one is the geometry from the queryWindowRDD. Point,Polygon Point,Polygon Point,Polygon Polygon,Polygon LineString,LineString Polygon,LineString ... Each object on the left is covered/intersected by the object on the right. Write a Distance Join Query \u00b6 !!!warning RDD distance joins are only reliable for points. For other geometry types, please use Spatial SQL. A distance join query takes as input two Spatial RDD A and B and a distance. For each geometry in A, finds the geometries (from B) are within the given distance to it. A and B can be any geometry type and are not necessary to have the same geometry type. The unit of the distance is explained here . Assume you now have two SpatialRDDs (typed or generic). You can use the following code to issue an Distance Join Query on them. objectRddA . analyze () val circleRDD = new CircleRDD ( objectRddA , 0.1 ) // Create a CircleRDD using the given distance circleRDD . spatialPartitioning ( GridType . KDBTREE ) objectRddB . spatialPartitioning ( circleRDD . getPartitioner ) val spatialPredicate = SpatialPredicate . COVERED_BY // Only return gemeotries fully covered by each query window in queryWindowRDD val usingIndex = false val result = JoinQuery . DistanceJoinQueryFlat ( objectRddB , circleRDD , usingIndex , spatialPredicate ) Distance join can only accept COVERED_BY and INTERSECTS as spatial predicates. The rest part of the join query is same as the spatial join query. The details of spatial partitioning in join query is here . The details of using spatial indexes in join query is here . The output format of the distance join query is here . Note Distance join query is equal to the following query in Spatial SQL: SELECT superhero . name FROM city , superhero WHERE ST_Distance ( city . geom , superhero . geom ) <= 10 ; Find the super heros within 10 miles of each city Save to permanent storage \u00b6 You can always save an SpatialRDD back to some permanent storage such as HDFS and Amazon S3. You can save distributed SpatialRDD to WKT, GeoJSON and object files. Note Non-spatial attributes such as price, age and name will also be stored to permanent storage. Save an SpatialRDD (not indexed) \u00b6 Typed SpatialRDD and generic SpatialRDD can be saved to permanent storage. Save to distributed WKT text file Use the following code to save an SpatialRDD as a distributed WKT text file: objectRDD . rawSpatialRDD . saveAsTextFile ( \"hdfs://PATH\" ) objectRDD . saveAsWKT ( \"hdfs://PATH\" ) Save to distributed WKB text file Use the following code to save an SpatialRDD as a distributed WKB text file: objectRDD . saveAsWKB ( \"hdfs://PATH\" ) Save to distributed GeoJSON text file Use the following code to save an SpatialRDD as a distributed GeoJSON text file: objectRDD . saveAsGeoJSON ( \"hdfs://PATH\" ) Save to distributed object file Use the following code to save an SpatialRDD as a distributed object file: objectRDD . rawSpatialRDD . saveAsObjectFile ( \"hdfs://PATH\" ) Note Each object in a distributed object file is a byte array (not human-readable). This byte array is the serialized format of a Geometry or a SpatialIndex. Save an SpatialRDD (indexed) \u00b6 Indexed typed SpatialRDD and generic SpatialRDD can be saved to permanent storage. However, the indexed SpatialRDD has to be stored as a distributed object file. Save to distributed object file Use the following code to save an SpatialRDD as a distributed object file: objectRDD.indexedRawRDD.saveAsObjectFile(\"hdfs://PATH\") Save an SpatialRDD (spatialPartitioned W/O indexed) \u00b6 A spatial partitioned RDD can be saved to permanent storage but Spark is not able to maintain the same RDD partition Id of the original RDD. This will lead to wrong join query results. We are working on some solutions. Stay tuned! Reload a saved SpatialRDD \u00b6 You can easily reload an SpatialRDD that has been saved to a distributed object file . Load to a typed SpatialRDD Use the following code to reload the PointRDD/PolygonRDD/LineStringRDD: var savedRDD = new PointRDD ( sc . objectFile [ Point ]( \"hdfs://PATH\" )) var savedRDD = new PointRDD ( sc . objectFile [ Polygon ]( \"hdfs://PATH\" )) var savedRDD = new PointRDD ( sc . objectFile [ LineString ]( \"hdfs://PATH\" )) Load to a generic SpatialRDD Use the following code to reload the SpatialRDD: var savedRDD = new SpatialRDD [ Geometry ] savedRDD . rawSpatialRDD = sc . objectFile [ Geometry ]( \"hdfs://PATH\" ) Use the following code to reload the indexed SpatialRDD: var savedRDD = new SpatialRDD [ Geometry ] savedRDD . indexedRawRDD = sc . objectFile [ SpatialIndex ]( \"hdfs://PATH\" )","title":"Scala/Java"},{"location":"tutorial/rdd/#set-up-dependencies","text":"Read Sedona Maven Central coordinates Select the minimum dependencies : Add Apache Spark (only the Spark core) and Sedona (core). Add the dependencies in build.sbt or pom.xml. Note To enjoy the full functions of Sedona, we suggest you include the full dependencies : Apache Spark core , Apache SparkSQL , Sedona-core, Sedona-SQL, Sedona-Viz. Please see RDD example project","title":"Set up dependencies"},{"location":"tutorial/rdd/#initiate-sparkcontext","text":"val conf = new SparkConf () conf . setAppName ( \"SedonaRunnableExample\" ) // Change this to a proper name conf . setMaster ( \"local[*]\" ) // Delete this if run in cluster mode // Enable Sedona custom Kryo serializer conf . set ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) // org.apache.spark.serializer.KryoSerializer conf . set ( \"spark.kryo.registrator\" , classOf [ SedonaKryoRegistrator ]. getName ) // org.apache.sedona.core.serde.SedonaKryoRegistrator val sc = new SparkContext ( conf ) Warning Sedona has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. If you add the Sedona full dependencies as suggested above, please use the following two lines to enable Sedona Kryo serializer instead: conf . set ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) // org.apache.spark.serializer.KryoSerializer conf . set ( \"spark.kryo.registrator\" , classOf [ SedonaVizKryoRegistrator ]. getName ) // org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator","title":"Initiate SparkContext"},{"location":"tutorial/rdd/#create-a-spatialrdd","text":"","title":"Create a SpatialRDD"},{"location":"tutorial/rdd/#create-a-typed-spatialrdd","text":"Sedona-core provides three special SpatialRDDs: PointRDD, PolygonRDD, and LineStringRDD . They can be loaded from CSV, TSV, WKT, WKB, Shapefiles, GeoJSON and NetCDF/HDF format.","title":"Create a typed SpatialRDD"},{"location":"tutorial/rdd/#create-a-generic-spatialrdd","text":"A generic SpatialRDD is not typed to a certain geometry type and open to more scenarios. It allows an input data file contains mixed types of geometries. For instance, a WKT file contains three types gemetries LineString , Polygon and MultiPolygon .","title":"Create a generic SpatialRDD"},{"location":"tutorial/rdd/#transform-the-coordinate-reference-system","text":"Sedona doesn't control the coordinate unit (degree-based or meter-based) of all geometries in an SpatialRDD. The unit of all related distances in Sedona is same as the unit of all geometries in an SpatialRDD. To convert Coordinate Reference System of an SpatialRDD, use the following code: val sourceCrsCode = \"epsg:4326\" // WGS84, the most common degree-based CRS val targetCrsCode = \"epsg:3857\" // The most common meter-based CRS objectRDD . CRSTransform ( sourceCrsCode , targetCrsCode , false ) false in CRSTransform(sourceCrsCode, targetCrsCode, false) means that it will not tolerate Datum shift. If you want it to be lenient, use true instead. Warning CRS transformation should be done right after creating each SpatialRDD, otherwise it will lead to wrong query results. For instace, use something like this: var objectRDD = new PointRDD ( sc , pointRDDInputLocation , pointRDDOffset , pointRDDSplitter , carryOtherAttributes ) objectRDD . CRSTransform ( \"epsg:4326\" , \"epsg:3857\" , false ) The details CRS information can be found on EPSG.io","title":"Transform the Coordinate Reference System"},{"location":"tutorial/rdd/#read-other-attributes-in-an-spatialrdd","text":"Each SpatialRDD can carry non-spatial attributes such as price, age and name as long as the user sets carryOtherAttributes as TRUE . The other attributes are combined together to a string and stored in UserData field of each geometry. To retrieve the UserData field, use the following code: val rddWithOtherAttributes = objectRDD . rawSpatialRDD . rdd . map [ String ]( f => f . getUserData . asInstanceOf [ String ])","title":"Read other attributes in an SpatialRDD"},{"location":"tutorial/rdd/#write-a-spatial-range-query","text":"A spatial range query takes as input a range query window and an SpatialRDD and returns all geometries that have specified relationship with the query window. Assume you now have an SpatialRDD (typed or generic). You can use the following code to issue an Spatial Range Query on it. val rangeQueryWindow = new Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) val spatialPredicate = SpatialPredicate . COVERED_BY // Only return gemeotries fully covered by the window val usingIndex = false var queryResult = RangeQuery . SpatialRangeQuery ( spatialRDD , rangeQueryWindow , spatialPredicate , usingIndex ) spatialPredicate can be set to SpatialPredicate.INTERSECTS to return all geometries intersect with query window. Supported spatial predicates are: CONTAINS : geometry is completely inside the query window INTERSECTS : geometry have at least one point in common with the query window WITHIN : geometry is completely within the query window (no touching edges) COVERS : query window has no point outside of the geometry COVERED_BY : geometry has no point outside of the query window OVERLAPS : geometry and the query window spatially overlap CROSSES : geometry and the query window spatially cross TOUCHES : the only points shared between geometry and the query window are on the boundary of geometry and the query window EQUALS : geometry and the query window are spatially equal Note Spatial range query is equivalent with a SELECT query with spatial predicate as search condition in Spatial SQL. An example query is as follows: SELECT * FROM checkin WHERE ST_Intersects ( checkin . location , queryWindow )","title":"Write a Spatial Range Query"},{"location":"tutorial/rdd/#range-query-window","text":"Besides the rectangle (Envelope) type range query window, Sedona range query window can be Point/Polygon/LineString. The code to create a point is as follows: val geometryFactory = new GeometryFactory () val pointObject = geometryFactory . createPoint ( new Coordinate ( - 84.01 , 34.01 )) The code to create a polygon (with 4 vertexes) is as follows: val geometryFactory = new GeometryFactory () val coordinates = new Array [ Coordinate ]( 5 ) coordinates ( 0 ) = new Coordinate ( 0 , 0 ) coordinates ( 1 ) = new Coordinate ( 0 , 4 ) coordinates ( 2 ) = new Coordinate ( 4 , 4 ) coordinates ( 3 ) = new Coordinate ( 4 , 0 ) coordinates ( 4 ) = coordinates ( 0 ) // The last coordinate is the same as the first coordinate in order to compose a closed ring val polygonObject = geometryFactory . createPolygon ( coordinates ) The code to create a line string (with 4 vertexes) is as follows: val geometryFactory = new GeometryFactory () val coordinates = new Array [ Coordinate ]( 4 ) coordinates ( 0 ) = new Coordinate ( 0 , 0 ) coordinates ( 1 ) = new Coordinate ( 0 , 4 ) coordinates ( 2 ) = new Coordinate ( 4 , 4 ) coordinates ( 3 ) = new Coordinate ( 4 , 0 ) val linestringObject = geometryFactory . createLineString ( coordinates )","title":"Range query window"},{"location":"tutorial/rdd/#use-spatial-indexes","text":"Sedona provides two types of spatial indexes, Quad-Tree and R-Tree. Once you specify an index type, Sedona will build a local tree index on each of the SpatialRDD partition. To utilize a spatial index in a spatial range query, use the following code: val rangeQueryWindow = new Envelope ( - 90.01 , - 80.01 , 30.01 , 40.01 ) val spatialPredicate = SpatialPredicate . COVERED_BY // Only return gemeotries fully covered by the window val buildOnSpatialPartitionedRDD = false // Set to TRUE only if run join query spatialRDD . buildIndex ( IndexType . QUADTREE , buildOnSpatialPartitionedRDD ) val usingIndex = true var queryResult = RangeQuery . SpatialRangeQuery ( spatialRDD , rangeQueryWindow , spatialPredicate , usingIndex ) Tip Using an index might not be the best choice all the time because building index also takes time. A spatial index is very useful when your data is complex polygons and line strings.","title":"Use spatial indexes"},{"location":"tutorial/rdd/#output-format","text":"The output format of the spatial range query is another SpatialRDD.","title":"Output format"},{"location":"tutorial/rdd/#write-a-spatial-knn-query","text":"A spatial K Nearnest Neighbor query takes as input a K, a query point and an SpatialRDD and finds the K geometries in the RDD which are the closest to he query point. Assume you now have an SpatialRDD (typed or generic). You can use the following code to issue an Spatial KNN Query on it. val geometryFactory = new GeometryFactory () val pointObject = geometryFactory . createPoint ( new Coordinate ( - 84.01 , 34.01 )) val K = 1000 // K Nearest Neighbors val usingIndex = false val result = KNNQuery . SpatialKnnQuery ( objectRDD , pointObject , K , usingIndex ) Note Spatial KNN query that returns 5 Nearest Neighbors is equal to the following statement in Spatial SQL SELECT ck . name , ck . rating , ST_Distance ( ck . location , myLocation ) AS distance FROM checkins ck ORDER BY distance DESC LIMIT 5","title":"Write a Spatial KNN Query"},{"location":"tutorial/rdd/#query-center-geometry","text":"Besides the Point type, Sedona KNN query center can be Polygon and LineString. To learn how to create Polygon and LineString object, see Range query window .","title":"Query center geometry"},{"location":"tutorial/rdd/#use-spatial-indexes_1","text":"To utilize a spatial index in a spatial KNN query, use the following code: val geometryFactory = new GeometryFactory () val pointObject = geometryFactory . createPoint ( new Coordinate ( - 84.01 , 34.01 )) val K = 1000 // K Nearest Neighbors val buildOnSpatialPartitionedRDD = false // Set to TRUE only if run join query objectRDD . buildIndex ( IndexType . RTREE , buildOnSpatialPartitionedRDD ) val usingIndex = true val result = KNNQuery . SpatialKnnQuery ( objectRDD , pointObject , K , usingIndex ) Warning Only R-Tree index supports Spatial KNN query","title":"Use spatial indexes"},{"location":"tutorial/rdd/#output-format_1","text":"The output format of the spatial KNN query is a list of geometries. The list has K geometry objects.","title":"Output format"},{"location":"tutorial/rdd/#write-a-spatial-join-query","text":"A spatial join query takes as input two Spatial RDD A and B. For each geometry in A, finds the geometries (from B) covered/intersected by it. A and B can be any geometry type and are not necessary to have the same geometry type. Assume you now have two SpatialRDDs (typed or generic). You can use the following code to issue an Spatial Join Query on them. val spatialPredicate = SpatialPredicate . COVERED_BY // Only return gemeotries fully covered by each query window in queryWindowRDD val usingIndex = false objectRDD . analyze () objectRDD . spatialPartitioning ( GridType . KDBTREE ) queryWindowRDD . spatialPartitioning ( objectRDD . getPartitioner ) val result = JoinQuery . SpatialJoinQuery ( objectRDD , queryWindowRDD , usingIndex , spatialPredicate ) Note Spatial join query is equal to the following query in Spatial SQL: SELECT superhero . name FROM city , superhero WHERE ST_Contains ( city . geom , superhero . geom ); Find the super heros in each city","title":"Write a Spatial Join Query"},{"location":"tutorial/rdd/#use-spatial-partitioning","text":"Sedona spatial partitioning method can significantly speed up the join query. Three spatial partitioning methods are available: KDB-Tree, Quad-Tree and R-Tree. Two SpatialRDD must be partitioned by the same way. If you first partition SpatialRDD A, then you must use the partitioner of A to partition B. objectRDD . spatialPartitioning ( GridType . KDBTREE ) queryWindowRDD . spatialPartitioning ( objectRDD . getPartitioner ) Or queryWindowRDD . spatialPartitioning ( GridType . KDBTREE ) objectRDD . spatialPartitioning ( queryWindowRDD . getPartitioner )","title":"Use spatial partitioning"},{"location":"tutorial/rdd/#use-spatial-indexes_2","text":"To utilize a spatial index in a spatial join query, use the following code: objectRDD . spatialPartitioning ( joinQueryPartitioningType ) queryWindowRDD . spatialPartitioning ( objectRDD . getPartitioner ) val buildOnSpatialPartitionedRDD = true // Set to TRUE only if run join query val usingIndex = true queryWindowRDD . buildIndex ( IndexType . QUADTREE , buildOnSpatialPartitionedRDD ) val result = JoinQuery . SpatialJoinQueryFlat ( objectRDD , queryWindowRDD , usingIndex , spatialPredicate ) The index should be built on either one of two SpatialRDDs. In general, you should build it on the larger SpatialRDD.","title":"Use spatial indexes"},{"location":"tutorial/rdd/#output-format_2","text":"The output format of the spatial join query is a PairRDD. In this PairRDD, each object is a pair of two geometries. The left one is the geometry from objectRDD and the right one is the geometry from the queryWindowRDD. Point,Polygon Point,Polygon Point,Polygon Polygon,Polygon LineString,LineString Polygon,LineString ... Each object on the left is covered/intersected by the object on the right.","title":"Output format"},{"location":"tutorial/rdd/#write-a-distance-join-query","text":"!!!warning RDD distance joins are only reliable for points. For other geometry types, please use Spatial SQL. A distance join query takes as input two Spatial RDD A and B and a distance. For each geometry in A, finds the geometries (from B) are within the given distance to it. A and B can be any geometry type and are not necessary to have the same geometry type. The unit of the distance is explained here . Assume you now have two SpatialRDDs (typed or generic). You can use the following code to issue an Distance Join Query on them. objectRddA . analyze () val circleRDD = new CircleRDD ( objectRddA , 0.1 ) // Create a CircleRDD using the given distance circleRDD . spatialPartitioning ( GridType . KDBTREE ) objectRddB . spatialPartitioning ( circleRDD . getPartitioner ) val spatialPredicate = SpatialPredicate . COVERED_BY // Only return gemeotries fully covered by each query window in queryWindowRDD val usingIndex = false val result = JoinQuery . DistanceJoinQueryFlat ( objectRddB , circleRDD , usingIndex , spatialPredicate ) Distance join can only accept COVERED_BY and INTERSECTS as spatial predicates. The rest part of the join query is same as the spatial join query. The details of spatial partitioning in join query is here . The details of using spatial indexes in join query is here . The output format of the distance join query is here . Note Distance join query is equal to the following query in Spatial SQL: SELECT superhero . name FROM city , superhero WHERE ST_Distance ( city . geom , superhero . geom ) <= 10 ; Find the super heros within 10 miles of each city","title":"Write a Distance Join Query"},{"location":"tutorial/rdd/#save-to-permanent-storage","text":"You can always save an SpatialRDD back to some permanent storage such as HDFS and Amazon S3. You can save distributed SpatialRDD to WKT, GeoJSON and object files. Note Non-spatial attributes such as price, age and name will also be stored to permanent storage.","title":"Save to permanent storage"},{"location":"tutorial/rdd/#save-an-spatialrdd-not-indexed","text":"Typed SpatialRDD and generic SpatialRDD can be saved to permanent storage.","title":"Save an SpatialRDD (not indexed)"},{"location":"tutorial/rdd/#save-an-spatialrdd-indexed","text":"Indexed typed SpatialRDD and generic SpatialRDD can be saved to permanent storage. However, the indexed SpatialRDD has to be stored as a distributed object file.","title":"Save an SpatialRDD (indexed)"},{"location":"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed","text":"A spatial partitioned RDD can be saved to permanent storage but Spark is not able to maintain the same RDD partition Id of the original RDD. This will lead to wrong join query results. We are working on some solutions. Stay tuned!","title":"Save an SpatialRDD (spatialPartitioned W/O indexed)"},{"location":"tutorial/rdd/#reload-a-saved-spatialrdd","text":"You can easily reload an SpatialRDD that has been saved to a distributed object file .","title":"Reload a saved SpatialRDD"},{"location":"tutorial/sql-pure-sql/","text":"Starting from Sedona v1.0.1 , you can use Sedona in a pure Spark SQL environment. The example code is written in SQL. SedonaSQL supports SQL/MM Part3 Spatial SQL Standard. Detailed SedonaSQL APIs are available here: SedonaSQL API Initiate Session \u00b6 Start spark-sql as following (replace <VERSION> with actual version, like, 1.0.1-incubating ): spark-sql --packages org.apache.sedona:sedona-python-adapter-3.0_2.12:<VERSION>,org.apache.sedona:sedona-viz-3.0_2.12:<VERSION>,org.datasyslab:geotools-wrapper:geotools-24.0 \\ --conf spark.serializer = org.apache.spark.serializer.KryoSerializer \\ --conf spark.kryo.registrator = org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator \\ --conf spark.sql.extensions = org.apache.sedona.viz.sql.SedonaVizExtensions,org.apache.sedona.sql.SedonaSqlExtensions This will register all User Defined Tyeps, functions and optimizations in SedonaSQL and SedonaViz. Load data \u00b6 Let use data from examples/sql . To load data from CSV file we need to execute two commands: Use the following code to load the data and create a raw DataFrame: CREATE TABLE IF NOT EXISTS pointraw ( _c0 string , _c1 string ) USING csv OPTIONS ( header = 'false' ) LOCATION '<some path>/incubator-sedona/examples/sql/src/test/resources/testpoint.csv' ; CREATE TABLE IF NOT EXISTS polygonraw ( _c0 string , _c1 string , _c2 string , _c3 string ) USING csv OPTIONS ( header = 'false' ) LOCATION '<some path>/incubator-sedona/examples/sql/src/test/resources/testenvelope.csv' ; Transform the data \u00b6 We need to transform our point and polygon data into respective types: CREATE OR REPLACE TEMP VIEW pointdata AS SELECT ST_Point ( cast ( pointraw . _c0 as Decimal ( 24 , 20 )), cast ( pointraw . _c1 as Decimal ( 24 , 20 ))) AS pointshape FROM pointraw ; CREATE OR REPLACE TEMP VIEW polygondata AS select ST_PolygonFromEnvelope ( cast ( polygonraw . _c0 as Decimal ( 24 , 20 )), cast ( polygonraw . _c1 as Decimal ( 24 , 20 )), cast ( polygonraw . _c2 as Decimal ( 24 , 20 )), cast ( polygonraw . _c3 as Decimal ( 24 , 20 ))) AS polygonshape FROM polygonraw ; Work with data \u00b6 For example, let join polygon and test data: SELECT * from polygondata , pointdata WHERE ST_Contains ( polygondata . polygonshape , pointdata . pointshape ) AND ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 101 . 0 , 501 . 0 , 601 . 0 ), polygondata . polygonshape ) LIMIT 5 ;","title":"Pure SQL"},{"location":"tutorial/sql-pure-sql/#initiate-session","text":"Start spark-sql as following (replace <VERSION> with actual version, like, 1.0.1-incubating ): spark-sql --packages org.apache.sedona:sedona-python-adapter-3.0_2.12:<VERSION>,org.apache.sedona:sedona-viz-3.0_2.12:<VERSION>,org.datasyslab:geotools-wrapper:geotools-24.0 \\ --conf spark.serializer = org.apache.spark.serializer.KryoSerializer \\ --conf spark.kryo.registrator = org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator \\ --conf spark.sql.extensions = org.apache.sedona.viz.sql.SedonaVizExtensions,org.apache.sedona.sql.SedonaSqlExtensions This will register all User Defined Tyeps, functions and optimizations in SedonaSQL and SedonaViz.","title":"Initiate Session"},{"location":"tutorial/sql-pure-sql/#load-data","text":"Let use data from examples/sql . To load data from CSV file we need to execute two commands: Use the following code to load the data and create a raw DataFrame: CREATE TABLE IF NOT EXISTS pointraw ( _c0 string , _c1 string ) USING csv OPTIONS ( header = 'false' ) LOCATION '<some path>/incubator-sedona/examples/sql/src/test/resources/testpoint.csv' ; CREATE TABLE IF NOT EXISTS polygonraw ( _c0 string , _c1 string , _c2 string , _c3 string ) USING csv OPTIONS ( header = 'false' ) LOCATION '<some path>/incubator-sedona/examples/sql/src/test/resources/testenvelope.csv' ;","title":"Load data"},{"location":"tutorial/sql-pure-sql/#transform-the-data","text":"We need to transform our point and polygon data into respective types: CREATE OR REPLACE TEMP VIEW pointdata AS SELECT ST_Point ( cast ( pointraw . _c0 as Decimal ( 24 , 20 )), cast ( pointraw . _c1 as Decimal ( 24 , 20 ))) AS pointshape FROM pointraw ; CREATE OR REPLACE TEMP VIEW polygondata AS select ST_PolygonFromEnvelope ( cast ( polygonraw . _c0 as Decimal ( 24 , 20 )), cast ( polygonraw . _c1 as Decimal ( 24 , 20 )), cast ( polygonraw . _c2 as Decimal ( 24 , 20 )), cast ( polygonraw . _c3 as Decimal ( 24 , 20 ))) AS polygonshape FROM polygonraw ;","title":"Transform the data"},{"location":"tutorial/sql-pure-sql/#work-with-data","text":"For example, let join polygon and test data: SELECT * from polygondata , pointdata WHERE ST_Contains ( polygondata . polygonshape , pointdata . pointshape ) AND ST_Contains ( ST_PolygonFromEnvelope ( 1 . 0 , 101 . 0 , 501 . 0 , 601 . 0 ), polygondata . polygonshape ) LIMIT 5 ;","title":"Work with data"},{"location":"tutorial/sql-python/","text":"Spatial SQL Application in Python \u00b6 Introduction \u00b6 This package is an extension to Apache Spark SQL package. It allow to use spatial functions on dataframes. SedonaSQL supports SQL/MM Part3 Spatial SQL Standard. It includes four kinds of SQL operators as follows. All these operators can be directly called through: spark . sql ( \"YOUR_SQL\" ) Note This tutorial is based on Sedona SQL Jupyter Notebook example . You can interact with Sedona Python Jupyter notebook immediately on Binder. Click and wait for a few minutes. Then select a notebook and enjoy! Installation \u00b6 Please read Quick start to install Sedona Python. Register package \u00b6 Before writing any code with Sedona please use the following code. from sedona.register import SedonaRegistrator SedonaRegistrator . registerAll ( spark ) You can also register functions by passing --conf spark.sql.extensions=org.apache.sedona.sql.SedonaSqlExtensions to spark-submit or spark-shell . Writing Application \u00b6 Use KryoSerializer.getName and SedonaKryoRegistrator.getName class properties to reduce memory impact. spark = SparkSession . \\ builder . \\ master ( \"local[*]\" ) . \\ appName ( \"Sedona App\" ) . \\ config ( \"spark.serializer\" , KryoSerializer . getName ) . \\ config ( \"spark.kryo.registrator\" , SedonaKryoRegistrator . getName ) . \\ getOrCreate () To turn on SedonaSQL function inside pyspark code use SedonaRegistrator.registerAll method on existing pyspark.sql.SparkSession instance ex. SedonaRegistrator.registerAll(spark) After that all the functions from SedonaSQL are available, moreover using collect or toPandas methods on Spark DataFrame returns Shapely BaseGeometry objects. Based on GeoPandas DataFrame, Pandas DataFrame with shapely objects or Sequence with shapely objects, Spark DataFrame can be created using spark.createDataFrame method. To specify Schema with geometry inside please use GeometryType() instance (look at examples section to see that in practice). Examples \u00b6 SedonaSQL \u00b6 All SedonaSQL functions (list depends on SedonaSQL version) are available in Python API. For details please refer to API/SedonaSQL page. For example use SedonaSQL for Spatial Join. counties = spark . \\ read . \\ option ( \"delimiter\" , \"|\" ) . \\ option ( \"header\" , \"true\" ) . \\ csv ( \"counties.csv\" ) counties . createOrReplaceTempView ( \"county\" ) counties_geom = spark . sql ( \"SELECT county_code, st_geomFromWKT(geom) as geometry from county\" ) counties_geom . show ( 5 ) +-----------+--------------------+ |county_code| geometry| +-----------+--------------------+ | 1815|POLYGON ((21.6942...| | 1410|POLYGON ((22.7238...| | 1418|POLYGON ((21.1100...| | 1425|POLYGON ((20.9891...| | 1427|POLYGON ((19.5087...| +-----------+--------------------+ import geopandas as gpd points = gpd . read_file ( \"gis_osm_pois_free_1.shp\" ) points_geom = spark . createDataFrame ( points [[ \"fclass\" , \"geometry\" ]] ) points_geom . show ( 5 , False ) +---------+-----------------------------+ |fclass |geometry | +---------+-----------------------------+ |camp_site|POINT (15.3393145 52.3504247)| |chalet |POINT (14.8709625 52.691693) | |motel |POINT (15.0946636 52.3130396)| |atm |POINT (15.0732014 52.3141083)| |hotel |POINT (15.0696777 52.3143013)| +---------+-----------------------------+ points_geom . createOrReplaceTempView ( \"pois\" ) counties_geom . createOrReplaceTempView ( \"counties\" ) spatial_join_result = spark . sql ( \"\"\" SELECT c.county_code, p.fclass FROM pois AS p, counties AS c WHERE ST_Intersects(p.geometry, c.geometry) \"\"\" ) spatial_join_result . explain () == Physical Plan == *(2) Project [county_code#230, fclass#239] +- RangeJoin geometry#240: geometry, geometry#236: geometry, true :- Scan ExistingRDD[fclass#239,geometry#240] +- Project [county_code#230, st_geomfromwkt(geom#232) AS geometry#236] +- *(1) FileScan csv [county_code#230,geom#232] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/projects/sedona/counties.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<county_code:string,geom:string> Calculating Number of Pois within counties per fclass. pois_per_county = spatial_join_result . groupBy ( \"county_code\" , \"fclass\" ) . \\ count () pois_per_county . show ( 5 , False ) +-----------+---------+-----+ |county_code|fclass |count| +-----------+---------+-----+ |0805 |atm |6 | |0805 |bench |75 | |0803 |museum |9 | |0802 |fast_food|5 | |0862 |atm |20 | +-----------+---------+-----+ Integration with GeoPandas and Shapely \u00b6 sedona has implemented serializers and deserializers which allows to convert Sedona Geometry objects into Shapely BaseGeometry objects. Based on that it is possible to load the data with geopandas from file (look at Fiona possible drivers) and create Spark DataFrame based on GeoDataFrame object. Example, loading the data from shapefile using geopandas read_file method and create Spark DataFrame based on GeoDataFrame: import geopandas as gpd from pyspark.sql import SparkSession from sedona.register import SedonaRegistrator spark = SparkSession . builder . \\ getOrCreate () SedonaRegistrator . registerAll ( spark ) gdf = gpd . read_file ( \"gis_osm_pois_free_1.shp\" ) spark . createDataFrame ( gdf ) . show () +---------+----+-----------+--------------------+--------------------+ | osm_id|code| fclass| name| geometry| +---------+----+-----------+--------------------+--------------------+ | 26860257|2422| camp_site| de Kroon|POINT (15.3393145...| | 26860294|2406| chalet| Le\u015bne Ustronie|POINT (14.8709625...| | 29947493|2402| motel| null|POINT (15.0946636...| | 29947498|2602| atm| null|POINT (15.0732014...| | 29947499|2401| hotel| null|POINT (15.0696777...| | 29947505|2401| hotel| null|POINT (15.0155749...| +---------+----+-----------+--------------------+--------------------+ Reading data with Spark and converting to GeoPandas import geopandas as gpd from pyspark.sql import SparkSession from sedona.register import SedonaRegistrator spark = SparkSession . builder . \\ getOrCreate () SedonaRegistrator . registerAll ( spark ) counties = spark . \\ read . \\ option ( \"delimiter\" , \"|\" ) . \\ option ( \"header\" , \"true\" ) . \\ csv ( \"counties.csv\" ) counties . createOrReplaceTempView ( \"county\" ) counties_geom = spark . sql ( \"SELECT *, st_geomFromWKT(geom) as geometry from county\" ) df = counties_geom . toPandas () gdf = gpd . GeoDataFrame ( df , geometry = \"geometry\" ) gdf . plot ( figsize = ( 10 , 8 ), column = \"value\" , legend = True , cmap = 'YlOrBr' , scheme = 'quantiles' , edgecolor = 'lightgray' ) DataFrame Style API \u00b6 Sedona functions can be called used a DataFrame style API similar to PySpark's own functions. The functions are spread across four different modules: sedona.sql.st_constructors , sedona.sql.st_functions , sedona.sql.st_predicates , and sedona.sql.st_aggregates . All of the functions can take columns or strings as arguments and will return a column representing the sedona function call. This makes them integratable with DataFrame.select , DataFrame.join , and all of the PySpark functions found in the pyspark.sql.functions module. As an example of the flexibility: from pyspark.sql import functions as f from sedona.sql import st_constructors as stc df = spark . sql ( \"SELECT array(0.0, 1.0, 2.0) AS values\" ) min_value = f . array_min ( \"values\" ) max_value = f . array_max ( \"values\" ) df = df . select ( stc . ST_Point ( min_value , max_value ) . alias ( \"point\" )) The above code will generate the following dataframe: +-----------+ |point | +-----------+ |POINT (0 2)| +-----------+ Some functions will take native python values and infer them as literals. For example: df = df . select ( stc . ST_Point ( 1.0 , 3.0 ) . alias ( \"point\" )) This will generate a dataframe with a constant point in a column: +-----------+ |point | +-----------+ |POINT (1 3)| +-----------+ For a description of what values a function may take please refer to their specific docstrings. The following rules are followed when passing values to the sedona functions: 1. Column type arguments are passed straight through and are always accepted. 1. str type arguments are always assumed to be names of columns and are wrapped in a Column to support that. If an actual string literal needs to be passed then it will need to be wrapped in a Column using pyspark.sql.functions.lit . 1. Any other types of arguments are checked on a per function basis. Generally, arguments that could reasonably support a python native type are accepted and passed through. Check the specific docstring of the function to be sure. 1. Shapely Geometry objects are not currently accepted in any of the functions. Creating Spark DataFrame based on shapely objects \u00b6 Supported Shapely objects \u00b6 shapely object Available Point MultiPoint LineString MultiLinestring Polygon MultiPolygon To create Spark DataFrame based on mentioned Geometry types, please use GeometryType from sedona.sql.types module. Converting works for list or tuple with shapely objects. Schema for target table with integer id and geometry type can be defined as follow: from pyspark.sql.types import IntegerType , StructField , StructType from sedona.sql.types import GeometryType schema = StructType ( [ StructField ( \"id\" , IntegerType (), False ), StructField ( \"geom\" , GeometryType (), False ) ] ) Also Spark DataFrame with geometry type can be converted to list of shapely objects with collect method. Example usage for Shapely objects \u00b6 Point \u00b6 from shapely.geometry import Point data = [ [ 1 , Point ( 21.0 , 52.0 )], [ 1 , Point ( 23.0 , 42.0 )], [ 1 , Point ( 26.0 , 32.0 )] ] gdf = spark . createDataFrame ( data , schema ) gdf . show () +---+-------------+ | id| geom| +---+-------------+ | 1|POINT (21 52)| | 1|POINT (23 42)| | 1|POINT (26 32)| +---+-------------+ gdf . printSchema () root |-- id: integer (nullable = false) |-- geom: geometry (nullable = false) MultiPoint \u00b6 from shapely.geometry import MultiPoint data = [ [ 1 , MultiPoint ([[ 19.511463 , 51.765158 ], [ 19.446408 , 51.779752 ]])] ] gdf = spark . createDataFrame ( data , schema ) . show ( 1 , False ) +---+---------------------------------------------------------+ |id |geom | +---+---------------------------------------------------------+ |1 |MULTIPOINT ((19.511463 51.765158), (19.446408 51.779752))| +---+---------------------------------------------------------+ LineString \u00b6 from shapely.geometry import LineString line = [( 40 , 40 ), ( 30 , 30 ), ( 40 , 20 ), ( 30 , 10 )] data = [ [ 1 , LineString ( line )] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+--------------------------------+ |id |geom | +---+--------------------------------+ |1 |LINESTRING (10 10, 20 20, 10 40)| +---+--------------------------------+ MultiLineString \u00b6 from shapely.geometry import MultiLineString line1 = [( 10 , 10 ), ( 20 , 20 ), ( 10 , 40 )] line2 = [( 40 , 40 ), ( 30 , 30 ), ( 40 , 20 ), ( 30 , 10 )] data = [ [ 1 , MultiLineString ([ line1 , line2 ])] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+---------------------------------------------------------------------+ |id |geom | +---+---------------------------------------------------------------------+ |1 |MULTILINESTRING ((10 10, 20 20, 10 40), (40 40, 30 30, 40 20, 30 10))| +---+---------------------------------------------------------------------+ Polygon \u00b6 from shapely.geometry import Polygon polygon = Polygon ( [ [ 19.51121 , 51.76426 ], [ 19.51056 , 51.76583 ], [ 19.51216 , 51.76599 ], [ 19.51280 , 51.76448 ], [ 19.51121 , 51.76426 ] ] ) data = [ [ 1 , polygon ] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+--------------------------------------------------------------------------------------------------------+ |id |geom | +---+--------------------------------------------------------------------------------------------------------+ |1 |POLYGON ((19.51121 51.76426, 19.51056 51.76583, 19.51216 51.76599, 19.5128 51.76448, 19.51121 51.76426))| +---+--------------------------------------------------------------------------------------------------------+ MultiPolygon \u00b6 from shapely.geometry import MultiPolygon exterior_p1 = [( 0 , 0 ), ( 0 , 2 ), ( 2 , 2 ), ( 2 , 0 ), ( 0 , 0 )] interior_p1 = [( 1 , 1 ), ( 1 , 1.5 ), ( 1.5 , 1.5 ), ( 1.5 , 1 ), ( 1 , 1 )] exterior_p2 = [( 0 , 0 ), ( 1 , 0 ), ( 1 , 1 ), ( 0 , 1 ), ( 0 , 0 )] polygons = [ Polygon ( exterior_p1 , [ interior_p1 ]), Polygon ( exterior_p2 ) ] data = [ [ 1 , MultiPolygon ( polygons )] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+----------------------------------------------------------------------------------------------------------+ |id |geom | +---+----------------------------------------------------------------------------------------------------------+ |1 |MULTIPOLYGON (((0 0, 0 2, 2 2, 2 0, 0 0), (1 1, 1.5 1, 1.5 1.5, 1 1.5, 1 1)), ((0 0, 0 1, 1 1, 1 0, 0 0)))| +---+----------------------------------------------------------------------------------------------------------+","title":"Python"},{"location":"tutorial/sql-python/#spatial-sql-application-in-python","text":"","title":"Spatial SQL Application in Python"},{"location":"tutorial/sql-python/#introduction","text":"This package is an extension to Apache Spark SQL package. It allow to use spatial functions on dataframes. SedonaSQL supports SQL/MM Part3 Spatial SQL Standard. It includes four kinds of SQL operators as follows. All these operators can be directly called through: spark . sql ( \"YOUR_SQL\" ) Note This tutorial is based on Sedona SQL Jupyter Notebook example . You can interact with Sedona Python Jupyter notebook immediately on Binder. Click and wait for a few minutes. Then select a notebook and enjoy!","title":"Introduction"},{"location":"tutorial/sql-python/#installation","text":"Please read Quick start to install Sedona Python.","title":"Installation"},{"location":"tutorial/sql-python/#register-package","text":"Before writing any code with Sedona please use the following code. from sedona.register import SedonaRegistrator SedonaRegistrator . registerAll ( spark ) You can also register functions by passing --conf spark.sql.extensions=org.apache.sedona.sql.SedonaSqlExtensions to spark-submit or spark-shell .","title":"Register package"},{"location":"tutorial/sql-python/#writing-application","text":"Use KryoSerializer.getName and SedonaKryoRegistrator.getName class properties to reduce memory impact. spark = SparkSession . \\ builder . \\ master ( \"local[*]\" ) . \\ appName ( \"Sedona App\" ) . \\ config ( \"spark.serializer\" , KryoSerializer . getName ) . \\ config ( \"spark.kryo.registrator\" , SedonaKryoRegistrator . getName ) . \\ getOrCreate () To turn on SedonaSQL function inside pyspark code use SedonaRegistrator.registerAll method on existing pyspark.sql.SparkSession instance ex. SedonaRegistrator.registerAll(spark) After that all the functions from SedonaSQL are available, moreover using collect or toPandas methods on Spark DataFrame returns Shapely BaseGeometry objects. Based on GeoPandas DataFrame, Pandas DataFrame with shapely objects or Sequence with shapely objects, Spark DataFrame can be created using spark.createDataFrame method. To specify Schema with geometry inside please use GeometryType() instance (look at examples section to see that in practice).","title":"Writing Application"},{"location":"tutorial/sql-python/#examples","text":"","title":"Examples"},{"location":"tutorial/sql-python/#sedonasql","text":"All SedonaSQL functions (list depends on SedonaSQL version) are available in Python API. For details please refer to API/SedonaSQL page. For example use SedonaSQL for Spatial Join. counties = spark . \\ read . \\ option ( \"delimiter\" , \"|\" ) . \\ option ( \"header\" , \"true\" ) . \\ csv ( \"counties.csv\" ) counties . createOrReplaceTempView ( \"county\" ) counties_geom = spark . sql ( \"SELECT county_code, st_geomFromWKT(geom) as geometry from county\" ) counties_geom . show ( 5 ) +-----------+--------------------+ |county_code| geometry| +-----------+--------------------+ | 1815|POLYGON ((21.6942...| | 1410|POLYGON ((22.7238...| | 1418|POLYGON ((21.1100...| | 1425|POLYGON ((20.9891...| | 1427|POLYGON ((19.5087...| +-----------+--------------------+ import geopandas as gpd points = gpd . read_file ( \"gis_osm_pois_free_1.shp\" ) points_geom = spark . createDataFrame ( points [[ \"fclass\" , \"geometry\" ]] ) points_geom . show ( 5 , False ) +---------+-----------------------------+ |fclass |geometry | +---------+-----------------------------+ |camp_site|POINT (15.3393145 52.3504247)| |chalet |POINT (14.8709625 52.691693) | |motel |POINT (15.0946636 52.3130396)| |atm |POINT (15.0732014 52.3141083)| |hotel |POINT (15.0696777 52.3143013)| +---------+-----------------------------+ points_geom . createOrReplaceTempView ( \"pois\" ) counties_geom . createOrReplaceTempView ( \"counties\" ) spatial_join_result = spark . sql ( \"\"\" SELECT c.county_code, p.fclass FROM pois AS p, counties AS c WHERE ST_Intersects(p.geometry, c.geometry) \"\"\" ) spatial_join_result . explain () == Physical Plan == *(2) Project [county_code#230, fclass#239] +- RangeJoin geometry#240: geometry, geometry#236: geometry, true :- Scan ExistingRDD[fclass#239,geometry#240] +- Project [county_code#230, st_geomfromwkt(geom#232) AS geometry#236] +- *(1) FileScan csv [county_code#230,geom#232] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/projects/sedona/counties.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<county_code:string,geom:string> Calculating Number of Pois within counties per fclass. pois_per_county = spatial_join_result . groupBy ( \"county_code\" , \"fclass\" ) . \\ count () pois_per_county . show ( 5 , False ) +-----------+---------+-----+ |county_code|fclass |count| +-----------+---------+-----+ |0805 |atm |6 | |0805 |bench |75 | |0803 |museum |9 | |0802 |fast_food|5 | |0862 |atm |20 | +-----------+---------+-----+","title":"SedonaSQL"},{"location":"tutorial/sql-python/#integration-with-geopandas-and-shapely","text":"sedona has implemented serializers and deserializers which allows to convert Sedona Geometry objects into Shapely BaseGeometry objects. Based on that it is possible to load the data with geopandas from file (look at Fiona possible drivers) and create Spark DataFrame based on GeoDataFrame object. Example, loading the data from shapefile using geopandas read_file method and create Spark DataFrame based on GeoDataFrame: import geopandas as gpd from pyspark.sql import SparkSession from sedona.register import SedonaRegistrator spark = SparkSession . builder . \\ getOrCreate () SedonaRegistrator . registerAll ( spark ) gdf = gpd . read_file ( \"gis_osm_pois_free_1.shp\" ) spark . createDataFrame ( gdf ) . show () +---------+----+-----------+--------------------+--------------------+ | osm_id|code| fclass| name| geometry| +---------+----+-----------+--------------------+--------------------+ | 26860257|2422| camp_site| de Kroon|POINT (15.3393145...| | 26860294|2406| chalet| Le\u015bne Ustronie|POINT (14.8709625...| | 29947493|2402| motel| null|POINT (15.0946636...| | 29947498|2602| atm| null|POINT (15.0732014...| | 29947499|2401| hotel| null|POINT (15.0696777...| | 29947505|2401| hotel| null|POINT (15.0155749...| +---------+----+-----------+--------------------+--------------------+ Reading data with Spark and converting to GeoPandas import geopandas as gpd from pyspark.sql import SparkSession from sedona.register import SedonaRegistrator spark = SparkSession . builder . \\ getOrCreate () SedonaRegistrator . registerAll ( spark ) counties = spark . \\ read . \\ option ( \"delimiter\" , \"|\" ) . \\ option ( \"header\" , \"true\" ) . \\ csv ( \"counties.csv\" ) counties . createOrReplaceTempView ( \"county\" ) counties_geom = spark . sql ( \"SELECT *, st_geomFromWKT(geom) as geometry from county\" ) df = counties_geom . toPandas () gdf = gpd . GeoDataFrame ( df , geometry = \"geometry\" ) gdf . plot ( figsize = ( 10 , 8 ), column = \"value\" , legend = True , cmap = 'YlOrBr' , scheme = 'quantiles' , edgecolor = 'lightgray' )","title":"Integration with GeoPandas and Shapely"},{"location":"tutorial/sql-python/#dataframe-style-api","text":"Sedona functions can be called used a DataFrame style API similar to PySpark's own functions. The functions are spread across four different modules: sedona.sql.st_constructors , sedona.sql.st_functions , sedona.sql.st_predicates , and sedona.sql.st_aggregates . All of the functions can take columns or strings as arguments and will return a column representing the sedona function call. This makes them integratable with DataFrame.select , DataFrame.join , and all of the PySpark functions found in the pyspark.sql.functions module. As an example of the flexibility: from pyspark.sql import functions as f from sedona.sql import st_constructors as stc df = spark . sql ( \"SELECT array(0.0, 1.0, 2.0) AS values\" ) min_value = f . array_min ( \"values\" ) max_value = f . array_max ( \"values\" ) df = df . select ( stc . ST_Point ( min_value , max_value ) . alias ( \"point\" )) The above code will generate the following dataframe: +-----------+ |point | +-----------+ |POINT (0 2)| +-----------+ Some functions will take native python values and infer them as literals. For example: df = df . select ( stc . ST_Point ( 1.0 , 3.0 ) . alias ( \"point\" )) This will generate a dataframe with a constant point in a column: +-----------+ |point | +-----------+ |POINT (1 3)| +-----------+ For a description of what values a function may take please refer to their specific docstrings. The following rules are followed when passing values to the sedona functions: 1. Column type arguments are passed straight through and are always accepted. 1. str type arguments are always assumed to be names of columns and are wrapped in a Column to support that. If an actual string literal needs to be passed then it will need to be wrapped in a Column using pyspark.sql.functions.lit . 1. Any other types of arguments are checked on a per function basis. Generally, arguments that could reasonably support a python native type are accepted and passed through. Check the specific docstring of the function to be sure. 1. Shapely Geometry objects are not currently accepted in any of the functions.","title":"DataFrame Style API"},{"location":"tutorial/sql-python/#creating-spark-dataframe-based-on-shapely-objects","text":"","title":"Creating Spark DataFrame based on shapely objects"},{"location":"tutorial/sql-python/#supported-shapely-objects","text":"shapely object Available Point MultiPoint LineString MultiLinestring Polygon MultiPolygon To create Spark DataFrame based on mentioned Geometry types, please use GeometryType from sedona.sql.types module. Converting works for list or tuple with shapely objects. Schema for target table with integer id and geometry type can be defined as follow: from pyspark.sql.types import IntegerType , StructField , StructType from sedona.sql.types import GeometryType schema = StructType ( [ StructField ( \"id\" , IntegerType (), False ), StructField ( \"geom\" , GeometryType (), False ) ] ) Also Spark DataFrame with geometry type can be converted to list of shapely objects with collect method.","title":"Supported Shapely objects"},{"location":"tutorial/sql-python/#example-usage-for-shapely-objects","text":"","title":"Example usage for Shapely objects"},{"location":"tutorial/sql-python/#point","text":"from shapely.geometry import Point data = [ [ 1 , Point ( 21.0 , 52.0 )], [ 1 , Point ( 23.0 , 42.0 )], [ 1 , Point ( 26.0 , 32.0 )] ] gdf = spark . createDataFrame ( data , schema ) gdf . show () +---+-------------+ | id| geom| +---+-------------+ | 1|POINT (21 52)| | 1|POINT (23 42)| | 1|POINT (26 32)| +---+-------------+ gdf . printSchema () root |-- id: integer (nullable = false) |-- geom: geometry (nullable = false)","title":"Point"},{"location":"tutorial/sql-python/#multipoint","text":"from shapely.geometry import MultiPoint data = [ [ 1 , MultiPoint ([[ 19.511463 , 51.765158 ], [ 19.446408 , 51.779752 ]])] ] gdf = spark . createDataFrame ( data , schema ) . show ( 1 , False ) +---+---------------------------------------------------------+ |id |geom | +---+---------------------------------------------------------+ |1 |MULTIPOINT ((19.511463 51.765158), (19.446408 51.779752))| +---+---------------------------------------------------------+","title":"MultiPoint"},{"location":"tutorial/sql-python/#linestring","text":"from shapely.geometry import LineString line = [( 40 , 40 ), ( 30 , 30 ), ( 40 , 20 ), ( 30 , 10 )] data = [ [ 1 , LineString ( line )] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+--------------------------------+ |id |geom | +---+--------------------------------+ |1 |LINESTRING (10 10, 20 20, 10 40)| +---+--------------------------------+","title":"LineString"},{"location":"tutorial/sql-python/#multilinestring","text":"from shapely.geometry import MultiLineString line1 = [( 10 , 10 ), ( 20 , 20 ), ( 10 , 40 )] line2 = [( 40 , 40 ), ( 30 , 30 ), ( 40 , 20 ), ( 30 , 10 )] data = [ [ 1 , MultiLineString ([ line1 , line2 ])] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+---------------------------------------------------------------------+ |id |geom | +---+---------------------------------------------------------------------+ |1 |MULTILINESTRING ((10 10, 20 20, 10 40), (40 40, 30 30, 40 20, 30 10))| +---+---------------------------------------------------------------------+","title":"MultiLineString"},{"location":"tutorial/sql-python/#polygon","text":"from shapely.geometry import Polygon polygon = Polygon ( [ [ 19.51121 , 51.76426 ], [ 19.51056 , 51.76583 ], [ 19.51216 , 51.76599 ], [ 19.51280 , 51.76448 ], [ 19.51121 , 51.76426 ] ] ) data = [ [ 1 , polygon ] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+--------------------------------------------------------------------------------------------------------+ |id |geom | +---+--------------------------------------------------------------------------------------------------------+ |1 |POLYGON ((19.51121 51.76426, 19.51056 51.76583, 19.51216 51.76599, 19.5128 51.76448, 19.51121 51.76426))| +---+--------------------------------------------------------------------------------------------------------+","title":"Polygon"},{"location":"tutorial/sql-python/#multipolygon","text":"from shapely.geometry import MultiPolygon exterior_p1 = [( 0 , 0 ), ( 0 , 2 ), ( 2 , 2 ), ( 2 , 0 ), ( 0 , 0 )] interior_p1 = [( 1 , 1 ), ( 1 , 1.5 ), ( 1.5 , 1.5 ), ( 1.5 , 1 ), ( 1 , 1 )] exterior_p2 = [( 0 , 0 ), ( 1 , 0 ), ( 1 , 1 ), ( 0 , 1 ), ( 0 , 0 )] polygons = [ Polygon ( exterior_p1 , [ interior_p1 ]), Polygon ( exterior_p2 ) ] data = [ [ 1 , MultiPolygon ( polygons )] ] gdf = spark . createDataFrame ( data , schema ) gdf . show ( 1 , False ) +---+----------------------------------------------------------------------------------------------------------+ |id |geom | +---+----------------------------------------------------------------------------------------------------------+ |1 |MULTIPOLYGON (((0 0, 0 2, 2 2, 2 0, 0 0), (1 1, 1.5 1, 1.5 1.5, 1 1.5, 1 1)), ((0 0, 0 1, 1 1, 1 0, 0 0)))| +---+----------------------------------------------------------------------------------------------------------+","title":"MultiPolygon"},{"location":"tutorial/sql-r/","text":"Spatial SQL applications in R language \u00b6 In apache.sedona , sdf_register() , a S3 generic from sparklyr converting a lower-level object to a Spark dataframe, can be applied to a SpatialRDD objects: library ( sparklyr ) library ( apache.sedona ) sc <- spark_connect ( master = \"local\" ) polygon_rdd <- sedona_read_geojson ( sc , location = \"/tmp/polygon.json\" ) polygon_sdf <- polygon_rdd %>% sdf_register () polygon_sdf %>% print ( n = 3 ) ## # Source : spark <? > [ ?? x 1 ] ## geometry ## <list> ## 1 <POLYGON ((-87.621765 34.873444, -87.617535 34.873369, -87.6123 34.873337, -8\u2026 ## 2 <POLYGON ((-85.719017 31.297901, -85.715626 31.305203, -85.714271 31.307096, \u2026 ## 3 <POLYGON ((-86.000685 34.00537, -85.998837 34.009768, -85.998012 34.010398, -\u2026 ## # \u2026 with more rows The resulting Spark dataframe object can then be modified using dplyr verbs familiar to many R users. In addition, spatial UDFs supported by Sedona can inter-operate seamlessly with other functions supported in sparklyr \u2019s dbplyr SQL translation env. For example, the code below finds the average area of all polygons in polygon_sdf : mean_area_sdf <- polygon_sdf %>% dplyr :: summarize ( mean_area = mean ( ST_Area ( geometry ))) print ( mean_area_sdf ) ## # Source : spark <? > [ ?? x 1 ] ## mean_area ## <dbl> ## 1 0.00217 Once spatial objects are imported into Spark dataframes, they can also be easily integrated with other non-spatial attributes, e.g., modified_polygon_sdf <- polygon_sdf %>% dplyr :: mutate ( type = \"polygon\" ) Notice that all of the above can open up many interesting possiblities. For example, one can extract ML features from geospatial data in Spark dataframes, build a ML pipeline using ml_* family of functions in sparklyr to work with such features, and if the output of a ML model happens to be a geospatial object as well, one can even apply visualization routines in apache.sedona to visualize the difference between any predicted geometry and the corresponding ground truth.","title":"R"},{"location":"tutorial/sql-r/#spatial-sql-applications-in-r-language","text":"In apache.sedona , sdf_register() , a S3 generic from sparklyr converting a lower-level object to a Spark dataframe, can be applied to a SpatialRDD objects: library ( sparklyr ) library ( apache.sedona ) sc <- spark_connect ( master = \"local\" ) polygon_rdd <- sedona_read_geojson ( sc , location = \"/tmp/polygon.json\" ) polygon_sdf <- polygon_rdd %>% sdf_register () polygon_sdf %>% print ( n = 3 ) ## # Source : spark <? > [ ?? x 1 ] ## geometry ## <list> ## 1 <POLYGON ((-87.621765 34.873444, -87.617535 34.873369, -87.6123 34.873337, -8\u2026 ## 2 <POLYGON ((-85.719017 31.297901, -85.715626 31.305203, -85.714271 31.307096, \u2026 ## 3 <POLYGON ((-86.000685 34.00537, -85.998837 34.009768, -85.998012 34.010398, -\u2026 ## # \u2026 with more rows The resulting Spark dataframe object can then be modified using dplyr verbs familiar to many R users. In addition, spatial UDFs supported by Sedona can inter-operate seamlessly with other functions supported in sparklyr \u2019s dbplyr SQL translation env. For example, the code below finds the average area of all polygons in polygon_sdf : mean_area_sdf <- polygon_sdf %>% dplyr :: summarize ( mean_area = mean ( ST_Area ( geometry ))) print ( mean_area_sdf ) ## # Source : spark <? > [ ?? x 1 ] ## mean_area ## <dbl> ## 1 0.00217 Once spatial objects are imported into Spark dataframes, they can also be easily integrated with other non-spatial attributes, e.g., modified_polygon_sdf <- polygon_sdf %>% dplyr :: mutate ( type = \"polygon\" ) Notice that all of the above can open up many interesting possiblities. For example, one can extract ML features from geospatial data in Spark dataframes, build a ML pipeline using ml_* family of functions in sparklyr to work with such features, and if the output of a ML model happens to be a geospatial object as well, one can even apply visualization routines in apache.sedona to visualize the difference between any predicted geometry and the corresponding ground truth.","title":"Spatial SQL applications in R language"},{"location":"tutorial/sql/","text":"The page outlines the steps to manage spatial data using SedonaSQL. The example code is written in Scala but also works for Java . SedonaSQL supports SQL/MM Part3 Spatial SQL Standard. It includes four kinds of SQL operators as follows. All these operators can be directly called through: var myDataFrame = sparkSession . sql ( \"YOUR_SQL\" ) Detailed SedonaSQL APIs are available here: SedonaSQL API Set up dependencies \u00b6 Read Sedona Maven Central coordinates Select the minimum dependencies : Add Apache Spark core , Apache SparkSQL , Sedona-core and Sedona-SQL Add the dependencies in build.sbt or pom.xml. Note To enjoy the full functions of Sedona, we suggest you include the full dependencies : Apache Spark core , Apache SparkSQL , Sedona-core, Sedona-SQL, Sedona-Viz. Please see SQL example project Initiate SparkSession \u00b6 Use the following code to initiate your SparkSession at the beginning: var sparkSession = SparkSession . builder () . master ( \"local[*]\" ) // Delete this if run in cluster mode . appName ( \"readTestScala\" ) // Change this to a proper name // Enable Sedona custom Kryo serializer . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) // org.apache.spark.serializer.KryoSerializer . config ( \"spark.kryo.registrator\" , classOf [ SedonaKryoRegistrator ]. getName ) . getOrCreate () // org.apache.sedona.core.serde.SedonaKryoRegistrator Warning Sedona has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. If you add the Sedona full dependencies as suggested above, please use the following two lines to enable Sedona Kryo serializer instead: . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) // org.apache.spark.serializer.KryoSerializer . config ( \"spark.kryo.registrator\" , classOf [ SedonaVizKryoRegistrator ]. getName ) // org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator Register SedonaSQL \u00b6 Add the following line after your SparkSession declaration SedonaSQLRegistrator . registerAll ( sparkSession ) This function will register Sedona User Defined Type, User Defined Function and optimized join query strategy. You can also register everything by passing --conf spark.sql.extensions=org.apache.sedona.sql.SedonaSqlExtensions to spark-submit or spark-shell . Load data from files \u00b6 Assume we have a WKT file, namely usa-county.tsv , at Path /Download/usa-county.tsv as follows: POLYGON (..., ...) Cuming County POLYGON (..., ...) Wahkiakum County POLYGON (..., ...) De Baca County POLYGON (..., ...) Lancaster County The file may have many other columns. Use the following code to load the data and create a raw DataFrame: var rawDf = sparkSession . read . format ( \"csv\" ). option ( \"delimiter\" , \"\\t\" ). option ( \"header\" , \"false\" ). load ( \"/Download/usa-county.tsv\" ) rawDf . createOrReplaceTempView ( \"rawdf\" ) rawDf . show () The output will be like this: | _c0|_c1|_c2| _c3| _c4| _c5| _c6|_c7|_c8| _c9|_c10| _c11|_c12|_c13| _c14| _c15| _c16| _c17| +--------------------+---+---+--------+-----+-----------+--------------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+ |POLYGON ((-97.019...| 31|039|00835841|31039| Cuming| Cuming County| 06| H1|G4020|null| null|null| A|1477895811|10447360|+41.9158651|-096.7885168| |POLYGON ((-123.43...| 53|069|01513275|53069| Wahkiakum| Wahkiakum County| 06| H1|G4020|null| null|null| A| 682138871|61658258|+46.2946377|-123.4244583| |POLYGON ((-104.56...| 35|011|00933054|35011| De Baca| De Baca County| 06| H1|G4020|null| null|null| A|6015539696|29159492|+34.3592729|-104.3686961| |POLYGON ((-96.910...| 31|109|00835876|31109| Lancaster| Lancaster County| 06| H1|G4020| 339|30700|null| A|2169240202|22877180|+40.7835474|-096.6886584| Create a Geometry type column \u00b6 All geometrical operations in SedonaSQL are on Geometry type objects. Therefore, before any kind of queries, you need to create a Geometry type column on a DataFrame. var spatialDf = sparkSession . sql ( \"\"\" |SELECT ST_GeomFromWKT(_c0) AS countyshape, _c1, _c2 |FROM rawdf \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () You can select many other attributes to compose this spatialdDf . The output will be something like this: | countyshape|_c1|_c2| _c3| _c4| _c5| _c6|_c7|_c8| _c9|_c10| _c11|_c12|_c13| _c14| _c15| _c16| _c17| +--------------------+---+---+--------+-----+-----------+--------------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+ |POLYGON ((-97.019...| 31|039|00835841|31039| Cuming| Cuming County| 06| H1|G4020|null| null|null| A|1477895811|10447360|+41.9158651|-096.7885168| |POLYGON ((-123.43...| 53|069|01513275|53069| Wahkiakum| Wahkiakum County| 06| H1|G4020|null| null|null| A| 682138871|61658258|+46.2946377|-123.4244583| |POLYGON ((-104.56...| 35|011|00933054|35011| De Baca| De Baca County| 06| H1|G4020|null| null|null| A|6015539696|29159492|+34.3592729|-104.3686961| |POLYGON ((-96.910...| 31|109|00835876|31109| Lancaster| Lancaster County| 06| H1|G4020| 339|30700|null| A|2169240202|22877180|+40.7835474|-096.6886584| Although it looks same with the input, but actually the type of column countyshape has been changed to Geometry type. To verify this, use the following code to print the schema of the DataFrame: spatialDf . printSchema () The output will be like this: root |-- countyshape: geometry (nullable = false) |-- _c1: string (nullable = true) |-- _c2: string (nullable = true) |-- _c3: string (nullable = true) |-- _c4: string (nullable = true) |-- _c5: string (nullable = true) |-- _c6: string (nullable = true) |-- _c7: string (nullable = true) Note SedonaSQL provides lots of functions to create a Geometry column, please read SedonaSQL constructor API . Load Shapefile and GeoJSON \u00b6 Shapefile and GeoJSON must be loaded by SpatialRDD and converted to DataFrame using Adapter. Please read Load SpatialRDD and DataFrame <-> RDD . Load GeoParquet \u00b6 Since v 1.3.0 , Sedona natively supports loading GeoParquet file. GeoParquet must be loaded using DataFrame if default name is geometry. val df = sparkSession . read . format ( \"geoparquet\" ). load ( geoparquetdatalocation1 ) df . printSchema () The output will be as follows: root |-- pop_est: long (nullable = true) |-- continent: string (nullable = true) |-- name: string (nullable = true) |-- iso_a3: string (nullable = true) |-- gdp_md_est: double (nullable = true) |-- geometry: geometry (nullable = true) If geometry column name is different var df = sparkSession . read . format ( \"geoparquet\" ). option ( \"fieldGeometry\" , \"new_geometry\" ). load ( geoparquetdatalocation1 ) The output will be as follows: root |-- pop_est: long (nullable = true) |-- continent: string (nullable = true) |-- name: string (nullable = true) |-- iso_a3: string (nullable = true) |-- gdp_md_est: double (nullable = true) |-- new_geometry: geometry (nullable = true) Transform the Coordinate Reference System \u00b6 Sedona doesn't control the coordinate unit (degree-based or meter-based) of all geometries in a Geometry column. The unit of all related distances in SedonaSQL is same as the unit of all geometries in a Geometry column. To convert Coordinate Reference System of the Geometry column created before, use the following code: spatialDf = sparkSession . sql ( \"\"\" |SELECT ST_Transform(countyshape, \"epsg:4326\", \"epsg:3857\") AS newcountyshape, _c1, _c2, _c3, _c4, _c5, _c6, _c7 |FROM spatialdf \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () The first EPSG code EPSG:4326 in ST_Transform is the source CRS of the geometries. It is WGS84, the most common degree-based CRS. The second EPSG code EPSG:3857 in ST_Transform is the target CRS of the geometries. It is the most common meter-based CRS. This ST_Transform transform the CRS of these geomtries from EPSG:4326 to EPSG:3857. The details CRS information can be found on EPSG.io The coordinates of polygons have been changed. The output will be like this: +--------------------+---+---+--------+-----+-----------+--------------------+---+ | newcountyshape|_c1|_c2| _c3| _c4| _c5| _c6|_c7| +--------------------+---+---+--------+-----+-----------+--------------------+---+ |POLYGON ((-108001...| 31|039|00835841|31039| Cuming| Cuming County| 06| |POLYGON ((-137408...| 53|069|01513275|53069| Wahkiakum| Wahkiakum County| 06| |POLYGON ((-116403...| 35|011|00933054|35011| De Baca| De Baca County| 06| |POLYGON ((-107880...| 31|109|00835876|31109| Lancaster| Lancaster County| 06| Run spatial queries \u00b6 After creating a Geometry type column, you are able to run spatial queries. Range query \u00b6 Use ST_Contains , ST_Intersects , ST_Within to run a range query over a single column. The following example finds all counties that are within the given polygon: spatialDf = sparkSession . sql ( \"\"\" |SELECT * |FROM spatialdf |WHERE ST_Contains (ST_PolygonFromEnvelope(1.0,100.0,1000.0,1100.0), newcountyshape) \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () Note Read SedonaSQL constructor API to learn how to create a Geometry type query window KNN query \u00b6 Use ST_Distance to calculate the distance and rank the distance. The following code returns the 5 nearest neighbor of the given polygon. spatialDf = sparkSession . sql ( \"\"\" |SELECT countyname, ST_Distance(ST_PolygonFromEnvelope(1.0,100.0,1000.0,1100.0), newcountyshape) AS distance |FROM spatialdf |ORDER BY distance DESC |LIMIT 5 \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () Join query \u00b6 The details of a join query is available here Join query . Other queries \u00b6 There are lots of other functions can be combined with these queries. Please read SedonaSQL functions and SedonaSQL aggregate functions . Save to permanent storage \u00b6 To save a Spatial DataFrame to some permanent storage such as Hive tables and HDFS, you can simply convert each geometry in the Geometry type column back to a plain String and save the plain DataFrame to wherever you want. Use the following code to convert the Geometry column in a DataFrame back to a WKT string column: var stringDf = sparkSession . sql ( \"\"\" |SELECT ST_AsText(countyshape) |FROM polygondf \"\"\" . stripMargin ) Note ST_AsGeoJSON is also available. We would like to invite you to contribute more functions Save GeoParquet \u00b6 Since v 1.3.0 , Sedona natively supports writing GeoParquet file. GeoParquet can be saved as follows: df . write . format ( \"geoparquet\" ). save ( geoparquetoutputlocation + \"/GeoParquet_File_Name.parquet\" ) Convert between DataFrame and SpatialRDD \u00b6 DataFrame to SpatialRDD \u00b6 Use SedonaSQL DataFrame-RDD Adapter to convert a DataFrame to an SpatialRDD. Please read Adapter Scaladoc var spatialRDD = Adapter . toSpatialRdd ( spatialDf , \"usacounty\" ) \"usacounty\" is the name of the geometry column Warning Only one Geometry type column is allowed per DataFrame. SpatialRDD to DataFrame \u00b6 Use SedonaSQL DataFrame-RDD Adapter to convert a DataFrame to an SpatialRDD. Please read Adapter Scaladoc var spatialDf = Adapter . toDf ( spatialRDD , sparkSession ) All other attributes such as price and age will be also brought to the DataFrame as long as you specify carryOtherAttributes (see Read other attributes in an SpatialRDD ). You may also manually specify a schema for the resulting DataFrame in case you require different column names or data types. Note that string schemas and not all data types are supported\u2014please check the Adapter Scaladoc and source code to confirm what is supported for your use case. At least one column for the user data must be provided. val schema = StructType ( Array ( StructField ( \"county\" , GeometryUDT , nullable = true ), StructField ( \"name\" , StringType , nullable = true ), StructField ( \"price\" , DoubleType , nullable = true ), StructField ( \"age\" , IntegerType , nullable = true ) )) val spatialDf = Adapter . toDf ( spatialRDD , schema , sparkSession ) SpatialPairRDD to DataFrame \u00b6 PairRDD is the result of a spatial join query or distance join query. SedonaSQL DataFrame-RDD Adapter can convert the result to a DataFrame. But you need to provide the name of other attributes. var joinResultDf = Adapter . toDf ( joinResultPairRDD , Seq ( \"left_attribute1\" , \"left_attribute2\" ), Seq ( \"right_attribute1\" , \"right_attribute2\" ), sparkSession ) or you can use the attribute names directly from the input RDD import scala . collection . JavaConversions . _ var joinResultDf = Adapter . toDf ( joinResultPairRDD , leftRdd . fieldNames , rightRdd . fieldNames , sparkSession ) All other attributes such as price and age will be also brought to the DataFrame as long as you specify carryOtherAttributes (see Read other attributes in an SpatialRDD ). You may also manually specify a schema for the resulting DataFrame in case you require different column names or data types. Note that string schemas and not all data types are supported\u2014please check the Adapter Scaladoc and source code to confirm what is supported for your use case. Columns for the left and right user data must be provided. val schema = StructType ( Array ( StructField ( \"leftGeometry\" , GeometryUDT , nullable = true ), StructField ( \"name\" , StringType , nullable = true ), StructField ( \"price\" , DoubleType , nullable = true ), StructField ( \"age\" , IntegerType , nullable = true ), StructField ( \"rightGeometry\" , GeometryUDT , nullable = true ), StructField ( \"category\" , StringType , nullable = true ) )) val joinResultDf = Adapter . toDf ( joinResultPairRDD , schema , sparkSession ) DataFrame Style API \u00b6 Sedona functions can be used in a DataFrame style API similar to Spark functions. The following objects contain the exposed functions: org.apache.spark.sql.sedona_sql.expressions.st_functions , org.apache.spark.sql.sedona_sql.expressions.st_constructors , org.apache.spark.sql.sedona_sql.expressions.st_predicates , and org.apache.spark.sql.sedona_sql.expressions.st_aggregates . Every functions can take all Column arguments. Additionally, overloaded forms can commonly take a mix of String and other Scala types (such as Double ) as arguments. In general the following rules apply (although check the documentation of specific functions for any exceptions): 1. Every function returns a Column so that it can be used interchangeably with Spark functions as well as DataFrame methods such as DataFrame.select or DataFrame.join . 1. Every function has a form that takes all Column arguments. These are the most versatile of the forms. 1. Most functions have a form that takes a mix of String arguments with other Scala types. The exact mixture of argument types allowed is function specific. However, in these instances, all String arguments are assumed to be the names of columns and will be wrapped in a Column automatically. Non- String arguments are assumed to be literals that are passed to the sedona function. If you need to pass a String literal then you should use the all Column form of the sedona function and wrap the String literal in a Column with the lit Spark function. A short example of using this API (uses the array_min and array_max Spark functions): val values_df = spark . sql ( \"SELECT array(0.0, 1.0, 2.0) AS values\" ) val min_value = array_min ( \"values\" ) val max_value = array_max ( \"values\" ) val point_df = values_df . select ( ST_Point ( min_value , max_value ). as ( \"point\" ))","title":"Scala/Java"},{"location":"tutorial/sql/#set-up-dependencies","text":"Read Sedona Maven Central coordinates Select the minimum dependencies : Add Apache Spark core , Apache SparkSQL , Sedona-core and Sedona-SQL Add the dependencies in build.sbt or pom.xml. Note To enjoy the full functions of Sedona, we suggest you include the full dependencies : Apache Spark core , Apache SparkSQL , Sedona-core, Sedona-SQL, Sedona-Viz. Please see SQL example project","title":"Set up dependencies"},{"location":"tutorial/sql/#initiate-sparksession","text":"Use the following code to initiate your SparkSession at the beginning: var sparkSession = SparkSession . builder () . master ( \"local[*]\" ) // Delete this if run in cluster mode . appName ( \"readTestScala\" ) // Change this to a proper name // Enable Sedona custom Kryo serializer . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) // org.apache.spark.serializer.KryoSerializer . config ( \"spark.kryo.registrator\" , classOf [ SedonaKryoRegistrator ]. getName ) . getOrCreate () // org.apache.sedona.core.serde.SedonaKryoRegistrator Warning Sedona has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. If you add the Sedona full dependencies as suggested above, please use the following two lines to enable Sedona Kryo serializer instead: . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) // org.apache.spark.serializer.KryoSerializer . config ( \"spark.kryo.registrator\" , classOf [ SedonaVizKryoRegistrator ]. getName ) // org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator","title":"Initiate SparkSession"},{"location":"tutorial/sql/#register-sedonasql","text":"Add the following line after your SparkSession declaration SedonaSQLRegistrator . registerAll ( sparkSession ) This function will register Sedona User Defined Type, User Defined Function and optimized join query strategy. You can also register everything by passing --conf spark.sql.extensions=org.apache.sedona.sql.SedonaSqlExtensions to spark-submit or spark-shell .","title":"Register SedonaSQL"},{"location":"tutorial/sql/#load-data-from-files","text":"Assume we have a WKT file, namely usa-county.tsv , at Path /Download/usa-county.tsv as follows: POLYGON (..., ...) Cuming County POLYGON (..., ...) Wahkiakum County POLYGON (..., ...) De Baca County POLYGON (..., ...) Lancaster County The file may have many other columns. Use the following code to load the data and create a raw DataFrame: var rawDf = sparkSession . read . format ( \"csv\" ). option ( \"delimiter\" , \"\\t\" ). option ( \"header\" , \"false\" ). load ( \"/Download/usa-county.tsv\" ) rawDf . createOrReplaceTempView ( \"rawdf\" ) rawDf . show () The output will be like this: | _c0|_c1|_c2| _c3| _c4| _c5| _c6|_c7|_c8| _c9|_c10| _c11|_c12|_c13| _c14| _c15| _c16| _c17| +--------------------+---+---+--------+-----+-----------+--------------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+ |POLYGON ((-97.019...| 31|039|00835841|31039| Cuming| Cuming County| 06| H1|G4020|null| null|null| A|1477895811|10447360|+41.9158651|-096.7885168| |POLYGON ((-123.43...| 53|069|01513275|53069| Wahkiakum| Wahkiakum County| 06| H1|G4020|null| null|null| A| 682138871|61658258|+46.2946377|-123.4244583| |POLYGON ((-104.56...| 35|011|00933054|35011| De Baca| De Baca County| 06| H1|G4020|null| null|null| A|6015539696|29159492|+34.3592729|-104.3686961| |POLYGON ((-96.910...| 31|109|00835876|31109| Lancaster| Lancaster County| 06| H1|G4020| 339|30700|null| A|2169240202|22877180|+40.7835474|-096.6886584|","title":"Load data from files"},{"location":"tutorial/sql/#create-a-geometry-type-column","text":"All geometrical operations in SedonaSQL are on Geometry type objects. Therefore, before any kind of queries, you need to create a Geometry type column on a DataFrame. var spatialDf = sparkSession . sql ( \"\"\" |SELECT ST_GeomFromWKT(_c0) AS countyshape, _c1, _c2 |FROM rawdf \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () You can select many other attributes to compose this spatialdDf . The output will be something like this: | countyshape|_c1|_c2| _c3| _c4| _c5| _c6|_c7|_c8| _c9|_c10| _c11|_c12|_c13| _c14| _c15| _c16| _c17| +--------------------+---+---+--------+-----+-----------+--------------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+ |POLYGON ((-97.019...| 31|039|00835841|31039| Cuming| Cuming County| 06| H1|G4020|null| null|null| A|1477895811|10447360|+41.9158651|-096.7885168| |POLYGON ((-123.43...| 53|069|01513275|53069| Wahkiakum| Wahkiakum County| 06| H1|G4020|null| null|null| A| 682138871|61658258|+46.2946377|-123.4244583| |POLYGON ((-104.56...| 35|011|00933054|35011| De Baca| De Baca County| 06| H1|G4020|null| null|null| A|6015539696|29159492|+34.3592729|-104.3686961| |POLYGON ((-96.910...| 31|109|00835876|31109| Lancaster| Lancaster County| 06| H1|G4020| 339|30700|null| A|2169240202|22877180|+40.7835474|-096.6886584| Although it looks same with the input, but actually the type of column countyshape has been changed to Geometry type. To verify this, use the following code to print the schema of the DataFrame: spatialDf . printSchema () The output will be like this: root |-- countyshape: geometry (nullable = false) |-- _c1: string (nullable = true) |-- _c2: string (nullable = true) |-- _c3: string (nullable = true) |-- _c4: string (nullable = true) |-- _c5: string (nullable = true) |-- _c6: string (nullable = true) |-- _c7: string (nullable = true) Note SedonaSQL provides lots of functions to create a Geometry column, please read SedonaSQL constructor API .","title":"Create a Geometry type column"},{"location":"tutorial/sql/#load-shapefile-and-geojson","text":"Shapefile and GeoJSON must be loaded by SpatialRDD and converted to DataFrame using Adapter. Please read Load SpatialRDD and DataFrame <-> RDD .","title":"Load Shapefile and GeoJSON"},{"location":"tutorial/sql/#load-geoparquet","text":"Since v 1.3.0 , Sedona natively supports loading GeoParquet file. GeoParquet must be loaded using DataFrame if default name is geometry. val df = sparkSession . read . format ( \"geoparquet\" ). load ( geoparquetdatalocation1 ) df . printSchema () The output will be as follows: root |-- pop_est: long (nullable = true) |-- continent: string (nullable = true) |-- name: string (nullable = true) |-- iso_a3: string (nullable = true) |-- gdp_md_est: double (nullable = true) |-- geometry: geometry (nullable = true) If geometry column name is different var df = sparkSession . read . format ( \"geoparquet\" ). option ( \"fieldGeometry\" , \"new_geometry\" ). load ( geoparquetdatalocation1 ) The output will be as follows: root |-- pop_est: long (nullable = true) |-- continent: string (nullable = true) |-- name: string (nullable = true) |-- iso_a3: string (nullable = true) |-- gdp_md_est: double (nullable = true) |-- new_geometry: geometry (nullable = true)","title":"Load GeoParquet"},{"location":"tutorial/sql/#transform-the-coordinate-reference-system","text":"Sedona doesn't control the coordinate unit (degree-based or meter-based) of all geometries in a Geometry column. The unit of all related distances in SedonaSQL is same as the unit of all geometries in a Geometry column. To convert Coordinate Reference System of the Geometry column created before, use the following code: spatialDf = sparkSession . sql ( \"\"\" |SELECT ST_Transform(countyshape, \"epsg:4326\", \"epsg:3857\") AS newcountyshape, _c1, _c2, _c3, _c4, _c5, _c6, _c7 |FROM spatialdf \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () The first EPSG code EPSG:4326 in ST_Transform is the source CRS of the geometries. It is WGS84, the most common degree-based CRS. The second EPSG code EPSG:3857 in ST_Transform is the target CRS of the geometries. It is the most common meter-based CRS. This ST_Transform transform the CRS of these geomtries from EPSG:4326 to EPSG:3857. The details CRS information can be found on EPSG.io The coordinates of polygons have been changed. The output will be like this: +--------------------+---+---+--------+-----+-----------+--------------------+---+ | newcountyshape|_c1|_c2| _c3| _c4| _c5| _c6|_c7| +--------------------+---+---+--------+-----+-----------+--------------------+---+ |POLYGON ((-108001...| 31|039|00835841|31039| Cuming| Cuming County| 06| |POLYGON ((-137408...| 53|069|01513275|53069| Wahkiakum| Wahkiakum County| 06| |POLYGON ((-116403...| 35|011|00933054|35011| De Baca| De Baca County| 06| |POLYGON ((-107880...| 31|109|00835876|31109| Lancaster| Lancaster County| 06|","title":"Transform the Coordinate Reference System"},{"location":"tutorial/sql/#run-spatial-queries","text":"After creating a Geometry type column, you are able to run spatial queries.","title":"Run spatial queries"},{"location":"tutorial/sql/#range-query","text":"Use ST_Contains , ST_Intersects , ST_Within to run a range query over a single column. The following example finds all counties that are within the given polygon: spatialDf = sparkSession . sql ( \"\"\" |SELECT * |FROM spatialdf |WHERE ST_Contains (ST_PolygonFromEnvelope(1.0,100.0,1000.0,1100.0), newcountyshape) \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show () Note Read SedonaSQL constructor API to learn how to create a Geometry type query window","title":"Range query"},{"location":"tutorial/sql/#knn-query","text":"Use ST_Distance to calculate the distance and rank the distance. The following code returns the 5 nearest neighbor of the given polygon. spatialDf = sparkSession . sql ( \"\"\" |SELECT countyname, ST_Distance(ST_PolygonFromEnvelope(1.0,100.0,1000.0,1100.0), newcountyshape) AS distance |FROM spatialdf |ORDER BY distance DESC |LIMIT 5 \"\"\" . stripMargin ) spatialDf . createOrReplaceTempView ( \"spatialdf\" ) spatialDf . show ()","title":"KNN query"},{"location":"tutorial/sql/#join-query","text":"The details of a join query is available here Join query .","title":"Join query"},{"location":"tutorial/sql/#other-queries","text":"There are lots of other functions can be combined with these queries. Please read SedonaSQL functions and SedonaSQL aggregate functions .","title":"Other queries"},{"location":"tutorial/sql/#save-to-permanent-storage","text":"To save a Spatial DataFrame to some permanent storage such as Hive tables and HDFS, you can simply convert each geometry in the Geometry type column back to a plain String and save the plain DataFrame to wherever you want. Use the following code to convert the Geometry column in a DataFrame back to a WKT string column: var stringDf = sparkSession . sql ( \"\"\" |SELECT ST_AsText(countyshape) |FROM polygondf \"\"\" . stripMargin ) Note ST_AsGeoJSON is also available. We would like to invite you to contribute more functions","title":"Save to permanent storage"},{"location":"tutorial/sql/#save-geoparquet","text":"Since v 1.3.0 , Sedona natively supports writing GeoParquet file. GeoParquet can be saved as follows: df . write . format ( \"geoparquet\" ). save ( geoparquetoutputlocation + \"/GeoParquet_File_Name.parquet\" )","title":"Save GeoParquet"},{"location":"tutorial/sql/#convert-between-dataframe-and-spatialrdd","text":"","title":"Convert between DataFrame and SpatialRDD"},{"location":"tutorial/sql/#dataframe-to-spatialrdd","text":"Use SedonaSQL DataFrame-RDD Adapter to convert a DataFrame to an SpatialRDD. Please read Adapter Scaladoc var spatialRDD = Adapter . toSpatialRdd ( spatialDf , \"usacounty\" ) \"usacounty\" is the name of the geometry column Warning Only one Geometry type column is allowed per DataFrame.","title":"DataFrame to SpatialRDD"},{"location":"tutorial/sql/#spatialrdd-to-dataframe","text":"Use SedonaSQL DataFrame-RDD Adapter to convert a DataFrame to an SpatialRDD. Please read Adapter Scaladoc var spatialDf = Adapter . toDf ( spatialRDD , sparkSession ) All other attributes such as price and age will be also brought to the DataFrame as long as you specify carryOtherAttributes (see Read other attributes in an SpatialRDD ). You may also manually specify a schema for the resulting DataFrame in case you require different column names or data types. Note that string schemas and not all data types are supported\u2014please check the Adapter Scaladoc and source code to confirm what is supported for your use case. At least one column for the user data must be provided. val schema = StructType ( Array ( StructField ( \"county\" , GeometryUDT , nullable = true ), StructField ( \"name\" , StringType , nullable = true ), StructField ( \"price\" , DoubleType , nullable = true ), StructField ( \"age\" , IntegerType , nullable = true ) )) val spatialDf = Adapter . toDf ( spatialRDD , schema , sparkSession )","title":"SpatialRDD to DataFrame"},{"location":"tutorial/sql/#spatialpairrdd-to-dataframe","text":"PairRDD is the result of a spatial join query or distance join query. SedonaSQL DataFrame-RDD Adapter can convert the result to a DataFrame. But you need to provide the name of other attributes. var joinResultDf = Adapter . toDf ( joinResultPairRDD , Seq ( \"left_attribute1\" , \"left_attribute2\" ), Seq ( \"right_attribute1\" , \"right_attribute2\" ), sparkSession ) or you can use the attribute names directly from the input RDD import scala . collection . JavaConversions . _ var joinResultDf = Adapter . toDf ( joinResultPairRDD , leftRdd . fieldNames , rightRdd . fieldNames , sparkSession ) All other attributes such as price and age will be also brought to the DataFrame as long as you specify carryOtherAttributes (see Read other attributes in an SpatialRDD ). You may also manually specify a schema for the resulting DataFrame in case you require different column names or data types. Note that string schemas and not all data types are supported\u2014please check the Adapter Scaladoc and source code to confirm what is supported for your use case. Columns for the left and right user data must be provided. val schema = StructType ( Array ( StructField ( \"leftGeometry\" , GeometryUDT , nullable = true ), StructField ( \"name\" , StringType , nullable = true ), StructField ( \"price\" , DoubleType , nullable = true ), StructField ( \"age\" , IntegerType , nullable = true ), StructField ( \"rightGeometry\" , GeometryUDT , nullable = true ), StructField ( \"category\" , StringType , nullable = true ) )) val joinResultDf = Adapter . toDf ( joinResultPairRDD , schema , sparkSession )","title":"SpatialPairRDD to DataFrame"},{"location":"tutorial/sql/#dataframe-style-api","text":"Sedona functions can be used in a DataFrame style API similar to Spark functions. The following objects contain the exposed functions: org.apache.spark.sql.sedona_sql.expressions.st_functions , org.apache.spark.sql.sedona_sql.expressions.st_constructors , org.apache.spark.sql.sedona_sql.expressions.st_predicates , and org.apache.spark.sql.sedona_sql.expressions.st_aggregates . Every functions can take all Column arguments. Additionally, overloaded forms can commonly take a mix of String and other Scala types (such as Double ) as arguments. In general the following rules apply (although check the documentation of specific functions for any exceptions): 1. Every function returns a Column so that it can be used interchangeably with Spark functions as well as DataFrame methods such as DataFrame.select or DataFrame.join . 1. Every function has a form that takes all Column arguments. These are the most versatile of the forms. 1. Most functions have a form that takes a mix of String arguments with other Scala types. The exact mixture of argument types allowed is function specific. However, in these instances, all String arguments are assumed to be the names of columns and will be wrapped in a Column automatically. Non- String arguments are assumed to be literals that are passed to the sedona function. If you need to pass a String literal then you should use the all Column form of the sedona function and wrap the String literal in a Column with the lit Spark function. A short example of using this API (uses the array_min and array_max Spark functions): val values_df = spark . sql ( \"SELECT array(0.0, 1.0, 2.0) AS values\" ) val min_value = array_min ( \"values\" ) val max_value = array_max ( \"values\" ) val point_df = values_df . select ( ST_Point ( min_value , max_value ). as ( \"point\" ))","title":"DataFrame Style API"},{"location":"tutorial/viz-gallery/","text":"Watch the high resolution version on a real map","title":"Gallery"},{"location":"tutorial/viz-r/","text":"Map Visualization applications in R language \u00b6 An important part of apache.sedona is its collection of R interfaces to Sedona visualization routines. For example, the following is essentially the R equivalent of this example in Scala . library ( sparklyr ) library ( apache.sedona ) sc <- spark_connect ( master = \"local\" ) resolution_x <- 1000 resolution_y <- 600 boundary <- c ( -126.790180 , -64.630926 , 24.863836 , 50.000 ) pt_rdd <- sedona_read_dsv_to_typed_rdd ( sc , location = \"arealm.csv\" , type = \"point\" ) polygon_rdd <- sedona_read_dsv_to_typed_rdd ( sc , location = \"primaryroads-polygon.csv\" , type = \"polygon\" ) pair_rdd <- sedona_spatial_join_count_by_key ( pt_rdd , polygon_rdd , join_type = \"intersect\" ) overlay <- sedona_render_scatter_plot ( polygon_rdd , resolution_x , resolution_y , output_location = tempfile ( \"scatter-plot-\" ), boundary = boundary , base_color = c ( 255 , 0 , 0 ), browse = FALSE ) sedona_render_choropleth_map ( pair_rdd , resolution_x , resolution_y , output_location = \"/tmp/choropleth-map\" , boundary = boundary , overlay = overlay , # vary the green color channel according to relative magnitudes of data points so # that the resulting map will show light blue, light purple, and light gray pixels color_of_variation = \"green\" , base_color = c ( 225 , 225 , 255 ) ) It will create a scatter plot, and then overlay it on top of a choropleth map, as shown below: See ?apache.sedona::sedona_render_scatter_plot , ?apache.sedona::sedona_render_heatmap , and ?apache.sedona::sedona_render_choropleth_map for more details on visualization-related R interfaces currently implemented by apache.sedona .","title":"R"},{"location":"tutorial/viz-r/#map-visualization-applications-in-r-language","text":"An important part of apache.sedona is its collection of R interfaces to Sedona visualization routines. For example, the following is essentially the R equivalent of this example in Scala . library ( sparklyr ) library ( apache.sedona ) sc <- spark_connect ( master = \"local\" ) resolution_x <- 1000 resolution_y <- 600 boundary <- c ( -126.790180 , -64.630926 , 24.863836 , 50.000 ) pt_rdd <- sedona_read_dsv_to_typed_rdd ( sc , location = \"arealm.csv\" , type = \"point\" ) polygon_rdd <- sedona_read_dsv_to_typed_rdd ( sc , location = \"primaryroads-polygon.csv\" , type = \"polygon\" ) pair_rdd <- sedona_spatial_join_count_by_key ( pt_rdd , polygon_rdd , join_type = \"intersect\" ) overlay <- sedona_render_scatter_plot ( polygon_rdd , resolution_x , resolution_y , output_location = tempfile ( \"scatter-plot-\" ), boundary = boundary , base_color = c ( 255 , 0 , 0 ), browse = FALSE ) sedona_render_choropleth_map ( pair_rdd , resolution_x , resolution_y , output_location = \"/tmp/choropleth-map\" , boundary = boundary , overlay = overlay , # vary the green color channel according to relative magnitudes of data points so # that the resulting map will show light blue, light purple, and light gray pixels color_of_variation = \"green\" , base_color = c ( 225 , 225 , 255 ) ) It will create a scatter plot, and then overlay it on top of a choropleth map, as shown below: See ?apache.sedona::sedona_render_scatter_plot , ?apache.sedona::sedona_render_heatmap , and ?apache.sedona::sedona_render_choropleth_map for more details on visualization-related R interfaces currently implemented by apache.sedona .","title":"Map Visualization applications in R language"},{"location":"tutorial/viz/","text":"The page outlines the steps to visualize spatial data using SedonaViz. The example code is written in Scala but also works for Java . SedonaViz provides native support for general cartographic design by extending Sedona to process large-scale spatial data. It can visulize Spatial RDD and Spatial Queries and render super high resolution image in parallel. SedonaViz offers Map Visualization SQL. This gives users a more flexible way to design beautiful map visualization effects including scatter plots and heat maps. SedonaViz RDD API is also available. Note All SedonaViz SQL/DataFrame APIs are explained in SedonaViz API . Please see Viz exmaple project Why scalable map visualization? \u00b6 Data visualization allows users to summarize, analyze and reason about data. Guaranteeing detailed and accurate geospatial map visualization (e.g., at multiple zoom levels) requires extremely high-resolution maps. Classic visualization solutions such as Google Maps, MapBox and ArcGIS suffer from limited computation resources and hence take a tremendous amount of time to generate maps for large-scale geospatial data. In big spatial data scenarios, these tools just crash or run forever. SedonaViz encapsulates the main steps of map visualization process, e.g., pixelize, aggregate, and render, into a set of massively parallelized GeoViz operators and the user can assemble any customized styles. Visualize SpatialRDD \u00b6 This tutorial mainly focuses on explaining SQL/DataFrame API. SedonaViz RDD example can be found in Please see Viz exmaple project Set up dependencies \u00b6 Read Sedona Maven Central coordinates Add Apache Spark core , Apache SparkSQL , Sedona-core, Sedona-SQL, Sedona-Viz Initiate SparkSession \u00b6 Use the following code to initiate your SparkSession at the beginning: This will register SedonaViz Kryo serializer. var sparkSession = SparkSession . builder () . master ( \"local[*]\" ) // Delete this if run in cluster mode . appName ( \"Sedona Viz\" ) // Change this to a proper name // Enable Sedona custom Kryo serializer . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) // org.apache.spark.serializer.KryoSerializer . config ( \"spark.kryo.registrator\" , classOf [ SedonaVizKryoRegistrator ]. getName ) // org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator . getOrCreate () Register SedonaSQL and SedonaViz \u00b6 Add the following line after your SparkSession declaration SedonaSQLRegistrator . registerAll ( sparkSession ) SedonaVizRegistrator . registerAll ( sparkSession ) This will register all User Defined Tyeps, functions and optimizations in SedonaSQL and SedonaViz. You can also register everything by passing --conf spark.sql.extensions=org.apache.sedona.viz.sql.SedonaVizExtensions,org.apache.sedona.sql.SedonaSqlExtensions to spark-submit or spark-shell . Create Spatial DataFrame \u00b6 There is a DataFrame as follows: +----------+---------+ | _c0| _c1| +----------+---------+ |-88.331492|32.324142| |-88.175933|32.360763| |-88.388954|32.357073| |-88.221102| 32.35078| You first need to create a Geometry type column. CREATE OR REPLACE TEMP VIEW pointtable AS SELECT ST_Point ( cast ( pointtable . _c0 as Decimal ( 24 , 20 )), cast ( pointtable . _c1 as Decimal ( 24 , 20 ))) as shape FROM pointtable As you know, Sedona provides many different methods to load various spatial data formats. Please read Write an Spatial DataFrame application . Generate a single image \u00b6 In most cases, you just want to see a single image out of your spatial dataset. Pixelize spatial objects \u00b6 To put spatial objects on a map image, you first need to convert them to pixels. First, compute the spatial boundary of this column. CREATE OR REPLACE TEMP VIEW boundtable AS SELECT ST_Envelope_Aggr ( shape ) as bound FROM pointtable Then use ST_Pixelize to convert them to pixels. This example is for Sedona before v1.0.1. ST_Pixelize extends Generator so it can directly flatten the array without the explode function. CREATE OR REPLACE TEMP VIEW pixels AS SELECT pixel , shape FROM pointtable LATERAL VIEW ST_Pixelize ( ST_Transform ( shape , 'epsg:4326' , 'epsg:3857' ), 256 , 256 , ( SELECT ST_Transform ( bound , 'epsg:4326' , 'epsg:3857' ) FROM boundtable )) AS pixel This example is for Sedona on and after v1.0.1. ST_Pixelize returns an array of pixels. You need to use explode to flatten it. CREATE OR REPLACE TEMP VIEW pixels AS SELECT pixel , shape FROM pointtable LATERAL VIEW explode ( ST_Pixelize ( ST_Transform ( shape , 'epsg:4326' , 'epsg:3857' ), 256 , 256 , ( SELECT ST_Transform ( bound , 'epsg:4326' , 'epsg:3857' ) FROM boundtable ))) AS pixel This will give you a 256*256 resolution image after you run ST_Render at the end of this tutorial. Warning We highly suggest that you should use ST_Transform to transfrom coordiantes to a visualization-specific coordinate sysmte such as epsg:3857. Otherwise you map may look distorted. Aggregate pixels \u00b6 Many objects may be pixelized to the same pixel locations. You now need to aggregate them based on either their spatial aggregation or spatial observations such as temperature or humidity. CREATE OR REPLACE TEMP VIEW pixelaggregates AS SELECT pixel , count ( * ) as weight FROM pixels GROUP BY pixel The weight indicates the degree of spatial aggregation or spatial observations. Later on, it will determine the color of this pixel. Colorize pixels \u00b6 Run the following command to assign colors for pixels based on their weights. CREATE OR REPLACE TEMP VIEW pixelaggregates AS SELECT pixel , ST_Colorize ( weight , ( SELECT max ( weight ) FROM pixelaggregates )) as color FROM pixelaggregates Please read ST_Colorize for a detailed API description. Render the image \u00b6 Use ST_Render to plot all pixels on a single image. CREATE OR REPLACE TEMP VIEW images AS SELECT ST_Render ( pixel , color ) AS image , ( SELECT ST_AsText ( bound ) FROM boundtable ) AS boundary FROM pixelaggregates This DataFrame will contain a Image type column which has only one image. Store the image on disk \u00b6 Fetch the image from the previous DataFrame var image = sparkSession.table(\"images\").take(1)(0)(0).asInstanceOf[ImageSerializableWrapper].getImage Use Sedona Viz ImageGenerator to store this image on disk. var imageGenerator = new ImageGenerator imageGenerator . SaveRasterImageAsLocalFile ( image , System . getProperty ( \"user.dir\" ) + \"/target/points\" , ImageType . PNG ) Generate map tiles \u00b6 If you are a map professional, you may need to generate map tiles for different zoom levels and eventually create the map tile layer. Pixelization and pixel aggregation \u00b6 Please first do pixelization and pixel aggregation using the same commands in single image generation. In ST_Pixelize, you need specify a very high resolution, such as 1000*1000. Note that, each dimension should be divisible by 2^zoom-level Create tile name \u00b6 Run the following command to compute the tile name for every pixels CREATE OR REPLACE TEMP VIEW pixelaggregates AS SELECT pixel , weight , ST_TileName ( pixel , 3 ) AS pid FROM pixelaggregates \"3\" is the zoom level for these map tiles. Colorize pixels \u00b6 Use the same command explained in single image generation to assign colors. Render map tiles \u00b6 You now need to group pixels by tiles and then render map tile images in parallel. CREATE OR REPLACE TEMP VIEW images AS SELECT ST_Render ( pixel , color , 3 ) AS image FROM pixelaggregates GROUP BY pid \"3\" is the zoom level for these map tiles. Store map tiles on disk \u00b6 You can use the same commands in single image generation to fetch all map tiles and store them one by one.","title":"Scala/Java"},{"location":"tutorial/viz/#why-scalable-map-visualization","text":"Data visualization allows users to summarize, analyze and reason about data. Guaranteeing detailed and accurate geospatial map visualization (e.g., at multiple zoom levels) requires extremely high-resolution maps. Classic visualization solutions such as Google Maps, MapBox and ArcGIS suffer from limited computation resources and hence take a tremendous amount of time to generate maps for large-scale geospatial data. In big spatial data scenarios, these tools just crash or run forever. SedonaViz encapsulates the main steps of map visualization process, e.g., pixelize, aggregate, and render, into a set of massively parallelized GeoViz operators and the user can assemble any customized styles.","title":"Why scalable map visualization?"},{"location":"tutorial/viz/#visualize-spatialrdd","text":"This tutorial mainly focuses on explaining SQL/DataFrame API. SedonaViz RDD example can be found in Please see Viz exmaple project","title":"Visualize SpatialRDD"},{"location":"tutorial/viz/#set-up-dependencies","text":"Read Sedona Maven Central coordinates Add Apache Spark core , Apache SparkSQL , Sedona-core, Sedona-SQL, Sedona-Viz","title":"Set up dependencies"},{"location":"tutorial/viz/#initiate-sparksession","text":"Use the following code to initiate your SparkSession at the beginning: This will register SedonaViz Kryo serializer. var sparkSession = SparkSession . builder () . master ( \"local[*]\" ) // Delete this if run in cluster mode . appName ( \"Sedona Viz\" ) // Change this to a proper name // Enable Sedona custom Kryo serializer . config ( \"spark.serializer\" , classOf [ KryoSerializer ]. getName ) // org.apache.spark.serializer.KryoSerializer . config ( \"spark.kryo.registrator\" , classOf [ SedonaVizKryoRegistrator ]. getName ) // org.apache.sedona.viz.core.Serde.SedonaVizKryoRegistrator . getOrCreate ()","title":"Initiate SparkSession"},{"location":"tutorial/viz/#register-sedonasql-and-sedonaviz","text":"Add the following line after your SparkSession declaration SedonaSQLRegistrator . registerAll ( sparkSession ) SedonaVizRegistrator . registerAll ( sparkSession ) This will register all User Defined Tyeps, functions and optimizations in SedonaSQL and SedonaViz. You can also register everything by passing --conf spark.sql.extensions=org.apache.sedona.viz.sql.SedonaVizExtensions,org.apache.sedona.sql.SedonaSqlExtensions to spark-submit or spark-shell .","title":"Register SedonaSQL and SedonaViz"},{"location":"tutorial/viz/#create-spatial-dataframe","text":"There is a DataFrame as follows: +----------+---------+ | _c0| _c1| +----------+---------+ |-88.331492|32.324142| |-88.175933|32.360763| |-88.388954|32.357073| |-88.221102| 32.35078| You first need to create a Geometry type column. CREATE OR REPLACE TEMP VIEW pointtable AS SELECT ST_Point ( cast ( pointtable . _c0 as Decimal ( 24 , 20 )), cast ( pointtable . _c1 as Decimal ( 24 , 20 ))) as shape FROM pointtable As you know, Sedona provides many different methods to load various spatial data formats. Please read Write an Spatial DataFrame application .","title":"Create Spatial DataFrame"},{"location":"tutorial/viz/#generate-a-single-image","text":"In most cases, you just want to see a single image out of your spatial dataset.","title":"Generate a single image"},{"location":"tutorial/viz/#pixelize-spatial-objects","text":"To put spatial objects on a map image, you first need to convert them to pixels. First, compute the spatial boundary of this column. CREATE OR REPLACE TEMP VIEW boundtable AS SELECT ST_Envelope_Aggr ( shape ) as bound FROM pointtable Then use ST_Pixelize to convert them to pixels. This example is for Sedona before v1.0.1. ST_Pixelize extends Generator so it can directly flatten the array without the explode function. CREATE OR REPLACE TEMP VIEW pixels AS SELECT pixel , shape FROM pointtable LATERAL VIEW ST_Pixelize ( ST_Transform ( shape , 'epsg:4326' , 'epsg:3857' ), 256 , 256 , ( SELECT ST_Transform ( bound , 'epsg:4326' , 'epsg:3857' ) FROM boundtable )) AS pixel This example is for Sedona on and after v1.0.1. ST_Pixelize returns an array of pixels. You need to use explode to flatten it. CREATE OR REPLACE TEMP VIEW pixels AS SELECT pixel , shape FROM pointtable LATERAL VIEW explode ( ST_Pixelize ( ST_Transform ( shape , 'epsg:4326' , 'epsg:3857' ), 256 , 256 , ( SELECT ST_Transform ( bound , 'epsg:4326' , 'epsg:3857' ) FROM boundtable ))) AS pixel This will give you a 256*256 resolution image after you run ST_Render at the end of this tutorial. Warning We highly suggest that you should use ST_Transform to transfrom coordiantes to a visualization-specific coordinate sysmte such as epsg:3857. Otherwise you map may look distorted.","title":"Pixelize spatial objects"},{"location":"tutorial/viz/#aggregate-pixels","text":"Many objects may be pixelized to the same pixel locations. You now need to aggregate them based on either their spatial aggregation or spatial observations such as temperature or humidity. CREATE OR REPLACE TEMP VIEW pixelaggregates AS SELECT pixel , count ( * ) as weight FROM pixels GROUP BY pixel The weight indicates the degree of spatial aggregation or spatial observations. Later on, it will determine the color of this pixel.","title":"Aggregate pixels"},{"location":"tutorial/viz/#colorize-pixels","text":"Run the following command to assign colors for pixels based on their weights. CREATE OR REPLACE TEMP VIEW pixelaggregates AS SELECT pixel , ST_Colorize ( weight , ( SELECT max ( weight ) FROM pixelaggregates )) as color FROM pixelaggregates Please read ST_Colorize for a detailed API description.","title":"Colorize pixels"},{"location":"tutorial/viz/#render-the-image","text":"Use ST_Render to plot all pixels on a single image. CREATE OR REPLACE TEMP VIEW images AS SELECT ST_Render ( pixel , color ) AS image , ( SELECT ST_AsText ( bound ) FROM boundtable ) AS boundary FROM pixelaggregates This DataFrame will contain a Image type column which has only one image.","title":"Render the image"},{"location":"tutorial/viz/#store-the-image-on-disk","text":"Fetch the image from the previous DataFrame var image = sparkSession.table(\"images\").take(1)(0)(0).asInstanceOf[ImageSerializableWrapper].getImage Use Sedona Viz ImageGenerator to store this image on disk. var imageGenerator = new ImageGenerator imageGenerator . SaveRasterImageAsLocalFile ( image , System . getProperty ( \"user.dir\" ) + \"/target/points\" , ImageType . PNG )","title":"Store the image on disk"},{"location":"tutorial/viz/#generate-map-tiles","text":"If you are a map professional, you may need to generate map tiles for different zoom levels and eventually create the map tile layer.","title":"Generate map tiles"},{"location":"tutorial/viz/#pixelization-and-pixel-aggregation","text":"Please first do pixelization and pixel aggregation using the same commands in single image generation. In ST_Pixelize, you need specify a very high resolution, such as 1000*1000. Note that, each dimension should be divisible by 2^zoom-level","title":"Pixelization and pixel aggregation"},{"location":"tutorial/viz/#create-tile-name","text":"Run the following command to compute the tile name for every pixels CREATE OR REPLACE TEMP VIEW pixelaggregates AS SELECT pixel , weight , ST_TileName ( pixel , 3 ) AS pid FROM pixelaggregates \"3\" is the zoom level for these map tiles.","title":"Create tile name"},{"location":"tutorial/viz/#colorize-pixels_1","text":"Use the same command explained in single image generation to assign colors.","title":"Colorize pixels"},{"location":"tutorial/viz/#render-map-tiles","text":"You now need to group pixels by tiles and then render map tile images in parallel. CREATE OR REPLACE TEMP VIEW images AS SELECT ST_Render ( pixel , color , 3 ) AS image FROM pixelaggregates GROUP BY pid \"3\" is the zoom level for these map tiles.","title":"Render map tiles"},{"location":"tutorial/viz/#store-map-tiles-on-disk","text":"You can use the same commands in single image generation to fetch all map tiles and store them one by one.","title":"Store map tiles on disk"},{"location":"tutorial/zeppelin/","text":"Sedona provides a Helium visualization plugin tailored for Apache Zeppelin . This finally bridges the gap between Sedona and Zeppelin. Please read Install Sedona-Zeppelin to learn how to install this plugin in Zeppelin. Sedona-Zeppelin equips two approaches to visualize spatial data in Zeppelin. The first approach uses Zeppelin to plot all spatial objects on the map. The second one leverages SedonaViz to generate map images and overlay them on maps. Small-scale without SedonaViz \u00b6 Danger Zeppelin is just a front-end visualization framework. This approach is not scalable and will fail at large-scale geospatial data. Please scroll down to read SedonaViz solution. You can use Apache Zeppelin to plot a small number of spatial objects, such as 1000 points. Assume you already have a Spatial DataFrame, you need to convert the geometry column to WKT string column use the following command in your Zeppelin Spark notebook Scala paragraph: spark . sql ( \"\"\" |CREATE OR REPLACE TEMP VIEW wktpoint AS |SELECT ST_AsText(shape) as geom |FROM pointtable \"\"\" . stripMargin ) Then create an SQL paragraph to fetch the data % sql SELECT * FROM wktpoint Select the geometry column to visualize: Large-scale with SedonaViz \u00b6 SedonaViz is a distributed visualization system that allows you to visualize big spatial data at scale. Please read How to use SedonaViz . You can use Sedona-Zeppelin to ask Zeppelin to overlay SedonaViz images on a map background. This way, you can easily visualize 1 billion spatial objects or more (depends on your cluster size). First, encode images of SedonaViz DataFrame in Zeppelin Spark notebook Scala paragraph, spark.sql( \"\"\" |CREATE OR REPLACE TEMP VIEW images AS |SELECT ST_EncodeImage(image) AS image, (SELECT ST_AsText(bound) FROM boundtable) AS boundary |FROM images \"\"\".stripMargin) Then create an SQL paragraph to fetch the data % sql SELECT * , 'I am the map center!' FROM images Select the image and its geospatial boundary: Zeppelin Spark notebook demo \u00b6 We provide a full Zeppelin Spark notebook which demonstrates al functions. Please download Sedona-Zeppelin notebook template and test data - arealm.csv . You need to use Zeppelin to import this notebook JSON file and modify the input data path in the notebook.","title":"Use Apache Zeppelin"},{"location":"tutorial/zeppelin/#small-scale-without-sedonaviz","text":"Danger Zeppelin is just a front-end visualization framework. This approach is not scalable and will fail at large-scale geospatial data. Please scroll down to read SedonaViz solution. You can use Apache Zeppelin to plot a small number of spatial objects, such as 1000 points. Assume you already have a Spatial DataFrame, you need to convert the geometry column to WKT string column use the following command in your Zeppelin Spark notebook Scala paragraph: spark . sql ( \"\"\" |CREATE OR REPLACE TEMP VIEW wktpoint AS |SELECT ST_AsText(shape) as geom |FROM pointtable \"\"\" . stripMargin ) Then create an SQL paragraph to fetch the data % sql SELECT * FROM wktpoint Select the geometry column to visualize:","title":"Small-scale without SedonaViz"},{"location":"tutorial/zeppelin/#large-scale-with-sedonaviz","text":"SedonaViz is a distributed visualization system that allows you to visualize big spatial data at scale. Please read How to use SedonaViz . You can use Sedona-Zeppelin to ask Zeppelin to overlay SedonaViz images on a map background. This way, you can easily visualize 1 billion spatial objects or more (depends on your cluster size). First, encode images of SedonaViz DataFrame in Zeppelin Spark notebook Scala paragraph, spark.sql( \"\"\" |CREATE OR REPLACE TEMP VIEW images AS |SELECT ST_EncodeImage(image) AS image, (SELECT ST_AsText(bound) FROM boundtable) AS boundary |FROM images \"\"\".stripMargin) Then create an SQL paragraph to fetch the data % sql SELECT * , 'I am the map center!' FROM images Select the image and its geospatial boundary:","title":"Large-scale with SedonaViz"},{"location":"tutorial/zeppelin/#zeppelin-spark-notebook-demo","text":"We provide a full Zeppelin Spark notebook which demonstrates al functions. Please download Sedona-Zeppelin notebook template and test data - arealm.csv . You need to use Zeppelin to import this notebook JSON file and modify the input data path in the notebook.","title":"Zeppelin Spark notebook demo"},{"location":"tutorial/flink/sql/","text":"The page outlines the steps to manage spatial data using SedonaSQL. The example code is written in Java but also works for Scala . SedonaSQL supports SQL/MM Part3 Spatial SQL Standard. It includes four kinds of SQL operators as follows. All these operators can be directly called through: Table myTable = tableEnv . sqlQuery ( \"YOUR_SQL\" ) Detailed SedonaSQL APIs are available here: SedonaSQL API Set up dependencies \u00b6 Read Sedona Maven Central coordinates Add Sedona dependencies in build.sbt or pom.xml. Add Flink dependencies in build.sbt or pom.xml. Initiate Stream Environment \u00b6 Use the following code to initiate your StreamExecutionEnvironment at the beginning: StreamExecutionEnvironment env = StreamExecutionEnvironment . getExecutionEnvironment () EnvironmentSettings settings = EnvironmentSettings . newInstance (). inStreamingMode (). build (); StreamTableEnvironment tableEnv = StreamTableEnvironment . create ( env , settings ); Register SedonaSQL \u00b6 Add the following line after your StreamExecutionEnvironment and StreamTableEnvironment declaration SedonaFlinkRegistrator . registerType ( env ); SedonaFlinkRegistrator . registerFunc ( tableEnv ); Warning Sedona has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. This function will register Sedona User Defined Type and User Defined Function Create a Geometry type column \u00b6 All geometrical operations in SedonaSQL are on Geometry type objects. Therefore, before any kind of queries, you need to create a Geometry type column on a DataFrame. Assume you have a Flink Table tbl like this: +----+--------------------------------+--------------------------------+ | op | geom_polygon | name_polygon | +----+--------------------------------+--------------------------------+ | +I | POLYGON ((-0.5 -0.5, -0.5 0... | polygon0 | | +I | POLYGON ((0.5 0.5, 0.5 1.5,... | polygon1 | | +I | POLYGON ((1.5 1.5, 1.5 2.5,... | polygon2 | | +I | POLYGON ((2.5 2.5, 2.5 3.5,... | polygon3 | | +I | POLYGON ((3.5 3.5, 3.5 4.5,... | polygon4 | | +I | POLYGON ((4.5 4.5, 4.5 5.5,... | polygon5 | | +I | POLYGON ((5.5 5.5, 5.5 6.5,... | polygon6 | | +I | POLYGON ((6.5 6.5, 6.5 7.5,... | polygon7 | | +I | POLYGON ((7.5 7.5, 7.5 8.5,... | polygon8 | | +I | POLYGON ((8.5 8.5, 8.5 9.5,... | polygon9 | +----+--------------------------------+--------------------------------+ 10 rows in set You can create a Table with a Geometry type column as follows: tableEnv . createTemporaryView ( \"myTable\" , tbl ) Table geomTbl = tableEnv . sql ( \"SELECT ST_GeomFromWKT(geom_polygon) as geom_polygon, name_polygon FROM myTable\" ) geomTbl . execute (). print () The output will be: +----+--------------------------------+--------------------------------+ | op | geom_polygon | name_polygon | +----+--------------------------------+--------------------------------+ | +I | POLYGON ((-0.5 -0.5, -0.5 0... | polygon0 | | +I | POLYGON ((0.5 0.5, 0.5 1.5,... | polygon1 | | +I | POLYGON ((1.5 1.5, 1.5 2.5,... | polygon2 | | +I | POLYGON ((2.5 2.5, 2.5 3.5,... | polygon3 | | +I | POLYGON ((3.5 3.5, 3.5 4.5,... | polygon4 | | +I | POLYGON ((4.5 4.5, 4.5 5.5,... | polygon5 | | +I | POLYGON ((5.5 5.5, 5.5 6.5,... | polygon6 | | +I | POLYGON ((6.5 6.5, 6.5 7.5,... | polygon7 | | +I | POLYGON ((7.5 7.5, 7.5 8.5,... | polygon8 | | +I | POLYGON ((8.5 8.5, 8.5 9.5,... | polygon9 | +----+--------------------------------+--------------------------------+ 10 rows in set Although it looks same with the input, actually the type of column geom_polygon has been changed to Geometry type. To verify this, use the following code to print the schema of the DataFrame: geomTbl . printSchema () The output will be like this: ( `geom_polygon` RAW('org.locationtech.jts.geom.Geometry', '...'), `name_polygon` STRING ) Note SedonaSQL provides lots of functions to create a Geometry column, please read SedonaSQL constructor API . Transform the Coordinate Reference System \u00b6 Sedona doesn't control the coordinate unit (degree-based or meter-based) of all geometries in a Geometry column. The unit of all related distances in SedonaSQL is same as the unit of all geometries in a Geometry column. To convert Coordinate Reference System of the Geometry column created before, use the following code: Table geomTbl3857 = tableEnv . sqlQuery ( \"SELECT ST_Transform(countyshape, \" epsg : 4326 \", \" epsg : 3857 \") AS geom_polygon, name_polygon FROM myTable\" ) geomTbl3857 . execute (). print () The first EPSG code EPSG:4326 in ST_Transform is the source CRS of the geometries. It is WGS84, the most common degree-based CRS. The second EPSG code EPSG:3857 in ST_Transform is the target CRS of the geometries. It is the most common meter-based CRS. This ST_Transform transform the CRS of these geomtries from EPSG:4326 to EPSG:3857. The details CRS information can be found on EPSG.io Note Read SedonaSQL ST_Transform API to learn different spatial query predicates. For example, a Table that has coordinates in the US will become like this. Before the transformation: +----+--------------------------------+--------------------------------+ | op | geom_point | name_point | +----+--------------------------------+--------------------------------+ | +I | POINT (32 -118) | point | | +I | POINT (33 -117) | point | | +I | POINT (34 -116) | point | | +I | POINT (35 -115) | point | | +I | POINT (36 -114) | point | | +I | POINT (37 -113) | point | | +I | POINT (38 -112) | point | | +I | POINT (39 -111) | point | | +I | POINT (40 -110) | point | | +I | POINT (41 -109) | point | +----+--------------------------------+--------------------------------+ After the transformation: +----+--------------------------------+--------------------------------+ | op | _c0 | name_point | +----+--------------------------------+--------------------------------+ | +I | POINT (-13135699.91360628 3... | point | | +I | POINT (-13024380.422813008 ... | point | | +I | POINT (-12913060.932019735 ... | point | | +I | POINT (-12801741.44122646 4... | point | | +I | POINT (-12690421.950433187 ... | point | | +I | POINT (-12579102.459639912 ... | point | | +I | POINT (-12467782.96884664 4... | point | | +I | POINT (-12356463.478053367 ... | point | | +I | POINT (-12245143.987260092 ... | point | | +I | POINT (-12133824.496466817 ... | point | +----+--------------------------------+--------------------------------+ Run spatial queries \u00b6 After creating a Geometry type column, you are able to run spatial queries. Range query \u00b6 Use ST_Contains , ST_Intersects and so on to run a range query over a single column. The following example finds all counties that are within the given polygon: geomTable = tableEnv . sqlQuery ( \" SELECT * FROM spatialdf WHERE ST_Contains (ST_PolygonFromEnvelope(1.0,100.0,1000.0,1100.0), newcountyshape) \" ) geomTable . execute (). print () Note Read SedonaSQL Predicate API to learn different spatial query predicates. KNN query \u00b6 Use ST_Distance to calculate the distance and rank the distance. The following code returns the 5 nearest neighbor of the given polygon. geomTable = tableEnv . sqlQuery ( \" SELECT countyname, ST_Distance(ST_PolygonFromEnvelope(1.0,100.0,1000.0,1100.0), newcountyshape) AS distance FROM geomTable ORDER BY distance DESC LIMIT 5 \" ) geomTable . execute (). print () Convert Spatial Table to Spatial DataStream \u00b6 Get DataStream \u00b6 Use TableEnv's toDataStream function DataStream < Row > geomStream = tableEnv . toDataStream ( geomTable ) Retrieve Geometries \u00b6 Then get the Geometry from each Row object using Map import org.locationtech.jts.geom.Geometry ; DataStream < Geometry > geometries = geomStream . map ( new MapFunction < Row , Geometry > () { @Override public Geometry map ( Row value ) throws Exception { return ( Geometry ) value . getField ( 0 ); } }); geometries . print (); The output will be 14> POLYGON ((1.5 1.5, 1.5 2.5, 2.5 2.5, 2.5 1.5, 1.5 1.5)) 2> POLYGON ((5.5 5.5, 5.5 6.5, 6.5 6.5, 6.5 5.5, 5.5 5.5)) 5> POLYGON ((8.5 8.5, 8.5 9.5, 9.5 9.5, 9.5 8.5, 8.5 8.5)) 16> POLYGON ((3.5 3.5, 3.5 4.5, 4.5 4.5, 4.5 3.5, 3.5 3.5)) 12> POLYGON ((-0.5 -0.5, -0.5 0.5, 0.5 0.5, 0.5 -0.5, -0.5 -0.5)) 13> POLYGON ((0.5 0.5, 0.5 1.5, 1.5 1.5, 1.5 0.5, 0.5 0.5)) 15> POLYGON ((2.5 2.5, 2.5 3.5, 3.5 3.5, 3.5 2.5, 2.5 2.5)) 3> POLYGON ((6.5 6.5, 6.5 7.5, 7.5 7.5, 7.5 6.5, 6.5 6.5)) 1> POLYGON ((4.5 4.5, 4.5 5.5, 5.5 5.5, 5.5 4.5, 4.5 4.5)) 4> POLYGON ((7.5 7.5, 7.5 8.5, 8.5 8.5, 8.5 7.5, 7.5 7.5)) Store non-spatial attributes in Geometries \u00b6 You can concatenate other non-spatial attributes and store them in Geometry's userData field so you can recover them later on. userData field can be any object type. import org.locationtech.jts.geom.Geometry ; DataStream < Geometry > geometries = geomStream . map ( new MapFunction < Row , Geometry > () { @Override public Geometry map ( Row value ) throws Exception { Geometry geom = ( Geometry ) value . getField ( 0 ); geom . setUserData ( value . getField ( 1 )); return geom ; } }); geometries . print (); The print command will not print out userData field. But you can get it this way: import org.locationtech.jts.geom.Geometry ; geometries . map ( new MapFunction < Geometry , String > () { @Override public String map ( Geometry value ) throws Exception { return ( String ) value . getUserData (); } }). print (); The output will be 13> polygon9 6> polygon2 10> polygon6 11> polygon7 5> polygon1 12> polygon8 8> polygon4 4> polygon0 7> polygon3 9> polygon5 Convert Spatial DataStream to Spatial Table \u00b6 Create Geometries using Sedona FormatUtils \u00b6 Create a Geometry from a WKT string import org.apache.sedona.core.formatMapper.FormatUtils ; import org.locationtech.jts.geom.Geometry ; DataStream < Geometry > geometries = text . map ( new MapFunction < String , Geometry > () { @Override public Geometry map ( String value ) throws Exception { FormatUtils formatUtils = new FormatUtils ( FileDataSplitter . WKT , false ); return formatUtils . readGeometry ( value ); } }) Create a Point from a String 1.1, 2.2 . Use , as the delimiter. import org.apache.sedona.core.formatMapper.FormatUtils ; import org.locationtech.jts.geom.Geometry ; DataStream < Geometry > geometries = text . map ( new MapFunction < String , Geometry > () { @Override public Geometry map ( String value ) throws Exception { FormatUtils < Geometry > formatUtils = new FormatUtils ( \",\" , false , GeometryType . POINT ); return formatUtils . readGeometry ( value ); } }) Create a Polygon from a String 1.1, 1.1, 10.1, 10.1 . This is a rectangle with (1.1, 1.1) and (10.1, 10.1) as their min/max corners. import org.apache.sedona.core.formatMapper.FormatUtils ; import org.locationtech.jts.geom.GeometryFactory ; import org.locationtech.jts.geom.Geometry ; DataStream < Geometry > geometries = text . map ( new MapFunction < String , Geometry > () { @Override public Geometry map ( String value ) throws Exception { // Write some code to get four double type values: minX, minY, maxX, maxY ... Coordinate [] coordinates = new Coordinate [ 5 ] ; coordinates [ 0 ] = new Coordinate ( minX , minY ); coordinates [ 1 ] = new Coordinate ( minX , maxY ); coordinates [ 2 ] = new Coordinate ( maxX , maxY ); coordinates [ 3 ] = new Coordinate ( maxX , minY ); coordinates [ 4 ] = coordinates [ 0 ] ; GeometryFactory geometryFactory = new GeometryFactory (); return geometryFactory . createPolygon ( coordinates ); } }) Create Row objects \u00b6 Put a geometry in a Flink Row to a geomStream . Note that you can put other attributes in Row as well. This example uses a constant value myName for all geometries. import org.apache.sedona.core.formatMapper.FormatUtils ; import org.locationtech.jts.geom.Geometry ; import org.apache.flink.types.Row ; DataStream < Row > geomStream = text . map ( new MapFunction < String , Row > () { @Override public Row map ( String value ) throws Exception { FormatUtils formatUtils = new FormatUtils ( FileDataSplitter . WKT , false ); return Row . of ( formatUtils . readGeometry ( value ), \"myName\" ); } }) Get Spatial Table \u00b6 Use TableEnv's fromDataStream function, with two column names geom and geom_name . Table geomTable = tableEnv . fromDataStream ( geomStream , \"geom\" , \"geom_name\" )","title":"Scala/Java"},{"location":"tutorial/flink/sql/#set-up-dependencies","text":"Read Sedona Maven Central coordinates Add Sedona dependencies in build.sbt or pom.xml. Add Flink dependencies in build.sbt or pom.xml.","title":"Set up dependencies"},{"location":"tutorial/flink/sql/#initiate-stream-environment","text":"Use the following code to initiate your StreamExecutionEnvironment at the beginning: StreamExecutionEnvironment env = StreamExecutionEnvironment . getExecutionEnvironment () EnvironmentSettings settings = EnvironmentSettings . newInstance (). inStreamingMode (). build (); StreamTableEnvironment tableEnv = StreamTableEnvironment . create ( env , settings );","title":"Initiate Stream Environment"},{"location":"tutorial/flink/sql/#register-sedonasql","text":"Add the following line after your StreamExecutionEnvironment and StreamTableEnvironment declaration SedonaFlinkRegistrator . registerType ( env ); SedonaFlinkRegistrator . registerFunc ( tableEnv ); Warning Sedona has a suite of well-written geometry and index serializers. Forgetting to enable these serializers will lead to high memory consumption. This function will register Sedona User Defined Type and User Defined Function","title":"Register SedonaSQL"},{"location":"tutorial/flink/sql/#create-a-geometry-type-column","text":"All geometrical operations in SedonaSQL are on Geometry type objects. Therefore, before any kind of queries, you need to create a Geometry type column on a DataFrame. Assume you have a Flink Table tbl like this: +----+--------------------------------+--------------------------------+ | op | geom_polygon | name_polygon | +----+--------------------------------+--------------------------------+ | +I | POLYGON ((-0.5 -0.5, -0.5 0... | polygon0 | | +I | POLYGON ((0.5 0.5, 0.5 1.5,... | polygon1 | | +I | POLYGON ((1.5 1.5, 1.5 2.5,... | polygon2 | | +I | POLYGON ((2.5 2.5, 2.5 3.5,... | polygon3 | | +I | POLYGON ((3.5 3.5, 3.5 4.5,... | polygon4 | | +I | POLYGON ((4.5 4.5, 4.5 5.5,... | polygon5 | | +I | POLYGON ((5.5 5.5, 5.5 6.5,... | polygon6 | | +I | POLYGON ((6.5 6.5, 6.5 7.5,... | polygon7 | | +I | POLYGON ((7.5 7.5, 7.5 8.5,... | polygon8 | | +I | POLYGON ((8.5 8.5, 8.5 9.5,... | polygon9 | +----+--------------------------------+--------------------------------+ 10 rows in set You can create a Table with a Geometry type column as follows: tableEnv . createTemporaryView ( \"myTable\" , tbl ) Table geomTbl = tableEnv . sql ( \"SELECT ST_GeomFromWKT(geom_polygon) as geom_polygon, name_polygon FROM myTable\" ) geomTbl . execute (). print () The output will be: +----+--------------------------------+--------------------------------+ | op | geom_polygon | name_polygon | +----+--------------------------------+--------------------------------+ | +I | POLYGON ((-0.5 -0.5, -0.5 0... | polygon0 | | +I | POLYGON ((0.5 0.5, 0.5 1.5,... | polygon1 | | +I | POLYGON ((1.5 1.5, 1.5 2.5,... | polygon2 | | +I | POLYGON ((2.5 2.5, 2.5 3.5,... | polygon3 | | +I | POLYGON ((3.5 3.5, 3.5 4.5,... | polygon4 | | +I | POLYGON ((4.5 4.5, 4.5 5.5,... | polygon5 | | +I | POLYGON ((5.5 5.5, 5.5 6.5,... | polygon6 | | +I | POLYGON ((6.5 6.5, 6.5 7.5,... | polygon7 | | +I | POLYGON ((7.5 7.5, 7.5 8.5,... | polygon8 | | +I | POLYGON ((8.5 8.5, 8.5 9.5,... | polygon9 | +----+--------------------------------+--------------------------------+ 10 rows in set Although it looks same with the input, actually the type of column geom_polygon has been changed to Geometry type. To verify this, use the following code to print the schema of the DataFrame: geomTbl . printSchema () The output will be like this: ( `geom_polygon` RAW('org.locationtech.jts.geom.Geometry', '...'), `name_polygon` STRING ) Note SedonaSQL provides lots of functions to create a Geometry column, please read SedonaSQL constructor API .","title":"Create a Geometry type column"},{"location":"tutorial/flink/sql/#transform-the-coordinate-reference-system","text":"Sedona doesn't control the coordinate unit (degree-based or meter-based) of all geometries in a Geometry column. The unit of all related distances in SedonaSQL is same as the unit of all geometries in a Geometry column. To convert Coordinate Reference System of the Geometry column created before, use the following code: Table geomTbl3857 = tableEnv . sqlQuery ( \"SELECT ST_Transform(countyshape, \" epsg : 4326 \", \" epsg : 3857 \") AS geom_polygon, name_polygon FROM myTable\" ) geomTbl3857 . execute (). print () The first EPSG code EPSG:4326 in ST_Transform is the source CRS of the geometries. It is WGS84, the most common degree-based CRS. The second EPSG code EPSG:3857 in ST_Transform is the target CRS of the geometries. It is the most common meter-based CRS. This ST_Transform transform the CRS of these geomtries from EPSG:4326 to EPSG:3857. The details CRS information can be found on EPSG.io Note Read SedonaSQL ST_Transform API to learn different spatial query predicates. For example, a Table that has coordinates in the US will become like this. Before the transformation: +----+--------------------------------+--------------------------------+ | op | geom_point | name_point | +----+--------------------------------+--------------------------------+ | +I | POINT (32 -118) | point | | +I | POINT (33 -117) | point | | +I | POINT (34 -116) | point | | +I | POINT (35 -115) | point | | +I | POINT (36 -114) | point | | +I | POINT (37 -113) | point | | +I | POINT (38 -112) | point | | +I | POINT (39 -111) | point | | +I | POINT (40 -110) | point | | +I | POINT (41 -109) | point | +----+--------------------------------+--------------------------------+ After the transformation: +----+--------------------------------+--------------------------------+ | op | _c0 | name_point | +----+--------------------------------+--------------------------------+ | +I | POINT (-13135699.91360628 3... | point | | +I | POINT (-13024380.422813008 ... | point | | +I | POINT (-12913060.932019735 ... | point | | +I | POINT (-12801741.44122646 4... | point | | +I | POINT (-12690421.950433187 ... | point | | +I | POINT (-12579102.459639912 ... | point | | +I | POINT (-12467782.96884664 4... | point | | +I | POINT (-12356463.478053367 ... | point | | +I | POINT (-12245143.987260092 ... | point | | +I | POINT (-12133824.496466817 ... | point | +----+--------------------------------+--------------------------------+","title":"Transform the Coordinate Reference System"},{"location":"tutorial/flink/sql/#run-spatial-queries","text":"After creating a Geometry type column, you are able to run spatial queries.","title":"Run spatial queries"},{"location":"tutorial/flink/sql/#range-query","text":"Use ST_Contains , ST_Intersects and so on to run a range query over a single column. The following example finds all counties that are within the given polygon: geomTable = tableEnv . sqlQuery ( \" SELECT * FROM spatialdf WHERE ST_Contains (ST_PolygonFromEnvelope(1.0,100.0,1000.0,1100.0), newcountyshape) \" ) geomTable . execute (). print () Note Read SedonaSQL Predicate API to learn different spatial query predicates.","title":"Range query"},{"location":"tutorial/flink/sql/#knn-query","text":"Use ST_Distance to calculate the distance and rank the distance. The following code returns the 5 nearest neighbor of the given polygon. geomTable = tableEnv . sqlQuery ( \" SELECT countyname, ST_Distance(ST_PolygonFromEnvelope(1.0,100.0,1000.0,1100.0), newcountyshape) AS distance FROM geomTable ORDER BY distance DESC LIMIT 5 \" ) geomTable . execute (). print ()","title":"KNN query"},{"location":"tutorial/flink/sql/#convert-spatial-table-to-spatial-datastream","text":"","title":"Convert Spatial Table to Spatial DataStream"},{"location":"tutorial/flink/sql/#get-datastream","text":"Use TableEnv's toDataStream function DataStream < Row > geomStream = tableEnv . toDataStream ( geomTable )","title":"Get DataStream"},{"location":"tutorial/flink/sql/#retrieve-geometries","text":"Then get the Geometry from each Row object using Map import org.locationtech.jts.geom.Geometry ; DataStream < Geometry > geometries = geomStream . map ( new MapFunction < Row , Geometry > () { @Override public Geometry map ( Row value ) throws Exception { return ( Geometry ) value . getField ( 0 ); } }); geometries . print (); The output will be 14> POLYGON ((1.5 1.5, 1.5 2.5, 2.5 2.5, 2.5 1.5, 1.5 1.5)) 2> POLYGON ((5.5 5.5, 5.5 6.5, 6.5 6.5, 6.5 5.5, 5.5 5.5)) 5> POLYGON ((8.5 8.5, 8.5 9.5, 9.5 9.5, 9.5 8.5, 8.5 8.5)) 16> POLYGON ((3.5 3.5, 3.5 4.5, 4.5 4.5, 4.5 3.5, 3.5 3.5)) 12> POLYGON ((-0.5 -0.5, -0.5 0.5, 0.5 0.5, 0.5 -0.5, -0.5 -0.5)) 13> POLYGON ((0.5 0.5, 0.5 1.5, 1.5 1.5, 1.5 0.5, 0.5 0.5)) 15> POLYGON ((2.5 2.5, 2.5 3.5, 3.5 3.5, 3.5 2.5, 2.5 2.5)) 3> POLYGON ((6.5 6.5, 6.5 7.5, 7.5 7.5, 7.5 6.5, 6.5 6.5)) 1> POLYGON ((4.5 4.5, 4.5 5.5, 5.5 5.5, 5.5 4.5, 4.5 4.5)) 4> POLYGON ((7.5 7.5, 7.5 8.5, 8.5 8.5, 8.5 7.5, 7.5 7.5))","title":"Retrieve Geometries"},{"location":"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries","text":"You can concatenate other non-spatial attributes and store them in Geometry's userData field so you can recover them later on. userData field can be any object type. import org.locationtech.jts.geom.Geometry ; DataStream < Geometry > geometries = geomStream . map ( new MapFunction < Row , Geometry > () { @Override public Geometry map ( Row value ) throws Exception { Geometry geom = ( Geometry ) value . getField ( 0 ); geom . setUserData ( value . getField ( 1 )); return geom ; } }); geometries . print (); The print command will not print out userData field. But you can get it this way: import org.locationtech.jts.geom.Geometry ; geometries . map ( new MapFunction < Geometry , String > () { @Override public String map ( Geometry value ) throws Exception { return ( String ) value . getUserData (); } }). print (); The output will be 13> polygon9 6> polygon2 10> polygon6 11> polygon7 5> polygon1 12> polygon8 8> polygon4 4> polygon0 7> polygon3 9> polygon5","title":"Store non-spatial attributes in Geometries"},{"location":"tutorial/flink/sql/#convert-spatial-datastream-to-spatial-table","text":"","title":"Convert Spatial DataStream to Spatial Table"},{"location":"tutorial/flink/sql/#create-geometries-using-sedona-formatutils","text":"Create a Geometry from a WKT string import org.apache.sedona.core.formatMapper.FormatUtils ; import org.locationtech.jts.geom.Geometry ; DataStream < Geometry > geometries = text . map ( new MapFunction < String , Geometry > () { @Override public Geometry map ( String value ) throws Exception { FormatUtils formatUtils = new FormatUtils ( FileDataSplitter . WKT , false ); return formatUtils . readGeometry ( value ); } }) Create a Point from a String 1.1, 2.2 . Use , as the delimiter. import org.apache.sedona.core.formatMapper.FormatUtils ; import org.locationtech.jts.geom.Geometry ; DataStream < Geometry > geometries = text . map ( new MapFunction < String , Geometry > () { @Override public Geometry map ( String value ) throws Exception { FormatUtils < Geometry > formatUtils = new FormatUtils ( \",\" , false , GeometryType . POINT ); return formatUtils . readGeometry ( value ); } }) Create a Polygon from a String 1.1, 1.1, 10.1, 10.1 . This is a rectangle with (1.1, 1.1) and (10.1, 10.1) as their min/max corners. import org.apache.sedona.core.formatMapper.FormatUtils ; import org.locationtech.jts.geom.GeometryFactory ; import org.locationtech.jts.geom.Geometry ; DataStream < Geometry > geometries = text . map ( new MapFunction < String , Geometry > () { @Override public Geometry map ( String value ) throws Exception { // Write some code to get four double type values: minX, minY, maxX, maxY ... Coordinate [] coordinates = new Coordinate [ 5 ] ; coordinates [ 0 ] = new Coordinate ( minX , minY ); coordinates [ 1 ] = new Coordinate ( minX , maxY ); coordinates [ 2 ] = new Coordinate ( maxX , maxY ); coordinates [ 3 ] = new Coordinate ( maxX , minY ); coordinates [ 4 ] = coordinates [ 0 ] ; GeometryFactory geometryFactory = new GeometryFactory (); return geometryFactory . createPolygon ( coordinates ); } })","title":"Create Geometries using Sedona FormatUtils"},{"location":"tutorial/flink/sql/#create-row-objects","text":"Put a geometry in a Flink Row to a geomStream . Note that you can put other attributes in Row as well. This example uses a constant value myName for all geometries. import org.apache.sedona.core.formatMapper.FormatUtils ; import org.locationtech.jts.geom.Geometry ; import org.apache.flink.types.Row ; DataStream < Row > geomStream = text . map ( new MapFunction < String , Row > () { @Override public Row map ( String value ) throws Exception { FormatUtils formatUtils = new FormatUtils ( FileDataSplitter . WKT , false ); return Row . of ( formatUtils . readGeometry ( value ), \"myName\" ); } })","title":"Create Row objects"},{"location":"tutorial/flink/sql/#get-spatial-table","text":"Use TableEnv's fromDataStream function, with two column names geom and geom_name . Table geomTable = tableEnv . fromDataStream ( geomStream , \"geom\" , \"geom_name\" )","title":"Get Spatial Table"}],"index":{"fieldVectors":[["title/",[0,8.336]],["text/",[1,6.617,2,2.327,3,3.954,4,5.323,5,4.319,6,2.419,7,4.59,8,3.77,9,5.023,10,2.233,11,4.456,12,3.357,13,2.514,14,4.59,15,2.514,16,5.555,17,1.505,18,3.609,19,5.677,20,1.858,21,3.301,22,2.207,23,0.564,24,6.617,25,5.555,26,1.198,27,5.023,28,5.396,29,5.555,30,6.617,31,4.128,32,4.894,33,3.995,34,5.555,35,4.176,36,1.994,37,6.617,38,5.555,39,5.257,40,6.617,41,5.257,42,3.042,43,6.617,44,3.096,45,5.396,46,4.456,47,2.285,48,2.94,49,5.023,50,1.048,51,2.134]],["title/#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes",[1,1.184,2,0.44,3,0.707,4,0.575,5,0.832,6,0.433,7,0.821,8,0.407,9,0.899,10,0.399,11,0.797,12,0.452,13,0.45,14,0.821,15,0.45,16,0.994,17,0.269,18,0.646,19,0.68,20,0.332,21,0.591,22,0.395]],["text/#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes",[]],["title/#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112",[2,0.459,4,1.102,5,0.869,8,0.78,19,1.303,24,2.268,25,1.904,26,0.309,27,1.722,28,1.85,29,1.904]],["text/#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112",[]],["title/#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink",[2,0.699,4,0.966,5,0.762,8,0.684,19,1.142,30,1.988,31,1.24,32,0.985,33,1.2,34,1.669,35,1.255,36,0.599]],["text/#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink",[]],["title/#11232021-sedona-111-incubating-is-released-it-now-supports-spark-32",[2,0.534,4,1.283,5,1.012,8,0.908,26,0.36,32,1.308,37,2.64,38,2.217,39,2.098]],["text/#11232021-sedona-111-incubating-is-released-it-now-supports-spark-32",[]],["title/#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported",[2,0.307,4,0.738,5,0.582,8,0.523,12,0.58,32,0.753,40,1.519,41,1.207,42,0.698,43,1.519,44,0.711,45,1.239,46,1.023,47,0.525,48,0.675,49,1.153,50,0.24,51,0.49]],["text/#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported",[]],["title/download/",[52,3.615]],["text/download/",[2,1.334,3,3.937,4,4.26,5,4.029,20,1.85,23,0.591,25,5.532,52,4.129,53,5.732,54,4.783,55,4.375,56,4.309,57,3.066,58,4.159,59,1.868,60,3.536,61,2.493,62,5.718,63,3.047,64,4.723,65,2.632,66,3.102,67,4.723,68,4.644,69,4.809,70,4.159,71,4.375,72,3.897,73,4.502,74,4.901,75,2.294,76,5.24,77,6.804,78,6.523,79,6.523,80,9.915,81,9.117,82,6.804,83,6.804,84,5.938,85,4.02,86,3.509,87,6.588,88,7.608,89,2.749,90,3.18,91,6.588]],["title/download/#github-repository",[53,3.381,54,3.381]],["text/download/#github-repository",[5,4.055,53,6.166,54,4.835,55,5.886,56,3.875,57,2.758,58,5.595,59,2.514,60,4.758,61,3.354,62,5.142,63,4.099,64,6.355,65,3.541,66,4.173,67,6.355,68,6.249,69,6.469]],["title/download/#verify-the-integrity",[70,3.913,71,4.117]],["text/download/#verify-the-integrity",[72,5.849,73,6.756,74,7.356]],["title/download/#versions",[75,2.673]],["text/download/#versions",[]],["title/download/#130-incubating",[3,3.704,4,3.012]],["text/download/#130-incubating",[52,4.375,56,4.062,57,2.891,62,5.391,76,5.552,77,7.21,78,6.912,79,6.912,80,10.26,81,9.435,82,7.21]],["title/download/#121-incubating",[4,3.012,25,5.205]],["text/download/#121-incubating",[52,4.375,56,4.062,57,2.891,62,5.391,76,5.552,77,7.21,78,6.912,79,6.912,80,10.26,81,9.435,82,7.21]],["title/download/#past-releases",[5,2.377,83,4.81]],["text/download/#past-releases",[2,1.952,5,3.696,83,7.48,84,8.69,85,5.883,86,5.134,87,9.641]],["title/download/#security",[88,6.662]],["text/download/#security",[20,2.741,88,8.471,89,4.074,90,4.713,91,9.763]],["title/api/java-api/",[92,3.743,93,3.783]],["text/api/java-api/",[12,4.093,13,4.075,20,2.548,22,3.027,94,3.004,95,7.04,96,4.054,97,4.713,98,6.887,99,5.478,100,4.263,101,1.755,102,3.478]],["title/api/python-api/",[15,2.356,93,3.783]],["text/api/python-api/",[44,4.658,103,8.356]],["title/api/r-api/",[42,2.85,93,3.783]],["text/api/r-api/",[20,2.759,42,4.517,93,5.995,94,3.253]],["title/api/flink/Aggregator/",[18,4.188]],["text/api/flink/Aggregator/",[23,0.622,50,1.547,104,6.661,105,1.811,106,2.138,107,5.244,108,4.054,109,3.967,110,1.506,111,1.636,112,7.268,113,4.6,114,1.466,115,1.547,116,5.086,117,4.562,118,7.654,119,3.839,120,6.188,121,3.156,122,3.831,123,4.562]],["title/api/flink/Aggregator/#st_envelope_aggr",[104,4.79]],["text/api/flink/Aggregator/#st_envelope_aggr",[23,0.584,50,1.411,104,6.621,105,1.652,106,1.951,107,6.003,108,4.641,109,4.541,110,1.724,111,1.493,112,6.632,113,4.197,114,1.338,115,1.411,116,5.524,117,5.222]],["title/api/flink/Aggregator/#st_union_aggr",[118,5.504]],["text/api/flink/Aggregator/#st_union_aggr",[23,0.582,50,1.403,105,1.643,106,1.94,111,1.485,112,6.593,113,4.173,114,1.33,115,1.403,118,7.582,119,4.065,120,7.043,121,3.591,122,4.147,123,5.192]],["title/api/flink/Constructor/",[124,3.967]],["text/api/flink/Constructor/",[23,0.642,26,0.36,50,1.663,62,1.533,105,1.922,110,1.864,111,1.76,113,2.071,114,1.577,115,1.701,116,2.289,119,1.582,123,3.858,125,3.413,126,0.794,127,2.1,128,2.092,129,2.964,130,3.495,131,2.382,132,3.566,133,3.886,134,2.382,135,4.148,136,1.125,137,3.919,138,4.901,139,1.346,140,2.219,141,3.912,142,5.661,143,3.376,144,4.743,145,2.006,146,2.382,147,2.382,148,2.382,149,2.382,150,2.382,151,2.382,152,4.743,153,2.006,154,2.382,155,2.382,156,2.382,157,2.382,158,2.483,159,2.034,160,3.272,161,3.481,162,3.272,163,3.495,164,4.202,165,5.173,166,1.533,167,2.219,168,2.382,169,2.642,170,5.11,171,1.892,172,4.022,173,5.039,174,5.478,175,4.722,176,3.339,177,2.164,178,2.571,179,1.844,180,4.384,181,5.233,182,1.805,183,4.208,184,2.419,185,3.964,186,2.022,187,2.552,188,2.882,189,3.693,190,3.693,191,5.233,192,4.731,193,3.964,194,3.964,195,3.964,196,3.964,197,3.964,198,3.964,199,3.057,200,1.467,201,2.419,202,2.552,203,2.219,204,2.219,205,3.566,206,1.668,207,4.384,208,2.219,209,2.985,210,2.1,211,2.1,212,2.1,213,2.1,214,2.219,215,2.219,216,2.219,217,2.219,218,1.396,219,0.68,220,1.932,221,1.376,222,1.318,223,1.548,224,4.384,225,1.466,226,1.649,227,3.495,228,2.1,229,2.1]],["title/api/flink/Constructor/#st_geomfromgeohash",[125,5.957]],["text/api/flink/Constructor/#st_geomfromgeohash",[23,0.579,50,1.387,105,1.624,110,1.695,111,1.468,114,1.315,115,1.387,125,6.799,126,2.632,127,6.963,128,3.889,129,3.551,130,8.346,131,7.898,132,5.531,133,4.313,134,7.898,135,4.342,136,3.731]],["title/api/flink/Constructor/#st_geomfromgeojson",[137,5.326]],["text/api/flink/Constructor/#st_geomfromgeojson",[23,0.585,50,1.42,105,1.662,110,1.734,111,1.502,114,1.346,115,1.42,123,5.252,137,7.388,138,4.301,139,4.567,140,7.529,141,4.443,142,7.635,143,5.358]],["title/api/flink/Constructor/#st_geomfromgml",[144,6.446]],["text/api/flink/Constructor/#st_geomfromgml",[23,0.547,50,1.411,105,1.652,110,2.052,111,1.493,113,4.197,114,1.338,115,1.411,138,4.276,144,8.91,145,6.768,146,8.036,147,8.036,148,8.036,149,8.036,150,8.036,151,8.036]],["title/api/flink/Constructor/#st_geomfromkml",[152,6.446]],["text/api/flink/Constructor/#st_geomfromkml",[23,0.55,50,1.428,105,1.672,110,2.067,111,1.511,113,4.247,114,1.353,115,1.428,138,4.326,152,8.972,153,6.847,154,8.13,155,8.13,156,8.13,157,8.13]],["title/api/flink/Constructor/#st_geomfromtext",[158,3.374]],["text/api/flink/Constructor/#st_geomfromtext",[23,0.548,50,1.42,105,1.662,110,2.059,111,1.502,114,1.346,115,1.42,133,4.414,138,4.301,158,4.68,159,4.147,160,6.67,161,4.739,162,6.67,163,7.125,164,6.67]],["title/api/flink/Constructor/#st_geomfromwkb",[165,5.031]],["text/api/flink/Constructor/#st_geomfromwkb",[23,0.611,50,1.582,62,4.684,105,1.496,110,1.561,111,1.674,114,1.499,115,1.582,123,5.853,128,2.989,133,3.974,138,3.873,141,4.001,142,8.13,143,5.971,165,7.636,166,4.684,167,6.779,168,7.277,169,8.074]],["title/api/flink/Constructor/#st_geomfromwkt",[161,4.057]],["text/api/flink/Constructor/#st_geomfromwkt",[23,0.552,50,1.436,105,1.682,110,2.074,111,1.52,114,1.361,115,1.436,138,4.352,141,4.496,159,4.196,161,5.667,162,6.749,163,7.209,164,6.749]],["title/api/flink/Constructor/#st_linefromtext",[170,5.957]],["text/api/flink/Constructor/#st_linefromtext",[23,0.541,50,1.387,105,1.624,111,1.468,114,1.315,115,1.387,129,3.551,133,4.313,135,4.342,138,4.203,170,8.15,171,3.77,172,4.463,173,6.037,174,6.079,175,6.283,176,6.652,177,2.88,178,3.42,179,3.675]],["title/api/flink/Constructor/#st_linestringfromtext",[180,5.957]],["text/api/flink/Constructor/#st_linestringfromtext",[23,0.535,26,1.174,50,1.364,105,1.597,111,1.443,114,1.293,115,1.364,129,3.491,133,4.241,135,4.269,138,4.133,160,6.409,170,6.685,171,3.707,172,4.389,173,5.976,174,5.977,175,6.177,176,6.54,177,2.831,178,3.363,179,3.613,180,8.067]],["title/api/flink/Constructor/#st_mlinefromtext",[181,6.101]],["text/api/flink/Constructor/#st_mlinefromtext",[23,0.597,50,1.252,105,1.466,111,1.324,114,1.187,115,1.562,129,3.204,132,4.991,135,5.578,138,3.793,172,4.028,174,5.486,177,3.242,178,3.85,181,8.543,182,5.403,183,6.302,184,4.349,185,8.891,186,4.535,187,5.723,188,6.463,189,8.282,190,6.64]],["title/api/flink/Constructor/#st_mpolyfromtext",[191,6.101]],["text/api/flink/Constructor/#st_mpolyfromtext",[23,0.617,50,1.252,105,1.466,111,1.324,114,1.187,115,1.562,129,3.204,132,4.991,138,3.793,172,4.028,174,5.486,183,6.302,184,4.349,190,6.64,191,8.543,192,7.493,193,8.891,194,8.891,195,8.891,196,8.891,197,8.891,198,8.891]],["title/api/flink/Constructor/#st_point",[199,4.154]],["text/api/flink/Constructor/#st_point",[23,0.582,50,1.403,105,1.643,111,1.485,114,1.33,115,1.403,133,4.363,138,4.252,199,5.722,200,2.957,201,5.817,202,6.136,203,7.442,204,7.442,205,5.595,206,5.595]],["title/api/flink/Constructor/#st_pointfromtext",[207,5.957]],["text/api/flink/Constructor/#st_pointfromtext",[23,0.602,50,1.395,105,1.634,111,1.476,114,1.322,115,1.395,138,4.227,141,4.367,164,6.556,172,4.489,173,6.057,174,6.114,175,6.318,200,2.94,205,5.563,207,8.178,208,7.4]],["title/api/flink/Constructor/#st_polygonfromenvelope",[209,4.057]],["text/api/flink/Constructor/#st_polygonfromenvelope",[23,0.642,50,1.246,105,1.458,111,1.318,114,1.181,115,1.246,116,5.119,119,2.829,138,3.774,141,3.898,205,4.966,209,5.196,210,6.251,211,6.251,212,6.251,213,6.251,214,6.606,215,6.606,216,6.606,217,6.606,218,4.158,219,2.026,220,3.295,221,4.095,222,3.925,223,4.608]],["title/api/flink/Constructor/#st_polygonfromtext",[224,5.957]],["text/api/flink/Constructor/#st_polygonfromtext",[23,0.61,50,1.356,105,1.588,111,1.435,114,1.286,115,1.356,119,3.081,123,5.019,138,4.11,141,4.245,172,4.364,173,5.956,174,5.944,175,6.143,224,8.04,225,4.752,226,5.346,227,8.234,228,6.808,229,6.808]],["title/api/flink/Function/",[51,2.477]],["text/api/flink/Function/",[2,0.142,8,0.834,17,0.433,22,0.636,23,0.636,26,0.849,44,0.625,50,1.018,51,0.227,62,0.774,75,0.663,89,0.293,90,0.644,96,0.314,101,0.258,102,0.27,105,1.805,106,2.109,108,0.366,109,0.97,110,2.057,111,1.683,113,3.933,114,1.476,115,1.564,119,2,121,2.606,122,3.669,126,0.211,127,1.514,128,0.897,129,0.541,130,1.061,132,1.203,133,2.612,135,2.756,136,1.741,139,0.358,141,1.434,145,0.534,153,0.534,158,2.987,159,0.881,161,0.372,166,0.774,171,2.768,172,0.68,176,0.534,177,3.094,178,2.653,179,0.295,183,2.379,186,3.275,187,1.679,188,0.461,199,1.566,200,2.961,201,1.83,202,1.93,219,3.02,220,3.337,230,1.514,231,1.061,232,1.529,233,0.634,234,1.032,235,0.695,236,0.583,237,2.793,238,0.716,239,3.192,240,1.39,241,0.425,242,2.15,243,1.067,244,1.768,245,0.38,246,1.271,247,1.121,248,1.344,249,3.39,250,1.121,251,1.839,252,2.735,253,0.941,254,1.417,255,0.559,256,1.446,257,1.474,258,1.512,259,2.35,260,1.478,261,1.631,262,0.59,263,0.614,264,0.747,265,1.121,266,0.711,267,1.061,268,0.974,269,1.013,270,0.912,271,1.768,272,0.634,273,0.288,274,1.802,275,1.343,276,1.6,277,1.6,278,1.189,279,0.993,280,0.59,281,0.273,282,0.59,283,2.469,284,1.579,285,0.59,286,0.59,287,1.708,288,0.59,289,0.974,290,0.59,291,0.59,292,0.59,293,1.158,294,1.417,295,1.121,296,0.899,297,0.559,298,0.449,299,0.393,300,0.59,301,0.42,302,1.478,303,0.634,304,1.15,305,0.574,306,0.634,307,0.559,308,1.335,309,1.335,310,0.634,311,3.426,312,0.703,313,2.373,314,0.634,315,2.034,316,2.423,317,0.703,318,1.203,319,1.085,320,0.48,321,1.417,322,0.993,323,0.59,324,1.302,325,0.439,326,0.703,327,3.738,328,1.446,329,0.559,330,0.634,331,0.634,332,1.478,333,0.559,334,0.38,335,2.019,336,2.496,337,1.203,338,0.634,339,0.634,340,0.634,341,1.203,342,0.634,343,0.634,344,0.634,345,0.634,346,0.634,347,0.993,348,0.634,349,0.195,350,0.61,351,0.61,352,0.702,353,0.634,354,0.974,355,0.644,356,1.681,357,0.993,358,0.59,359,0.59,360,0.59,361,0.574,362,0.59,363,1.39,364,0.59,365,0.408,366,0.449,367,0.993,368,0.993,369,0.412,370,0.301,371,0.59,372,1.343,373,0.677,374,0.325,375,0.59,376,1.478,377,0.938,378,0.449,379,0.993,380,1.655,381,0.59,382,0.496,383,0.455,384,0.372,385,1.366,386,1.478,387,0.59,388,1.514,389,0.474,390,0.634,391,1.655,392,1.478,393,1.061,394,0.467,395,0.634,396,1.366,397,1.201,398,1.514,399,0.993,400,1.203,401,0.634,402,0.39,403,0.632,404,0.926,405,0.634,406,0.634,407,0.496,408,0.59,409,0.59,410,0.634,411,0.327,412,0.257,413,0.496,414,0.634,415,1.587,416,2.24,417,1.061,418,0.634,419,0.634,420,1.158,421,0.634,422,1.417,423,0.546,424,0.657,425,0.993,426,0.59,427,1.036,428,0.634,429,1.121,430,0.61,431,0.79,432,1.061,433,1.248,434,0.703,435,0.703,436,0.703,437,1.061,438,0.496,439,0.634,440,0.59,441,0.634,442,1.089,443,0.634,444,1.478,445,0.559,446,0.711,447,0.634,448,6.043,449,0.957,450,0.782,451,0.574,452,0.296,453,1.121,454,1.514,455,0.351,456,0.434,457,0.278,458,1.121,459,1.089,460,1.121,461,0.634,462,1.514,463,1.93,464,0.346,465,1.121,466,1.121,467,0.374,468,0.59,469,0.634,470,0.455,471,0.444,472,0.534,473,0.534,474,0.695,475,0.38,476,0.237,477,0.59,478,0.455,479,0.59,480,0.416,481,0.496,482,0.59,483,0.59,484,0.59,485,0.504,486,0.767,487,0.823,488,0.253,489,0.307,490,0.48,491,0.408,492,0.48,493,0.48,494,0.993,495,0.59,496,0.546,497,1.478,498,0.61,499,0.634,500,2.44,501,0.926,502,1.6,503,0.634,504,0.993,505,0.59,506,0.59,507,1.478,508,1.036,509,0.634,510,1.061,511,0.634,512,0.634,513,1.061,514,0.634,515,0.634,516,0.534,517,1.061,518,0.634,519,0.634,520,0.634]],["title/api/flink/Function/#st_3ddistance",[230,6.101]],["text/api/flink/Function/#st_3ddistance",[23,0.61,105,1.588,106,1.875,111,1.435,113,4.034,114,1.286,115,1.356,122,4.368,178,3.344,230,8.234,231,6.808,232,5.408,233,7.723,234,3.648,235,4.46,236,3.745,237,2.936,238,4.599,239,4.458]],["title/api/flink/Function/#st_addpoint",[240,5.604]],["text/api/flink/Function/#st_addpoint",[23,0.62,44,3.096,105,1.226,106,1.448,110,2.036,111,1.473,113,3.115,114,0.993,115,1.392,158,4.626,171,2.847,179,2.775,200,3.512,219,3.139,220,3.424,240,6.418,241,3.995,242,2.681,243,2.44,244,6.418,245,3.58,246,3.47,247,7.384,248,3.67,249,6.724,250,7.384,251,7.991,252,2.119,253,6.199]],["title/api/flink/Function/#st_area",[254,5.711]],["text/api/flink/Function/#st_area",[23,0.589,105,1.692,106,1.997,111,1.529,113,4.297,114,1.37,115,1.445,122,4.219,237,3.128,239,3.927,254,8.004,255,7.252]],["title/api/flink/Function/#st_asbinary",[256,5.828]],["text/api/flink/Function/#st_asbinary",[23,0.584,62,5.172,105,1.652,106,1.951,110,1.724,111,1.493,113,4.197,114,1.338,115,1.411,122,4.161,237,3.055,239,3.836,256,8.056,257,4.541,258,5.562,259,5.124]],["title/api/flink/Function/#st_asewkb",[260,5.957]],["text/api/flink/Function/#st_asewkb",[8,2.735,23,0.555,62,4.611,75,2.767,105,1.473,106,1.74,110,2.084,111,1.805,113,3.742,114,1.193,115,1.258,122,3.88,166,5.741,183,6.322,237,2.724,239,3.42,257,4.049,258,4.959,259,4.568,260,7.679,261,6.664,262,6.674,263,3.654,264,4.447,265,6.674,266,4.233,267,6.316,268,5.801,269,6.034,270,5.431]],["title/api/flink/Function/#st_asewkt",[271,5.604]],["text/api/flink/Function/#st_asewkt",[8,2.679,23,0.55,26,1.061,50,1.233,75,2.711,105,1.443,106,1.704,110,2.065,111,1.788,114,1.169,115,1.233,122,3.831,133,3.833,159,4.518,172,3.967,183,6.242,237,2.669,239,3.351,257,3.967,258,4.859,259,4.476,261,6.579,263,3.58,264,4.357,265,6.539,266,4.147,267,6.188,268,5.684,269,5.912,270,5.321,271,7.131,272,7.019,273,3.186,274,5.793]],["title/api/flink/Function/#st_asgeojson",[275,5.412]],["text/api/flink/Function/#st_asgeojson",[23,0.582,26,1.207,50,1.403,105,1.643,106,1.94,110,1.714,111,1.485,113,4.173,114,1.33,115,1.403,122,4.147,128,3.282,139,4.515,237,3.038,239,3.814,259,5.094,275,7.455]],["title/api/flink/Function/#st_asgml",[276,6.446]],["text/api/flink/Function/#st_asgml",[23,0.582,26,1.207,50,1.403,105,1.643,106,1.94,110,1.714,111,1.485,113,4.173,114,1.33,115,1.403,122,4.147,128,3.282,145,6.729,237,3.038,239,3.814,259,5.094,276,8.88]],["title/api/flink/Function/#st_askml",[277,6.446]],["text/api/flink/Function/#st_askml",[23,0.582,26,1.207,50,1.403,105,1.643,106,1.94,110,1.714,111,1.485,113,4.173,114,1.33,115,1.403,122,4.147,128,3.282,153,6.729,237,3.038,239,3.814,259,5.094,277,8.88]],["title/api/flink/Function/#st_astext",[278,4.79]],["text/api/flink/Function/#st_astext",[23,0.582,105,1.643,106,1.94,110,1.714,111,1.485,113,4.173,114,1.33,115,1.403,122,4.147,128,3.282,172,4.515,237,3.038,239,3.814,257,4.515,258,5.53,259,5.094,278,6.598]],["title/api/flink/Function/#st_azimuth",[279,5.711]],["text/api/flink/Function/#st_azimuth",[23,0.637,105,1.473,106,1.74,111,1.331,113,3.742,114,1.193,115,1.258,199,5.354,200,3.595,220,3.518,242,3.221,252,2.545,279,5.913,280,6.674,281,3.089,282,6.674,283,4.138,284,4.336,285,6.674,286,6.674,287,5.603,288,6.674]],["title/api/flink/Function/#st_boundary",[289,5.604]],["text/api/flink/Function/#st_boundary",[23,0.562,105,1.512,106,1.786,109,4.156,110,1.945,111,1.367,113,3.842,114,1.224,115,1.292,119,2.934,158,3.586,219,3.213,220,3.338,252,2.613,289,5.955,290,6.851,291,6.851,292,6.851,293,7.079]],["title/api/flink/Function/#st_buffer",[294,5.711]],["text/api/flink/Function/#st_buffer",[23,0.593,26,1.148,50,1.334,105,1.562,106,1.844,111,1.411,114,1.265,115,1.334,122,4.023,141,4.176,200,2.811,219,2.17,234,4.368,237,2.888,239,3.626,294,7.631,295,8.613,296,5.675,297,6.696,298,5.384,299,4.715,300,7.076,301,5.035]],["title/api/flink/Function/#st_buildarea",[302,5.957]],["text/api/flink/Function/#st_buildarea",[23,0.582,105,1.348,106,1.592,110,1.809,111,1.218,114,1.091,115,1.151,121,3.79,133,3.58,136,3.097,220,3.202,237,2.493,252,2.329,302,7.259,303,6.555,304,4.391,305,5.932,306,6.555,307,5.779,308,9.355,309,9.355,310,6.555,311,6.462,312,7.273,313,6.334,314,6.555,315,7.855,316,10.918,317,7.273,318,8.432]],["title/api/flink/Function/#st_distance",[319,4.372]],["text/api/flink/Function/#st_distance",[23,0.611,26,1.174,50,1.364,105,1.597,106,1.886,111,1.443,114,1.293,115,1.364,122,4.379,141,4.269,234,3.669,235,4.485,236,3.766,237,2.953,238,4.624,239,4.473,319,5.921,320,5.887]],["title/api/flink/Function/#st_envelope",[321,5.711]],["text/api/flink/Function/#st_envelope",[23,0.588,105,1.682,106,1.986,108,4.723,109,4.621,111,1.52,113,4.272,114,1.361,115,1.436,122,4.205,237,3.109,239,3.904,321,7.976]],["title/api/flink/Function/#st_exteriorring",[322,5.711]],["text/api/flink/Function/#st_exteriorring",[23,0.541,105,1.394,106,2.092,110,1.849,111,1.26,114,1.129,115,1.191,119,3.778,121,3.048,133,3.702,171,4.112,177,3.141,219,3.179,220,3.578,252,2.409,283,3.915,296,5.065,322,5.595,323,6.315,324,5.139,325,4.693,326,7.522,327,5.13]],["title/api/flink/Function/#st_flipcoordinates",[328,5.828]],["text/api/flink/Function/#st_flipcoordinates",[23,0.568,26,1.142,50,1.327,75,2.918,105,1.553,106,1.834,110,1.977,111,1.404,114,1.258,115,1.327,121,3.396,141,4.153,177,3.36,200,3.411,201,4.61,202,4.862,219,2.633,242,3.396,252,2.684,327,5.488,328,6.362,329,6.66,330,7.554,331,7.554]],["title/api/flink/Function/#st_force_2d",[332,5.957]],["text/api/flink/Function/#st_force_2d",[23,0.54,105,1.387,110,1.843,111,1.254,114,1.123,115,1.185,121,3.033,133,3.684,136,3.187,177,3.131,178,2.922,186,3.441,201,4.117,202,4.342,219,2.842,220,3.074,231,5.948,237,2.565,252,3.051,259,4.302,315,8,327,5.114,332,7.394,333,5.948,334,4.05,335,2.606,336,5.814,337,8.589,338,6.747,339,6.747,340,6.747,341,8.589,342,6.747,343,6.747,344,6.747,345,6.747,346,6.747]],["title/api/flink/Function/#st_geohash",[347,5.711]],["text/api/flink/Function/#st_geohash",[23,0.643,105,1.512,106,1.786,110,1.945,111,1.367,114,1.224,115,1.292,127,8.664,130,7.992,132,5.15,141,4.043,158,3.586,186,3.751,242,3.306,347,6.069,348,7.354,349,2.261,350,7.079,351,7.079,352,3.008,353,7.354]],["title/api/flink/Function/#st_geometryn",[354,5.604]],["text/api/flink/Function/#st_geometryn",[23,0.58,105,1.466,106,2.159,110,2.079,111,1.324,113,3.723,114,1.187,115,1.252,132,4.991,135,4.888,158,3.476,177,2.599,178,3.85,186,3.635,187,4.588,200,2.638,219,2.036,220,2.319,252,2.532,283,4.116,284,4.313,354,5.772,355,3.817,356,5.486,357,5.882,358,6.64,359,6.64,360,6.64,361,6.45,362,6.64,363,5.772,364,6.64,365,4.588,366,5.052]],["title/api/flink/Function/#st_interiorringn",[367,5.711]],["text/api/flink/Function/#st_interiorringn",[23,0.539,105,1.211,106,1.908,110,1.898,111,1.094,113,3.076,114,0.98,115,1.034,119,3.135,132,4.123,135,5.562,158,2.871,171,2.811,177,3.913,178,4.602,186,4.814,219,3.163,220,3.292,242,2.647,252,2.092,283,3.4,293,5.668,324,4.463,336,3.986,356,4.532,363,6.364,367,4.859,368,4.859,369,3.826,370,2.796,371,5.485]],["title/api/flink/Function/#st_isclosed",[372,5.412]],["text/api/flink/Function/#st_isclosed",[23,0.576,102,3.322,105,1.606,106,1.896,110,1.676,111,1.451,113,4.079,114,1.3,115,1.372,158,3.808,171,3.728,200,2.89,219,2.883,220,3.059,246,4.544,249,5.535,372,6.108,373,3.078,374,4.007,375,7.275]],["title/api/flink/Function/#st_isempty",[376,5.957]],["text/api/flink/Function/#st_isempty",[23,0.584,26,1.214,50,1.411,105,1.652,110,2.052,111,1.493,114,1.338,115,1.411,122,4.161,133,4.388,237,3.055,239,3.836,376,8.234,377,4.388,378,5.695]],["title/api/flink/Function/#st_isring",[379,5.711]],["text/api/flink/Function/#st_isring",[23,0.571,105,1.571,106,1.855,110,1.639,111,1.419,113,3.99,114,1.272,115,1.342,158,3.724,171,3.646,219,2.969,220,3.465,249,5.413,252,2.713,372,5.973,373,3.656,379,6.303,380,5.79,381,7.115]],["title/api/flink/Function/#st_issimple",[380,5.246]],["text/api/flink/Function/#st_issimple",[23,0.584,105,1.652,109,4.541,111,1.493,113,4.197,114,1.338,115,1.411,122,4.161,200,2.974,237,3.055,239,3.836,377,4.388,380,7.251,382,6.285,383,5.767,384,4.711]],["title/api/flink/Function/#st_isvalid",[385,5.504]],["text/api/flink/Function/#st_isvalid",[23,0.586,105,1.672,110,1.744,111,1.511,113,4.247,114,1.353,115,1.428,122,4.19,237,3.091,239,3.881,257,4.594,304,5.445,377,4.44,385,7.661]],["title/api/flink/Function/#st_length",[386,5.957]],["text/api/flink/Function/#st_length",[23,0.589,105,1.692,106,1.997,111,1.529,113,4.297,114,1.37,115,1.445,122,4.219,237,3.128,239,3.927,386,8.349,387,7.663]],["title/api/flink/Function/#st_linefrommultipoint",[388,6.101]],["text/api/flink/Function/#st_linefrommultipoint",[23,0.559,105,1.496,110,1.933,111,1.352,113,3.801,114,1.212,115,1.278,121,3.271,126,2.425,136,3.438,171,4.299,237,2.767,252,2.585,311,5.779,313,6.579,327,5.363,388,7.94,389,5.437,390,7.277,391,7.748,392,6.92]],["title/api/flink/Function/#st_normalize",[393,6.101]],["text/api/flink/Function/#st_normalize",[23,0.633,105,1.408,106,1.662,110,1.86,111,1.272,113,3.576,114,1.14,115,1.203,119,2.731,121,3.078,136,4.095,161,4.014,219,3.124,220,3.584,271,5.544,304,4.586,336,4.635,352,2.801,393,6.036,394,5.044,395,6.846]],["title/api/flink/Function/#st_npoints",[396,5.504]],["text/api/flink/Function/#st_npoints",[23,0.586,105,1.672,106,1.974,110,1.744,111,1.511,113,4.247,114,1.353,115,1.428,122,4.19,200,3.009,237,3.091,239,3.881,396,7.661,397,4.469]],["title/api/flink/Function/#st_ndims",[398,6.101]],["text/api/flink/Function/#st_ndims",[2,1.381,8,3.087,23,0.596,26,1.222,50,1.588,89,2.846,105,1.264,106,1.493,110,2.197,111,1.143,114,1.347,115,1.421,158,2.998,177,3.295,178,3.503,219,2.311,252,2.873,335,3.491,398,7.13,399,6.675,400,8.088,401,6.149,402,3.784,403,4.251,404,6.225,405,6.149,406,6.149,407,4.809,408,5.728,409,5.728,410,6.149,411,3.173,412,2.494,413,4.809,414,6.149,415,4.47,416,4.594,417,7.13,418,6.149,419,6.149,420,7.786,421,6.149]],["title/api/flink/Function/#st_numgeometries",[422,5.711]],["text/api/flink/Function/#st_numgeometries",[23,0.574,105,1.588,106,2.438,110,2.292,111,1.435,113,4.034,114,1.286,115,1.356,219,2.206,237,2.936,327,5.562,357,6.373,397,5.135,422,7.708,423,6.648,424,4.217]],["title/api/flink/Function/#st_numinteriorrings",[425,5.711]],["text/api/flink/Function/#st_numinteriorrings",[23,0.555,105,1.473,106,1.74,110,1.914,111,1.331,113,3.742,114,1.193,115,1.258,119,3.559,158,3.494,177,3.706,186,5.185,219,3.089,220,3.469,252,2.545,324,5.431,368,5.913,397,3.939,425,5.913,426,6.674]],["title/api/flink/Function/#st_pointn",[427,5.957]],["text/api/flink/Function/#st_pointn",[23,0.539,105,1.211,106,1.908,110,1.898,111,1.094,114,0.98,115,1.034,121,3.977,133,3.215,135,5.189,171,4.506,177,3.974,178,3.831,187,5.694,200,3.64,219,3.114,220,2.557,246,3.426,249,5.57,252,3.143,283,3.4,327,4.68,356,4.532,424,3.215,427,5.069,428,5.888,429,5.485,430,2.986,431,3.864,432,5.191,433,4.28,434,6.532,435,6.532,436,6.532]],["title/api/flink/Function/#st_pointonsurface",[437,6.101]],["text/api/flink/Function/#st_pointonsurface",[23,0.526,105,1.311,106,1.548,110,1.368,111,1.185,114,1.061,115,1.12,121,4.377,133,3.481,177,2.324,186,5.504,200,3.828,219,2.628,220,3.607,249,5.869,252,3.459,311,4.893,327,4.931,336,4.316,437,5.62,438,4.986,439,6.375,440,5.938,441,6.375,442,7.493,443,6.375]],["title/api/flink/Function/#st_reverse",[444,5.957]],["text/api/flink/Function/#st_reverse",[23,0.593,105,1.436,106,1.696,110,1.884,111,1.298,114,1.163,115,1.227,119,3.502,121,3.14,133,3.814,136,3.299,237,2.656,252,2.481,327,5.228,444,7.557,445,6.157,446,4.127,447,6.984,448,10.993]],["title/api/flink/Function/#st_removepoint",[449,5.504]],["text/api/flink/Function/#st_removepoint",[23,0.581,105,1.473,106,1.74,110,1.914,111,1.657,113,3.742,114,1.193,115,1.258,158,3.494,171,3.42,200,2.652,219,2.988,220,3.307,242,3.221,243,2.931,244,7.223,248,4.409,249,6.322,252,2.545,433,5.208,449,5.699,450,5.797,451,6.483,452,3.35,453,8.309]],["title/api/flink/Function/#st_setpoint",[454,6.101]],["text/api/flink/Function/#st_setpoint",[23,0.64,105,1.287,110,1.756,111,1.163,113,3.27,114,1.042,115,1.1,136,3.866,158,3.99,171,4.616,177,2.282,200,3.714,219,2.996,220,3.499,242,2.814,243,3.73,248,3.852,352,2.561,355,3.352,356,4.818,429,5.831,431,4.108,432,5.518,433,4.55,454,7.214,455,3.465,456,4.284]],["title/api/flink/Function/#st_setsrid",[274,5.711]],["text/api/flink/Function/#st_setsrid",[17,1.97,23,0.598,105,1.606,110,1.676,111,1.451,113,4.079,114,1.3,115,1.372,122,4.091,183,6.665,237,2.969,239,3.728,248,4.806,274,7.76,457,3.429,458,7.275,459,3.893,460,7.275,461,7.809]],["title/api/flink/Function/#st_srid",[462,6.101]],["text/api/flink/Function/#st_srid",[17,2.015,23,0.582,105,1.643,106,1.94,110,1.714,111,1.485,113,4.173,114,1.33,115,1.403,122,4.147,183,5.663,237,3.038,239,3.814,458,7.442,459,3.983,460,7.442,462,8.403]],["title/api/flink/Function/#st_transform",[463,4.454]],["text/api/flink/Function/#st_transform",[17,1.408,22,3.186,23,0.622,26,1.146,44,2.897,50,1.331,51,1.997,90,4.06,96,2.766,101,1.626,105,1.147,111,1.409,114,1.262,115,1.331,122,4.018,129,3.407,141,3.068,159,2.863,201,3.405,202,3.592,237,2.122,239,3.618,246,3.247,328,4.7,335,2.155,415,4.056,430,2.83,446,3.297,459,3.779,463,6.215,464,3.047,465,7.061,466,7.061,467,3.297,468,5.198,469,5.58,470,4.004,471,3.908,472,4.7,473,4.7,474,4.378,475,3.35,476,2.089,477,5.198,478,4.004,479,5.198,480,3.662,481,4.364,482,5.198,483,5.198,484,5.198,485,4.439,486,4.833,487,5.188,488,2.226,489,2.706,490,4.23,491,3.592,492,4.23,493,4.23]],["title/api/flink/Function/#st_x",[494,5.711]],["text/api/flink/Function/#st_x",[23,0.61,105,1.588,106,1.875,111,1.435,113,4.034,114,1.286,115,1.356,199,4.636,200,3.457,201,4.712,220,3.267,242,3.472,252,2.744,283,4.46,284,4.673,287,6.04,335,2.983,494,6.373,495,7.194,496,6.648]],["title/api/flink/Function/#st_xmax",[497,5.957]],["text/api/flink/Function/#st_xmax",[23,0.587,105,1.52,106,1.795,110,1.952,111,1.374,114,1.231,115,1.299,119,2.95,121,3.324,133,4.038,177,3.316,201,4.512,219,2.814,220,2.406,237,2.811,252,2.627,311,4.368,327,5.416,335,2.856,497,7.83,498,7.117,499,7.393,500,7.161,501,5.691]],["title/api/flink/Function/#st_xmin",[502,6.446]],["text/api/flink/Function/#st_xmin",[23,0.587,105,1.52,106,1.795,110,1.952,111,1.374,114,1.231,115,1.299,119,2.95,121,3.324,133,4.038,177,2.696,201,4.512,219,2.936,220,2.406,232,5.178,237,2.811,252,2.627,311,4.368,327,5.416,335,2.856,500,7.161,501,5.691,502,8.472,503,7.393]],["title/api/flink/Function/#st_y",[504,5.711]],["text/api/flink/Function/#st_y",[23,0.61,105,1.588,106,1.875,111,1.435,113,4.034,114,1.286,115,1.356,199,4.636,200,3.457,202,4.971,220,3.267,242,3.472,252,2.744,283,4.46,284,4.673,287,6.04,335,2.983,504,6.373,505,7.194,506,7.194]],["title/api/flink/Function/#st_ymax",[507,5.957]],["text/api/flink/Function/#st_ymax",[23,0.586,26,1.111,50,1.292,105,1.512,106,1.786,111,1.367,114,1.224,115,1.292,133,4.016,158,3.586,177,3.305,202,4.734,219,3.182,220,3.198,232,5.15,237,2.796,252,2.613,335,2.841,336,4.979,507,7.804]],["title/api/flink/Function/#st_ymin",[508,5.957]],["text/api/flink/Function/#st_ymin",[23,0.586,26,1.111,50,1.292,105,1.512,106,1.786,111,1.367,114,1.224,115,1.292,133,4.016,158,3.586,177,2.681,202,4.734,219,3.182,220,3.338,232,5.15,237,2.796,252,2.613,335,2.841,336,4.979,508,6.331,509,7.354]],["title/api/flink/Function/#st_z",[510,6.101]],["text/api/flink/Function/#st_z",[23,0.618,105,1.562,106,1.844,111,1.411,113,3.968,114,1.265,115,1.334,199,4.56,200,3.422,220,3.375,242,3.415,252,2.699,283,4.387,284,4.597,287,5.941,335,2.934,416,5.675,500,5.522,510,6.696,511,7.596,512,7.596]],["title/api/flink/Function/#st_zmax",[513,6.101]],["text/api/flink/Function/#st_zmax",[23,0.558,26,1.094,50,1.272,105,1.489,106,1.758,110,1.926,111,1.345,114,1.205,115,1.272,158,3.53,177,2.639,219,3.175,220,3.175,242,3.254,252,2.572,283,4.181,335,2.796,336,4.901,415,5.262,416,6.707,513,6.382,514,7.239,515,7.239,516,6.097]],["title/api/flink/Function/#st_zmin",[517,6.101]],["text/api/flink/Function/#st_zmin",[23,0.57,26,1.148,50,1.334,105,1.562,106,1.844,110,1.984,111,1.411,114,1.265,115,1.334,135,4.176,158,3.704,176,6.397,178,3.289,186,3.874,187,4.889,188,5.522,242,3.415,252,2.699,283,4.387,335,2.934,415,5.522,416,6.908,517,6.696,518,7.596,519,7.596,520,7.596]],["title/api/flink/Overview/",[521,7.678]],["text/api/flink/Overview/",[2,1.712,8,2.147,17,1.419,18,4.612,19,3.587,20,1.752,21,3.113,23,0.435,50,1.518,51,2.728,94,2.066,104,3.894,105,1.157,106,2.351,107,4.203,108,3.249,109,3.179,110,2.078,114,1.543,121,2.529,124,3.225,126,1.875,128,3.551,138,2.994,159,2.886,161,3.298,218,3.298,234,2.657,236,4.696,242,4.488,263,2.869,281,2.425,319,3.554,320,4.264,335,2.173,373,3.004,424,3.072,430,2.853,488,3.041,522,3.273,523,4.264,524,4.264,525,4.203,526,4.959,527,5.415,528,5.625,529,3.249,530,1.633,531,4.816,532,4.874,533,3.692,534,3.522,535,4.642,536,5.24,537,3.157,538,2.836,539,5.09]],["title/api/flink/Overview/#introduction",[105,1.423]],["text/api/flink/Overview/#introduction",[2,1.721,8,2.165,17,1.431,18,4.638,19,3.616,20,1.767,21,3.139,23,0.324,50,1.525,51,2.743,94,2.083,104,3.926,106,2.358,107,4.237,108,3.275,109,3.205,110,2.084,114,1.548,121,2.549,124,3.251,126,1.89,128,3.566,138,3.018,159,2.91,161,3.325,218,3.325,234,2.679,236,4.71,242,4.499,263,2.893,281,2.445,319,3.583,320,4.299,335,2.191,373,3.02,424,3.097,430,2.876,488,3.057,522,3.3,523,4.299,524,4.299,525,4.237,526,5,527,5.459,528,5.671,529,3.275,530,1.646,531,4.842,532,4.884,533,3.722,534,3.551,535,4.68,536,5.283,537,3.182,538,2.859,539,5.132]],["title/api/flink/Predicate/",[534,4.333]],["text/api/flink/Predicate/",[23,0.654,26,0.44,50,1.501,102,1.238,105,1.691,106,1.996,110,1.255,111,1.528,113,3.056,114,1.423,115,1.501,116,5.437,117,5.086,133,2.551,141,2.568,161,3.926,177,3.535,209,4.588,218,3.43,219,2.349,220,3.564,221,4.52,222,4.331,223,5.086,236,3.988,237,2.976,238,4.66,252,1.66,299,1.807,335,1.125,336,1.971,373,3.368,384,1.707,446,1.72,488,1.161,537,1.634,538,1.468,540,4.021,541,2.911,542,2.911,543,3.6,544,4.147,545,1.748,546,5.158,547,2.911,548,5.85,549,5.158,550,3.097,551,5.158]],["title/api/flink/Predicate/#st_contains",[218,4.057]],["text/api/flink/Predicate/#st_contains",[23,0.643,50,1.265,105,1.481,106,1.749,111,1.338,114,1.199,115,1.265,116,5.168,117,4.68,141,3.959,209,4.222,218,5.247,219,2.058,220,3.313,221,4.159,222,3.986,223,4.68,236,3.493,237,2.738,238,4.289,373,2.838,537,4.041,538,3.631]],["title/api/flink/Predicate/#st_disjoint",[540,5.957]],["text/api/flink/Predicate/#st_disjoint",[23,0.643,26,1.088,50,1.265,105,1.481,106,1.749,111,1.338,114,1.199,115,1.265,116,5.168,117,4.68,133,3.933,209,4.222,219,2.058,220,3.313,221,4.159,222,3.986,223,4.68,236,3.493,237,2.738,238,4.289,373,2.838,540,6.2,541,7.202,542,7.202]],["title/api/flink/Predicate/#st_intersects",[543,4.259]],["text/api/flink/Predicate/#st_intersects",[23,0.644,50,1.272,105,1.489,106,1.758,111,1.345,114,1.205,115,1.272,116,5.185,117,4.704,141,3.98,209,4.244,219,2.068,220,3.32,221,4.181,222,4.007,223,4.704,236,3.511,237,2.753,238,4.311,373,2.853,384,4.244,543,5.525]],["title/api/flink/Predicate/#st_within",[544,4.905]],["text/api/flink/Predicate/#st_within",[23,0.644,50,1.272,105,1.489,106,1.758,111,1.345,113,3.782,114,1.205,115,1.272,116,5.185,117,4.704,209,4.244,219,2.068,220,3.32,221,4.181,222,4.007,223,4.704,236,3.511,237,2.753,238,4.311,373,2.853,544,6.363,545,4.345]],["title/api/flink/Predicate/#st_orderingequals",[546,6.101]],["text/api/flink/Predicate/#st_orderingequals",[23,0.618,50,1.417,102,2.604,105,1.259,106,1.486,110,1.935,111,1.138,114,1.343,115,1.417,133,3.343,161,5.62,177,4.039,219,1.749,220,3.62,236,2.969,252,2.865,299,3.8,335,2.365,336,4.144,373,3.178,446,3.617,488,2.442,546,7.109,547,6.122,548,9.019]],["title/api/flink/Predicate/#st_covers",[549,6.101]],["text/api/flink/Predicate/#st_covers",[23,0.644,50,1.272,105,1.489,106,1.758,111,1.345,113,3.782,114,1.205,115,1.272,116,5.185,117,4.704,209,4.244,219,2.068,220,3.32,221,4.181,222,4.007,223,4.704,236,3.511,237,2.753,238,4.311,373,2.853,549,7.914,550,4.799]],["title/api/flink/Predicate/#st_coveredby",[551,6.101]],["text/api/flink/Predicate/#st_coveredby",[23,0.644,50,1.272,105,1.489,106,1.758,111,1.345,113,3.782,114,1.205,115,1.272,116,5.185,117,4.704,209,4.244,219,2.068,220,3.32,221,4.181,222,4.007,223,4.704,236,3.511,237,2.753,238,4.311,373,2.853,550,4.799,551,7.914]],["title/api/sql/AggregateFunction/",[18,3.381,51,2]],["text/api/sql/AggregateFunction/",[23,0.629,26,1.384,50,1.609,104,6.339,105,1.883,106,2.224,107,4.719,108,3.648,109,3.57,110,1.355,111,1.702,112,7.558,114,1.525,115,1.609,116,4.754,117,4.105,118,7.284,119,3.871,120,5.569,122,4.221,123,5.35,384,3.703,552,3.93,553,7.713]],["title/api/sql/AggregateFunction/#st_envelope_aggr",[104,4.79]],["text/api/sql/AggregateFunction/#st_envelope_aggr",[23,0.582,26,1.207,50,1.403,104,6.598,105,1.643,106,1.94,107,5.969,108,4.614,109,4.515,110,1.714,111,1.485,112,6.593,114,1.33,115,1.403,116,5.505,117,5.192,552,3.429]],["title/api/sql/AggregateFunction/#st_intersection_aggr",[553,5.828]],["text/api/sql/AggregateFunction/#st_intersection_aggr",[23,0.584,26,1.214,50,1.411,105,1.652,106,1.951,111,1.493,112,6.632,114,1.338,115,1.411,119,3.816,122,4.161,123,5.222,384,4.711,552,3.449,553,8.056]],["title/api/sql/AggregateFunction/#st_union_aggr",[118,5.504]],["text/api/sql/AggregateFunction/#st_union_aggr",[23,0.584,26,1.214,50,1.411,105,1.652,106,1.951,111,1.493,112,6.632,114,1.338,115,1.411,118,7.608,119,3.816,120,7.084,122,4.161,123,5.222,552,3.449]],["title/api/sql/Constructor/",[124,3.967]],["text/api/sql/Constructor/",[10,0.574,20,0.478,22,0.568,23,0.651,26,1.178,50,1.488,62,0.987,94,1.622,96,1.346,101,0.583,105,1.712,110,1.673,111,1.575,113,1.418,114,1.411,115,1.591,116,1.568,119,1.457,122,1.181,123,2.87,125,2.338,126,0.905,127,1.352,128,1.501,129,2.269,130,2.394,131,1.534,132,1.074,133,0.838,134,1.534,135,3.068,136,1.283,137,2.09,138,4.346,139,1.535,140,1.429,142,5.114,143,4.001,144,3.403,145,1.292,146,1.534,147,1.534,148,1.534,149,1.534,150,1.534,151,1.534,152,3.403,153,1.292,154,1.534,155,1.534,156,1.534,157,1.534,158,2.153,159,2.59,160,1.266,161,3.539,162,5.589,163,2.394,164,3.015,165,3.21,166,0.987,167,1.429,168,1.534,170,3.801,171,0.732,172,2.496,173,3.849,174,2.812,175,2.906,176,1.292,177,1.332,178,1.582,179,1.263,180,3.801,181,4.45,182,1.163,183,3.956,185,2.715,186,1.385,187,1.748,188,1.974,189,2.53,190,2.53,191,4.45,192,3.623,193,2.715,194,2.715,195,2.715,196,2.715,197,2.715,198,2.715,199,2.651,200,1.005,201,0.936,202,0.987,203,2.53,204,2.53,205,3.092,206,3.535,207,3.801,208,1.429,209,2.142,210,1.352,211,1.352,212,1.352,213,1.352,214,1.429,215,1.429,216,1.429,217,1.429,218,0.899,219,0.438,220,2.092,221,0.886,222,0.849,223,0.997,224,3.801,225,0.944,226,1.062,227,3.221,228,2.394,229,2.394,239,0.732,245,1.63,284,0.928,313,1.748,352,0.628,412,0.622,415,3.21,457,2.217,459,1.354,467,2.609,474,1.568,476,0.574,488,0.612,522,1.58,532,1.296,538,0.773,552,3.036,554,1.352,555,1.58,556,1.535,557,2.853,558,1.546,559,1.05,560,1.181,561,1.163,562,2.422,563,1.087,564,1.429,565,4.416,566,0.811,567,1.2,568,1.748,569,2.558,570,1.534,571,1.974,572,1.22,573,1.819,574,1.982,575,1.115,576,1.699,577,1.181,578,1.292,579,1.242,580,1.2,581,1.429,582,0.899,583,0.838,584,3.403,585,1.074,586,1.429,587,1.429,588,1.429,589,1.429,590,1.429,591,1.427,592,0.756,593,0.843,594,0.568,595,0.906,596,1.429,597,1.292,598,1.429,599,1.429,600,1.2,601,1.101,602,2.843,603,1.146,604,0.861,605,1.429,606,1.429,607,1.429,608,1.242,609,4.053,610,4.053,611,4.899,612,3.653,613,0.893,614,1.242,615,1.039,616,0.822,617,1.534,618,1.534,619,0.936,620,0.806,621,3.801,622,4.251,623,3.013,624,1.702,625,2.715,626,2.715,627,1.702,628,2.09,629,2.058,630,2.124]],["title/api/sql/Constructor/#read-esri-shapefile",[94,1.721,554,4.13,555,2.726]],["text/api/sql/Constructor/#read-esri-shapefile",[10,1.793,20,1.492,22,1.773,23,0.65,50,0.841,94,1.76,96,3.379,101,1.463,105,0.985,110,1.463,114,1.135,126,1.596,138,2.549,161,2.809,284,2.899,412,1.943,457,2.103,459,3.398,476,1.793,522,2.787,532,3.254,538,2.415,552,2.056,555,2.787,556,2.707,557,4.485,558,3.027,559,3.279,560,3.687,561,3.631,562,3.808,563,3.395,564,4.462,565,8.645,566,2.533,567,3.747,568,3.083,569,5.557,570,4.79,571,3.482,572,3.81,573,3.209,574,2.599,575,3.482,576,3.326,577,3.687,578,4.035,579,3.879,580,3.747,581,4.462,582,2.809,583,2.616,584,7.392,585,3.355,586,4.462,587,4.462,588,4.462,589,4.462,590,4.462,591,2.518,592,2.362,593,2.634,594,1.773,595,2.83,596,4.462,597,4.035,598,4.462,599,4.462,600,3.747,601,3.438,602,7.136,603,3.579,604,2.688,605,4.462,606,4.462,607,4.462]],["title/api/sql/Constructor/#st_geomfromgeohash",[125,5.957]],["text/api/sql/Constructor/#st_geomfromgeohash",[23,0.636,26,1.061,50,1.233,105,1.443,110,1.506,111,1.304,114,1.169,115,1.233,119,2.8,125,6.043,126,2.339,127,6.188,128,3.618,129,3.156,130,7.764,131,7.019,132,4.916,134,7.019,135,3.859,136,4.16,352,2.871,608,5.684,609,10.676,610,10.676,611,11.196]],["title/api/sql/Constructor/#st_geomfromgeojson",[137,5.326]],["text/api/sql/Constructor/#st_geomfromgeojson",[23,0.653,26,0.913,50,1.404,94,2.937,105,1.242,110,1.296,111,1.486,114,1.006,115,1.061,122,3.478,129,3.594,137,4.65,138,3.215,139,4.518,140,5.628,142,6.359,173,3.852,239,2.884,488,2.41,522,3.515,552,2.593,556,3.414,557,4.518,562,3.836,568,3.889,573,4.047,574,4.337,591,3.175,612,8.96,613,3.515,614,4.892,615,4.09,616,3.236,617,6.042,618,6.042,619,3.687,620,3.175]],["title/api/sql/Constructor/#st_geomfromgml",[144,6.446]],["text/api/sql/Constructor/#st_geomfromgml",[23,0.547,50,1.411,105,1.652,110,2.052,111,1.493,113,4.197,114,1.338,115,1.411,138,4.276,144,8.91,145,6.768,146,8.036,147,8.036,148,8.036,149,8.036,150,8.036,151,8.036]],["title/api/sql/Constructor/#st_geomfromkml",[152,6.446]],["text/api/sql/Constructor/#st_geomfromkml",[23,0.55,50,1.428,105,1.672,110,2.067,111,1.511,113,4.247,114,1.353,115,1.428,138,4.326,152,8.972,153,6.847,154,8.13,155,8.13,156,8.13,157,8.13]],["title/api/sql/Constructor/#st_geomfromtext",[158,3.374]],["text/api/sql/Constructor/#st_geomfromtext",[23,0.523,26,1.129,50,1.313,105,1.537,110,1.964,111,1.389,114,1.244,115,1.313,129,3.359,138,3.977,158,4.826,159,3.834,160,6.167,161,4.381,162,7.556,163,6.588,164,6.167,183,6.489,220,2.431,245,4.486,415,5.433,457,3.281,467,4.415,474,4.316,552,3.207,621,6.433,622,7.194]],["title/api/sql/Constructor/#st_geomfromwkb",[165,5.031]],["text/api/sql/Constructor/#st_geomfromwkb",[23,0.578,26,1.187,50,1.38,62,5.055,105,1.615,110,1.685,111,1.459,114,1.308,115,1.38,123,5.104,128,3.226,138,4.179,142,7.505,143,5.206,165,7.352,166,5.055,167,7.316,168,7.854,552,3.37]],["title/api/sql/Constructor/#st_geomfromwkt",[161,4.057]],["text/api/sql/Constructor/#st_geomfromwkt",[23,0.598,26,1.088,50,1.265,105,1.481,110,1.92,111,1.338,114,1.199,115,1.572,123,4.68,129,3.237,138,3.832,142,7.118,143,4.774,159,3.695,161,5.971,162,7.385,163,6.349,164,5.943,183,6.342,220,2.343,245,4.323,415,5.235,457,3.162,467,4.255,474,4.159,552,3.091,621,6.2,622,6.932]],["title/api/sql/Constructor/#st_linefromtext",[170,5.957]],["text/api/sql/Constructor/#st_linefromtext",[23,0.608,26,1.148,50,1.334,105,1.562,111,1.411,114,1.265,115,1.624,133,4.148,135,4.176,138,4.042,143,5.035,159,3.897,162,6.269,170,8.582,172,4.292,176,6.397,177,2.769,178,3.289,179,4.302,623,10.259,624,8.427]],["title/api/sql/Constructor/#st_linestringfromtext",[180,5.957]],["text/api/sql/Constructor/#st_linestringfromtext",[23,0.636,26,1.111,50,1.292,105,1.512,111,1.367,114,1.224,115,1.592,138,3.914,143,4.875,171,3.511,172,4.156,173,5.78,174,5.661,175,5.85,180,8.46,227,6.483,228,6.483,229,6.483,552,3.156,625,9.065,626,9.065]],["title/api/sql/Constructor/#st_mlinefromtext",[181,6.101]],["text/api/sql/Constructor/#st_mlinefromtext",[23,0.612,26,1.04,50,1.209,105,1.415,111,1.278,114,1.145,115,1.528,135,5.508,138,3.661,159,3.53,162,7.177,177,3.171,178,3.766,181,8.832,182,5.216,183,4.876,185,8.696,186,4.435,187,5.597,188,6.322,189,8.101,190,6.409,220,2.239,415,5.002,457,3.021,467,4.065,621,5.923,622,6.623]],["title/api/sql/Constructor/#st_mpolyfromtext",[191,6.101]],["text/api/sql/Constructor/#st_mpolyfromtext",[23,0.614,26,1.05,50,1.221,105,1.429,111,1.291,114,1.157,115,1.537,138,3.698,159,3.565,162,7.222,183,4.925,190,6.473,191,8.864,192,7.437,193,8.751,194,8.751,195,8.751,196,8.751,197,8.751,198,8.751,220,2.261,415,5.052,457,3.051,467,4.106,621,5.982,622,6.69]],["title/api/sql/Constructor/#st_point",[199,4.154]],["text/api/sql/Constructor/#st_point",[23,0.636,26,1.061,50,1.233,105,1.443,111,1.636,114,1.169,115,1.233,138,3.736,143,4.653,199,5.777,200,2.598,201,4.283,202,4.518,203,8.204,204,8.204,205,4.916,206,6.739,313,5.668,552,3.013,571,5.103,627,7.788,628,6.778,629,6.676,630,6.888]],["title/api/sql/Constructor/#st_pointfromtext",[207,5.957]],["text/api/sql/Constructor/#st_pointfromtext",[23,0.634,26,1.123,50,1.306,105,1.529,111,1.381,114,1.237,115,1.603,138,3.956,143,4.928,164,6.134,172,4.201,173,5.818,174,5.721,175,5.912,200,2.751,205,6.39,206,6.39,207,8.5,208,6.924,552,3.19]],["title/api/sql/Constructor/#st_polygonfromenvelope",[209,4.057]],["text/api/sql/Constructor/#st_polygonfromenvelope",[23,0.642,26,1.066,50,1.239,105,1.451,111,1.311,114,1.175,115,1.239,116,5.102,119,2.815,138,3.755,205,4.941,209,5.18,210,6.22,211,6.22,212,6.22,213,6.22,214,6.572,215,6.572,216,6.572,217,6.572,218,4.136,219,2.016,220,3.289,221,4.075,222,3.905,223,4.585,552,3.028]],["title/api/sql/Constructor/#st_polygonfromtext",[224,5.957]],["text/api/sql/Constructor/#st_polygonfromtext",[23,0.635,26,1.094,50,1.272,105,1.489,111,1.345,114,1.205,115,1.577,119,2.888,123,5.834,138,3.852,142,7.141,143,4.799,172,4.091,173,5.724,174,5.572,175,5.758,224,8.401,225,4.455,226,5.011,227,7.914,228,6.382,229,6.382,552,3.107]],["title/api/sql/Function/",[51,2.477]],["text/api/sql/Function/",[2,0.159,8,0.51,17,0.26,21,0.202,22,0.601,23,0.641,26,1.152,44,0.368,50,1.347,51,0.254,57,0.126,62,0.456,65,0.162,75,0.516,89,0.169,90,0.379,96,0.181,101,0.287,102,0.569,105,1.72,106,2.039,108,0.211,109,0.583,110,2.02,111,1.604,113,0.849,114,1.392,115,1.521,119,2.044,120,0.322,121,1.184,122,3.316,126,0.236,127,0.91,128,0.78,129,0.464,130,0.625,132,1.138,133,1.786,135,2.748,136,2.819,139,0.206,141,1.185,145,0.308,153,0.308,158,3.298,159,0.529,160,0.301,161,1.675,166,0.456,171,2.892,172,0.4,176,0.597,177,2.891,178,3.772,179,0.756,182,1.013,183,1.528,186,3.703,187,2.347,188,1.38,192,0.262,199,0.975,200,2.708,201,1.158,202,1.221,219,2.891,220,3.187,221,2.488,226,0.253,230,0.91,231,0.625,232,0.936,233,0.365,234,0.631,235,1.096,236,1.046,237,2.598,238,1.13,239,2.758,240,0.835,241,0.245,242,2.004,243,0.665,244,1.082,245,0.219,246,0.945,247,0.66,248,1,249,2.829,250,0.66,251,1.126,252,2.087,253,3.249,254,0.851,255,0.322,256,0.869,257,0.918,258,0.925,259,1.68,260,0.888,261,0.999,262,0.34,263,0.682,264,0.64,265,0.66,266,0.419,267,0.625,268,0.574,269,0.597,270,0.537,271,1.082,272,0.365,273,0.166,274,1.341,275,0.807,276,0.961,277,0.961,278,1.978,279,0.585,280,0.34,281,0.157,282,0.34,283,1.65,284,0.983,285,0.34,286,0.34,287,1.045,288,0.34,289,0.574,290,0.34,291,0.34,292,0.34,294,0.851,295,0.66,296,0.771,297,0.322,298,0.259,299,0.227,300,0.34,301,1.429,302,0.888,303,0.365,304,0.895,305,0.641,306,0.365,307,1.178,310,0.365,311,3.682,313,4.398,314,0.365,315,1.245,318,0.708,319,0.652,320,0.277,321,0.851,322,0.585,323,0.34,324,0.782,327,1.569,328,0.869,329,0.322,330,0.365,331,0.365,332,0.888,333,0.322,334,0.219,335,1.542,336,1.934,337,0.708,338,0.365,339,0.365,340,0.365,341,0.708,342,0.365,343,0.365,344,0.365,345,0.365,346,0.365,347,0.585,348,0.365,349,0.411,350,0.993,351,1.564,352,1.882,353,0.365,354,0.574,355,0.87,356,1.029,357,0.851,358,0.34,359,0.34,360,0.34,361,0.641,362,0.34,363,1.082,364,0.34,365,1.046,366,1.528,367,0.585,368,0.585,369,0.237,370,0.173,371,0.34,372,0.807,373,0.64,374,0.363,375,0.34,376,0.888,377,0.563,378,0.947,379,0.585,380,1.013,381,0.34,382,0.286,383,0.262,384,0.784,385,0.821,386,0.888,387,0.34,388,0.91,389,1.214,390,0.365,391,3.693,392,3.115,393,0.625,394,0.269,395,0.365,396,0.821,397,1.185,398,0.91,399,1.341,400,0.708,401,0.365,402,0.225,403,0.372,404,0.545,405,0.365,406,0.365,407,0.286,408,0.34,409,0.34,410,0.365,411,0.979,412,0.418,413,0.286,414,0.365,415,0.972,416,1.418,417,0.625,418,0.365,419,0.365,420,0.993,421,0.365,422,0.851,423,1.151,424,0.563,425,0.585,426,0.34,427,0.61,428,0.365,429,0.66,430,0.523,431,0.465,432,0.625,433,1.181,437,0.322,438,0.286,439,0.365,440,0.34,441,0.365,442,0.33,443,0.365,444,0.888,445,0.322,446,0.419,447,0.365,449,0.563,450,0.46,451,0.641,452,0.482,453,0.66,454,0.91,455,0.202,456,0.25,457,0.311,458,0.66,459,0.666,460,0.66,461,0.365,462,0.91,463,1.221,464,0.199,465,0.66,466,0.66,467,0.419,468,0.34,469,0.365,470,0.262,471,0.256,472,0.308,473,0.308,474,0.596,475,0.219,476,0.137,477,0.34,478,0.262,479,0.34,480,0.24,481,0.554,482,0.34,483,0.34,484,0.34,485,0.563,486,0.452,487,0.485,488,0.283,489,0.177,490,0.277,491,0.235,492,0.277,493,0.277,494,0.585,495,0.34,496,0.314,497,0.888,498,0.682,499,0.365,500,1.567,501,0.545,502,0.961,503,0.365,504,0.585,505,0.34,506,0.34,507,0.888,508,0.61,509,0.365,510,0.625,511,0.365,512,0.365,513,0.625,514,0.365,515,0.365,516,0.308,517,0.625,518,0.365,519,0.365,520,0.365,538,0.52,543,0.635,552,2.745,593,0.201,594,0.382,608,1.316,620,0.703,629,1.013,631,0.405,632,0.961,633,0.961,634,0.786,635,1.337,636,0.786,637,0.786,638,0.961,639,0.322,640,0.742,641,0.294,642,0.405,643,0.706,644,0.405,645,0.405,646,0.742,647,0.786,648,1.483,649,0.786,650,0.786,651,1.564,652,0.405,653,0.652,654,0.405,655,0.405,656,0.786,657,0.405,658,0.786,659,0.786,660,0.405,661,0.869,662,0.365,663,0.365,664,0.365,665,0.993,666,0.502,667,0.625,668,0.365,669,0.554,670,0.365,671,0.314,672,0.869,673,0.365,674,0.625,675,0.526,676,0.262,677,0.365,678,0.625,679,0.365,680,1.432,681,0.66,682,2.441,683,0.66,684,0.585,685,0.625,686,0.851,687,0.365,688,0.365,689,0.869,690,0.365,691,0.365,692,0.365,693,0.993,694,1.145,695,0.308,696,0.359,697,1.013,698,0.76,699,0.934,700,0.502,701,0.545,702,0.211,703,1.029,704,0.742,705,0.66,706,0.869,707,0.851,708,0.641,709,0.405,710,0.405,711,0.91,712,0.365,713,0.269,714,0.365,715,0.259,716,0.993,717,0.322,718,1.145,719,0.405,720,0.296,721,0.405,722,0.405,723,0.405,724,0.405,725,0.405,726,0.405,727,0.405,728,0.405,729,0.682,730,0.375,731,0.786,732,0.405,733,0.61,734,0.405,735,0.405,736,1.509,737,0.308,738,0.75,739,0.405,740,0.405,741,0.365,742,0.786,743,0.405,744,0.405,745,0.188,746,0.405,747,0.405,748,0.314,749,0.314,750,0.262,751,0.34,752,0.277,753,0.259,754,0.322,755,0.682,756,0.742,757,0.682,758,0.405,759,0.405,760,0.682,761,0.352,762,0.269,763,0.365,764,0.405,765,0.993,766,0.365,767,0.405,768,0.405,769,0.405,770,0.786,771,0.786,772,0.405,773,0.405,774,0.869,775,0.269,776,1.082,777,0.365,778,0.365,779,0.869,780,0.296,781,0.269,782,0.66,783,0.365,784,0.34,785,0.365,786,0.625,787,0.365,788,0.365,789,1.245,790,0.365,791,0.405,792,0.405,793,0.742,794,0.786,795,1.625,796,2.173,797,3.397,798,0.405,799,0.405,800,1.145,801,0.786,802,0.405,803,2.665,804,0.786,805,2.392,806,0.405,807,2.665,808,3.17,809,1.145,810,1.145,811,0.405,812,0.786,813,0.405,814,3.68,815,3.046,816,1.08,817,1.08,818,1.08,819,1.08,820,1.08,821,0.934,822,0.273,823,0.216,824,0.405,825,0.485,826,0.444,827,0.245,828,1.08,829,0.405,830,0.993]],["title/api/sql/Function/#st_3ddistance",[230,6.101]],["text/api/sql/Function/#st_3ddistance",[23,0.608,26,1.154,50,1.342,105,1.571,106,1.855,111,1.419,114,1.272,115,1.342,122,4.347,141,4.199,178,3.308,230,8.179,231,6.733,232,5.349,233,7.638,234,3.608,235,4.411,236,3.704,237,2.904,238,4.548,239,4.429]],["title/api/sql/Function/#st_addpoint",[240,5.604]],["text/api/sql/Function/#st_addpoint",[23,0.619,26,0.894,44,3.07,50,1.039,105,1.216,106,1.436,110,2.029,111,1.464,114,0.984,115,1.384,158,4.611,171,2.823,179,2.751,200,3.5,219,3.135,220,3.418,240,6.382,241,3.961,242,2.658,243,2.419,244,6.382,245,3.549,246,3.441,247,7.342,248,3.639,249,6.701,250,7.342,251,7.963,252,2.101,253,6.164,552,2.538]],["title/api/sql/Function/#st_area",[254,5.711]],["text/api/sql/Function/#st_area",[23,0.586,26,1.229,50,1.428,105,1.672,106,1.974,111,1.511,114,1.353,115,1.428,122,4.19,237,3.091,239,3.881,254,7.949,255,7.167,552,3.489]],["title/api/sql/Function/#st_asbinary",[256,5.828]],["text/api/sql/Function/#st_asbinary",[23,0.581,26,1.2,50,1.395,62,5.113,105,1.634,106,1.929,110,1.704,111,1.476,114,1.322,115,1.395,122,4.133,237,3.02,239,3.792,256,8.001,257,4.489,258,5.499,259,5.065,608,6.432]],["title/api/sql/Function/#st_asewkb",[260,5.957]],["text/api/sql/Function/#st_asewkb",[8,2.679,23,0.55,26,1.061,50,1.233,62,4.518,75,2.711,105,1.443,106,1.704,110,2.065,111,1.788,114,1.169,115,1.233,122,3.831,166,5.668,183,6.242,237,2.669,239,3.351,257,3.967,258,4.859,259,4.476,260,7.581,261,6.579,262,6.539,263,3.58,264,4.357,265,6.539,266,4.147,267,6.188,268,5.684,269,5.912,270,5.321,274,5.793,608,5.684,631,7.788]],["title/api/sql/Function/#st_asewkt",[271,5.604]],["text/api/sql/Function/#st_asewkt",[8,2.679,23,0.55,26,1.061,50,1.233,75,2.711,105,1.443,106,1.704,110,2.065,111,1.788,114,1.169,115,1.233,122,3.831,133,3.833,159,4.518,172,3.967,183,6.242,237,2.669,239,3.351,257,3.967,258,4.859,259,4.476,261,6.579,263,3.58,264,4.357,265,6.539,266,4.147,267,6.188,268,5.684,269,5.912,270,5.321,271,7.131,272,7.019,273,3.186,274,5.793]],["title/api/sql/Function/#st_asgeojson",[275,5.412]],["text/api/sql/Function/#st_asgeojson",[23,0.582,26,1.207,50,1.403,105,1.643,106,1.94,110,1.714,111,1.485,114,1.33,115,1.403,122,4.147,128,3.282,139,4.515,237,3.038,239,3.814,259,5.094,275,7.455,552,3.429]],["title/api/sql/Function/#st_asgml",[276,6.446]],["text/api/sql/Function/#st_asgml",[23,0.582,26,1.207,50,1.403,105,1.643,106,1.94,110,1.714,111,1.485,113,4.173,114,1.33,115,1.403,122,4.147,128,3.282,145,6.729,237,3.038,239,3.814,259,5.094,276,8.88]],["title/api/sql/Function/#st_askml",[277,6.446]],["text/api/sql/Function/#st_askml",[23,0.582,26,1.207,50,1.403,105,1.643,106,1.94,110,1.714,111,1.485,113,4.173,114,1.33,115,1.403,122,4.147,128,3.282,153,6.729,237,3.038,239,3.814,259,5.094,277,8.88]],["title/api/sql/Function/#st_astext",[278,4.79]],["text/api/sql/Function/#st_astext",[23,0.579,26,1.194,50,1.387,105,1.624,106,1.918,110,1.695,111,1.468,114,1.315,115,1.387,122,4.119,128,3.245,172,4.463,237,3.003,239,3.77,257,4.463,258,5.467,259,5.036,278,6.553,552,3.39]],["title/api/sql/Function/#st_azimuth",[279,5.711]],["text/api/sql/Function/#st_azimuth",[23,0.636,26,1.072,50,1.246,105,1.458,106,1.722,111,1.318,114,1.181,115,1.246,199,5.32,200,3.578,220,3.51,242,3.188,252,2.519,279,5.852,280,6.606,281,3.057,282,6.606,283,4.095,284,4.291,285,6.606,286,6.606,287,5.546,288,6.606,552,3.043]],["title/api/sql/Function/#st_boundary",[289,5.604]],["text/api/sql/Function/#st_boundary",[23,0.562,26,1.111,50,1.292,105,1.512,106,1.786,109,4.156,110,1.945,111,1.367,114,1.224,115,1.292,158,3.586,171,3.511,219,3.182,220,3.198,252,2.613,289,5.955,290,6.851,291,6.851,292,6.851,552,3.156,632,6.851,633,6.851]],["title/api/sql/Function/#st_buffer",[294,5.711]],["text/api/sql/Function/#st_buffer",[23,0.593,26,1.148,50,1.334,105,1.562,106,1.844,111,1.411,114,1.265,115,1.334,122,4.023,200,2.811,219,2.17,234,4.368,237,2.888,239,3.626,294,7.631,295,8.613,296,5.675,297,6.696,298,5.384,299,4.715,300,7.076,301,5.035,552,3.26]],["title/api/sql/Function/#st_buildarea",[302,5.957]],["text/api/sql/Function/#st_buildarea",[23,0.631,105,1.329,106,1.569,110,1.793,111,1.201,114,1.076,115,1.135,121,2.906,133,3.53,136,3.947,158,3.152,177,3.785,220,3.185,237,2.458,302,7.193,303,6.464,304,4.33,305,5.849,306,6.464,310,6.464,313,6.3,315,7.784,318,8.356,336,4.376,352,2.644,634,9.27,635,9.789,636,9.27,637,9.27]],["title/api/sql/Function/#st_centroid",[638,6.446]],["text/api/sql/Function/#st_centroid",[23,0.585,26,1.221,50,1.42,105,1.662,106,1.963,111,1.502,114,1.346,115,1.42,122,4.176,200,2.991,237,3.073,239,3.858,552,3.469,638,8.941,639,7.125]],["title/api/sql/Function/#st_collect",[307,6.101]],["text/api/sql/Function/#st_collect",[23,0.653,105,1.237,106,1.461,110,1.918,111,1.118,114,1.327,115,1.4,136,4.497,141,3.307,158,4.642,307,7.028,350,7.674,351,9.164,352,3.261,355,3.222,389,5.956,640,6.297,641,2.492,642,6.674,643,5.456,644,6.674,645,6.674,646,6.297,647,8.844,648,10.562,649,8.844,650,8.844]],["title/api/sql/Function/#st_collectionextract",[651,6.662]],["text/api/sql/Function/#st_collectionextract",[23,0.639,105,1.171,106,1.866,110,1.866,111,1.428,114,0.948,115,1,119,2.272,133,3.11,136,4.109,158,2.777,171,2.718,177,2.076,178,2.466,186,5.312,200,2.108,219,2.196,220,3.471,237,2.922,242,2.56,311,4.541,314,5.695,336,3.855,352,2.329,397,3.131,399,4.7,423,6.616,451,5.153,474,3.289,594,2.844,651,8.964,652,6.318,653,3.598,654,6.318,655,6.318,656,8.526,657,6.318,658,8.526,659,8.526,660,6.318]],["title/api/sql/Function/#st_convexhull",[661,5.828]],["text/api/sql/Function/#st_convexhull",[23,0.584,26,1.214,50,1.411,105,1.652,106,1.951,111,1.493,114,1.338,115,1.411,122,4.161,237,3.055,239,3.836,552,3.449,661,8.056,662,8.036,663,8.036,664,8.036]],["title/api/sql/Function/#st_difference",[665,6.662]],["text/api/sql/Function/#st_difference",[23,0.593,105,1.329,106,2.029,110,1.987,111,1.201,114,1.076,115,1.135,119,3.694,135,5.808,141,3.553,161,4.899,178,4.879,220,3.378,235,3.733,236,4.053,237,2.458,238,3.849,352,2.644,384,3.79,620,3.397,665,8.044,666,4.581]],["title/api/sql/Function/#st_distance",[319,4.372]],["text/api/sql/Function/#st_distance",[23,0.611,26,1.174,50,1.364,105,1.597,106,1.886,111,1.443,114,1.293,115,1.364,122,4.379,234,3.669,235,4.485,236,3.766,237,2.953,238,4.624,239,4.473,319,5.921,320,5.887,552,3.333]],["title/api/sql/Function/#st_dump",[667,6.101]],["text/api/sql/Function/#st_dump",[23,0.537,26,1.01,50,1.174,65,2.961,105,1.374,106,2.073,110,2.197,111,1.242,114,1.112,115,1.174,119,2.666,158,3.258,171,3.189,200,3.79,252,2.374,311,5.856,313,6.379,389,4.992,391,7.513,392,6.71,423,5.752,485,5.315,552,2.867,653,5.393,667,5.89,668,6.682,669,5.226,670,6.682,671,5.752,672,5.627,673,6.682]],["title/api/sql/Function/#st_dumppoints",[674,6.101]],["text/api/sql/Function/#st_dumppoints",[23,0.554,26,1.077,50,1.252,105,1.466,106,1.731,110,1.908,111,1.324,114,1.187,115,1.252,158,3.476,171,3.402,200,3.941,219,3.086,220,3.582,252,2.532,552,3.059,674,6.284,675,3.635,676,5.115,677,7.128]],["title/api/sql/Function/#st_endpoint",[678,6.101]],["text/api/sql/Function/#st_endpoint",[23,0.571,26,1.154,50,1.342,105,1.571,106,1.855,110,1.639,111,1.419,114,1.272,115,1.342,158,3.724,171,3.646,200,2.827,242,3.433,252,2.713,433,5.552,552,3.278,678,6.733,679,7.638,680,6.733,681,7.115,682,6.075,683,7.115,684,6.303,685,6.733,686,7.657,687,7.638]],["title/api/sql/Function/#st_envelope",[321,5.711]],["text/api/sql/Function/#st_envelope",[23,0.585,26,1.221,50,1.42,105,1.662,106,1.963,108,4.668,109,4.567,111,1.502,114,1.346,115,1.42,122,4.176,237,3.073,239,3.858,321,7.921,552,3.469]],["title/api/sql/Function/#st_exteriorring",[322,5.711]],["text/api/sql/Function/#st_exteriorring",[23,0.54,26,1.02,50,1.185,105,1.387,106,2.085,110,2.027,111,1.254,114,1.123,115,1.185,119,3.426,128,2.771,158,3.29,171,3.22,177,3.131,179,3.139,219,3.214,220,3.471,252,2.397,283,3.896,296,5.04,322,5.568,323,6.285,324,5.114,336,4.567,552,2.895,688,6.747]],["title/api/sql/Function/#st_flipcoordinates",[328,5.828]],["text/api/sql/Function/#st_flipcoordinates",[23,0.568,26,1.142,50,1.327,75,2.918,105,1.553,106,1.834,110,1.977,111,1.404,114,1.258,115,1.327,121,3.396,177,3.36,200,3.411,201,4.61,202,4.862,219,2.633,242,3.396,252,2.684,327,5.488,328,6.362,329,6.66,330,7.554,331,7.554,552,3.242]],["title/api/sql/Function/#st_force_2d",[332,5.957]],["text/api/sql/Function/#st_force_2d",[23,0.635,105,1.329,110,1.387,111,1.201,114,1.076,115,1.135,133,3.53,136,3.947,158,3.152,177,3.046,178,2.799,186,3.297,201,3.944,202,4.16,219,2.797,220,3.013,231,5.698,237,2.458,252,2.296,259,4.122,278,4.474,315,7.784,332,7.193,333,5.698,334,3.88,335,2.497,336,5.657,337,8.356,338,6.464,339,6.464,340,6.464,341,8.356,342,6.464,343,6.464,344,6.464,345,6.464,346,6.464,352,2.644]],["title/api/sql/Function/#st_geohash",[347,5.711]],["text/api/sql/Function/#st_geohash",[23,0.643,105,1.512,106,1.786,110,1.945,111,1.367,114,1.224,115,1.292,127,8.664,130,7.992,132,5.15,158,3.586,186,3.751,242,3.306,347,6.069,348,7.354,349,2.261,350,7.079,351,7.079,352,3.008,353,7.354,608,5.955]],["title/api/sql/Function/#st_geometryn",[354,5.604]],["text/api/sql/Function/#st_geometryn",[23,0.578,26,1.066,50,1.239,105,1.451,106,2.145,110,2.07,111,1.311,114,1.175,115,1.239,132,4.941,135,4.857,158,3.44,177,2.572,178,3.826,186,3.598,187,4.541,200,2.611,219,2.016,220,2.296,252,2.507,283,4.075,284,4.27,354,5.713,355,3.778,356,5.43,357,5.822,358,6.572,359,6.572,360,6.572,361,6.384,362,6.572,363,5.713,364,6.572,365,4.541,366,5,552,3.028]],["title/api/sql/Function/#st_geometrytype",[689,5.828]],["text/api/sql/Function/#st_geometrytype",[23,0.578,26,1.187,50,1.38,105,1.615,106,1.907,110,1.685,111,1.459,114,1.308,115,1.38,122,4.105,128,3.226,237,2.986,239,3.749,552,3.37,594,2.907,669,6.142,689,7.946,690,7.854,691,7.854,692,7.854]],["title/api/sql/Function/#st_interiorringn",[367,5.711]],["text/api/sql/Function/#st_interiorringn",[23,0.537,26,0.882,50,1.026,105,1.201,106,1.898,110,1.89,111,1.085,114,0.972,115,1.026,119,3.118,132,4.089,135,5.548,158,2.847,171,3.73,177,3.907,178,4.594,186,4.798,219,3.16,220,3.284,242,2.625,252,2.074,283,3.372,324,4.426,336,3.952,356,4.494,363,6.328,367,4.818,368,4.818,369,3.794,370,2.772,371,5.439,552,2.506]],["title/api/sql/Function/#st_intersection",[543,4.259]],["text/api/sql/Function/#st_intersection",[23,0.612,26,1.18,50,1.372,105,1.606,106,1.896,110,1.676,111,1.451,114,1.3,115,1.372,122,4.389,236,3.788,237,2.969,238,4.651,239,4.489,384,4.579,543,5.787,552,3.352]],["title/api/sql/Function/#st_isclosed",[372,5.412]],["text/api/sql/Function/#st_isclosed",[23,0.571,26,1.154,50,1.342,102,3.249,105,1.571,106,1.855,110,1.639,111,1.419,114,1.272,115,1.342,158,3.724,171,3.646,200,2.827,219,2.855,220,3.019,246,4.444,249,5.413,252,2.713,372,5.973,373,3.01,374,3.918,375,7.115,488,3.047,552,3.278]],["title/api/sql/Function/#st_isempty",[376,5.957]],["text/api/sql/Function/#st_isempty",[23,0.584,26,1.214,50,1.411,105,1.652,110,2.052,111,1.493,114,1.338,115,1.411,122,4.161,133,4.388,237,3.055,239,3.836,376,8.234,377,4.388,378,5.695]],["title/api/sql/Function/#st_isring",[379,5.711]],["text/api/sql/Function/#st_isring",[23,0.568,26,1.142,50,1.327,105,1.553,106,1.834,110,1.621,111,1.404,114,1.258,115,1.327,158,3.684,171,3.606,219,2.958,220,3.454,249,5.354,252,2.684,372,5.908,373,3.632,379,6.234,380,5.727,381,7.037,552,3.242]],["title/api/sql/Function/#st_issimple",[380,5.246]],["text/api/sql/Function/#st_issimple",[23,0.581,26,1.2,50,1.395,105,1.634,109,4.489,111,1.476,114,1.322,115,1.395,122,4.133,200,2.94,237,3.02,239,3.792,377,4.338,380,7.201,382,6.213,383,5.701,384,4.657,552,3.409]],["title/api/sql/Function/#st_isvalid",[385,5.504]],["text/api/sql/Function/#st_isvalid",[23,0.584,26,1.214,50,1.411,105,1.652,110,1.724,111,1.493,114,1.338,115,1.411,122,4.161,237,3.055,239,3.836,257,4.541,304,5.382,377,4.388,385,7.608,552,3.449]],["title/api/sql/Function/#st_length",[386,5.957]],["text/api/sql/Function/#st_length",[23,0.586,26,1.229,50,1.428,105,1.672,106,1.974,111,1.511,114,1.353,115,1.428,122,4.19,237,3.091,239,3.881,386,8.291,387,7.573,552,3.489]],["title/api/sql/Function/#st_linefrommultipoint",[388,6.101]],["text/api/sql/Function/#st_linefrommultipoint",[23,0.641,105,1.429,110,1.491,111,1.291,113,3.63,114,1.157,115,1.221,126,2.316,136,4.134,158,3.389,171,4.177,237,2.642,278,4.81,311,5.66,313,6.472,352,2.843,388,7.715,389,5.192,390,6.949,391,7.622,392,6.807]],["title/api/sql/Function/#st_lineinterpolatepoint",[693,6.662]],["text/api/sql/Function/#st_lineinterpolatepoint",[23,0.632,26,0.981,50,1.141,105,1.335,106,1.577,110,1.393,111,1.207,114,1.081,115,1.141,136,3.068,161,3.807,171,4.001,177,2.368,179,3.021,200,3.435,219,1.855,220,2.727,221,3.75,235,3.75,252,2.307,296,4.852,301,5.556,693,8.068,694,10.296,695,5.469,696,3.293,697,6.353,698,4.784,699,7.584,700,4.603,701,4.998,702,3.75,703,4.998,704,6.798,705,6.049,706,5.469,707,5.359,708,5.876,709,7.205,710,7.205]],["title/api/sql/Function/#st_linemerge",[711,6.101]],["text/api/sql/Function/#st_linemerge",[22,2.751,23,0.521,101,1.595,105,1.529,106,2.398,110,1.958,111,1.381,115,1.306,171,3.548,179,3.458,182,7.806,237,2.826,264,4.614,304,4.979,305,6.726,327,4.426,357,6.134,378,5.268,411,4.709,552,3.19,711,8.044,712,7.433,713,5.476,714,7.433,715,5.268]],["title/api/sql/Function/#st_linesubstring",[716,6.662]],["text/api/sql/Function/#st_linesubstring",[23,0.633,26,0.929,50,1.08,105,1.264,106,1.493,110,1.319,111,1.143,114,1.024,115,1.08,121,2.764,136,2.905,161,3.605,171,4.314,219,1.757,220,2.941,221,4.671,235,3.551,242,2.764,246,3.578,252,2.184,301,5.992,374,3.155,411,3.173,430,3.118,452,2.875,697,4.661,698,4.53,699,5.564,700,4.358,701,4.733,703,4.733,704,6.436,705,5.728,706,6.812,707,5.074,708,5.564,716,7.786,717,5.421,718,10.028,719,6.822,720,4.979,721,6.822,722,6.822,723,6.822,724,6.822,725,6.822,726,6.822,727,6.822,728,6.822]],["title/api/sql/Function/#st_makepolygon",[729,6.662]],["text/api/sql/Function/#st_makepolygon",[23,0.631,51,2.144,105,1.232,110,1.285,111,1.113,114,0.997,115,1.052,119,3.791,158,3.876,171,2.859,177,3.707,187,6.863,188,7.19,219,3.076,226,4.146,263,3.055,349,1.842,352,2.45,365,6.117,366,6.736,643,4.099,646,6.27,729,5.766,730,3.168,731,8.819,732,6.645,733,3.539,734,6.645,735,6.645]],["title/api/sql/Function/#st_makevalid",[736,5.504]],["text/api/sql/Function/#st_makevalid",[2,1.224,21,3.016,22,2.017,23,0.636,26,0.823,50,0.957,57,1.881,75,2.105,105,1.12,106,1.323,110,2.055,111,1.386,114,0.907,115,1.31,121,2.449,126,1.816,136,4.017,161,3.195,171,4.059,176,4.589,200,2.017,219,2.736,237,2.836,242,2.449,259,3.474,263,2.779,352,2.229,361,4.93,373,2.939,378,5.286,399,4.497,411,2.812,424,2.976,467,3.219,481,4.261,552,2.338,593,2.995,620,3.92,697,4.13,698,4.014,730,2.881,736,7.617,737,4.589,738,5.421,739,6.045,740,6.045,741,5.449,742,8.274,743,6.045,744,6.045,745,2.812,746,6.045,747,6.045,748,4.691,749,4.691,750,3.91,751,5.076,752,4.13,753,3.862,754,4.803]],["title/api/sql/Function/#st_minimumboundingcircle",[755,6.662]],["text/api/sql/Function/#st_minimumboundingcircle",[23,0.571,26,1.154,50,1.342,105,1.571,106,1.855,110,1.991,111,1.419,114,1.272,115,1.342,119,3.047,129,3.433,158,3.724,219,2.969,220,2.485,538,3.851,632,7.115,633,7.115,703,5.879,755,7.352,756,7.995,757,7.352,758,8.474,759,8.474]],["title/api/sql/Function/#st_minimumboundingradius",[760,6.662]],["text/api/sql/Function/#st_minimumboundingradius",[23,0.568,26,1.142,50,1.327,105,1.553,106,1.834,110,1.977,111,1.404,114,1.258,115,1.327,158,3.684,200,2.796,219,2.958,220,2.458,538,4.647,632,7.037,633,7.037,703,5.815,756,7.908,757,7.272,760,7.272,761,7.272,762,5.566,763,7.554,764,8.381]],["title/api/sql/Function/#st_multi",[765,6.662]],["text/api/sql/Function/#st_multi",[23,0.64,105,1.473,106,1.74,110,2.084,111,1.331,114,1.193,115,1.258,121,3.221,136,4.214,141,3.939,158,3.494,160,5.913,219,2.775,307,6.316,352,2.931,355,3.837,389,5.353,420,6.897,452,3.35,640,7.5,641,2.968,765,8.586,766,7.164,767,7.949]],["title/api/sql/Function/#st_ndims",[398,6.101]],["text/api/sql/Function/#st_ndims",[2,1.381,8,3.087,23,0.596,26,1.222,50,1.588,89,2.846,105,1.264,106,1.493,110,2.197,111,1.143,114,1.347,115,1.421,158,2.998,177,3.295,178,3.503,219,2.311,252,2.873,335,3.491,398,7.13,399,6.675,400,8.088,401,6.149,402,3.784,403,4.251,404,6.225,405,6.149,406,6.149,407,4.809,408,5.728,409,5.728,410,6.149,411,3.173,412,2.494,413,4.809,414,6.149,415,4.47,416,4.594,417,7.13,418,6.149,419,6.149,420,7.786,421,6.149]],["title/api/sql/Function/#st_normalize",[393,6.101]],["text/api/sql/Function/#st_normalize",[23,0.633,105,1.408,106,1.662,110,1.86,111,1.272,113,3.576,114,1.14,115,1.203,119,2.731,121,3.078,136,4.095,161,4.014,219,3.124,220,3.584,271,5.544,304,4.586,336,4.635,352,2.801,393,6.036,394,5.044,395,6.846]],["title/api/sql/Function/#st_npoints",[396,5.504]],["text/api/sql/Function/#st_npoints",[23,0.589,105,1.692,106,1.997,110,1.765,111,1.529,115,1.445,122,4.219,200,3.045,237,3.128,239,3.927,396,7.715,552,3.53]],["title/api/sql/Function/#st_numgeometries",[422,5.711]],["text/api/sql/Function/#st_numgeometries",[23,0.575,105,1.597,106,2.444,110,2.296,111,1.443,115,1.364,219,2.219,237,2.953,327,5.581,357,6.409,397,5.152,422,7.734,423,6.685,424,4.241,552,3.333]],["title/api/sql/Function/#st_numinteriorrings",[425,5.711]],["text/api/sql/Function/#st_numinteriorrings",[23,0.552,26,1.072,50,1.246,105,1.458,106,1.722,110,1.902,111,1.318,114,1.181,115,1.246,119,3.536,158,3.458,177,3.692,186,5.166,219,3.082,220,3.46,252,2.519,324,5.376,368,5.852,397,3.898,425,5.852,426,6.606,552,3.043]],["title/api/sql/Function/#st_pointn",[427,5.957]],["text/api/sql/Function/#st_pointn",[23,0.632,26,0.981,50,1.141,105,1.335,106,2.035,110,1.991,111,1.207,114,1.081,115,1.141,133,3.546,135,3.57,136,3.959,158,3.167,171,4.681,177,3.575,178,2.812,187,4.18,200,3.435,219,2.651,220,2.113,246,3.779,248,3.996,249,4.603,283,3.75,352,2.656,356,4.998,363,5.259,424,3.546,427,5.59,428,6.494,429,6.049,430,3.293,431,4.262,432,5.725,433,4.721,768,7.205]],["title/api/sql/Function/#st_pointonsurface",[437,6.101]],["text/api/sql/Function/#st_pointonsurface",[105,1.387,106,1.638,111,1.254,114,1.123,115,1.747,133,3.684,177,2.46,186,5.562,200,3.179,219,2.699,220,3.575,278,6.885,311,5.074,438,5.277,439,6.747,440,6.285,441,6.747,442,6.105,443,6.747,769,7.485,770,9.529,771,9.529,772,7.485,773,7.485]],["title/api/sql/Function/#st_precisionreduce",[774,5.828]],["text/api/sql/Function/#st_precisionreduce",[23,0.585,26,1.106,50,1.285,105,1.504,110,1.57,111,1.359,114,1.218,115,1.285,122,3.931,237,2.782,239,3.492,242,3.289,335,3.49,366,6.404,397,4.022,412,2.967,433,5.318,552,3.14,629,7.762,774,7.61,775,5.39,776,8.292,777,7.315,778,7.315]],["title/api/sql/Function/#st_removepoint",[449,5.504]],["text/api/sql/Function/#st_removepoint",[23,0.579,26,1.072,50,1.246,105,1.458,106,1.722,110,1.902,111,1.647,114,1.181,115,1.246,158,3.458,179,3.299,200,2.625,219,2.979,220,3.295,242,3.188,243,2.901,244,7.177,248,4.364,249,6.282,252,2.519,433,5.155,449,5.641,450,5.76,451,6.417,452,3.316,453,8.256,552,3.043]],["title/api/sql/Function/#st_reverse",[444,5.957]],["text/api/sql/Function/#st_reverse",[23,0.64,105,1.422,106,1.679,110,1.484,111,1.285,114,1.151,115,1.215,133,3.776,135,4.796,136,4.121,158,3.372,171,3.301,177,3.659,178,3.778,187,5.615,219,2.492,220,3.11,237,2.629,249,4.901,278,4.786,352,2.828,444,7.51,445,6.096,446,4.085,447,6.915]],["title/api/sql/Function/#st_setpoint",[454,6.101]],["text/api/sql/Function/#st_setpoint",[23,0.633,105,1.305,110,1.772,111,1.179,113,3.315,114,1.056,115,1.115,136,3.9,158,4.026,171,4.64,177,2.313,200,3.73,219,3.005,220,3.508,242,2.853,243,3.754,248,3.905,352,2.596,355,3.398,356,4.884,429,5.911,431,4.164,432,5.594,433,4.613,454,7.279,455,3.512,456,4.343]],["title/api/sql/Function/#st_setsrid",[274,5.711]],["text/api/sql/Function/#st_setsrid",[17,1.948,23,0.596,26,1.167,50,1.356,105,1.588,110,1.657,111,1.435,114,1.286,115,1.356,122,4.063,183,6.62,237,2.936,239,3.686,248,4.752,274,7.708,457,3.391,458,7.194,459,3.85,460,7.194,461,7.723,608,6.253]],["title/api/sql/Function/#st_simplifypreservetopology",[779,5.828]],["text/api/sql/Function/#st_simplifypreservetopology",[23,0.602,102,3.856,105,1.512,110,1.945,111,1.367,115,1.292,121,3.306,122,3.944,220,2.393,237,2.796,239,3.511,301,4.875,311,4.345,352,3.008,397,4.043,399,6.069,552,3.156,672,7.635,738,5.346,779,7.635,780,5.955,781,5.418,782,8.445,783,7.354,784,6.851,785,7.354]],["title/api/sql/Function/#st_srid",[462,6.101]],["text/api/sql/Function/#st_srid",[17,1.993,23,0.579,26,1.194,50,1.387,105,1.624,106,1.918,110,1.695,111,1.468,114,1.315,115,1.387,122,4.119,183,5.598,237,3.003,239,3.77,458,7.357,459,3.937,460,7.357,462,8.346,608,6.396]],["title/api/sql/Function/#st_startpoint",[786,6.101]],["text/api/sql/Function/#st_startpoint",[23,0.571,26,1.154,50,1.342,105,1.571,106,1.855,110,1.639,111,1.419,114,1.272,115,1.342,158,3.724,171,3.646,200,2.827,242,3.433,252,2.713,552,3.278,680,6.733,681,7.115,682,6.075,683,7.115,684,6.303,685,6.733,686,6.303,696,3.873,707,6.303,786,6.733,787,7.638,788,7.638]],["title/api/sql/Function/#st_subdivide",[789,6.446]],["text/api/sql/Function/#st_subdivide",[23,0.567,26,0.835,50,0.971,105,0.742,106,0.876,110,1.186,111,0.67,114,0.92,115,0.971,132,2.526,158,2.695,186,4.548,220,1.798,221,4.69,242,1.622,249,3.918,252,1.964,253,6.351,311,5.784,313,7.084,355,1.932,391,7.704,392,6.724,397,1.983,498,3.473,675,1.84,680,3.18,682,5.345,733,2.131,789,5.149,790,3.607,791,4.002,792,4.002,793,3.776,794,6.132,795,8.12,796,8.324,797,9.467,798,4.002,799,4.002,800,7.455,801,6.132,802,4.002,803,10.205,804,6.132,805,9.892,806,4.002,807,10.205,808,10.678,809,7.455,810,7.455,811,4.002,812,6.132,813,4.002,814,7.816,815,7.015,816,3.776,817,3.776,818,3.776,819,3.776,820,3.776]],["title/api/sql/Function/#st_subdivideexplode",[821,6.262]],["text/api/sql/Function/#st_subdivideexplode",[23,0.649,101,0.929,102,1.841,105,0.89,106,1.051,110,1.883,111,0.804,114,0.72,115,1.113,132,3.03,136,3.896,158,2.11,186,5.267,220,2.683,221,5.817,249,5.845,253,7.877,311,5.951,349,1.948,352,2.591,411,2.233,412,1.755,675,2.207,680,5.584,682,7.294,733,2.557,789,4.031,793,4.53,814,9.695,815,9.048,816,6.631,817,6.631,818,6.631,819,6.631,820,6.631,821,5.732,822,3.233,823,2.557,824,4.801,825,4.336,826,3.967,827,2.899]],["title/api/sql/Function/#st_symdifference",[828,7.244]],["text/api/sql/Function/#st_symdifference",[23,0.605,105,1.259,106,1.958,110,1.73,111,1.138,114,1.019,115,1.075,119,3.217,135,5.27,141,3.365,161,4.728,177,3.729,178,4.962,192,4.393,235,3.535,236,2.969,237,2.328,238,3.645,352,2.504,384,3.589,457,2.688,620,3.217,666,4.339,828,8.442,829,6.792]],["title/api/sql/Function/#st_transform",[463,4.454]],["text/api/sql/Function/#st_transform",[17,1.408,22,3.186,23,0.622,26,1.146,44,2.897,50,1.331,51,1.997,90,4.06,96,2.766,101,1.626,105,1.147,111,1.409,114,1.262,115,1.331,122,4.018,129,3.407,159,2.863,201,3.405,202,3.592,237,2.122,239,3.618,246,3.247,328,4.7,335,2.155,415,4.056,430,2.83,446,3.297,459,3.779,463,6.215,464,3.047,465,7.061,466,7.061,467,3.297,468,5.198,469,5.58,470,4.004,471,3.908,472,4.7,473,4.7,474,4.378,475,3.35,476,2.089,477,5.198,478,4.004,479,5.198,480,3.662,481,4.364,482,5.198,483,5.198,484,5.198,485,4.439,486,4.833,487,5.188,488,2.226,489,2.706,490,4.23,491,3.592,492,4.23,493,4.23,552,2.395]],["title/api/sql/Function/#st_union",[830,6.662]],["text/api/sql/Function/#st_union",[23,0.595,105,1.348,106,1.592,110,1.407,111,1.218,114,1.091,115,1.151,119,3.719,120,5.779,141,3.604,161,4.944,177,3.399,178,4.928,186,4.301,219,2.977,220,2.744,236,3.179,237,2.493,238,3.904,352,2.682,830,8.117]],["title/api/sql/Function/#st_x",[494,5.711]],["text/api/sql/Function/#st_x",[23,0.608,26,1.154,50,1.342,105,1.571,106,1.855,111,1.419,114,1.272,115,1.342,199,4.585,200,3.434,201,4.66,220,3.251,242,3.433,252,2.713,283,4.411,284,4.622,287,5.973,335,2.95,494,6.303,495,7.115,496,6.575,552,3.278]],["title/api/sql/Function/#st_xmax",[497,5.957]],["text/api/sql/Function/#st_xmax",[23,0.587,105,1.52,106,1.795,110,1.952,111,1.374,114,1.231,115,1.299,119,2.95,121,3.324,133,4.038,177,3.316,201,4.512,219,2.814,220,2.406,237,2.811,252,2.627,311,4.368,327,5.416,335,2.856,497,7.83,498,7.117,499,7.393,500,7.161,501,5.691]],["title/api/sql/Function/#st_xmin",[502,6.446]],["text/api/sql/Function/#st_xmin",[23,0.587,105,1.52,106,1.795,110,1.952,111,1.374,114,1.231,115,1.299,119,2.95,121,3.324,133,4.038,177,2.696,201,4.512,219,2.936,220,2.406,232,5.178,237,2.811,252,2.627,311,4.368,327,5.416,335,2.856,500,7.161,501,5.691,502,8.472,503,7.393]],["title/api/sql/Function/#st_y",[504,5.711]],["text/api/sql/Function/#st_y",[23,0.608,26,1.154,50,1.342,105,1.571,106,1.855,111,1.419,114,1.272,115,1.342,199,4.585,200,3.434,202,4.916,220,3.251,242,3.433,252,2.713,283,4.411,284,4.622,287,5.973,335,2.95,504,6.303,505,7.115,506,7.115,552,3.278]],["title/api/sql/Function/#st_ymax",[507,5.957]],["text/api/sql/Function/#st_ymax",[23,0.563,26,1.117,50,1.299,105,1.52,106,1.795,111,1.374,114,1.231,115,1.299,133,4.038,158,3.605,177,3.316,202,4.759,219,3.185,220,3.205,232,5.178,237,2.811,252,2.627,335,2.856,336,5.005,507,7.83]],["title/api/sql/Function/#st_ymin",[508,5.957]],["text/api/sql/Function/#st_ymin",[23,0.586,26,1.111,50,1.292,105,1.512,106,1.786,111,1.367,114,1.224,115,1.292,133,4.016,158,3.586,177,2.681,202,4.734,219,3.182,220,3.338,232,5.15,237,2.796,252,2.613,335,2.841,336,4.979,508,6.331,509,7.354]],["title/api/sql/Function/#st_z",[510,6.101]],["text/api/sql/Function/#st_z",[23,0.616,26,1.136,50,1.32,105,1.545,106,1.824,111,1.396,114,1.251,115,1.32,141,4.131,199,4.51,200,3.4,220,3.363,242,3.378,252,2.669,283,4.339,284,4.547,287,5.876,335,2.902,416,5.613,500,5.462,510,6.624,511,7.514,512,7.514]],["title/api/sql/Function/#st_zmax",[513,6.101]],["text/api/sql/Function/#st_zmax",[23,0.558,26,1.094,50,1.272,105,1.489,106,1.758,110,1.926,111,1.345,114,1.205,115,1.272,158,3.53,177,2.639,219,3.175,220,3.175,242,3.254,252,2.572,283,4.181,335,2.796,336,4.901,415,5.262,416,6.707,513,6.382,514,7.239,515,7.239,516,6.097]],["title/api/sql/Function/#st_zmin",[517,6.101]],["text/api/sql/Function/#st_zmin",[23,0.57,26,1.148,50,1.334,105,1.562,106,1.844,110,1.984,111,1.411,114,1.265,115,1.334,135,4.176,158,3.704,176,6.397,178,3.289,186,3.874,187,4.889,188,5.522,242,3.415,252,2.699,283,4.387,335,2.934,415,5.522,416,6.908,517,6.696,518,7.596,519,7.596,520,7.596]],["title/api/sql/Optimizer/",[349,1.441,831,1.832,832,3.106]],["text/api/sql/Optimizer/",[2,0.958,8,1.629,17,0.473,20,0.584,22,1.197,23,0.648,26,1.074,36,0.627,50,1.248,60,1.926,65,1.433,90,1.003,101,0.402,102,1.376,105,1.044,110,1.932,114,0.71,115,1.101,116,4.458,122,3.467,123,3.725,160,4.191,177,1.556,205,3.556,209,1.099,218,2.502,219,0.535,220,1.652,234,3.511,236,1.569,242,0.842,273,0.85,298,1.328,299,1.163,319,2.696,320,1.42,335,0.724,349,2.184,370,2.412,373,1.275,382,1.465,384,1.099,411,0.967,452,0.876,459,0.934,463,1.206,464,1.023,475,1.125,488,1.702,522,2.483,529,1.082,530,0.544,531,2.044,534,3.926,537,1.815,543,1.153,544,1.328,545,1.942,556,1.059,591,0.985,594,0.693,595,1.107,613,4.491,696,1.64,697,1.42,831,3.567,832,3.367,833,1.134,834,1.942,835,3.013,836,1.868,837,1.586,838,2.321,839,1.578,840,4.277,841,1.874,842,6.14,843,6.14,844,2.53,845,4.731,846,4.731,847,3.374,848,3.013,849,8.098,850,3.762,851,3.013,852,3.013,853,3.013,854,6.14,855,3.013,856,3.013,857,4.477,858,3.114,859,1.4,860,2.383,861,6.469,862,6.036,863,3.234,864,3.234,865,1.652,866,3.234,867,3.234,868,3.102,869,1.874,870,1.874,871,1.874,872,2.214,873,1.312,874,1.874,875,2.062,876,1.282,877,1.345,878,0.881,879,7.397,880,4.987,881,1.465,882,0.95,883,1.517,884,1.328,885,3.588,886,1.465,887,1.745,888,3.968,889,1.42,890,2.079,891,3.515,892,2.079,893,3.588,894,3.013,895,2.079,896,2.079,897,3.588,898,6.359,899,4.735,900,2.079,901,4.735,902,4.735,903,3.013,904,3.588,905,2.383,906,2.079,907,2.079,908,2.079,909,2.079,910,2.079,911,2.079,912,2.079,913,2.079,914,2.079,915,4.735,916,2.079,917,1.578,918,1.804,919,1.255,920,1.546,921,2.851,922,1.745,923,1.745,924,1.745,925,2.079]],["title/api/sql/Optimizer/#sedonasql-query-optimizer",[349,1.441,522,2.726,832,3.106]],["text/api/sql/Optimizer/#sedonasql-query-optimizer",[2,1.754,8,2.981,17,1.97,36,2.612,60,5.6,234,3.689,349,3.22,370,3.708,529,4.51,530,2.266,534,4.89,537,4.382,556,4.413,831,3.676,832,6.689,833,4.726,834,4.688,835,7.275]],["title/api/sql/Optimizer/#range-join",[370,2.653,831,2.184]],["text/api/sql/Optimizer/#range-join",[8,1.994,22,1.933,23,0.646,26,1.095,50,1.272,65,2.315,105,1.074,110,2.024,114,0.87,115,1.461,116,5.637,122,4.247,123,5.404,205,5.824,218,3.062,236,2.533,349,1.606,370,2.48,488,2.084,522,4.215,534,4.536,543,3.214,544,3.702,613,4.215,831,3.251,836,3.017,837,2.561,838,3.748,839,4.399,840,4.399,841,5.223,842,5.762,843,5.762,844,4.085,845,6.748,846,6.748,847,3.166,848,4.865,849,8.056,850,4.605,851,4.865,852,4.865,853,4.865,854,5.762,855,4.865,856,4.865,857,4.605,858,5.028]],["title/api/sql/Optimizer/#distance-join",[234,2.64,831,2.184]],["text/api/sql/Optimizer/#distance-join",[2,1.135,20,1.574,23,0.639,26,1.07,50,1.243,65,2.239,90,2.706,102,2.149,105,1.039,110,2.073,114,0.841,115,1.243,177,2.58,234,4.182,236,2.45,273,2.293,298,3.581,299,3.136,319,4.472,320,3.83,335,1.951,373,1.991,382,3.951,384,2.962,459,2.518,463,3.252,464,2.759,537,2.835,545,4.248,591,2.655,613,4.118,836,2.918,837,2.477,838,3.625,840,6.88,842,5.63,843,5.63,847,3.093,849,7.305,850,4.454,854,5.63,857,6.239,859,3.774,860,5.214,861,8.521,862,8.521,863,7.078,864,7.078,865,4.454,866,7.078,867,7.078,868,3.673,869,5.052,870,5.052,871,5.052,872,3.458,873,3.538,874,5.052,875,4.513,876,3.458,877,3.625,878,2.374]],["title/api/sql/Optimizer/#broadcast-join",[831,2.184,879,4.926]],["text/api/sql/Optimizer/#broadcast-join",[2,0.857,8,1.457,22,1.412,23,0.644,26,0.872,50,1.013,101,0.819,105,0.785,110,1.663,116,3.331,122,2.51,160,6.398,177,1.391,234,3.286,319,2.411,370,1.812,373,1.504,411,1.969,452,1.784,475,2.291,488,1.522,594,1.412,595,2.255,613,4.511,696,1.935,697,2.893,831,3.66,834,2.291,842,6.166,843,6.166,847,3.388,849,8.06,854,6.166,858,3.673,861,6.695,862,5.553,868,4.193,872,2.612,879,8.866,880,6.964,881,2.984,882,1.935,883,3.09,884,2.704,885,6.4,886,2.984,887,3.554,888,5.762,889,2.893,890,4.233,891,5.366,892,4.233,893,6.4,894,5.373,895,4.233,896,4.233,897,6.4,898,9.236,899,7.716,900,4.233,901,7.716,902,7.716,903,5.373,904,6.4,905,4.25,906,4.233,907,4.233,908,4.233,909,4.233,910,4.233,911,4.233,912,4.233,913,4.233,914,4.233,915,7.716,916,4.233,917,3.214,918,3.673,919,2.556]],["title/api/sql/Optimizer/#predicate-pushdown",[534,3.499,835,5.205]],["text/api/sql/Optimizer/#predicate-pushdown",[23,0.648,26,1.13,50,1.314,102,2.327,105,1.125,110,1.605,114,0.911,115,0.961,116,4.319,122,3.707,123,4.86,205,3.831,209,3.207,218,4.384,219,1.563,220,2.98,242,2.459,349,2.299,488,2.182,531,4.725,534,4.683,613,4.351,696,2.774,831,2.923,842,5.948,843,5.948,844,4.278,845,6.966,846,6.966,847,3.268,848,5.096,849,8.171,850,4.822,851,5.096,852,5.096,853,5.096,854,5.948,855,5.096,856,5.096,857,4.822,920,4.514,921,6.592,922,5.096,923,5.096,924,5.096,925,6.069]],["title/api/sql/Overview/",[374,2.867,926,4.174]],["text/api/sql/Overview/",[2,1.722,6,2.302,8,2.166,10,1.398,17,0.942,18,3.434,20,1.163,21,2.066,23,0.64,26,0.564,36,1.249,50,1.448,51,2.744,66,1.95,86,5.13,94,1.372,96,1.851,101,0.801,104,2.584,105,0.768,106,2.002,107,2.789,108,2.156,109,2.11,110,1.863,114,1.276,121,1.678,124,2.141,126,1.244,128,2.819,138,1.987,159,1.916,161,2.189,179,1.737,218,2.189,234,1.764,236,3.999,242,3.903,263,1.904,281,1.61,319,2.359,320,2.83,335,1.442,349,1.148,373,2.236,374,1.916,430,1.893,488,2.264,489,1.811,522,3.302,523,2.83,524,2.83,525,2.789,529,3.277,530,1.647,531,3.585,532,4.308,533,2.45,534,2.338,535,3.081,536,3.478,537,2.095,538,1.882,539,3.379,556,2.11,557,2.11,558,1.307,562,3.957,566,3.001,675,1.904,730,1.975,832,2.475,847,1.632,894,5.286,926,2.789,927,2.714,928,2.751,929,2.679,930,2.751,931,5.286,932,3.214,933,3.291,934,5.286,935,4.142,936,5.462,937,5.411,938,1.861,939,3.291,940,2.615,941,2.039,942,3.145,943,2.317,944,1.554,945,2.206,946,2.298,947,4.18,948,2.751,949,2.317,950,3.492,951,2.189,952,2.714,953,2.156,954,3.081,955,1.72,956,2.501,957,3.734,958,2.317,959,1.56,960,3.734,961,2.45,962,4.779,963,2.501]],["title/api/sql/Overview/#introduction",[105,1.423]],["text/api/sql/Overview/#introduction",[]],["title/api/sql/Overview/#function-list",[51,2,675,2.85]],["text/api/sql/Overview/#function-list",[2,1.058,8,2.571,10,1.763,17,1.188,18,4.075,20,1.467,21,2.606,23,0.605,50,1.381,51,2.813,86,5.362,94,1.73,96,2.334,101,1.01,104,3.26,106,2.204,107,3.518,108,2.72,109,2.661,110,2.026,114,1.428,121,2.117,124,2.7,126,1.569,128,3.229,138,2.506,159,2.416,161,2.761,218,2.761,234,2.225,236,4.402,242,4.244,263,2.402,281,2.03,319,2.975,320,3.57,335,1.819,349,1.448,373,2.654,430,2.388,488,2.687,522,3.918,523,3.57,524,3.57,525,3.518,529,3.889,530,1.367,531,4.255,532,4.639,533,3.091,534,2.949,535,3.886,536,4.387,537,2.643,538,2.374,539,4.261,556,2.661,557,2.661,558,1.649,562,2.26,566,3.561,730,2.49,832,3.122,894,6.273,927,3.423,928,3.469,929,3.379,930,3.469,931,6.273,932,4.054,933,4.151,934,6.273,935,5.225,936,6.482,937,5.956,938,2.348,939,4.151]],["title/api/sql/Overview/#quick-start",[374,2.867,926,4.174]],["text/api/sql/Overview/#quick-start",[2,2.048,6,3.319,23,0.65,26,0.946,36,2.093,50,1.437,66,3.27,86,3.698,179,2.912,489,3.036,530,1.817,562,4.64,847,2.736,940,4.384,941,3.418,942,5.272,943,3.885,944,2.605,945,3.698,946,3.852,947,6.029,948,4.612,949,3.885,950,5.036,951,3.67,952,4.55,953,3.615,954,5.166,955,2.883,956,4.193,957,6.26,958,3.885,959,2.616,960,6.26,961,4.108,962,6.892,963,4.193]],["title/api/sql/Parameter/",[474,3.997]],["text/api/sql/Parameter/",[2,1.419,8,2.413,17,2.211,21,2.388,23,0.638,50,1.11,66,2.253,99,2.89,100,3.299,101,1.356,219,1.233,234,2.038,243,2.585,248,2.655,266,2.549,349,1.943,370,2.049,373,3.245,397,2.372,402,3.889,412,1.75,430,4.799,457,2.775,467,5.412,474,3.65,488,2.521,522,3.677,562,3.952,594,2.339,738,3.136,831,3.219,878,2.97,880,5.949,882,4.176,888,5.7,889,3.27,891,4.375,905,5.511,930,3.178,940,3.021,949,2.678,950,4.603,951,2.529,952,3.136,953,2.491,954,3.56,955,1.987,956,2.89,957,4.314,958,2.678,964,3.178,965,3.493,966,8.62,967,2.803,968,2.253,969,7.48,970,4.426,971,4.314,972,4.314,973,6.415,974,4.786,975,3.493,976,4.786,977,3.493,978,4.375,979,4.786,980,5.67,981,2.356,982,3.136,983,4.786,984,2.89,985,4.786,986,4.314,987,3.431]],["title/api/sql/Parameter/#usage",[964,5.098]],["text/api/sql/Parameter/#usage",[2,1.369,8,2.326,21,3.373,23,0.653,66,3.184,266,3.601,373,2.402,402,3.751,412,2.472,430,3.091,457,3.531,474,4.644,488,2.431,522,4.679,562,4.592,878,3.779,930,4.49,949,3.783,950,5.538,951,3.573,952,4.431,953,3.52,954,5.03,955,2.807,956,4.082,957,6.095,958,3.783,965,4.935,966,8.417,967,3.961,968,3.184,969,8.999,970,5.631,971,6.095,972,6.095]],["title/api/sql/Parameter/#explanation",[940,4.846]],["text/api/sql/Parameter/#explanation",[2,1.284,8,2.183,17,2.457,50,1.354,99,3.83,100,3.845,101,1.654,219,1.634,234,2.701,243,3.152,248,3.519,349,2.369,370,2.715,373,3.435,397,3.144,402,3.519,430,5.087,467,5.927,488,2.281,594,2.852,738,4.157,831,3.647,880,6.933,882,4.73,888,6.457,889,4.335,891,5.334,905,6.422,966,8.067,973,7.025,974,6.344,975,4.63,976,6.344,977,4.63,978,5.334,979,6.344,980,6.608,981,3.123,982,4.157,983,6.344,984,3.83,985,6.344,986,5.718,987,4.548]],["title/api/sql/Predicate/",[534,4.333]],["text/api/sql/Predicate/",[23,0.655,26,1.284,50,1.493,102,0.949,105,1.748,106,2.063,110,1.043,111,1.579,113,1.962,114,1.415,115,1.528,116,5.38,117,4.997,133,2.051,136,3.254,161,3.341,177,3.297,209,4.508,218,2.85,219,2.285,220,3.522,221,4.441,222,4.256,223,4.997,236,4.122,237,3.143,238,4.922,252,1.334,299,2.331,335,0.862,336,1.511,373,3.429,384,1.309,446,1.319,488,0.891,537,2.107,538,1.893,540,3.233,541,2.232,542,2.232,543,2.991,544,3.445,546,4.285,547,2.232,548,4.86,549,4.285,550,2.489,551,4.285,552,3.143,988,4.093,989,2.079,990,3.615,991,3.615,992,4.093,993,4.093,994,2.079,995,4.011,996,2.079]],["title/api/sql/Predicate/#st_contains",[218,4.057]],["text/api/sql/Predicate/#st_contains",[23,0.643,26,1.083,50,1.258,105,1.473,106,1.74,111,1.331,114,1.193,115,1.258,116,5.151,117,4.656,209,4.201,218,5.23,219,2.047,220,3.307,221,4.138,222,3.965,223,4.656,236,3.475,237,2.724,238,4.266,373,2.823,537,4.02,538,3.612,552,3.075]],["title/api/sql/Predicate/#st_crosses",[988,5.828]],["text/api/sql/Predicate/#st_crosses",[23,0.643,26,1.088,50,1.265,105,1.481,106,1.749,111,1.338,114,1.199,115,1.265,116,5.168,117,4.68,209,4.222,219,2.058,220,3.313,221,4.159,222,3.986,223,4.68,236,3.493,237,2.738,238,4.289,373,2.838,552,3.091,988,7.537,989,6.708]],["title/api/sql/Predicate/#st_disjoint",[540,5.957]],["text/api/sql/Predicate/#st_disjoint",[23,0.621,26,1.174,50,1.364,105,1.597,106,1.886,111,1.443,114,1.293,115,1.364,133,4.241,136,4.755,236,3.766,237,2.953,238,4.624,373,3.06,540,6.685,541,7.766,542,7.766,990,7.476,991,7.476]],["title/api/sql/Predicate/#st_equals",[992,5.828]],["text/api/sql/Predicate/#st_equals",[23,0.643,26,1.088,50,1.265,105,1.481,106,1.749,111,1.338,114,1.199,115,1.265,116,5.168,117,4.68,209,4.222,219,2.058,220,3.313,221,4.159,222,3.986,223,4.68,236,3.493,237,2.738,238,4.289,299,4.47,373,2.838,552,3.091,992,7.537]],["title/api/sql/Predicate/#st_intersects",[543,4.259]],["text/api/sql/Predicate/#st_intersects",[23,0.643,26,1.088,50,1.265,105,1.481,106,1.749,111,1.338,114,1.199,115,1.265,116,5.168,117,4.68,209,4.222,219,2.058,220,3.313,221,4.159,222,3.986,223,4.68,236,3.493,237,2.738,238,4.289,373,2.838,384,4.222,543,5.507,552,3.091]],["title/api/sql/Predicate/#st_orderingequals",[546,6.101]],["text/api/sql/Predicate/#st_orderingequals",[23,0.617,26,1.212,50,1.408,102,2.581,105,1.248,106,1.473,110,1.927,111,1.128,114,1.335,115,1.408,133,3.314,161,5.601,177,4.034,219,1.734,220,3.616,236,2.943,252,2.849,299,3.766,335,2.344,336,4.108,373,3.16,446,3.585,488,2.421,546,7.068,547,6.068,548,8.98]],["title/api/sql/Predicate/#st_overlaps",[993,5.828]],["text/api/sql/Predicate/#st_overlaps",[23,0.621,26,1.174,50,1.364,105,1.597,106,1.886,111,1.443,114,1.293,115,1.364,136,4.755,236,3.766,237,2.953,238,4.624,373,3.06,552,3.333,990,7.476,991,7.476,993,7.893,994,7.234]],["title/api/sql/Predicate/#st_touches",[995,5.711]],["text/api/sql/Predicate/#st_touches",[23,0.645,105,1.504,106,1.776,111,1.359,115,1.285,116,5.219,117,4.754,209,4.289,219,2.09,220,3.332,221,4.225,222,4.049,223,4.754,236,3.548,237,2.782,238,4.356,373,2.883,552,3.14,995,7.457,996,6.815]],["title/api/sql/Predicate/#st_within",[544,4.905]],["text/api/sql/Predicate/#st_within",[23,0.643,26,1.083,50,1.258,105,1.473,106,1.74,111,1.331,114,1.193,115,1.258,116,5.151,117,4.656,209,4.201,219,2.047,220,3.307,221,4.138,222,3.965,223,4.656,236,3.475,237,2.724,238,4.266,373,2.823,537,4.02,538,3.612,544,6.322,552,3.075]],["title/api/sql/Predicate/#st_covers",[549,6.101]],["text/api/sql/Predicate/#st_covers",[23,0.643,26,1.088,50,1.265,105,1.481,106,1.749,111,1.338,113,3.762,114,1.199,115,1.265,116,5.168,117,4.68,209,4.222,219,2.058,220,3.313,221,4.159,222,3.986,223,4.68,236,3.493,237,2.738,238,4.289,373,2.838,549,7.889,550,4.774]],["title/api/sql/Predicate/#st_coveredby",[551,6.101]],["text/api/sql/Predicate/#st_coveredby",[23,0.643,26,1.088,50,1.265,105,1.481,106,1.749,111,1.338,113,3.762,114,1.199,115,1.265,116,5.168,117,4.68,209,4.222,219,2.058,220,3.313,221,4.159,222,3.986,223,4.68,236,3.493,237,2.738,238,4.289,373,2.838,550,4.774,551,7.889]],["title/api/sql/Raster-loader/",[46,3.5,121,2.106,252,1.665]],["text/api/sql/Raster-loader/",[2,0.462,10,2.839,22,0.761,23,0.656,26,0.916,44,0.585,47,2.324,50,0.949,56,1.377,60,0.671,65,0.499,79,1.698,90,2.184,94,1.843,96,1.02,101,0.441,105,0.941,106,0.689,110,1.591,111,1.309,114,0.958,115,0.616,121,0.925,126,0.686,128,1.881,129,3.711,133,0.615,135,1.131,136,1.341,138,0.6,177,0.411,178,0.488,219,0.811,220,0.669,225,2.51,242,0.507,243,0.842,248,4.061,252,1.782,264,3.57,281,0.887,296,1.537,301,2.323,327,0.671,334,2.448,335,1.938,369,0.732,373,3.685,374,0.578,397,1.131,407,0.881,412,0.457,424,1.55,430,3.346,452,0.962,457,0.495,459,2.033,464,1.124,467,3.399,474,1.64,478,0.809,480,0.739,486,3.199,488,0.45,496,1.771,530,0.597,532,3.028,545,0.676,557,1.604,562,1.682,568,0.725,574,1.901,575,1.496,576,0.434,616,2.184,620,0.592,629,0.854,643,3.133,675,0.575,696,0.571,700,0.799,702,1.64,715,0.799,733,2.071,737,0.949,753,0.799,761,2.733,823,0.666,833,0.682,882,1.043,919,0.755,934,3.264,941,3.141,968,1.075,982,3.929,984,1.378,997,6.3,998,2.839,999,0.842,1000,3.914,1001,2.121,1002,0.993,1003,0.854,1004,5.997,1005,3.668,1006,2.283,1007,6.628,1008,5.648,1009,5.648,1010,4.829,1011,3.373,1012,3.668,1013,0.771,1014,0.589,1015,3.15,1016,3.668,1017,1.216,1018,1.25,1019,0.789,1020,0.718,1021,2.283,1022,1.05,1023,1.085,1024,0.763,1025,1.25,1026,1.25,1027,0.607,1028,1.127,1029,2.972,1030,2.154,1031,2.972,1032,2.972,1033,2.972,1034,2.972,1035,3.583,1036,2.154,1037,1.25,1038,1.25,1039,2.283,1040,1.25,1041,1.733,1042,1.25,1043,2.154,1044,1.25,1045,1.25,1046,2.154,1047,1.25,1048,2.256,1049,0.732,1050,0.881,1051,0.908,1052,2.283,1053,1.25,1054,0.97,1055,2.529,1056,0.93,1057,4.524,1058,7.038,1059,2.283,1060,4.524,1061,1.02,1062,0.993,1063,1.05,1064,1.25,1065,1.25,1066,0.632,1067,2.283,1068,0.666,1069,0.896,1070,0.799,1071,2.283,1072,1.25,1073,2.283,1074,2.283,1075,1.25,1076,1.25,1077,2.057,1078,1.25,1079,2.154,1080,1.25,1081,1.25,1082,2.154,1083,1.862,1084,1.25,1085,1.25,1086,1.25,1087,2.761,1088,1.25,1089,1.25,1090,1.25,1091,3.668,1092,1.25,1093,2.283,1094,0.881,1095,0.912,1096,2.283,1097,2.283,1098,1.25,1099,1.25,1100,0.896,1101,1.25,1102,1.05,1103,1.25,1104,0.809,1105,1.127,1106,1.98,1107,0.896,1108,0.896,1109,1.25,1110,1.25,1111,1.25,1112,3.15,1113,1.25,1114,1.25,1115,1.25,1116,1.25,1117,1.05,1118,2.644,1119,0.993,1120,1.25,1121,1.25,1122,1.25,1123,1.25,1124,1.25,1125,2.283,1126,2.283]],["title/api/sql/Raster-loader/#geotiff-dataframe-loader",[10,1.754,997,3.106,998,4.685]],["text/api/sql/Raster-loader/#geotiff-dataframe-loader",[2,0.978,10,1.631,23,0.657,26,0.658,47,2.439,50,0.469,56,1.295,60,1.59,65,1.183,90,3.409,94,2.576,105,0.549,110,1.775,111,0.809,114,0.919,115,0.469,121,1.2,128,1.79,129,3.956,135,2.395,136,1.262,138,1.421,225,2.681,248,4.629,252,1.96,264,3.951,296,1.995,301,2.888,335,2.709,373,3.945,397,1.468,407,2.089,412,1.083,424,2.379,430,2.209,459,3.173,464,2.379,467,1.578,474,1.542,478,1.916,480,1.753,486,3.518,488,1.065,557,2.462,562,2.09,568,1.719,574,1.449,575,3.167,616,2.955,620,1.404,643,2.982,702,2.516,733,1.578,737,2.249,761,4.193,934,2.488,982,1.941,997,5.973,998,2.67,999,1.995,1000,4.27,1001,1.995,1002,2.354,1003,2.024,1004,9.179,1005,4.56,1006,4.833,1007,7.196,1008,5.139,1009,5.139,1010,4.193,1011,4.193,1012,4.56,1013,1.828,1014,1.395,1015,6.121,1016,4.56,1017,1.578,1018,2.963,1019,1.87,1020,1.703,1021,4.833,1022,2.488,1023,2.571,1024,1.808,1025,2.963,1026,2.963,1027,1.439,1028,2.67,1029,2.795,1030,2.795,1031,2.795,1032,2.795,1033,2.795,1034,2.795,1035,1.77,1036,2.795,1037,2.963,1038,2.963,1039,4.833,1040,2.963,1041,3.669,1042,2.963,1043,2.795,1044,2.963,1045,2.963,1046,2.795]],["title/api/sql/Raster-loader/#geotiff-dataframe-writer",[10,1.754,997,3.106,1047,5.198]],["text/api/sql/Raster-loader/#geotiff-dataframe-writer",[10,3.147,23,0.656,26,0.553,44,1.123,47,2.596,50,0.38,56,1.773,90,1.158,94,1.343,96,1.812,101,0.464,105,0.445,110,1.627,111,1.409,114,0.609,128,1.502,129,3.672,133,1.181,136,1.727,219,0.618,225,2.923,248,4.169,252,0.768,264,3.875,281,1.576,296,1.616,301,2.424,334,3.747,335,1.412,373,3.688,424,1.181,430,3.846,452,1.71,457,0.95,459,1.078,467,4.481,474,2.112,486,3.561,530,1.061,532,4.012,545,1.298,557,1.222,562,1.754,576,0.832,616,1.958,643,2.502,675,1.103,702,1.249,715,1.533,753,1.533,761,2.082,833,1.309,882,1.854,919,1.449,934,3.406,941,4.313,982,5.245,984,2.449,997,6.559,1000,3.914,1001,2.732,1005,3.827,1007,6.667,1008,6.311,1009,6.311,1010,6.009,1011,3.52,1012,3.827,1016,3.827,1017,1.278,1029,3.827,1030,2.264,1031,3.827,1032,3.827,1033,3.827,1034,3.827,1035,2.424,1048,3.594,1049,1.405,1050,1.692,1051,1.613,1052,4.056,1053,2.399,1054,1.862,1055,3.638,1056,1.785,1057,6.926,1058,9.324,1059,4.056,1060,6.926,1061,1.957,1062,1.907,1063,2.015,1064,2.399,1065,2.399,1066,1.214,1067,4.056,1068,1.278,1069,1.72,1070,1.533,1071,4.056,1072,2.399,1073,4.056,1074,4.056,1075,2.399,1076,2.399,1077,3.656,1078,2.399]],["title/api/sql/Raster-loader/#rs_array",[1079,7.244]],["text/api/sql/Raster-loader/#rs_array",[23,0.601,26,1.194,50,1.387,105,1.624,111,1.468,114,1.315,115,1.387,126,2.632,242,3.551,430,4.801,496,6.799,629,5.987,643,5.406,733,4.667,1008,7.357,1009,7.357,1079,8.268,1080,8.763,1081,8.763]],["title/api/sql/Raster-loader/#rs_base64",[1082,7.244]],["text/api/sql/Raster-loader/#rs_base64",[10,2.292,22,2.266,23,0.636,26,1.219,50,1.417,101,1.313,105,1.259,106,1.486,111,1.138,114,1.019,115,1.075,121,2.752,126,2.04,128,2.515,129,2.752,178,2.651,220,1.992,252,2.175,369,3.978,496,5.27,574,3.321,643,4.19,733,3.617,968,3.198,997,4.058,1000,3.159,1035,4.058,1082,6.408,1083,5.539,1084,6.792,1085,6.792,1086,6.792,1087,6.489,1088,6.792,1089,6.792,1090,6.792,1091,8.442,1092,6.792,1093,8.947,1094,4.788,1095,4.957,1096,8.947,1097,8.947,1098,6.792,1099,6.792,1100,4.869,1101,6.792,1102,5.702,1103,6.792,1104,4.393,1105,6.122]],["title/api/sql/Raster-loader/#rs_getband",[1106,6.662]],["text/api/sql/Raster-loader/#rs_getband",[10,2.376,22,2.349,23,0.638,26,1.248,50,1.45,105,1.305,106,1.541,111,1.179,114,1.056,115,1.115,177,2.313,219,2.359,220,2.065,243,3.377,252,2.254,374,3.256,397,3.488,574,3.443,696,3.218,700,4.497,733,3.749,823,3.749,968,3.315,997,5.473,998,6.346,1035,6.444,1036,6.642,1043,6.642,1046,6.642,1087,4.296,1091,8.643,1106,6.108,1107,5.047,1108,5.047,1109,7.04,1110,7.04,1111,7.04,1112,10.182,1113,7.04,1114,7.04,1115,7.04]],["title/api/sql/Raster-loader/#rs_html",[1116,7.678]],["text/api/sql/Raster-loader/#rs_html",[23,0.646,26,1.066,50,1.239,79,7.291,105,1.451,106,1.713,111,1.311,114,1.175,128,2.898,129,3.172,252,2.507,327,4.201,574,3.828,934,6.572,1083,6.384,1117,6.572,1118,8.985,1119,6.22,1120,7.827,1121,7.827,1122,7.827,1123,7.827,1124,7.827,1125,9.802,1126,9.802]],["title/api/sql/Raster-operators/",[46,4.174,529,3.227]],["text/api/sql/Raster-operators/",[6,0.617,10,3.345,23,0.636,26,1.543,46,1.136,47,1.033,50,1.793,86,0.898,99,1.805,101,0.326,105,1.858,106,1.637,111,1.66,114,1.52,115,1.587,132,1.887,133,0.83,177,0.554,178,0.659,219,1.586,220,1.428,235,2.899,242,0.684,243,1.484,246,0.885,257,0.859,264,0.944,281,2.759,298,1.91,299,2.252,301,3.68,304,1.019,334,1.617,335,0.587,355,0.814,394,3.233,412,1.472,430,4.285,431,1.768,480,1.768,529,1.556,533,0.998,620,2.306,643,1.844,733,5.279,790,1.521,836,2.534,968,4.667,997,5.15,1000,4.01,1008,1.416,1009,1.416,1010,2.594,1020,5.294,1035,6.214,1087,6.565,1094,6.493,1095,7.235,1106,1.464,1107,4.415,1127,2.82,1128,5.295,1129,1.687,1130,1.687,1131,1.687,1132,1.687,1133,1.687,1134,2.82,1135,3.628,1136,2.438,1137,1.34,1138,1.019,1139,1.136,1140,1.153,1141,2.989,1142,1.687,1143,1.687,1144,1.687,1145,1.687,1146,2.82,1147,2.82,1148,1.687,1149,1.687,1150,1.687,1151,2.82,1152,1.687,1153,1.687,1154,2.82,1155,1.687,1156,1.687,1157,2.82,1158,2.82,1159,1.687,1160,1.687,1161,2.82,1162,1.189,1163,1.687,1164,4.025,1165,1.687,1166,1.687,1167,1.687,1168,1.687,1169,2.989,1170,1.687,1171,1.687,1172,1.687,1173,2.82,1174,4.224,1175,2.594,1176,1.687,1177,1.687,1178,4.224,1179,2.82,1180,1.687,1181,1.687,1182,2.82,1183,1.687,1184,1.687,1185,2.82,1186,1.687,1187,1.687,1188,2.82,1189,1.687,1190,1.687,1191,1.687,1192,2.82,1193,1.687,1194,1.687,1195,1.687,1196,1.687,1197,2.82,1198,1.687,1199,1.687,1200,2.82,1201,1.687,1202,1.687,1203,2.82,1204,2.989,1205,0.859,1206,1.521,1207,1.687,1208,1.687,1209,2.82,1210,2.82,1211,1.687,1212,1.687,1213,2.82,1214,2.51,1215,1.687,1216,1.687,1217,1.687,1218,2.82,1219,1.521,1220,1.687,1221,1.687,1222,1.687,1223,1.687,1224,1.687,1225,1.687,1226,2.82,1227,1.687,1228,0.928,1229,1.687,1230,1.687,1231,1.687,1232,2.82,1233,1.687,1234,1.687,1235,1.687,1236,1.687,1237,1.687]],["title/api/sql/Raster-operators/#rs_add",[1127,7.244]],["text/api/sql/Raster-operators/#rs_add",[6,3.081,10,2.844,23,0.593,26,1.397,50,1.624,105,1.562,111,1.411,114,1.265,115,1.334,281,3.275,733,4.488,968,3.968,997,5.035,1000,3.92,1035,5.035,1087,6.26,1094,5.941,1095,7.487,1127,7.951,1128,6.696,1129,8.427,1130,8.427,1131,8.427]],["title/api/sql/Raster-operators/#rs_append",[1132,7.678]],["text/api/sql/Raster-operators/#rs_append",[10,2.344,23,0.573,26,1.237,47,3.136,50,1.437,86,3.698,101,1.343,105,1.287,106,1.52,111,1.163,114,1.362,115,1.1,132,4.384,133,3.418,235,4.726,243,3.348,246,3.642,281,3.528,394,6.029,412,3.698,480,5.371,529,4.726,533,4.108,620,4.301,968,3.27,997,4.15,1000,3.231,1010,7.878,1035,6.652,1087,5.54,1106,6.026,1133,6.945,1134,6.553,1135,6.26,1136,7.405,1137,5.518,1138,4.193,1139,4.677,1140,4.745,1141,9.079,1142,6.945,1143,6.945,1144,6.945,1145,6.945]],["title/api/sql/Raster-operators/#rs_bitwiseand",[1146,7.244]],["text/api/sql/Raster-operators/#rs_bitwiseand",[10,2.828,23,0.592,26,1.393,50,1.619,105,1.553,111,1.404,114,1.258,115,1.327,235,4.363,281,3.257,733,4.463,836,4.363,968,3.946,997,5.008,1000,3.899,1035,5.008,1087,6.239,1094,5.908,1095,7.463,1146,7.908,1147,7.908,1148,8.381,1149,8.381,1150,8.381]],["title/api/sql/Raster-operators/#rs_bitwiseor",[1151,7.244]],["text/api/sql/Raster-operators/#rs_bitwiseor",[10,2.844,23,0.593,26,1.397,50,1.624,105,1.562,111,1.411,114,1.265,115,1.334,235,4.387,281,3.275,733,4.488,836,4.387,968,3.968,997,5.035,1000,3.92,1035,5.035,1087,6.26,1094,5.941,1095,7.487,1147,7.951,1151,7.951,1152,8.427,1153,8.427]],["title/api/sql/Raster-operators/#rs_count",[1154,7.244]],["text/api/sql/Raster-operators/#rs_count",[10,2.813,23,0.591,26,1.388,46,5.613,50,1.613,105,1.545,106,1.824,111,1.396,114,1.251,115,1.32,301,4.981,430,3.81,431,6.028,733,4.439,968,3.925,1000,3.878,1020,5.857,1035,4.981,1087,5.087,1094,5.876,1107,5.976,1128,6.624,1154,7.865,1155,8.336,1156,8.336]],["title/api/sql/Raster-operators/#rs_divide",[1157,7.244]],["text/api/sql/Raster-operators/#rs_divide",[10,2.859,23,0.594,26,1.402,50,1.63,105,1.571,111,1.419,114,1.272,115,1.342,733,4.513,790,7.638,968,3.99,997,5.063,1000,3.942,1087,6.281,1094,7.256,1095,8.092,1157,7.995,1158,7.995,1159,8.474,1160,8.474]],["title/api/sql/Raster-operators/#rs_fetchregion",[1161,7.244]],["text/api/sql/Raster-operators/#rs_fetchregion",[10,2.615,23,0.576,26,1.327,50,1.542,105,1.436,111,1.298,114,1.163,115,1.227,178,3.025,219,1.995,220,2.272,242,3.14,243,2.857,257,3.947,264,4.335,335,2.698,355,3.74,733,4.127,968,3.648,997,4.63,1000,4.531,1008,6.506,1009,6.506,1035,4.63,1087,4.728,1161,7.311,1162,5.462,1163,7.749,1164,10.652,1165,7.749,1166,7.749,1167,7.749,1168,7.749,1169,9.74,1170,7.749,1171,7.749,1172,7.749]],["title/api/sql/Raster-operators/#rs_greaterthan",[1173,7.244]],["text/api/sql/Raster-operators/#rs_greaterthan",[10,2.828,23,0.592,26,1.393,50,1.619,105,1.553,111,1.404,114,1.258,115,1.327,219,2.158,301,5.008,430,4.673,733,4.463,968,3.946,1020,6.341,1035,5.008,1087,5.114,1107,6.009,1173,7.908,1174,7.272,1175,7.272,1176,8.381,1177,8.381,1178,7.272]],["title/api/sql/Raster-operators/#rs_greaterthanequal",[1179,7.244]],["text/api/sql/Raster-operators/#rs_greaterthanequal",[10,2.813,23,0.591,26,1.388,50,1.613,105,1.545,111,1.396,114,1.251,115,1.32,219,2.147,299,4.664,301,4.981,430,4.658,733,4.439,968,3.925,1020,6.326,1035,4.981,1087,5.087,1107,5.976,1174,7.233,1175,7.233,1178,7.233,1179,7.865,1180,8.336,1181,8.336]],["title/api/sql/Raster-operators/#rs_lessthan",[1182,7.244]],["text/api/sql/Raster-operators/#rs_lessthan",[10,2.828,23,0.592,26,1.393,50,1.619,105,1.553,111,1.404,114,1.258,115,1.327,219,2.158,298,5.354,301,5.008,430,4.673,733,4.463,968,3.946,1020,6.341,1035,5.008,1087,5.114,1107,6.009,1174,7.272,1178,7.272,1182,7.908,1183,8.381,1184,8.381]],["title/api/sql/Raster-operators/#rs_lessthanequal",[1185,7.244]],["text/api/sql/Raster-operators/#rs_lessthanequal",[10,2.813,23,0.591,26,1.388,50,1.613,105,1.545,111,1.396,114,1.251,115,1.32,219,2.147,298,5.325,299,4.664,301,4.981,430,4.658,733,4.439,968,3.925,1020,6.326,1035,4.981,1087,5.087,1107,5.976,1174,7.233,1178,7.233,1185,7.865,1186,8.336,1187,8.336]],["title/api/sql/Raster-operators/#rs_logicaldifference",[1188,7.244]],["text/api/sql/Raster-operators/#rs_logicaldifference",[10,2.783,23,0.588,26,1.379,50,1.603,105,1.529,106,2.216,111,1.381,114,1.237,115,1.306,219,2.124,220,2.418,430,4.627,620,3.907,733,4.392,968,3.883,1035,4.928,1087,6.178,1094,7.137,1095,7.996,1188,7.781,1189,8.247,1190,8.247,1191,8.247]],["title/api/sql/Raster-operators/#rs_logicalover",[1192,7.244]],["text/api/sql/Raster-operators/#rs_logicalover",[10,2.798,23,0.589,26,1.384,50,1.608,105,1.537,106,2.223,111,1.389,114,1.244,115,1.313,220,2.431,299,4.639,430,4.642,733,4.415,968,3.904,1087,6.198,1094,7.16,1095,8.015,1192,7.823,1193,8.291,1194,8.291,1195,8.291,1196,8.291]],["title/api/sql/Raster-operators/#rs_mean",[1197,7.244]],["text/api/sql/Raster-operators/#rs_mean",[10,2.875,23,0.595,26,1.407,50,1.635,99,6.235,105,1.579,106,1.865,111,1.427,114,1.279,115,1.349,430,3.894,733,4.538,968,4.012,997,5.091,1000,3.964,1035,6.171,1087,5.199,1128,6.77,1197,8.039,1198,8.52,1199,8.52]],["title/api/sql/Raster-operators/#rs_mode",[1200,7.244]],["text/api/sql/Raster-operators/#rs_mode",[10,2.859,23,0.594,26,1.402,50,1.63,105,1.571,106,1.855,111,1.419,114,1.272,115,1.342,304,5.116,334,5.569,643,5.227,733,4.513,968,3.99,997,5.063,1000,3.942,1035,6.15,1087,5.171,1128,6.733,1200,7.995,1201,8.474,1202,8.474]],["title/api/sql/Raster-operators/#rs_modulo",[1203,7.244]],["text/api/sql/Raster-operators/#rs_modulo",[10,2.844,23,0.593,26,1.397,50,1.624,105,1.562,111,1.411,114,1.265,115,1.334,301,5.035,430,3.852,733,4.488,836,4.387,968,3.968,1020,5.896,1035,5.035,1087,5.142,1107,6.042,1203,7.951,1204,10.259,1205,4.292,1206,7.596,1207,8.427,1208,8.427]],["title/api/sql/Raster-operators/#rs_multiply",[1209,7.244]],["text/api/sql/Raster-operators/#rs_multiply",[10,2.844,23,0.593,26,1.397,50,1.624,105,1.562,111,1.411,114,1.265,115,1.334,281,3.275,733,4.488,968,3.968,997,5.035,1000,3.92,1035,5.035,1087,6.26,1094,5.941,1095,7.487,1128,6.696,1158,7.951,1209,7.951,1210,7.951,1211,8.427,1212,8.427]],["title/api/sql/Raster-operators/#rs_multiplyfactor",[1213,7.244]],["text/api/sql/Raster-operators/#rs_multiplyfactor",[10,2.844,23,0.593,26,1.397,50,1.624,105,1.562,111,1.411,114,1.265,115,1.334,132,5.319,177,2.769,733,4.488,968,3.968,997,5.035,1000,3.92,1035,5.035,1087,5.142,1094,5.941,1128,6.696,1210,7.951,1213,7.951,1214,8.613,1215,8.427,1216,8.427,1217,8.427]],["title/api/sql/Raster-operators/#rs_normalize",[1218,7.244]],["text/api/sql/Raster-operators/#rs_normalize",[23,0.556,26,1.251,50,1.454,105,1.702,114,1.378,115,1.454,220,2.692,394,6.097,430,4.196,643,5.664,733,4.889,1035,5.486,1218,8.662,1219,8.275]],["title/api/sql/Raster-operators/#rs_normalizeddifference",[1135,6.92]],["text/api/sql/Raster-operators/#rs_normalizeddifference",[10,2.768,23,0.587,26,1.375,50,1.598,105,1.52,106,1.795,111,1.374,114,1.231,115,1.299,235,4.27,281,3.187,394,5.447,620,3.886,733,4.368,968,3.862,997,4.901,1087,6.157,1094,7.113,1095,7.365,1134,7.739,1135,7.393,1220,8.203,1221,8.203,1222,8.203,1223,8.203,1224,8.203,1225,8.203]],["title/api/sql/Raster-operators/#rs_squareroot",[1226,7.244]],["text/api/sql/Raster-operators/#rs_squareroot",[10,2.875,23,0.595,26,1.407,50,1.635,105,1.579,111,1.427,114,1.279,115,1.349,430,3.894,733,4.538,836,4.435,968,4.012,997,5.091,1000,3.964,1035,6.171,1087,5.199,1226,8.039,1227,8.52,1228,4.686,1229,8.52,1230,8.52,1231,8.52]],["title/api/sql/Raster-operators/#rs_subtract",[1232,7.244]],["text/api/sql/Raster-operators/#rs_subtract",[10,2.828,23,0.592,26,1.393,50,1.619,105,1.553,111,1.404,114,1.258,115,1.327,281,3.257,733,4.463,968,3.946,997,5.008,1035,5.008,1087,6.239,1094,7.208,1095,7.463,1128,6.66,1232,7.908,1233,8.381,1234,8.381,1235,8.381,1236,8.381,1237,8.381]],["title/api/viz/java-api/",[1238,2.892]],["text/api/viz/java-api/",[12,4.093,13,4.075,20,2.548,22,3.027,94,3.004,95,7.04,96,4.054,97,4.713,98,6.887,99,5.478,100,4.263,101,1.755,102,3.478]],["title/api/viz/sql/",[1239,6.446]],["text/api/viz/sql/",[2,0.929,6,1.677,10,0.938,17,1.546,18,2.503,20,1.288,22,1.531,23,0.638,26,1.167,36,0.838,48,2.039,50,1.282,51,2.193,66,1.309,86,2.443,90,2.215,97,2.017,101,0.887,102,1.066,104,1.735,105,1.394,106,1.488,110,0.538,111,1.356,114,1.343,115,1.282,121,1.127,122,1.09,128,2.517,129,2.373,178,1.791,179,1.166,201,3.221,202,3.398,206,1.755,237,0.953,242,2.754,248,1.542,259,1.598,270,3.135,329,3.646,335,1.597,374,1.286,394,1.847,416,3.09,424,2.258,430,2.097,474,1.448,489,1.216,530,0.727,552,2.909,562,3.253,574,1.36,583,2.258,594,0.928,600,1.96,620,2.174,641,1.039,643,1.716,675,1.278,697,1.9,713,1.847,720,2.03,730,1.326,823,1.481,825,1.716,826,1.569,837,1.229,847,1.095,860,1.847,926,1.873,929,1.799,940,1.755,944,1.043,945,1.481,946,1.542,947,3.047,948,1.847,949,1.556,950,2.545,951,1.47,952,1.822,953,1.448,955,1.155,956,1.679,958,1.556,962,2.111,963,2.77,1000,2.725,1017,1.481,1019,1.755,1051,2.99,1068,1.481,1069,1.994,1083,3.742,1102,3.852,1108,1.994,1118,2.335,1139,1.873,1205,5.479,1240,1.378,1241,2.335,1242,2.781,1243,1.216,1244,2.03,1245,2.781,1246,2.506,1247,2.03,1248,4.792,1249,6.251,1250,6.636,1251,2.03,1252,2.21,1253,2.21,1254,1.662,1255,2.506,1256,2.111,1257,2.354,1258,2.506,1259,2.506,1260,2.21,1261,2.21,1262,2.158,1263,2.21,1264,5.707,1265,4.588,1266,2.781,1267,1.96,1268,1.697,1269,1.9,1270,2.781,1271,1.735,1272,2.21,1273,2.781,1274,1.9,1275,2.781,1276,2.781,1277,2.781,1278,2.781,1279,2.781,1280,2.111,1281,4.446,1282,3.483,1283,3.852,1284,1.96,1285,2.335,1286,1.645,1287,2.506,1288,1.342,1289,2.506,1290,3.944,1291,1.822,1292,2.335,1293,2.506,1294,2.506,1295,2.506,1296,3.646,1297,4.129,1298,4.838,1299,5.302,1300,4.172,1301,4.136,1302,2.506,1303,3.852,1304,2.506,1305,3.838,1306,3.349,1307,2.506,1308,1.9,1309,2.506,1310,2.781,1311,4.136,1312,2.506]],["title/api/viz/sql/#quick-start",[374,2.867,926,4.174]],["text/api/viz/sql/#quick-start",[2,1.865,6,3.369,17,1.616,23,0.649,26,0.968,66,3.345,86,3.784,179,2.979,489,3.106,530,1.859,562,4.85,847,2.799,940,4.485,944,2.665,945,3.784,946,3.941,947,6.119,948,4.718,949,3.975,950,5.111,951,3.755,952,4.655,953,3.699,955,2.95,956,4.29,958,3.975,962,5.394,963,5.563,1240,3.521,1241,5.966,1242,7.105,1243,3.106,1244,5.186,1245,7.105,1246,6.404]],["title/api/viz/sql/#regular-functions",[51,2,1247,4.524]],["text/api/viz/sql/#regular-functions",[]],["title/api/viz/sql/#st_colorize",[1248,5.412]],["text/api/viz/sql/#st_colorize",[10,2.696,17,2.456,18,4.358,22,2.665,105,1.481,106,1.749,111,1.338,128,2.958,129,3.237,242,3.237,248,4.432,430,4.538,552,3.091,574,3.907,594,2.665,600,5.632,641,2.984,837,3.531,1069,5.728,1102,6.708,1205,4.07,1248,5.632,1249,7.246,1250,6.97,1251,5.832,1252,6.349,1253,6.349,1254,4.774,1255,7.202,1256,6.065,1257,4.099,1258,7.202,1259,7.202]],["title/api/viz/sql/#st_encodeimage",[1281,5.828]],["text/api/viz/sql/#st_encodeimage",[23,0.564,26,1.123,36,2.486,50,1.306,97,3.625,105,1.529,106,1.805,111,1.381,114,1.519,115,1.306,128,3.749,259,4.74,552,3.19,1000,4.709,1083,8.257,1118,6.924,1139,5.553,1257,4.231,1281,7.685,1282,6.26,1283,6.924,1284,5.813,1285,6.924,1286,4.878,1287,7.433,1288,3.981,1289,7.433]],["title/api/viz/sql/#st_pixelize",[1290,5.17]],["text/api/viz/sql/#st_pixelize",[23,0.626,26,1.094,50,1.272,101,1.553,104,5.011,105,1.489,110,1.553,111,1.345,114,1.205,115,1.272,122,3.149,206,5.07,237,2.753,242,3.254,552,3.107,583,4.903,643,4.955,713,5.333,730,3.828,825,4.955,826,4.533,1205,4.091,1290,6.707,1291,5.262,1292,6.743,1293,7.239,1294,7.239,1295,7.239,1296,7.914]],["title/api/viz/sql/#st_tilename",[1297,5.412]],["text/api/viz/sql/#st_tilename",[20,2.081,22,2.473,23,0.585,26,1.01,48,3.294,50,1.174,90,3.578,105,1.374,106,1.622,111,1.586,114,1.112,115,1.174,128,2.745,178,2.894,201,5.739,202,6.054,242,3.004,329,7.525,335,3.297,416,6.377,552,2.867,1051,4.149,1205,4.824,1264,6.224,1297,6.676,1298,6.789,1299,6.676,1300,5.253,1301,8.536,1302,6.682,1303,6.224,1304,6.682]],["title/api/viz/sql/#aggregate-functions",[18,3.381,51,2]],["text/api/viz/sql/#aggregate-functions",[]],["title/api/viz/sql/#st_render",[1305,5.031]],["text/api/viz/sql/#st_render",[23,0.599,26,1.015,50,1.179,97,3.274,101,1.441,105,1.381,106,1.63,111,1.248,114,1.118,115,1.179,129,3.849,178,2.908,242,3.018,424,4.676,474,3.878,552,2.881,823,3.967,1000,3.465,1017,3.967,1205,5.611,1250,5.86,1264,6.254,1282,5.655,1283,6.254,1298,4.451,1299,7.373,1300,5.801,1303,6.254,1305,6.224,1306,6.933,1307,6.714,1308,5.089,1309,6.714,1310,7.449,1311,8.562,1312,6.714]],["title/archive/api/GeoSpark-Python-API/",[15,2.356,93,3.783]],["text/archive/api/GeoSpark-Python-API/",[44,4.658,103,8.356]],["title/archive/api/GeoSpark-Scala-and-Java-API/",[92,3.743,93,3.783]],["text/archive/api/GeoSpark-Scala-and-Java-API/",[12,4.489,13,4.357,22,2.781,23,0.429,55,5.536,59,3.252,75,2.902,96,3.725,97,5.04,98,6.328,99,5.033,100,4.052,101,1.612,102,3.196,1313,8.336,1314,6.433,1315,3.973]],["title/archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api",[12,1.984,13,1.975,97,2.285]],["text/archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api",[12,4.409,13,4.223,22,2.842,55,5.658,59,3.276,75,2.966,96,3.807,97,4.884,98,6.468,99,5.144,100,4.106,101,1.648,102,3.267,1313,8.52,1314,6.519,1315,4.061]],["title/archive/api/sql/GeoSparkSQL-AggregateFunction/",[18,3.381,51,2]],["text/archive/api/sql/GeoSparkSQL-AggregateFunction/",[23,0.629,26,1.384,50,1.609,104,6.339,105,1.883,106,2.224,107,4.719,108,3.648,109,3.57,110,1.355,111,1.702,112,7.558,114,1.525,115,1.609,116,4.754,117,4.105,118,7.284,119,3.871,120,5.569,122,4.221,123,5.35,133,3.45,384,3.703,552,3.533,553,7.713]],["title/archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr",[104,4.79]],["text/archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr",[23,0.582,26,1.207,50,1.403,104,6.598,105,1.643,106,1.94,107,5.969,108,4.614,109,4.515,110,1.714,111,1.485,112,6.593,114,1.33,115,1.403,116,5.505,117,5.192,552,3.429]],["title/archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr",[118,5.504]],["text/archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr",[23,0.584,26,1.214,50,1.411,105,1.652,106,1.951,111,1.493,112,6.632,114,1.338,115,1.411,118,7.608,119,3.816,120,7.084,122,4.161,123,5.222,552,3.449]],["title/archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr",[553,5.828]],["text/archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr",[23,0.584,26,1.214,50,1.411,105,1.652,106,1.951,111,1.493,112,6.632,114,1.338,115,1.411,119,3.816,122,4.161,123,5.222,133,4.388,384,4.711,553,8.056]],["title/archive/api/sql/GeoSparkSQL-Constructor/",[124,3.967]],["text/archive/api/sql/GeoSparkSQL-Constructor/",[10,1.19,17,1.06,20,0.99,22,1.556,23,0.652,26,1.113,50,1.389,59,0.578,65,0.814,90,0.984,94,1.84,96,1.576,101,0.682,102,0.781,105,1.574,110,1.581,111,1.422,114,1.317,115,1.464,116,2.893,119,1.268,122,1.383,123,3.256,126,0.612,128,3.145,129,1.429,137,2.447,138,4.074,139,1.796,140,1.711,141,1.01,142,5.597,143,4.11,159,0.942,161,3.32,162,1.516,163,1.619,164,2.623,165,3.055,166,1.182,167,1.711,171,0.877,172,2.375,173,4.241,174,3.235,175,3.343,180,4.313,199,2.523,200,1.177,201,1.121,202,1.182,203,1.711,204,1.711,205,3.965,206,3.965,207,4.313,208,1.711,209,2.464,210,1.619,211,1.619,212,1.619,213,1.619,214,1.711,215,1.711,216,1.711,217,1.711,218,1.077,219,0.908,220,1.842,221,1.061,222,1.016,223,1.193,224,4.313,225,1.13,226,1.271,227,3.705,228,2.802,229,2.802,237,0.698,239,0.877,273,0.834,284,1.111,313,2.046,335,0.709,382,1.436,412,0.745,456,1.257,457,0.806,459,2.095,463,1.182,464,1.003,476,1.19,480,4.618,488,0.733,532,1.517,538,0.926,552,3.162,554,1.619,555,1.85,556,1.796,557,3.2,558,1.754,559,1.257,560,1.414,561,1.392,562,2.717,563,1.302,564,1.711,565,5.01,566,0.971,567,1.436,568,2.046,569,2.943,570,1.836,571,2.311,572,1.461,573,2.129,574,2.28,575,1.335,576,1.927,577,1.414,578,1.547,579,1.487,580,1.436,581,1.711,582,1.077,583,1.736,584,3.915,585,1.286,586,1.711,587,1.711,588,1.711,589,1.711,590,1.711,591,1.671,592,0.905,593,1.01,594,0.68,595,1.878,596,1.711,597,1.547,598,1.711,599,1.711,600,1.436,601,1.318,603,1.372,604,1.031,605,1.711,606,1.711,607,1.711,612,4.203,613,1.069,614,1.487,615,1.243,616,0.984,617,1.836,618,1.836,619,1.121,620,0.965,625,3.179,626,3.179,628,2.447,629,2.41,630,2.486,730,0.971,757,1.768,763,1.836,781,1.353,872,1.257,873,1.286,875,2.027,876,1.257,877,1.318,878,0.863,1017,1.085,1027,0.99,1238,0.768,1316,5.67,1317,2.212,1318,1.335,1319,1.335,1320,1.335,1321,6.057,1322,6.057,1323,6.057,1324,1.759,1325,3.328,1326,3.803,1327,2.037,1328,1.711,1329,2.037]],["title/archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt",[161,4.057]],["text/archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt",[23,0.615,26,1.123,50,1.306,105,1.529,110,1.958,111,1.381,114,1.237,115,1.603,123,4.83,128,3.053,138,3.956,142,7.258,143,4.928,159,3.814,161,5.789,162,6.134,163,6.553,164,6.134,480,4.878,552,3.19,1316,5.721,1321,6.399,1322,6.399,1323,6.399]],["title/archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb",[165,5.031]],["text/archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb",[23,0.595,26,1.161,50,1.349,105,1.579,110,1.648,111,1.427,114,1.279,115,1.349,123,4.991,128,3.824,138,4.087,141,4.222,142,7.404,143,5.091,165,6.767,166,4.943,167,7.154,480,5.04,1316,5.911,1321,6.611,1322,6.611,1323,6.611]],["title/archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson",[137,5.326]],["text/archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson",[23,0.653,26,0.886,50,1.377,94,2.879,105,1.206,110,1.258,111,1.456,114,0.976,115,1.03,122,3.409,128,2.409,129,3.523,137,4.513,138,3.12,139,4.429,140,5.462,142,6.234,173,3.738,239,2.799,480,3.848,488,2.339,552,2.516,556,3.313,557,4.429,562,3.761,568,3.774,573,3.927,574,4.252,591,3.081,612,8.827,613,3.411,614,4.748,615,3.969,616,3.14,617,5.863,618,5.863,619,3.578,620,3.081,1316,4.513,1321,5.047,1322,5.047,1323,5.047,1324,3.245]],["title/archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile",[94,1.721,554,4.13,555,2.726]],["text/archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile",[10,1.793,20,1.492,22,1.773,23,0.65,50,0.841,94,1.76,96,3.379,101,1.463,105,0.985,110,1.463,114,1.135,126,1.596,138,2.549,161,2.809,284,2.899,412,1.943,457,2.103,459,3.398,476,1.793,532,3.254,538,2.415,552,2.056,555,2.787,556,2.707,557,4.485,558,3.027,559,3.279,560,3.687,561,3.631,562,3.808,563,3.395,564,4.462,565,8.645,566,2.533,567,3.747,568,3.083,569,5.557,570,4.79,571,3.482,572,3.81,573,3.209,574,2.599,575,3.482,576,3.326,577,3.687,578,4.035,579,3.879,580,3.747,581,4.462,582,2.809,583,2.616,584,7.392,585,3.355,586,4.462,587,4.462,588,4.462,589,4.462,590,4.462,591,2.518,592,2.362,593,2.634,594,1.773,595,2.83,596,4.462,597,4.035,598,4.462,599,4.462,600,3.747,601,3.438,603,3.579,604,2.688,605,4.462,606,4.462,607,4.462,1324,2.651,1325,7.136]],["title/archive/api/sql/GeoSparkSQL-Constructor/#st_point",[199,4.154]],["text/archive/api/sql/GeoSparkSQL-Constructor/#st_point",[23,0.638,26,1.05,50,1.221,105,1.429,111,1.291,114,1.157,115,1.221,128,2.855,138,3.698,143,4.607,199,5.253,200,2.572,201,4.24,202,4.473,203,6.473,204,6.473,205,4.867,206,6.708,313,5.633,480,4.561,552,2.982,571,5.052,628,6.736,629,6.634,630,6.844,1316,5.349,1321,5.982,1322,5.982,1323,5.982]],["title/archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext",[207,5.957]],["text/archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext",[23,0.634,26,1.083,50,1.258,105,1.473,111,1.331,114,1.193,115,1.567,128,2.943,138,3.813,143,4.75,164,5.913,172,4.049,173,5.688,174,5.514,175,5.699,200,2.652,205,6.246,206,6.246,207,8.361,208,6.674,480,4.702,552,3.075,1316,5.514,1321,6.168,1322,6.168,1323,6.168]],["title/archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext",[224,5.957]],["text/archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext",[23,0.635,26,1.056,50,1.227,105,1.436,111,1.298,114,1.163,115,1.542,119,2.786,123,5.705,128,2.869,138,3.717,142,6.983,143,4.63,172,3.947,173,5.598,174,5.376,175,5.555,224,8.265,225,4.298,226,4.834,227,7.739,228,6.157,229,6.157,480,4.584,552,2.997,1316,5.376,1321,6.012,1322,6.012,1323,6.012]],["title/archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext",[180,5.957]],["text/archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext",[23,0.636,26,1.072,50,1.246,105,1.458,111,1.318,114,1.181,115,1.557,128,2.913,138,3.774,143,4.701,171,3.385,172,4.007,173,5.651,174,5.458,175,5.641,180,8.323,227,6.251,228,6.251,229,6.251,480,4.654,552,3.043,625,8.863,626,8.863,1316,5.458,1321,6.105,1322,6.105,1323,6.105]],["title/archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope",[209,4.057]],["text/archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope",[23,0.641,26,1.03,50,1.197,105,1.401,111,1.266,114,1.134,115,1.197,116,4.991,119,2.718,128,2.799,138,3.626,205,4.771,209,5.067,210,6.006,211,6.006,212,6.006,213,6.006,214,6.346,215,6.346,216,6.346,217,6.346,218,3.994,219,1.946,220,3.248,221,3.935,222,3.771,223,4.427,480,4.471,552,2.924,1316,5.244,1321,5.865,1322,5.865,1323,5.865]],["title/archive/api/sql/GeoSparkSQL-Constructor/#st_circle",[1326,6.262]],["text/archive/api/sql/GeoSparkSQL-Constructor/#st_circle",[20,2.176,22,2.585,23,0.605,26,1.056,50,1.227,59,2.197,90,3.74,102,2.971,105,1.436,110,1.499,111,1.298,114,1.163,115,1.227,116,5.07,138,3.717,205,4.891,219,1.995,220,2.272,237,2.656,273,3.17,335,2.698,382,5.462,459,3.482,463,4.495,464,3.814,552,2.997,757,6.723,763,6.984,872,4.78,873,4.891,875,5.598,876,4.78,877,5.012,878,3.283,1326,7.944,1327,7.749,1328,6.506,1329,7.749]],["title/archive/api/sql/GeoSparkSQL-Function/",[51,2.477]],["text/archive/api/sql/GeoSparkSQL-Function/",[17,0.232,22,1.47,23,0.634,26,1.314,44,0.478,50,1.527,65,0.408,90,0.914,96,0.456,101,0.366,102,1.016,105,1.828,106,2.2,108,0.531,109,1.349,110,2.033,111,1.674,114,1.447,115,1.582,119,2.553,121,0.414,122,3.918,126,0.307,128,1.225,129,1.073,132,1.195,133,1.304,135,2.619,139,0.52,141,2.184,158,3.31,171,2.838,172,0.52,177,2.539,178,2.464,179,1.388,182,2.261,186,2.602,187,0.592,192,1.225,199,1.791,200,3.164,201,0.561,202,0.592,219,2.954,220,3.244,234,1.128,235,0.531,236,0.828,237,2.821,238,1.016,239,3.542,240,1.934,241,0.616,242,2.431,243,0.698,244,2.415,245,0.552,246,1.389,247,1.59,248,1.05,249,3.376,250,1.59,251,2.512,252,2.412,253,1.335,254,1.971,255,0.811,257,0.965,258,0.637,259,1.523,264,0.571,275,1.868,278,1.653,279,1.409,280,0.857,281,0.397,282,0.857,283,2.294,284,1.805,285,0.857,286,0.857,287,1.868,288,0.857,289,1.382,290,0.857,291,0.857,292,0.857,294,1.971,295,1.59,296,1.275,297,0.811,298,0.652,299,0.571,300,0.857,301,1.132,304,1.143,305,0.832,311,2.072,313,1.92,319,1.509,320,0.697,321,1.971,322,1.409,323,0.857,324,1.81,327,1.422,335,1.535,336,1.156,352,0.376,354,1.382,355,0.493,356,1.314,357,1.971,358,0.857,359,0.857,360,0.857,361,0.832,362,0.857,363,1.934,364,0.857,365,0.592,366,1.692,367,1.409,368,1.409,369,0.598,370,0.437,371,0.857,372,1.868,373,1.175,374,0.472,375,0.857,377,0.932,378,0.652,379,1.409,380,2.261,381,0.857,382,0.719,383,0.66,384,1.001,385,1.899,386,2.056,387,0.857,389,0.687,391,2.261,392,2.019,396,1.899,397,1.928,399,0.759,411,0.881,412,0.373,422,1.971,423,1.469,424,0.502,425,1.409,426,0.857,430,0.466,433,1.736,449,1.358,450,1.109,451,0.832,452,0.798,453,1.59,457,0.404,459,0.851,463,2.825,464,0.502,465,0.857,466,0.857,467,0.544,470,1.225,471,1.195,472,0.775,473,0.775,474,0.986,475,0.552,476,0.639,477,0.857,478,0.66,479,0.857,480,0.604,481,1.335,482,0.857,483,0.857,484,0.857,485,1.358,486,1.088,487,1.168,488,1.19,489,0.446,490,0.697,491,0.592,492,0.697,493,0.697,494,1.409,495,0.857,496,0.792,504,1.409,505,0.857,506,0.857,543,1.469,552,1.884,582,0.539,594,0.34,629,2.261,632,0.857,633,0.857,638,2.224,639,0.811,653,1.078,661,2.011,662,0.92,663,0.92,664,0.92,667,1.505,668,0.92,669,1.335,670,0.92,671,0.792,672,2.011,673,0.92,674,1.505,675,0.469,676,0.66,677,0.92,678,1.505,679,0.92,680,1.505,681,1.59,682,1.358,683,1.59,684,1.409,685,1.505,686,1.971,687,0.92,688,0.92,689,2.011,690,0.92,691,0.92,692,0.92,696,0.466,707,0.759,711,2.105,712,0.92,713,0.678,714,0.92,715,0.652,733,0.544,736,1.899,737,1.438,738,1.241,753,0.652,774,2.011,775,0.678,776,2.415,777,0.92,778,0.92,779,2.011,780,0.745,781,0.678,782,1.59,783,0.92,784,0.857,785,0.92,786,1.505,787,0.92,788,0.92,825,1.168,826,1.069,827,0.616,917,0.775,1068,0.544,1330,0.92,1331,1.021,1332,1.021,1333,1.021,1334,1.021,1335,1.021,1336,1.021,1337,1.894,1338,1.021,1339,0.687,1340,1.021,1341,5.223]],["title/archive/api/sql/GeoSparkSQL-Function/#st_distance",[319,4.372]],["text/archive/api/sql/GeoSparkSQL-Function/#st_distance",[23,0.611,26,1.174,50,1.364,105,1.597,106,1.886,111,1.443,114,1.293,115,1.364,122,4.379,234,3.669,235,4.485,236,3.766,237,2.953,238,4.624,239,4.473,319,5.921,320,5.887,552,3.333]],["title/archive/api/sql/GeoSparkSQL-Function/#st_convexhull",[661,5.828]],["text/archive/api/sql/GeoSparkSQL-Function/#st_convexhull",[23,0.584,26,1.214,50,1.411,105,1.652,106,1.951,111,1.493,114,1.338,115,1.411,122,4.161,237,3.055,239,3.836,552,3.449,661,8.056,662,8.036,663,8.036,664,8.036]],["title/archive/api/sql/GeoSparkSQL-Function/#st_envelope",[321,5.711]],["text/archive/api/sql/GeoSparkSQL-Function/#st_envelope",[23,0.585,26,1.221,50,1.42,105,1.662,106,1.963,108,4.668,109,4.567,111,1.502,114,1.346,115,1.42,122,4.176,237,3.073,239,3.858,321,7.921,552,3.469]],["title/archive/api/sql/GeoSparkSQL-Function/#st_length",[386,5.957]],["text/archive/api/sql/GeoSparkSQL-Function/#st_length",[23,0.586,26,1.229,50,1.428,105,1.672,106,1.974,111,1.511,114,1.353,115,1.428,122,4.19,237,3.091,239,3.881,386,8.291,387,7.573,552,3.489]],["title/archive/api/sql/GeoSparkSQL-Function/#st_area",[254,5.711]],["text/archive/api/sql/GeoSparkSQL-Function/#st_area",[23,0.586,26,1.229,50,1.428,105,1.672,106,1.974,111,1.511,114,1.353,115,1.428,122,4.19,237,3.091,239,3.881,254,7.949,255,7.167,552,3.489]],["title/archive/api/sql/GeoSparkSQL-Function/#st_centroid",[638,6.446]],["text/archive/api/sql/GeoSparkSQL-Function/#st_centroid",[23,0.585,26,1.221,50,1.42,105,1.662,106,1.963,111,1.502,114,1.346,115,1.42,122,4.176,200,2.991,237,3.073,239,3.858,552,3.469,638,8.941,639,7.125]],["title/archive/api/sql/GeoSparkSQL-Function/#st_transform",[463,4.454]],["text/archive/api/sql/GeoSparkSQL-Function/#st_transform",[17,1.419,22,3.199,23,0.626,26,1.152,50,1.339,90,4.082,96,2.789,105,1.157,111,1.045,114,1.269,115,1.339,122,4.031,129,3.886,237,2.139,239,3.638,246,3.273,335,2.944,373,2.217,430,2.853,457,2.47,459,3.799,463,6.426,464,3.072,465,5.24,466,5.24,467,3.324,470,4.037,471,3.939,472,4.738,473,4.738,474,4.402,475,3.377,476,2.106,477,5.24,478,4.037,479,5.24,480,3.692,481,4.4,482,5.24,483,5.24,484,5.24,485,4.475,486,4.86,487,5.217,488,3.041,489,2.728,490,4.264,491,3.621,492,4.264,493,4.264,552,2.414,582,3.298,1068,3.324,1330,5.625,1331,6.241,1332,6.241,1333,6.241]],["title/archive/api/sql/GeoSparkSQL-Function/#st_intersection",[543,4.259]],["text/archive/api/sql/GeoSparkSQL-Function/#st_intersection",[23,0.612,26,1.18,50,1.372,105,1.606,106,1.896,110,1.676,111,1.451,114,1.3,115,1.372,122,4.389,236,3.788,237,2.969,238,4.651,239,4.489,384,4.579,543,5.787,733,4.614]],["title/archive/api/sql/GeoSparkSQL-Function/#st_isvalid",[385,5.504]],["text/archive/api/sql/GeoSparkSQL-Function/#st_isvalid",[23,0.584,26,1.214,50,1.411,105,1.652,110,1.724,111,1.493,114,1.338,115,1.411,122,4.161,141,4.418,237,3.055,239,3.836,257,4.541,304,5.382,377,4.388,385,7.608]],["title/archive/api/sql/GeoSparkSQL-Function/#st_makevalid",[736,5.504]],["text/archive/api/sql/GeoSparkSQL-Function/#st_makevalid",[22,3.15,23,0.565,26,1.005,50,1.168,101,1.427,105,1.367,106,1.615,110,1.826,111,1.236,114,1.107,115,1.168,119,4.243,126,2.216,141,3.656,192,6.107,237,2.528,242,2.989,259,4.24,452,3.109,470,4.772,471,4.657,476,2.49,481,5.201,488,2.653,736,6.769,737,7.167,738,4.834,753,4.713,825,5.824,826,5.328,827,4.454,917,5.6,1334,7.377,1335,7.377,1336,7.377,1337,9.441,1338,7.377,1339,4.968,1340,7.377]],["title/archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce",[774,5.828]],["text/archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce",[23,0.585,26,1.106,50,1.285,105,1.504,110,1.57,111,1.359,114,1.218,115,1.285,122,3.931,141,4.022,237,2.782,239,3.492,242,3.289,335,3.49,366,6.404,397,4.022,412,2.967,433,5.318,629,7.762,774,7.61,775,5.39,776,8.292,777,7.315,778,7.315]],["title/archive/api/sql/GeoSparkSQL-Function/#st_issimple",[380,5.246]],["text/archive/api/sql/GeoSparkSQL-Function/#st_issimple",[23,0.581,26,1.2,50,1.395,105,1.634,109,4.489,111,1.476,114,1.322,115,1.395,122,4.133,141,4.367,200,2.94,237,3.02,239,3.792,377,4.338,380,7.201,382,6.213,383,5.701,384,4.657]],["title/archive/api/sql/GeoSparkSQL-Function/#st_buffer",[294,5.711]],["text/archive/api/sql/GeoSparkSQL-Function/#st_buffer",[23,0.593,26,1.148,50,1.334,105,1.562,106,1.844,111,1.411,114,1.265,115,1.334,122,4.023,141,4.176,200,2.811,219,2.17,234,4.368,237,2.888,239,3.626,294,7.631,295,8.613,296,5.675,297,6.696,298,5.384,299,4.715,300,7.076,301,5.035]],["title/archive/api/sql/GeoSparkSQL-Function/#st_astext",[278,4.79]],["text/archive/api/sql/GeoSparkSQL-Function/#st_astext",[23,0.579,26,1.194,50,1.387,105,1.624,106,1.918,110,1.695,111,1.468,114,1.315,115,1.387,122,4.119,128,3.245,141,4.342,172,4.463,237,3.003,239,3.77,257,4.463,258,5.467,259,5.036,278,6.553]],["title/archive/api/sql/GeoSparkSQL-Function/#st_asgeojson",[275,5.412]],["text/archive/api/sql/GeoSparkSQL-Function/#st_asgeojson",[23,0.582,26,1.207,50,1.403,105,1.643,106,1.94,110,1.714,111,1.485,114,1.33,115,1.403,122,4.147,128,3.282,139,4.515,237,3.038,239,3.814,259,5.094,275,7.455,1341,5.733]],["title/archive/api/sql/GeoSparkSQL-Function/#st_npoints",[396,5.504]],["text/archive/api/sql/GeoSparkSQL-Function/#st_npoints",[23,0.589,105,1.692,106,1.997,110,1.765,111,1.529,115,1.445,122,4.219,133,4.492,200,3.045,237,3.128,239,3.927,396,7.715]],["title/archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology",[779,5.828]],["text/archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology",[23,0.602,102,3.856,105,1.512,110,1.945,111,1.367,115,1.292,121,3.306,122,3.944,133,4.016,220,2.393,237,2.796,239,3.511,301,4.875,311,4.345,352,3.008,397,4.043,399,6.069,672,7.635,738,5.346,779,7.635,780,5.955,781,5.418,782,8.445,783,7.354,784,6.851,785,7.354]],["title/archive/api/sql/GeoSparkSQL-Function/#st_geometrytype",[689,5.828]],["text/archive/api/sql/GeoSparkSQL-Function/#st_geometrytype",[23,0.578,26,1.187,50,1.38,105,1.615,106,1.907,110,1.685,111,1.459,114,1.308,115,1.38,122,4.105,128,3.226,133,4.289,237,2.986,239,3.749,594,2.907,669,6.142,689,7.946,690,7.854,691,7.854,692,7.854]],["title/archive/api/sql/GeoSparkSQL-Function/#st_linemerge",[711,6.101]],["text/archive/api/sql/GeoSparkSQL-Function/#st_linemerge",[22,2.751,23,0.521,101,1.595,105,1.529,106,2.398,110,1.958,111,1.381,115,1.306,171,3.548,179,3.458,182,7.806,237,2.826,264,4.614,304,4.979,305,6.726,327,4.426,357,6.134,378,5.268,411,4.709,711,8.044,712,7.433,713,5.476,714,7.433,715,5.268,1341,5.334]],["title/archive/api/sql/GeoSparkSQL-Function/#st_azimuth",[279,5.711]],["text/archive/api/sql/GeoSparkSQL-Function/#st_azimuth",[23,0.63,26,1.083,50,1.258,105,1.473,106,1.74,111,1.331,114,1.193,115,1.258,199,5.354,200,3.595,220,3.518,242,3.221,252,2.545,279,5.913,280,6.674,281,3.089,282,6.674,283,4.138,284,4.336,285,6.674,286,6.674,287,5.603,288,6.674,1341,5.141]],["title/archive/api/sql/GeoSparkSQL-Function/#st_x",[494,5.711]],["text/archive/api/sql/GeoSparkSQL-Function/#st_x",[23,0.608,26,1.154,50,1.342,105,1.571,106,1.855,111,1.419,114,1.272,115,1.342,199,4.585,200,3.434,201,4.66,220,3.251,242,3.433,252,2.713,283,4.411,284,4.622,287,5.973,335,2.95,494,6.303,495,7.115,496,6.575,1341,5.481]],["title/archive/api/sql/GeoSparkSQL-Function/#st_y",[504,5.711]],["text/archive/api/sql/GeoSparkSQL-Function/#st_y",[23,0.608,26,1.154,50,1.342,105,1.571,106,1.855,111,1.419,114,1.272,115,1.342,199,4.585,200,3.434,202,4.916,220,3.251,242,3.433,252,2.713,283,4.411,284,4.622,287,5.973,335,2.95,504,6.303,505,7.115,506,7.115,1341,5.481]],["title/archive/api/sql/GeoSparkSQL-Function/#st_startpoint",[786,6.101]],["text/archive/api/sql/GeoSparkSQL-Function/#st_startpoint",[23,0.571,26,1.154,50,1.342,105,1.571,106,1.855,110,1.639,111,1.419,114,1.272,115,1.342,158,3.724,171,3.646,200,2.827,242,3.433,252,2.713,680,6.733,681,7.115,682,6.075,683,7.115,684,6.303,685,6.733,686,6.303,696,3.873,707,6.303,786,6.733,787,7.638,788,7.638,1341,5.481]],["title/archive/api/sql/GeoSparkSQL-Function/#st_endpoint",[678,6.101]],["text/archive/api/sql/GeoSparkSQL-Function/#st_endpoint",[23,0.571,26,1.154,50,1.342,105,1.571,106,1.855,110,1.639,111,1.419,114,1.272,115,1.342,158,3.724,171,3.646,200,2.827,242,3.433,252,2.713,433,5.552,678,6.733,679,7.638,680,6.733,681,7.115,682,6.075,683,7.115,684,6.303,685,6.733,686,7.657,687,7.638,1341,5.481]],["title/archive/api/sql/GeoSparkSQL-Function/#st_boundary",[289,5.604]],["text/archive/api/sql/GeoSparkSQL-Function/#st_boundary",[23,0.562,26,1.111,50,1.292,105,1.512,106,1.786,109,4.156,110,1.945,111,1.367,114,1.224,115,1.292,158,3.586,171,3.511,219,3.182,220,3.198,252,2.613,289,5.955,290,6.851,291,6.851,292,6.851,632,6.851,633,6.851,1341,5.278]],["title/archive/api/sql/GeoSparkSQL-Function/#st_exteriorring",[322,5.711]],["text/archive/api/sql/GeoSparkSQL-Function/#st_exteriorring",[23,0.54,26,1.02,50,1.185,105,1.387,106,2.085,110,2.027,111,1.254,114,1.123,115,1.185,119,3.426,128,2.771,158,3.29,171,3.22,177,3.131,179,3.139,219,3.214,220,3.471,252,2.397,283,3.896,296,5.04,322,5.568,323,6.285,324,5.114,336,4.567,688,6.747,1341,4.842]],["title/archive/api/sql/GeoSparkSQL-Function/#st_geometryn",[354,5.604]],["text/archive/api/sql/GeoSparkSQL-Function/#st_geometryn",[23,0.578,26,1.066,50,1.239,105,1.451,106,2.145,110,2.07,111,1.311,114,1.175,115,1.239,132,4.941,135,4.857,158,3.44,177,2.572,178,3.826,186,3.598,187,4.541,200,2.611,219,2.524,252,2.507,283,4.075,284,4.27,354,5.713,355,3.778,356,5.43,357,5.822,358,6.572,359,6.572,360,6.572,361,6.384,362,6.572,363,5.713,364,6.572,365,4.541,366,5,1341,5.063]],["title/archive/api/sql/GeoSparkSQL-Function/#st_interiorringn",[367,5.711]],["text/archive/api/sql/GeoSparkSQL-Function/#st_interiorringn",[23,0.537,26,0.882,50,1.026,105,1.201,106,1.898,110,1.89,111,1.085,114,0.972,115,1.026,119,3.118,132,4.089,135,5.548,158,2.847,171,3.73,177,3.907,178,4.594,186,4.798,219,3.16,220,3.284,242,2.625,252,2.074,283,3.372,324,4.426,336,3.952,356,4.494,363,6.328,367,4.818,368,4.818,369,3.794,370,2.772,371,5.439,1341,4.19]],["title/archive/api/sql/GeoSparkSQL-Function/#st_dump",[667,6.101]],["text/archive/api/sql/GeoSparkSQL-Function/#st_dump",[23,0.537,26,1.01,50,1.174,65,2.961,105,1.374,106,2.073,110,2.197,111,1.242,114,1.112,115,1.174,119,2.666,158,3.258,171,3.189,200,3.79,252,2.374,311,5.856,313,6.379,389,4.992,391,7.513,392,6.71,423,5.752,485,5.315,653,5.393,667,5.89,668,6.682,669,5.226,670,6.682,671,5.752,672,5.627,673,6.682,1341,4.795]],["title/archive/api/sql/GeoSparkSQL-Function/#st_dumppoints",[674,6.101]],["text/archive/api/sql/GeoSparkSQL-Function/#st_dumppoints",[23,0.554,26,1.077,50,1.252,105,1.466,106,1.731,110,1.908,111,1.324,114,1.187,115,1.252,158,3.476,171,3.402,200,3.941,219,3.086,220,3.582,252,2.532,674,6.284,675,3.635,676,5.115,677,7.128,1341,5.115]],["title/archive/api/sql/GeoSparkSQL-Function/#st_isclosed",[372,5.412]],["text/archive/api/sql/GeoSparkSQL-Function/#st_isclosed",[23,0.571,26,1.154,50,1.342,102,3.249,105,1.571,106,1.855,110,1.639,111,1.419,114,1.272,115,1.342,158,3.724,171,3.646,200,2.827,219,2.855,220,3.019,246,4.444,249,5.413,252,2.713,372,5.973,373,3.01,374,3.918,375,7.115,488,3.047,1341,5.481]],["title/archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings",[425,5.711]],["text/archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings",[23,0.552,26,1.072,50,1.246,105,1.458,106,1.722,110,1.902,111,1.318,114,1.181,115,1.246,119,3.536,158,3.458,177,3.692,186,5.166,219,3.082,220,3.46,252,2.519,324,5.376,368,5.852,397,3.898,425,5.852,426,6.606,1341,5.089]],["title/archive/api/sql/GeoSparkSQL-Function/#st_addpoint",[240,5.604]],["text/archive/api/sql/GeoSparkSQL-Function/#st_addpoint",[23,0.619,26,0.894,44,3.07,50,1.039,105,1.216,106,1.436,110,2.029,111,1.464,114,0.984,115,1.384,158,4.611,171,2.823,179,2.751,200,3.5,219,3.135,220,3.418,240,6.382,241,3.961,242,2.658,243,2.419,244,6.382,245,3.549,246,3.441,247,7.342,248,3.639,249,6.701,250,7.342,251,7.963,252,2.101,253,6.164,1341,4.243]],["title/archive/api/sql/GeoSparkSQL-Function/#st_removepoint",[449,5.504]],["text/archive/api/sql/GeoSparkSQL-Function/#st_removepoint",[23,0.579,26,1.072,50,1.246,105,1.458,106,1.722,110,1.902,111,1.647,114,1.181,115,1.246,158,3.458,179,3.299,200,2.625,219,2.979,220,3.295,242,3.188,243,2.901,244,7.177,248,4.364,249,6.282,252,2.519,433,5.155,449,5.641,450,5.76,451,6.417,452,3.316,453,8.256,1341,5.089]],["title/archive/api/sql/GeoSparkSQL-Function/#st_isring",[379,5.711]],["text/archive/api/sql/GeoSparkSQL-Function/#st_isring",[23,0.568,26,1.142,50,1.327,105,1.553,106,1.834,110,1.621,111,1.404,114,1.258,115,1.327,158,3.684,171,3.606,219,2.958,220,3.454,249,5.354,252,2.684,372,5.908,373,3.632,379,6.234,380,5.727,381,7.037,1341,5.421]],["title/archive/api/sql/GeoSparkSQL-Function/#st_numgeometries",[422,5.711]],["text/archive/api/sql/GeoSparkSQL-Function/#st_numgeometries",[23,0.575,105,1.597,106,2.444,110,2.296,111,1.443,115,1.364,219,2.219,237,2.953,327,5.581,357,6.409,397,5.152,422,7.734,423,6.685,424,4.241,1341,5.573]],["title/archive/api/sql/GeoSparkSQL-Optimizer/",[349,1.441,831,1.832,832,3.106]],["text/archive/api/sql/GeoSparkSQL-Optimizer/",[8,1.645,17,0.665,20,0.821,22,0.975,23,0.648,26,1.13,36,0.881,50,1.313,59,1.356,60,2.566,65,1.91,90,1.411,102,1.833,105,1.124,110,1.999,114,0.91,115,1.313,116,4.753,122,3.705,123,4.525,177,1.571,205,4.422,209,1.545,218,3.205,219,0.753,220,2.055,234,3.531,236,2.09,242,1.184,273,1.196,298,1.868,299,1.636,319,2.722,320,1.997,335,1.018,349,2.531,370,2.596,373,1.038,382,2.061,384,1.545,459,1.314,463,1.696,464,1.439,488,1.719,529,1.522,530,0.765,531,2.722,534,4.68,537,2.418,543,1.621,544,1.868,545,2.586,556,1.489,591,1.385,613,4.349,696,1.336,831,3.33,832,4.186,833,1.595,834,1.582,835,4.014,836,2.489,837,2.113,838,3.092,839,2.219,840,5.318,841,2.635,842,5.945,843,5.945,844,3.37,845,5.882,846,5.882,847,3.267,848,4.014,849,8.007,850,4.819,851,4.014,852,4.014,853,4.014,854,5.945,855,4.014,856,4.014,857,5.567,858,2.536,859,1.969,860,3.175,861,6.079,862,6.079,863,4.309,864,4.309,865,2.323,866,4.309,867,4.309,868,1.915,869,2.635,870,2.635,871,2.635,872,1.803,873,1.845,874,2.635,875,2.748,876,1.803,877,1.891,878,1.238,920,2.175,921,3.799,922,2.455,923,2.455,924,2.455,1324,3.026,1342,2.923]],["title/archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer",[349,1.441,832,3.106,1324,2.593]],["text/archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer",[8,2.981,17,1.97,36,2.612,59,2.457,60,5.6,234,3.689,349,3.22,370,3.708,529,4.51,530,2.266,534,4.89,537,4.382,556,4.413,831,3.676,832,6.689,833,4.726,834,4.688,835,7.275]],["title/archive/api/sql/GeoSparkSQL-Optimizer/#range-join",[370,2.653,831,2.184]],["text/archive/api/sql/GeoSparkSQL-Optimizer/#range-join",[8,1.994,22,1.933,23,0.646,26,1.095,50,1.272,65,2.315,105,1.074,110,2.024,114,0.87,115,1.461,116,5.637,122,4.247,123,5.404,205,5.824,218,3.062,236,2.533,349,1.606,370,2.48,488,2.084,534,4.536,543,3.214,544,3.702,613,4.215,831,3.251,836,3.017,837,2.561,838,3.748,839,4.399,840,4.399,841,5.223,842,5.762,843,5.762,844,4.085,845,6.748,846,6.748,847,3.166,848,4.865,849,8.056,850,4.605,851,4.865,852,4.865,853,4.865,854,5.762,855,4.865,856,4.865,857,4.605,858,5.028,1324,4.009]],["title/archive/api/sql/GeoSparkSQL-Optimizer/#distance-join",[234,2.64,831,2.184]],["text/archive/api/sql/GeoSparkSQL-Optimizer/#distance-join",[20,1.574,23,0.639,26,1.07,50,1.243,59,1.59,65,2.239,90,2.706,102,2.149,105,1.039,110,2.073,114,0.841,115,1.243,177,2.58,234,4.182,236,2.45,273,2.293,298,3.581,299,3.136,319,4.472,320,3.83,335,1.951,373,1.991,382,3.951,384,2.962,459,2.518,463,3.252,464,2.759,537,2.835,545,4.248,591,2.655,613,4.118,836,2.918,837,2.477,838,3.625,840,6.88,842,5.63,843,5.63,847,3.093,849,7.305,850,4.454,854,5.63,857,6.239,859,3.774,860,5.214,861,8.521,862,8.521,863,7.078,864,7.078,865,4.454,866,7.078,867,7.078,868,3.673,869,5.052,870,5.052,871,5.052,872,3.458,873,3.538,874,5.052,875,4.513,876,3.458,877,3.625,878,2.374]],["title/archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown",[534,3.499,835,5.205]],["text/archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown",[23,0.648,26,1.13,50,1.314,102,2.327,105,1.125,110,1.605,114,0.911,115,0.961,116,4.319,122,3.707,123,4.86,205,3.831,209,3.207,218,4.384,219,1.563,220,2.98,242,2.459,349,2.299,488,2.182,531,4.725,534,4.683,613,4.351,696,2.774,831,2.923,842,5.948,843,5.948,844,4.278,845,6.966,846,6.966,847,3.268,848,5.096,849,8.171,850,4.822,851,5.096,852,5.096,853,5.096,854,5.948,855,5.096,856,5.096,857,4.822,920,4.514,921,6.592,922,5.096,923,5.096,924,5.096,1342,6.069]],["title/archive/api/sql/GeoSparkSQL-Overview/",[374,2.867,926,4.174]],["text/archive/api/sql/GeoSparkSQL-Overview/",[6,2.479,8,2.333,17,1.04,18,3.698,21,2.281,23,0.634,26,0.623,50,1.279,51,2.883,59,1.297,66,2.153,86,5.324,96,2.043,104,2.853,105,0.848,106,2.089,107,3.079,108,2.38,109,2.329,110,1.846,114,1.341,121,1.853,124,2.363,126,1.374,128,2.992,138,2.193,159,2.115,161,2.417,179,1.918,218,2.417,234,1.947,236,4.172,242,4.051,263,2.102,281,1.777,319,2.604,320,3.125,335,1.592,349,1.267,373,2.408,374,2.115,430,2.09,488,2.438,489,1.999,523,3.125,524,3.125,525,3.079,529,3.53,530,1.774,531,3.861,532,4.452,533,2.705,534,2.581,535,3.402,536,3.84,537,2.313,538,2.078,539,3.73,556,2.329,557,2.329,562,4.128,675,2.102,832,2.732,847,1.801,926,3.079,927,2.996,928,3.037,929,2.958,930,3.037,931,3.84,932,3.548,937,5.646,940,2.886,941,2.251,942,3.471,943,2.558,944,1.715,945,2.435,946,2.536,947,4.503,948,3.037,949,2.558,950,3.761,951,2.417,953,2.38,955,1.899,956,2.761,958,2.558,963,2.761,1324,4.031,1343,4.386,1344,2.604,1345,3.934,1346,3.224,1347,4.122,1348,3.634]],["title/archive/api/sql/GeoSparkSQL-Overview/#introduction",[105,1.423]],["text/archive/api/sql/GeoSparkSQL-Overview/#introduction",[]],["title/archive/api/sql/GeoSparkSQL-Overview/#function-list",[51,2,675,2.85]],["text/archive/api/sql/GeoSparkSQL-Overview/#function-list",[8,2.772,17,1.323,18,4.395,21,2.902,23,0.514,50,1.464,51,2.982,86,5.581,96,2.599,104,3.629,106,2.294,107,3.917,108,3.028,109,2.963,110,2.027,114,1.498,121,2.357,124,3.006,126,1.747,128,3.423,138,2.79,159,2.69,161,3.074,218,3.074,234,2.477,236,4.581,242,4.393,263,2.674,281,2.26,319,3.313,320,3.974,335,2.025,349,1.612,373,2.862,430,2.659,488,2.897,523,3.974,524,3.974,525,3.917,529,4.194,530,1.522,531,4.589,532,4.783,533,3.441,534,3.283,535,4.327,536,4.884,537,2.942,538,2.643,539,4.744,556,2.963,557,2.963,562,2.516,832,3.476,927,3.811,928,3.863,929,3.762,930,3.863,931,4.884,932,4.513,937,6.199,1324,4.02]],["title/archive/api/sql/GeoSparkSQL-Overview/#quick-start",[374,2.867,926,4.174]],["text/archive/api/sql/GeoSparkSQL-Overview/#quick-start",[6,3.369,23,0.65,26,0.968,59,2.015,66,3.345,86,3.784,179,2.979,489,3.106,530,1.859,562,4.681,847,2.799,940,4.485,941,3.497,942,5.394,943,3.975,944,2.665,945,3.784,946,3.941,947,6.119,948,4.718,949,3.975,950,5.111,951,3.755,953,3.699,955,2.95,956,4.29,958,3.975,963,4.29,1324,3.544,1343,5.961,1344,4.046,1345,5.346,1346,5.009,1347,6.404,1348,5.646]],["title/archive/api/sql/GeoSparkSQL-Parameter/",[474,3.997]],["text/archive/api/sql/GeoSparkSQL-Parameter/",[8,2.424,17,2.217,21,2.403,23,0.638,50,1.115,59,1.366,66,2.268,99,2.908,100,3.311,101,1.362,219,1.24,234,2.051,243,2.597,248,2.671,266,2.565,349,1.952,370,2.061,373,3.255,397,2.386,402,3.907,412,1.761,430,4.808,457,1.906,467,5.424,474,2.507,488,1.732,562,3.602,563,3.077,594,2.35,738,3.156,831,3.229,878,2.04,880,5.971,882,4.188,888,5.717,889,3.291,891,4.395,905,5.53,930,3.198,940,3.04,949,2.694,950,4.619,951,2.545,953,2.507,955,2,956,2.908,958,2.694,964,3.198,965,3.515,967,2.821,968,2.268,971,4.341,973,6.429,975,6.078,977,3.515,978,3.005,980,5.69,981,2.371,982,3.156,984,2.908,986,4.341,987,3.453,1324,3.514,1343,4.556,1344,2.743,1345,4.087,1346,3.395,1347,4.341,1349,7.858,1350,6.993,1351,4.816,1352,4.816,1353,4.816,1354,4.816,1355,4.816,1356,4.816,1357,4.816]],["title/archive/api/sql/GeoSparkSQL-Parameter/#usage",[964,5.098]],["text/archive/api/sql/GeoSparkSQL-Parameter/#usage",[8,2.368,21,3.434,23,0.654,66,3.241,266,3.665,373,2.445,402,3.818,412,2.516,430,3.146,457,2.724,474,3.583,562,4.356,563,4.397,878,2.916,930,4.571,949,3.851,950,5.586,951,3.637,953,3.583,955,2.858,956,4.155,958,3.851,965,5.023,967,4.032,968,3.241,971,6.204,1324,4.503,1343,5.838,1344,3.92,1345,5.236,1346,4.852,1347,6.204,1349,6.494,1350,8.456,1351,6.883]],["title/archive/api/sql/GeoSparkSQL-Parameter/#explanation",[940,4.846]],["text/archive/api/sql/GeoSparkSQL-Parameter/#explanation",[8,2.165,17,2.45,50,1.346,59,1.784,99,3.799,100,3.829,101,1.644,219,1.62,234,2.679,243,3.135,248,3.49,349,2.356,370,2.693,373,3.421,397,3.118,402,3.49,430,5.075,467,5.913,488,2.263,594,2.837,738,4.123,831,3.634,880,6.904,882,4.714,888,6.435,889,4.299,891,5.305,905,6.395,973,7.008,975,7.029,977,4.592,978,3.926,980,6.58,981,3.097,982,4.123,984,3.799,986,5.671,987,4.511,1349,8.022,1352,6.292,1353,6.292,1354,6.292,1355,6.292,1356,6.292,1357,6.292]],["title/archive/api/sql/GeoSparkSQL-Predicate/",[534,4.333]],["text/archive/api/sql/GeoSparkSQL-Predicate/",[23,0.656,26,1.235,50,1.435,105,1.758,106,2.076,111,1.588,114,1.36,115,1.501,116,5.579,117,5.31,136,2.95,141,3.892,209,4.791,218,3.662,219,2.335,220,3.458,221,4.719,222,4.523,223,5.31,236,4.146,237,3.25,238,5.09,299,1.995,373,3.369,384,1.885,537,2.836,538,2.548,543,3.843,544,4.427,552,2.68,988,5.26,989,2.995,990,3.095,991,3.095,992,5.26,993,5.26,994,2.995,995,5.154,996,2.995]],["title/archive/api/sql/GeoSparkSQL-Predicate/#st_contains",[218,4.057]],["text/archive/api/sql/GeoSparkSQL-Predicate/#st_contains",[23,0.643,26,1.083,50,1.258,105,1.473,106,1.74,111,1.331,114,1.193,115,1.258,116,5.151,117,4.656,209,4.201,218,5.23,219,2.047,220,3.307,221,4.138,222,3.965,223,4.656,236,3.475,237,2.724,238,4.266,373,2.823,537,4.02,538,3.612,552,3.075]],["title/archive/api/sql/GeoSparkSQL-Predicate/#st_intersects",[543,4.259]],["text/archive/api/sql/GeoSparkSQL-Predicate/#st_intersects",[23,0.643,26,1.088,50,1.265,105,1.481,106,1.749,111,1.338,114,1.199,115,1.265,116,5.168,117,4.68,209,4.222,219,2.058,220,3.313,221,4.159,222,3.986,223,4.68,236,3.493,237,2.738,238,4.289,373,2.838,384,4.222,543,5.507,552,3.091]],["title/archive/api/sql/GeoSparkSQL-Predicate/#st_within",[544,4.905]],["text/archive/api/sql/GeoSparkSQL-Predicate/#st_within",[23,0.643,26,1.083,50,1.258,105,1.473,106,1.74,111,1.331,114,1.193,115,1.258,116,5.151,117,4.656,209,4.201,219,2.047,220,3.307,221,4.138,222,3.965,223,4.656,236,3.475,237,2.724,238,4.266,373,2.823,537,4.02,538,3.612,544,6.322,552,3.075]],["title/archive/api/sql/GeoSparkSQL-Predicate/#st_equals",[992,5.828]],["text/archive/api/sql/GeoSparkSQL-Predicate/#st_equals",[23,0.643,26,1.088,50,1.265,105,1.481,106,1.749,111,1.338,114,1.199,115,1.265,116,5.168,117,4.68,141,3.959,209,4.222,219,2.058,220,3.313,221,4.159,222,3.986,223,4.68,236,3.493,237,2.738,238,4.289,299,4.47,373,2.838,992,7.537]],["title/archive/api/sql/GeoSparkSQL-Predicate/#st_crosses",[988,5.828]],["text/archive/api/sql/GeoSparkSQL-Predicate/#st_crosses",[23,0.643,26,1.088,50,1.265,105,1.481,106,1.749,111,1.338,114,1.199,115,1.265,116,5.168,117,4.68,141,3.959,209,4.222,219,2.058,220,3.313,221,4.159,222,3.986,223,4.68,236,3.493,237,2.738,238,4.289,373,2.838,988,7.537,989,6.708]],["title/archive/api/sql/GeoSparkSQL-Predicate/#st_touches",[995,5.711]],["text/archive/api/sql/GeoSparkSQL-Predicate/#st_touches",[23,0.645,105,1.504,106,1.776,111,1.359,115,1.285,116,5.219,117,4.754,141,4.022,209,4.289,219,2.09,220,3.332,221,4.225,222,4.049,223,4.754,236,3.548,237,2.782,238,4.356,373,2.883,995,7.457,996,6.815]],["title/archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps",[993,5.828]],["text/archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps",[23,0.621,26,1.174,50,1.364,105,1.597,106,1.886,111,1.443,114,1.293,115,1.364,136,4.755,141,4.269,236,3.766,237,2.953,238,4.624,373,3.06,990,7.476,991,7.476,993,7.893,994,7.234]],["title/archive/api/sql/GeoSparkSQL-javadoc/",[95,5.957]],["text/archive/api/sql/GeoSparkSQL-javadoc/",[12,4.489,13,4.357,22,2.781,23,0.429,55,5.536,59,3.122,75,2.902,96,3.725,97,5.04,98,6.328,99,5.033,100,4.052,101,1.612,102,3.196,1314,6.433,1315,3.973,1324,4.159,1358,8.336]],["title/archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api",[12,1.984,13,1.975,97,2.285]],["text/archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api",[12,4.409,13,4.223,22,2.842,55,5.658,59,3.152,75,2.966,96,3.807,97,4.884,98,6.468,99,5.144,100,4.106,101,1.648,102,3.267,1314,6.519,1315,4.061,1324,4.251,1358,8.52]],["title/archive/api/viz/Babylon-Scala-and-Java-API/",[1238,2.892]],["text/archive/api/viz/Babylon-Scala-and-Java-API/",[12,4.418,13,4.398,22,2.858,23,0.441,59,2.43,96,3.828,97,5.087,98,6.504,99,5.173,100,4.12,101,1.657,102,3.285,1238,3.227,1243,3.745,1257,5.316,1359,8.568]],["title/archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd",[12,1.708,13,1.701,97,1.967,1238,1.686]],["text/archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd",[12,4.304,13,4.285,22,2.94,59,2.499,96,3.938,97,4.956,98,6.69,99,5.321,100,4.19,101,1.704,102,3.379,1243,3.853,1257,5.407,1359,8.813]],["title/archive/api/viz/sql/",[1239,6.446]],["text/archive/api/viz/sql/",[6,1.726,10,0.972,17,1.579,18,2.576,20,1.326,22,1.575,23,0.642,26,1.184,36,0.868,48,2.098,50,1.304,51,2.24,59,0.817,66,1.356,86,2.515,90,2.279,97,2.075,102,1.104,104,1.797,105,1.42,106,1.677,111,1.379,114,1.362,115,1.304,121,1.167,122,1.129,128,2.571,129,1.167,141,3.797,178,1.124,179,1.208,201,3.301,202,3.482,206,1.818,237,0.987,242,2.813,248,1.597,259,1.655,270,3.226,329,3.752,335,1.644,374,1.332,394,1.912,416,3.18,424,1.417,430,2.158,489,1.259,530,0.753,562,3.315,574,1.408,583,2.324,594,0.961,600,2.03,620,2.237,641,1.075,675,1.324,697,1.968,720,2.102,837,1.273,847,1.134,860,1.912,926,1.939,929,1.863,940,1.818,944,1.08,945,1.534,946,1.597,947,3.136,948,1.912,949,1.611,950,2.619,951,1.522,953,1.499,955,1.196,956,1.739,958,1.611,963,2.851,1000,2.197,1019,1.818,1051,3.047,1068,1.534,1069,2.065,1083,3.851,1102,3.965,1108,2.065,1118,2.418,1139,1.939,1205,5.523,1240,1.427,1241,2.418,1247,2.102,1248,4.894,1249,6.346,1250,6.689,1251,2.102,1252,2.288,1253,2.288,1254,1.721,1255,2.596,1256,2.186,1257,3.079,1258,2.596,1259,2.596,1260,2.288,1261,2.288,1262,2.234,1263,2.288,1264,5.829,1265,4.722,1266,2.88,1267,2.03,1268,1.757,1269,1.968,1270,2.88,1271,1.797,1272,2.288,1273,2.88,1274,1.968,1275,2.88,1276,2.88,1277,2.88,1278,2.88,1279,2.88,1280,2.186,1281,4.556,1282,3.584,1283,3.965,1284,2.03,1285,2.418,1286,1.703,1287,2.596,1288,1.39,1289,2.596,1290,4.042,1291,1.887,1293,2.596,1294,2.596,1295,2.596,1296,3.752,1297,4.231,1298,4.579,1299,3.329,1300,2.619,1301,4.256,1302,2.596,1303,3.965,1304,2.596,1305,3.932,1306,3.446,1309,2.596,1311,4.256,1312,2.596,1324,1.437,1343,3.054,1344,1.64,1345,2.739,1348,2.288,1360,2.288,1361,2.88,1362,2.596]],["title/archive/api/viz/sql/#quick-start",[374,2.867,926,4.174]],["text/archive/api/viz/sql/#quick-start",[6,3.3,17,1.565,23,0.651,26,0.938,59,1.952,66,3.241,86,3.665,179,2.886,489,3.009,530,1.8,562,4.801,847,2.711,940,4.344,944,2.581,945,3.665,946,3.818,947,5.994,948,4.571,949,3.851,950,5.006,951,3.637,953,3.583,955,2.858,956,4.155,958,3.851,963,5.449,1240,3.41,1241,5.779,1257,3.531,1324,3.434,1343,5.838,1344,3.92,1345,5.236,1348,5.469,1360,5.469,1361,6.883,1362,6.204]],["title/archive/api/viz/sql/#regular-functions",[51,2,1247,4.524]],["text/archive/api/viz/sql/#regular-functions",[]],["title/archive/api/viz/sql/#st_pixelize",[1290,5.17]],["text/archive/api/viz/sql/#st_pixelize",[23,0.63,26,1.136,50,1.32,104,5.201,105,1.545,106,1.824,111,1.396,114,1.251,115,1.32,122,3.269,141,4.131,206,5.262,237,2.857,242,3.378,583,5.016,1205,4.246,1290,6.862,1291,5.462,1293,7.514,1294,7.514,1295,7.514,1296,8.098]],["title/archive/api/viz/sql/#st_tilename",[1297,5.412]],["text/archive/api/viz/sql/#st_tilename",[20,2.081,22,2.473,23,0.585,26,1.01,48,3.294,50,1.174,90,3.578,105,1.374,106,1.622,111,1.586,114,1.112,115,1.174,128,2.745,141,3.673,178,2.894,201,5.739,202,6.054,242,3.004,329,7.525,335,3.297,416,6.377,1051,4.149,1205,4.824,1264,6.224,1297,6.676,1298,6.789,1299,6.676,1300,5.253,1301,8.536,1302,6.682,1303,6.224,1304,6.682]],["title/archive/api/viz/sql/#st_colorize",[1248,5.412]],["text/archive/api/viz/sql/#st_colorize",[10,2.696,17,2.456,18,4.358,22,2.665,105,1.481,106,1.749,111,1.338,128,2.958,129,3.237,141,3.959,242,3.237,248,4.432,430,4.538,574,3.907,594,2.665,600,5.632,641,2.984,837,3.531,1069,5.728,1102,6.708,1205,4.07,1248,5.632,1249,7.246,1250,6.97,1251,5.832,1252,6.349,1253,6.349,1254,4.774,1255,7.202,1256,6.065,1257,4.099,1258,7.202,1259,7.202]],["title/archive/api/viz/sql/#st_encodeimage",[1281,5.828]],["text/archive/api/viz/sql/#st_encodeimage",[23,0.564,26,1.123,36,2.486,50,1.306,97,3.625,105,1.529,106,1.805,111,1.381,114,1.519,115,1.306,128,3.749,141,4.086,259,4.74,1000,4.709,1083,8.257,1118,6.924,1139,5.553,1257,4.231,1281,7.685,1282,6.26,1283,6.924,1284,5.813,1285,6.924,1286,4.878,1287,7.433,1288,3.981,1289,7.433]],["title/archive/api/viz/sql/#aggregate-functions",[18,3.381,51,2]],["text/archive/api/viz/sql/#aggregate-functions",[]],["title/archive/api/viz/sql/#st_render",[1305,5.031]],["text/archive/api/viz/sql/#st_render",[23,0.614,26,1.117,50,1.299,97,3.605,105,1.52,106,1.795,111,1.374,114,1.231,115,1.299,141,4.065,242,3.324,424,4.038,1205,5.808,1250,6.225,1264,6.887,1282,6.227,1283,6.887,1303,6.887,1305,6.612,1306,7.365,1309,7.393,1311,9.095,1312,7.393]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/",[335,1.81,1363,2.248,1364,2.812]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/",[5,1.601,6,2.798,20,1.779,23,0.61,26,1.163,31,2.605,36,1.909,50,0.661,52,1.966,54,5.008,59,3.341,75,4.053,184,5.522,373,2.25,413,2.944,446,2.224,476,1.409,488,1.502,530,2.002,556,4.922,752,2.853,825,2.576,944,2.376,945,4.548,946,4.737,1137,3.318,1243,4.013,1314,6.816,1365,3.318,1366,2.579,1367,7.281,1368,7.579,1369,7.281,1370,4.541,1371,5.976,1372,4.541,1373,4.176,1374,4.915,1375,4.176,1376,4.176,1377,4.176,1378,4.176,1379,5.496,1380,6.425,1381,4.176,1382,3.17,1383,3.506,1384,3.764,1385,4.176,1386,7.652,1387,4.176,1388,4.176,1389,5.976,1390,6.966,1391,3.904,1392,2.042,1393,4.176,1394,4.176,1395,2.548,1396,5.709,1397,3.764,1398,3.764,1399,3.764,1400,3.764]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions",[26,0.61,36,1.349,75,1.558,1365,3.556]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions",[6,3.547,20,2.724,530,2.538,945,5.167,946,5.381,1366,3.95]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core",[59,1.758,944,2.325]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core",[59,2.751,75,3.378,184,5.336,1367,6.275,1368,6.533,1369,6.275]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-sql",[50,0.981,59,1.758]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-sql",[]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23",[556,3.158,1370,4.444]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23",[59,2.734,75,3.356,184,5.302,1367,6.236,1368,6.492,1369,6.236,1371,9.096]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22",[556,3.158,1372,4.444]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22",[59,2.734,75,3.356,184,5.302,1367,6.236,1368,6.492,1369,6.236,1373,9.641]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21",[556,3.158,1374,4.81]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21",[59,2.734,75,3.356,184,5.302,1367,6.236,1368,6.492,1369,6.236,1375,9.641]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-120-and-later",[31,2.792,59,1.269,825,2.761,1243,1.956]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-120-and-later",[]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23_1",[556,3.158,1370,4.444]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23_1",[59,2.734,75,3.356,184,5.302,1367,6.236,1368,6.492,1369,6.236,1376,9.641]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22_1",[556,3.158,1372,4.444]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22_1",[59,2.734,75,3.356,184,5.302,1367,6.236,1368,6.492,1369,6.236,1377,9.641]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21_1",[556,3.158,1374,4.81]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21_1",[59,2.734,75,3.356,184,5.302,1367,6.236,1368,6.492,1369,6.236,1378,9.641]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier",[59,1.269,1137,3.556,1243,1.956,1379,3.883]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier",[59,2.734,75,3.356,1243,4.214,1367,6.236,1368,6.492,1369,6.236,1379,8.365]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions",[26,0.61,36,1.349,75,1.558,1380,3.758]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions",[6,3.547,20,2.724,530,2.538,945,5.167,946,5.381,1366,3.95]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1",[59,1.758,944,2.325]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1",[26,1.305,59,2.717,75,3.336,1367,6.197,1368,6.452,1369,6.197,1380,8.044,1381,9.581]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz",[59,1.758,1243,2.71]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz",[26,1.305,75,3.336,1367,6.197,1368,6.452,1369,6.197,1380,8.044,1382,7.273,1383,8.044]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions",[75,2.158,1314,3.913]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions",[5,3.063,6,2.921,52,3.762,54,4.358,59,3.204,75,3.934,446,4.255,476,2.696,530,2.09,752,5.459,945,4.255,946,4.432,1243,3.493,1314,7.475,1367,6.987,1368,7.273,1369,6.987,1371,7.539,1384,7.202,1385,7.99,1386,10.801]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#buildsbt",[946,4.259]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#buildsbt",[23,0.601,413,6.754,1314,6.047,1387,9.581,1388,9.581,1389,9.04]],["title/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml",[945,4.089]],["text/archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml",[54,6.302,373,3.668,488,3.064,1314,6.519,1389,8.039,1390,9.422,1391,5.28,1392,4.166,1393,8.52,1394,8.52,1395,5.199,1396,9.309,1397,7.68,1398,7.68,1399,7.68,1400,7.68]],["title/archive/download/GeoSpark-All-Modules-Release-notes/",[5,2.377,22,2.068]],["text/archive/download/GeoSpark-All-Modules-Release-notes/",[5,1.186,6,2.648,7,0.529,8,2.598,10,0.486,12,2.406,13,0.987,15,1.175,17,1.936,20,1.111,21,0.38,23,0.615,26,0.638,31,0.476,32,1.756,33,0.87,35,0.481,36,0.783,42,0.662,44,0.357,46,0.97,47,1.729,50,0.883,51,2.283,57,0.448,58,1.952,59,2.994,60,0.773,61,0.775,63,0.353,65,0.818,71,0.957,75,2.116,86,0.767,89,3.921,90,0.696,93,1.25,94,1.173,95,0.592,96,1.583,97,1.141,100,2.59,101,1.079,102,0.292,106,0.315,108,0.397,109,0.734,110,0.685,111,0.888,113,0.359,114,0.837,118,0.547,119,0.737,121,1.756,124,2.42,128,0.534,129,0.309,139,2.015,141,0.378,165,0.5,166,0.442,171,0.62,172,0.388,177,1.918,178,0.562,199,0.412,200,0.683,219,1.289,220,0.224,221,0.397,225,0.423,234,1.846,235,0.75,241,0.87,243,1.307,245,2.708,252,1.135,261,0.513,263,0.35,264,0.806,269,0.579,273,3.028,278,0.476,281,1.009,283,1.352,298,0.487,333,0.606,334,0.412,335,1.742,349,2.359,352,1.307,355,0.696,370,2.142,377,0.375,378,0.487,380,0.521,384,0.403,385,1.033,396,0.547,397,0.714,403,2.053,407,0.537,412,2.76,413,0.537,415,0.5,424,0.709,430,1.187,431,0.852,438,0.537,450,1.811,452,0.607,455,0.719,456,0.889,459,0.647,464,1.522,467,1.091,470,0.493,471,0.91,472,0.579,473,0.579,474,2.438,475,0.412,476,1.58,478,0.493,480,0.451,486,0.438,487,0.47,489,0.333,492,0.521,501,0.529,523,0.521,524,0.521,525,0.513,530,0.377,533,0.451,537,0.386,538,1.18,543,0.799,552,0.295,553,0.579,554,0.606,555,1.859,556,0.734,558,1.673,559,0.47,566,0.977,576,0.5,578,0.579,579,1.052,580,1.444,583,0.375,585,0.481,594,1.032,595,1.091,597,0.579,603,0.513,608,0.556,613,0.4,616,1.91,619,0.419,620,1.23,641,1.749,661,0.579,666,0.487,682,0.547,684,0.567,686,0.567,689,0.579,695,0.579,696,0.348,700,1.309,701,0.529,702,0.75,703,0.529,706,0.579,707,0.567,708,0.622,713,0.506,715,1.309,733,0.406,736,0.547,745,0.67,774,0.579,775,0.957,779,0.579,780,1.052,822,0.513,823,1.091,831,2.66,832,0.456,833,0.416,834,2.345,837,0.637,839,0.579,844,0.537,847,0.3,859,0.97,865,1.628,868,0.5,872,1.602,873,0.481,875,0.438,876,0.47,877,0.493,878,1.676,880,1.033,882,1.981,883,1.052,888,0.476,889,0.521,891,0.476,917,1.094,921,0.606,933,0.606,938,1.389,940,0.481,944,2.093,955,0.317,959,0.287,961,0.451,964,1.361,965,0.556,967,0.447,977,0.556,981,0.709,988,0.579,992,0.579,993,0.579,995,0.567,1000,2.328,1003,0.521,1014,1.668,1017,0.406,1022,0.64,1024,2.162,1027,1.922,1055,0.346,1068,0.406,1104,1.325,1107,0.547,1140,0.521,1205,0.388,1238,2.374,1240,1.015,1243,2.047,1247,1.052,1248,0.537,1254,0.861,1256,0.579,1257,1.818,1267,1.016,1268,0.879,1281,0.579,1288,0.989,1290,0.513,1291,0.5,1297,0.537,1298,0.456,1300,0.423,1305,0.5,1308,0.521,1315,0.363,1316,0.529,1318,0.944,1326,0.622,1328,0.64,1350,1.21,1363,1.533,1364,0.78,1365,0.606,1366,1.057,1370,1.033,1372,0.547,1374,0.592,1382,3.799,1383,0.64,1391,0.348,1392,1.002,1401,0.513,1402,1.62,1403,3.96,1404,4.332,1405,0.409,1406,0.487,1407,0.687,1408,0.506,1409,0.687,1410,5.617,1411,0.687,1412,2.257,1413,1.971,1414,0.687,1415,0.687,1416,0.687,1417,0.687,1418,0.687,1419,0.687,1420,0.606,1421,0.687,1422,0.606,1423,0.687,1424,0.687,1425,0.687,1426,0.687,1427,0.687,1428,0.687,1429,0.687,1430,0.622,1431,0.687,1432,0.687,1433,0.64,1434,0.687,1435,0.687,1436,0.687,1437,0.932,1438,1.094,1439,0.687,1440,0.687,1441,0.64,1442,0.64,1443,0.687,1444,0.687,1445,0.687,1446,0.687,1447,1.145,1448,1.145,1449,0.687,1450,0.687,1451,0.64,1452,0.64,1453,0.687,1454,0.687,1455,1.21,1456,1,1457,1,1458,0.687,1459,0.687,1460,0.687,1461,0.687,1462,1.033,1463,1.342,1464,0.661,1465,0.43,1466,0.899,1467,0.64,1468,0.687,1469,0.687,1470,0.687,1471,0.97,1472,0.687,1473,0.687,1474,0.687,1475,0.687,1476,0.687,1477,0.687,1478,0.579,1479,0.606,1480,0.687,1481,0.687,1482,0.592,1483,1.016,1484,0.687,1485,0.687,1486,0.687,1487,0.861,1488,0.687,1489,0.687,1490,1.175,1491,0.64,1492,1.237,1493,0.687,1494,0.687,1495,0.687,1496,0.687,1497,1.2,1498,1.051,1499,1.072,1500,0.567,1501,0.687,1502,0.687,1503,0.687,1504,0.687,1505,0.687,1506,0.687,1507,0.687,1508,0.687,1509,0.687,1510,0.687,1511,0.687,1512,0.687,1513,0.687,1514,0.687,1515,0.687,1516,0.687,1517,0.687,1518,0.687,1519,0.622,1520,0.687,1521,1.21,1522,1.733,1523,0.687,1524,0.687,1525,1.895,1526,0.687,1527,1.052,1528,0.985,1529,1.309,1530,0.687,1531,1.299,1532,1.299,1533,1.145,1534,1.555,1535,1.299,1536,1.094,1537,0.64,1538,1.21,1539,1.4,1540,0.579,1541,0.687,1542,0.661,1543,0.687,1544,1.175,1545,0.661,1546,0.687,1547,0.687,1548,0.661,1549,0.944,1550,0.687,1551,0.476,1552,0.985,1553,0.687,1554,0.547,1555,0.64,1556,0.756,1557,0.687,1558,0.537,1559,1.21,1560,2.96,1561,2.237,1562,0.687,1563,0.592,1564,1.778,1565,0.687,1566,0.661,1567,0.921,1568,0.64,1569,1.051,1570,0.687,1571,0.64,1572,1.264,1573,0.661,1574,0.661,1575,0.661,1576,0.622,1577,0.661,1578,0.687,1579,0.661,1580,0.661,1581,0.5,1582,0.879,1583,1.575,1584,0.687,1585,0.465,1586,0.687,1587,0.64,1588,0.687,1589,0.687,1590,0.687,1591,0.687,1592,0.661,1593,1.293,1594,1.108,1595,0.606,1596,0.687,1597,0.592,1598,0.977,1599,0.661,1600,0.47,1601,0.687,1602,0.687,1603,1.175,1604,0.687,1605,0.687,1606,0.687,1607,0.687,1608,0.606,1609,1.094,1610,0.64,1611,0.521,1612,0.687,1613,1.21,1614,1.299,1615,0.556,1616,1.21,1617,1.323,1618,0.687,1619,0.687,1620,0.271,1621,0.361,1622,0.687,1623,0.687,1624,1.299,1625,1.21,1626,1.21,1627,0.687,1628,0.456,1629,0.687,1630,0.64,1631,0.687,1632,0.687,1633,0.844,1634,0.579,1635,0.64,1636,0.687,1637,2.789,1638,1,1639,0.687,1640,0.687,1641,0.687,1642,0.687,1643,0.493,1644,0.687,1645,0.606,1646,1.016,1647,0.661,1648,0.513,1649,0.687,1650,0.687,1651,0.687,1652,0.687,1653,0.687,1654,1.299,1655,0.687,1656,0.529,1657,2.596,1658,1.072,1659,0.687,1660,0.687,1661,0.64,1662,0.687,1663,0.687,1664,1.444,1665,0.687,1666,1.628,1667,1,1668,1.4,1669,0.606,1670,0.64,1671,0.687,1672,0.64,1673,0.687,1674,0.687,1675,1.21,1676,0.687,1677,0.687,1678,0.606,1679,0.64,1680,0.556,1681,0.64,1682,0.687,1683,1.495,1684,0.622,1685,0.687,1686,0.547,1687,0.506,1688,1.299,1689,0.932,1690,0.355,1691,0.567,1692,0.687,1693,0.687,1694,1.175,1695,1.21,1696,1.21,1697,1.361,1698,0.687,1699,0.687,1700,0.687,1701,2.386,1702,2.559,1703,0.493,1704,0.687,1705,0.687,1706,0.622,1707,0.687,1708,0.547,1709,0.579,1710,0.529,1711,0.403,1712,0.687,1713,0.687,1714,0.687,1715,0.687,1716,0.622,1717,0.521,1718,1.299,1719,0.78,1720,0.537,1721,0.487,1722,0.687,1723,1.299,1724,0.481,1725,0.661,1726,0.687,1727,0.687,1728,0.687,1729,0.687,1730,0.687,1731,0.579,1732,0.481,1733,0.47,1734,0.687,1735,1.21,1736,0.687,1737,0.493,1738,0.493,1739,0.687,1740,0.687,1741,0.416,1742,0.687,1743,0.606,1744,0.687,1745,0.687,1746,0.687,1747,0.579,1748,0.537,1749,0.579,1750,0.687,1751,0.547,1752,0.687,1753,0.687,1754,0.687,1755,0.687,1756,0.556,1757,0.606,1758,1.299,1759,0.606,1760,0.556,1761,0.687,1762,0.687,1763,1.094,1764,0.687,1765,0.687,1766,0.687,1767,0.687,1768,0.687,1769,0.687,1770,0.661,1771,0.622]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v131",[415,5.031]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v131",[5,1.774,6,1.692,12,1.766,15,3.416,23,0.638,50,1.083,51,2.9,59,2.946,71,3.073,75,1.611,89,4.45,101,0.895,110,0.895,139,3.484,263,2.128,283,2.409,396,3.318,397,2.293,412,3.287,413,3.262,430,2.115,501,3.211,538,2.103,553,3.513,566,2.206,603,3.116,689,3.513,736,3.318,779,3.513,834,3.701,938,2.079,944,1.736,964,3.073,981,2.278,1238,1.743,1243,2.023,1257,2.374,1363,2.002,1366,1.884,1391,2.115,1401,3.116,1402,5.077,1403,4.462,1404,4.286,1405,2.484,1406,2.956,1407,4.171,1408,3.073,1409,4.171,1410,7.339,1411,4.171,1412,3.378,1413,5.193,1414,4.171,1415,4.171,1416,4.171,1417,4.171,1418,4.171,1419,4.171,1420,3.677,1421,4.171,1422,3.677,1423,4.171,1424,4.171,1425,4.171,1426,4.171,1427,4.171,1428,4.171,1429,4.171,1430,3.775,1431,4.171,1432,4.171,1433,3.886,1434,4.171,1435,4.171,1436,4.171,1437,2.993,1438,3.513,1439,4.171,1440,4.171,1441,3.886,1442,3.886,1443,4.171,1444,4.171,1445,4.171,1446,4.171,1447,3.677,1448,3.677,1449,4.171,1450,4.171,1451,3.886,1452,3.886,1453,4.171,1454,4.171,1455,3.886,1456,3.211,1457,3.211,1458,4.171,1459,4.171,1460,4.171,1461,4.171]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v130",[113,3.615]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v130",[5,3.696,15,3.664,59,2.734,1402,6.015,1403,4.485,1462,6.912,1463,6.317]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v120",[141,3.804]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v120",[6,3.282,8,2.552,10,2.057,12,2.327,17,0.903,20,2.083,23,0.595,26,0.541,31,2.478,36,1.197,47,1.372,50,1.175,51,3.056,59,3.074,60,2.132,75,2.122,89,4.356,93,4.527,94,2.755,100,1.579,101,0.768,114,0.596,118,2.847,139,4.239,199,2.149,235,2.067,273,1.625,278,2.478,283,3.173,335,2.122,380,2.714,385,4.37,407,2.8,412,3.464,430,2.786,476,2.057,538,1.805,566,2.906,594,1.325,595,2.115,613,2.083,616,2.943,702,2.067,774,3.015,868,2.602,872,3.761,878,3.525,880,2.847,944,1.49,964,2.637,988,3.015,992,3.015,993,3.015,995,2.954,1000,1.847,1027,3.604,1205,2.023,1238,1.496,1243,1.736,1248,2.8,1257,3.127,1281,3.015,1288,3.581,1290,2.674,1297,2.8,1305,2.602,1316,2.755,1318,2.602,1326,3.239,1363,2.637,1403,4.176,1404,3.718,1410,5.316,1412,5.415,1413,4.628,1438,3.015,1447,3.156,1448,3.156,1455,3.334,1456,2.755,1457,2.755,1464,3.446,1465,2.241,1466,3.803,1467,3.334,1468,3.58,1469,3.58,1470,3.58,1471,4.105,1472,3.58,1473,3.58,1474,3.58,1475,3.58,1476,3.58,1477,3.58,1478,3.015,1479,3.156,1480,3.58,1481,3.58,1482,3.082,1483,2.8,1484,3.58,1485,3.58,1486,3.58,1487,2.373,1488,3.58,1489,3.58,1490,4.972,1491,3.334,1492,2.398,1493,3.58,1494,3.58,1495,3.58,1496,3.58,1497,2.326,1498,2.037,1499,4.534,1500,2.954,1501,3.58,1502,3.58,1503,3.58,1504,3.58,1505,3.58,1506,3.58,1507,3.58,1508,3.58,1509,3.58,1510,3.58,1511,3.58,1512,3.58,1513,3.58,1514,3.58,1515,3.58,1516,3.58,1517,3.58,1518,3.58]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v113",[1328,6.446]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v113",[12,3.165,17,1.885,23,0.566,50,1.313,59,3.246,75,2.887,89,3.459,110,1.603,273,3.392,538,3.768,595,4.415,944,3.81,1027,4.028,1238,3.123,1243,3.624,1403,3.857,1404,4.538,1410,5.297,1519,6.762,1520,7.473,1521,6.961,1522,4.054,1523,7.473,1524,7.473,1525,7.413]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v112",[1526,6.92]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v112",[8,1.822,23,0.633,26,0.721,50,0.839,59,2.492,65,2.116,75,2.627,89,4.223,100,2.106,101,1.459,110,1.459,111,0.887,121,2.146,124,2.737,128,1.961,165,3.47,166,3.073,177,2.479,220,1.553,245,4.755,273,4.429,352,1.953,378,3.384,397,2.624,538,2.407,543,2.938,558,2.773,594,2.517,616,2.557,620,2.509,666,3.384,715,3.384,780,3.866,844,3.734,882,2.421,917,5.727,944,1.987,1017,2.821,1238,1.995,1243,2.315,1254,3.165,1403,2.464,1404,4.279,1410,6.916,1521,4.447,1522,2.59,1525,3.866,1527,5.506,1528,3.619,1529,3.384,1530,4.774,1531,6.8,1532,6.8,1533,5.995,1534,6.671,1535,6.8,1536,5.727,1537,4.447,1538,4.447,1539,3.619,1540,4.021,1541,4.774,1542,4.596,1543,4.774,1544,4.32,1545,4.596,1546,4.774,1547,4.774,1548,4.596,1549,3.47,1550,4.774,1551,3.305,1552,3.619,1553,4.774,1554,3.797,1555,4.447,1556,2.778,1557,4.774]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v111",[608,5.604]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v111",[5,3.696,967,5.647,1363,4.17,1364,5.216,1462,6.912,1463,6.317,1549,6.317]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v110",[733,4.089]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v110",[6,3.219,8,3.029,23,0.633,26,1.199,36,2.28,42,3.477,50,0.841,51,1.714,59,2.874,75,2.633,89,4.395,110,1.028,121,2.153,177,1.747,243,3.536,273,4.434,335,1.85,403,4.99,470,3.438,471,3.355,472,4.035,473,4.035,474,2.767,543,2.948,555,2.787,556,2.707,594,1.773,597,4.035,661,4.035,702,2.767,708,4.335,872,4.666,944,1.993,1104,3.438,1107,3.81,1243,2.323,1257,2.727,1363,2.299,1364,2.876,1370,5.422,1404,4.529,1410,6.729,1412,3.879,1483,3.747,1487,3.176,1558,3.747,1559,4.462,1560,5.674,1561,4.774,1562,4.79,1563,4.124,1564,7.639,1565,4.79,1566,4.611,1567,3.395,1568,4.462,1569,2.727,1570,4.79,1571,4.462,1572,3.279,1573,4.611,1574,4.611,1575,4.611,1576,4.335,1577,4.611,1578,4.79,1579,4.611]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v101",[703,5.326]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v101",[8,2.915,23,0.594,26,1.154,50,1.63,59,3.27,89,4.295,245,4.585,335,2.95,556,4.316,686,6.303,944,3.178,1243,3.704,1363,3.665,1372,6.075,1374,6.575,1404,4.599,1525,6.185,1552,5.79,1580,7.352,1581,5.552]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v100",[552,2.97]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v100",[5,3.213,6,3.064,8,2.884,17,1.906,50,1.619,59,3.258,94,2.775,128,3.103,455,4.181,523,5.727,524,5.727,525,5.644,537,4.239,944,3.144,965,6.117,1243,4.47,1257,5.245,1315,3.995,1350,8.585,1382,6.362,1582,5.114,1583,4.269,1584,7.554,1585,5.114]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core",[59,1.474,944,1.95,1586,4.685]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core",[6,2.673,8,2.516,12,1.935,17,1.153,23,0.583,47,1.751,51,1.635,59,1.438,61,1.918,65,2.025,89,3.051,90,2.447,94,1.679,101,0.98,106,1.11,110,0.98,119,1.823,121,2.054,200,2.439,234,4.415,243,1.869,245,2.743,273,2.991,281,1.97,298,3.239,349,3.263,352,1.869,370,4.438,403,3.464,412,1.854,430,2.317,438,3.574,450,2.97,452,2.137,467,2.7,530,1.913,555,3.835,558,1.6,583,2.495,619,2.788,701,3.517,706,3.849,707,3.771,775,3.367,822,3.414,831,3.855,834,2.743,880,3.635,882,2.317,883,3.7,888,3.163,891,3.163,1014,3.443,1403,2.358,1404,3.832,1410,4.671,1522,2.479,1529,3.239,1544,4.135,1559,4.257,1560,4.325,1561,3.2,1567,3.239,1572,4.511,1587,4.257,1588,4.57,1589,4.57,1590,4.57,1591,4.57,1592,4.399,1593,3.2,1594,3.956,1595,4.028,1596,4.57,1597,3.934,1598,2.417,1599,4.399,1600,3.128,1601,4.57,1602,4.57,1603,4.135,1604,4.57,1605,4.57,1606,4.57,1607,4.57,1608,4.028,1609,3.849,1610,4.257,1611,3.464,1612,4.57,1613,6.139,1614,6.59,1615,3.7,1616,4.257,1617,2.582]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core",[59,1.474,944,1.95,1618,4.685]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core",[17,1.836,23,0.515,51,2.604,89,3.369,96,3.607,100,3.21,245,4.368,273,3.303,283,4.203,334,4.368,412,2.952,474,4.203,555,4.234,558,3.154,873,5.096,882,3.69,938,3.628,961,4.776,1104,5.222,1238,3.041,1403,4.648,1404,4.465,1498,4.142,1619,7.277,1620,2.868,1621,3.825,1622,7.277,1623,7.277,1624,9.007,1625,6.779,1626,6.779,1627,7.277,1628,4.824]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core",[59,1.474,944,1.95,1629,4.685]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core",[23,0.444,51,2.779,59,2.443,96,3.85,100,3.426,124,4.452,177,2.831,219,2.219,464,4.241,478,5.573,576,2.988,579,6.288,580,7.33,616,4.159,695,6.54,1024,5.257,1027,4.186,1392,5.084,1403,4.008,1404,4.646,1569,4.42,1630,7.234,1631,7.766]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core",[59,1.474,944,1.95,1632,4.685]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core",[6,1.371,8,1.29,12,2.225,13,2.216,17,2.429,20,1.053,21,1.87,23,0.579,26,0.511,51,1.881,58,3.68,59,2.91,61,1.418,75,1.305,89,2.433,96,1.675,97,2.563,100,4.08,101,1.561,108,1.952,109,2.97,111,1.352,114,1.312,121,2.362,124,3.697,177,1.916,219,1.501,221,1.952,225,2.079,234,2.483,241,2.263,245,3.155,273,1.534,281,1.457,333,2.979,349,2.907,370,1.605,412,2.132,431,3.449,450,3.415,452,1.58,474,4.818,476,3.26,480,2.218,492,2.562,533,2.218,554,2.979,555,3.058,558,2.258,578,2.846,579,2.736,580,2.643,594,1.251,616,1.81,641,3.014,696,1.714,700,4.57,745,2.712,823,3.105,831,3.52,834,3.871,859,2.525,878,1.588,882,3.27,883,2.736,933,2.979,938,2.62,955,1.556,977,2.736,981,1.845,1014,1.765,1140,2.562,1238,3.04,1403,2.712,1404,2.605,1492,3.52,1522,2.851,1539,2.562,1560,4.774,1561,4.516,1583,2.97,1603,3.058,1617,1.91,1633,2.196,1634,2.846,1635,3.148,1636,3.379,1637,5.043,1638,4.045,1639,3.379,1640,3.379,1641,3.379,1642,3.379,1643,2.425,1644,3.379,1645,2.979,1646,2.643,1647,3.253,1648,2.525,1649,3.379,1650,3.379,1651,3.379,1652,3.379,1653,3.379,1654,5.255,1655,3.379,1656,2.601,1657,6.776,1658,4.337,1659,3.379,1660,3.379,1661,3.148,1662,3.379,1663,3.379,1664,5.043,1665,3.379,1666,2.979,1667,4.045,1668,4.888,1669,2.979,1670,3.148,1671,3.379,1672,3.148]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07",[1673,5.587,1674,5.587]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07",[5,0.996,6,2.862,7,1.802,8,2.858,12,2.988,13,0.987,17,2.312,20,1.218,23,0.539,26,0.591,32,3.229,33,2.618,35,1.64,36,0.783,44,1.216,47,2.869,51,1.8,57,1.349,58,1.64,59,2.78,60,1.394,63,1.201,65,1.038,71,1.725,75,1.943,86,2.309,89,2.719,90,1.254,95,2.016,96,2.494,97,1.142,100,1.724,101,0.502,102,0.996,106,0.569,111,1.091,114,0.978,119,1.559,121,2.261,124,3.367,129,1.053,139,1.323,171,1.866,172,1.323,177,2.573,178,1.693,200,0.867,219,2.016,235,1.352,241,1.568,243,0.958,245,2.346,252,1.787,261,1.749,264,2.426,269,1.972,273,1.063,281,1.009,335,2.726,349,2.17,352,2.403,355,2.093,370,2.389,377,1.279,384,1.373,412,2.383,450,2.54,455,1.296,456,2.675,459,1.948,464,3.208,467,2.309,471,1.64,474,1.352,475,1.406,486,1.493,487,1.603,489,1.136,558,1.369,559,1.603,576,0.901,585,1.64,595,1.383,616,2.093,620,2.054,641,2.706,682,1.862,713,1.725,715,1.66,775,1.725,780,1.896,823,1.383,831,2.758,832,1.552,834,1.406,837,1.916,839,1.972,847,1.023,859,1.749,865,4.435,875,1.493,876,1.603,877,1.68,878,1.837,882,1.982,889,1.775,921,2.064,938,1.167,940,1.64,959,0.979,964,1.725,1003,1.775,1014,2.628,1022,2.181,1024,4.421,1027,2.107,1055,1.181,1068,1.383,1104,1.68,1238,2.949,1240,2.149,1247,3.165,1254,1.552,1256,1.972,1300,1.441,1318,1.702,1365,2.064,1366,2.272,1382,4.947,1392,1.27,1403,4.207,1404,4.467,1463,1.702,1497,2.54,1498,1.333,1522,1.27,1528,1.775,1529,1.66,1538,2.181,1539,1.775,1556,1.362,1569,1.333,1583,1.323,1593,1.64,1594,1.406,1598,2.067,1609,1.972,1616,2.181,1617,2.209,1625,2.181,1626,2.181,1637,3.934,1646,1.831,1657,2.181,1666,2.064,1675,2.181,1676,2.342,1677,2.342,1678,2.064,1679,2.181,1680,1.896,1681,2.181,1682,2.342,1683,3.165,1684,2.119,1685,2.342,1686,1.862,1687,1.725,1688,3.908,1689,2.805,1690,1.208,1691,1.932,1692,2.342,1693,2.342,1694,2.119,1695,2.181,1696,2.181,1697,3.706,1698,2.342,1699,2.342,1700,2.342,1701,4.388,1702,4.215,1703,1.68,1704,2.342,1705,2.342,1706,2.119,1707,2.342,1708,1.862,1709,1.972,1710,1.802,1711,1.373,1712,2.342,1713,2.342,1714,2.342,1715,2.342,1716,2.119,1717,1.775,1718,3.908,1719,1.406,1720,1.831,1721,1.66,1722,2.342,1723,3.908,1724,1.64,1725,2.254,1726,2.342,1727,2.342,1728,2.342,1729,2.342,1730,2.342,1731,1.972,1732,1.64,1733,1.603,1734,2.342,1735,3.641,1736,2.342,1737,1.68,1738,1.68,1739,2.342,1740,2.342,1741,1.417,1742,2.342,1743,2.064,1744,2.342,1745,2.342,1746,2.342,1747,1.972,1748,1.831,1749,1.972,1750,2.342,1751,1.862]],["title/archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old",[58,3.281,59,1.474,1243,2.272]],["text/archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old",[6,2.095,8,3.156,12,3.044,13,2.177,20,1.609,23,0.556,32,3.951,46,5.37,47,1.979,58,3.617,61,2.168,75,2.776,89,2.391,97,2.518,100,2.278,101,1.542,111,1.336,114,1.197,177,1.883,219,1.476,252,2.937,281,2.227,412,3.625,424,3.925,620,2.714,684,4.262,715,3.661,833,3.126,834,3.1,1000,5.334,1240,2.839,1267,5.621,1268,4.866,1291,3.755,1298,3.424,1308,3.915,1382,7.913,1383,4.811,1403,3.71,1404,3.563,1437,3.706,1582,3.497,1583,2.919,1593,3.617,1633,3.356,1637,4.039,1666,4.553,1675,4.811,1683,4.182,1694,4.674,1695,4.811,1696,4.811,1701,5.37,1702,5.932,1719,3.1,1752,5.165,1753,5.165,1754,5.165,1755,5.165,1756,4.182,1757,4.553,1758,7.187,1759,4.553,1760,4.182,1761,5.165,1762,5.165,1763,6.053,1764,5.165,1765,5.165,1766,5.165,1767,5.165,1768,5.165,1769,5.165,1770,4.972,1771,4.674]],["title/archive/download/cluster/",[26,0.61,457,1.771,745,2.082,1772,4.475]],["text/archive/download/cluster/",[6,2.581,17,1.605,20,1.357,23,0.503,26,1.562,36,2.128,47,2.439,52,3.324,59,2.002,65,2.82,66,2.275,69,3.526,179,2.026,221,2.515,222,2.41,243,1.781,284,2.635,298,4.51,349,1.957,352,3.076,369,2.83,374,3.265,394,3.208,403,2.289,457,3.632,467,2.573,470,3.125,474,3.675,476,2.382,478,5.397,489,2.112,526,5.61,529,2.515,530,1.264,576,2.448,592,2.147,593,2.394,601,3.125,653,2.751,675,2.221,700,3.086,745,3.284,752,4.824,781,3.208,825,2.98,831,1.702,838,3.125,882,2.208,883,3.526,967,2.83,977,3.526,981,2.378,1014,2.275,1066,2.444,1104,4.567,1138,2.917,1228,2.657,1251,3.526,1315,3.365,1497,4.135,1569,2.478,1594,4.514,1598,2.303,1621,4.347,1643,3.125,1658,3.594,1689,3.125,1710,3.352,1748,4.977,1773,4.355,1774,5.252,1775,5.928,1776,6.364,1777,4.355,1778,3.667,1779,1.996,1780,4.355,1781,3.526,1782,3.464,1783,4.355,1784,3.301,1785,2.917,1786,4.355,1787,4.355,1788,6.364,1789,4.355,1790,6.364,1791,6.364,1792,4.355,1793,4.355,1794,5.928,1795,5.478,1796,3.839,1797,3.301,1798,6.364,1799,4.355,1800,3.086,1801,4.355,1802,3.94,1803,3.166,1804,4.355,1805,3.526,1806,2.98,1807,4.056,1808,2.887,1809,3.125,1810,4.056,1811,2.98,1812,4.355,1813,4.355]],["title/archive/download/cluster/#set-up-your-apache-spark-cluster",[26,0.535,36,1.184,457,1.555,745,1.828,1621,1.861]],["text/archive/download/cluster/#set-up-your-apache-spark-cluster",[23,0.496,26,1.513,52,5.231,1066,4.876,1138,5.821]],["title/archive/download/cluster/#preliminary",[1773,6.92]],["text/archive/download/cluster/#preliminary",[6,2.786,17,1.732,20,1.508,23,0.277,26,1.481,47,2.632,59,2.161,65,3.044,66,2.529,69,3.92,179,2.252,221,2.796,222,2.679,243,1.98,284,2.929,298,4.867,349,2.112,352,3.265,369,3.146,394,3.566,403,2.544,457,3.504,467,2.86,470,3.474,474,3.966,476,2.571,478,5.728,489,2.348,526,6.054,529,2.796,530,1.405,576,2.642,592,2.386,593,2.661,653,3.058,675,2.469,700,3.431,745,2.498,752,5.206,781,3.566,825,3.313,831,1.892,838,3.474,882,2.455,883,3.92,967,3.146,977,3.92,981,2.643,1014,2.529,1104,4.928,1251,3.92,1497,4.463,1569,2.755,1594,4.791,1598,2.56,1621,2.544,1643,3.474,1658,3.995,1689,3.474,1710,3.726,1748,5.371,1774,5.668,1775,6.397,1776,6.867,1777,4.841,1778,4.077,1779,2.219,1780,4.841,1781,3.92,1782,3.85,1783,4.841,1784,3.669,1785,3.242,1786,4.841,1787,4.841,1788,6.867,1789,4.841,1790,6.867,1791,6.867,1792,4.841,1793,4.841,1794,6.397,1795,5.912,1796,4.267,1797,3.669,1798,6.867,1799,4.841,1800,3.431,1801,4.841,1802,4.38,1803,3.519,1804,4.841,1805,3.92,1806,3.313,1807,4.509,1808,3.209]],["title/archive/download/cluster/#start-your-cluster",[374,2.867,1621,2.937]],["text/archive/download/cluster/#start-your-cluster",[26,1.476,36,2.784,374,4.271,601,5.974,1228,5.08,1315,5.165,1621,4.375,1809,5.974,1810,7.755,1811,5.698,1812,8.325,1813,8.325]],["title/archive/download/compile/",[56,2.272,57,1.617,1690,2.418]],["text/archive/download/compile/",[20,2.285,23,0.535,36,2.062,50,0.733,52,3.221,53,2.524,54,2.524,56,4.662,57,3.318,58,2.921,59,3.225,62,2.685,65,1.849,92,2.794,93,2.824,94,1.532,97,2.034,102,1.774,129,1.875,178,2.67,377,4.425,392,2.824,450,2.711,476,1.562,530,1.211,576,2.372,591,2.192,592,3.616,593,4.032,696,3.127,745,2.153,847,2.695,875,4.677,878,1.96,937,4.814,944,1.736,955,1.921,967,2.711,999,3.116,1013,5.546,1017,2.465,1049,2.711,1228,4.476,1243,2.023,1274,4.674,1315,4.572,1363,2.959,1395,2.824,1405,3.672,1462,3.318,1465,6.019,1598,2.206,1600,2.855,1620,2.43,1661,3.886,1689,2.993,1690,5.153,1747,3.513,1779,3.362,1808,4.862,1811,2.855,1814,4.628,1815,3.513,1816,2.993,1817,3.318,1818,3.513,1819,2.636,1820,4.13,1821,4.785,1822,4.543,1823,4.822,1824,4.746,1825,3.073,1826,3.318,1827,4.171,1828,8.474,1829,4.171,1830,7.335,1831,2.66,1832,3.513]],["title/archive/download/compile/#compile-geospark",[59,1.758,1690,2.884]],["text/archive/download/compile/#compile-geospark",[23,0.53,52,4.846,53,4.622,56,5.041,57,3.587,59,3.351,476,2.859,696,3.873,878,3.59,1017,4.513,1395,5.171,1661,7.115,1690,3.942,1814,8.474,1815,6.433,1816,5.481,1817,6.075]],["title/archive/download/compile/#compile-the-source-code",[56,2.272,57,1.617,1690,2.418]],["text/archive/download/compile/#compile-the-source-code",[20,2.428,36,2.606,50,1.021,58,4.071,59,2.766,62,3.742,65,2.577,92,3.894,97,2.835,102,2.473,129,2.614,178,3.375,377,4.8,392,3.936,450,3.778,530,1.687,576,2.237,591,3.056,592,4.333,593,4.832,696,2.948,745,3.001,847,3.406,875,5.605,944,2.419,1013,6.428,1228,3.548,1243,2.82,1274,5.907,1315,4.121,1363,3.739,1462,4.624,1465,6.552,1598,3.075,1600,3.979,1620,2.291,1689,4.172,1690,4.847,1779,3.572,1811,3.979,1818,4.897,1819,3.673,1820,3.894,1821,5.198,1822,5.741,1823,6.095,1824,5.998,1825,4.283,1826,4.624]],["title/archive/download/compile/#compile-the-documentation",[937,3.667,1690,2.884]],["text/archive/download/compile/#compile-the-documentation",[20,2.081,23,0.488,54,4.043,56,4.562,57,3.247,59,2.959,93,4.523,94,2.454,377,3.649,576,2.571,937,5.602,955,3.078,967,4.342,999,4.992,1049,4.342,1228,5.209,1315,4.974,1405,5.083,1620,2.633,1690,4.405,1747,5.627,1779,3.062,1808,6.235,1820,4.475,1821,3.698,1827,6.682,1828,9.503,1829,6.682,1830,9.406,1831,4.26,1832,5.627]],["title/archive/download/overview/",[374,2.867,926,4.174]],["text/archive/download/overview/",[5,3.731,13,3.698,22,2.876,23,0.588,26,1.326,36,2.599,51,2.072,52,3.024,53,4.703,54,3.504,56,2.808,57,1.998,59,3.332,63,3.987,86,3.421,97,3.789,100,2.554,101,1.242,281,2.496,325,4.008,374,3.987,383,4.155,412,2.348,452,2.707,476,2.168,485,4.605,538,2.919,592,2.854,593,3.183,604,3.249,619,3.533,847,3.396,1280,6.545,1363,2.778,1364,3.475,1497,3.762,1620,2.282,1621,3.043,1690,4.011,1778,4.876,1779,2.654,1800,5.508,1803,4.209,1819,3.658,1833,9.732,1834,5.79,1835,4.605,1836,3.563,1837,5.573,1838,6.061,1839,4.605,1840,6.061,1841,4.054,1842,6.061,1843,3.272]],["title/archive/download/overview/#direct-download",[52,2.919,1778,4.706]],["text/archive/download/overview/#direct-download",[5,4.22,22,3.4,23,0.591,53,5.559,54,4.547,56,3.644,57,2.593,59,3.393,63,4.713,86,4.439,1280,7.736,1363,3.605,1364,4.51,1690,4.741,1833,11.007]],["title/archive/download/overview/#install-geospark",[59,1.758,1779,2.561]],["text/archive/download/overview/#install-geospark",[13,4.02,23,0.393,26,1.441,36,2.908,51,2.462,59,2.736,97,4.24,100,3.035,101,1.476,281,2.966,325,4.763,374,4.462,383,4.938,412,2.791,452,3.217,476,2.576,485,5.473,538,3.469,592,3.392,593,3.782,604,3.861,619,4.198,847,3.801,1497,4.471,1620,2.711,1621,3.616,1800,6.164,1803,5.002,1819,4.347,1834,6.88,1835,5.473,1836,4.234,1837,6.623,1838,7.202,1839,5.473,1840,7.202,1841,4.818,1842,7.202,1843,3.888]],["title/archive/download/project/",[383,3.362,538,2.362,847,2.048]],["text/archive/download/project/",[6,1.759,8,1.014,13,2.317,20,1.351,21,1.47,22,1.605,23,0.629,26,1.432,44,1.379,50,0.965,51,0.95,52,1.387,56,1.288,57,0.916,59,2.887,62,1.709,63,4.382,66,3.314,75,1.026,94,0.975,96,2.149,97,2.68,101,1.93,102,1.129,114,0.722,115,0.762,126,0.885,243,1.086,266,1.569,281,1.145,334,3.808,335,1.026,349,0.816,374,2.224,383,3.944,394,1.956,450,1.725,452,1.242,457,1.166,459,1.324,476,2.617,489,2.103,530,0.771,535,2.191,538,3.198,557,1.5,562,2.637,576,2.441,591,1.395,592,2.709,593,3.021,604,1.49,753,1.882,776,3.511,823,1.569,836,1.533,847,4.292,878,2.038,926,1.984,938,1.324,940,1.859,941,1.45,944,1.105,945,3.748,946,3.904,949,1.648,950,2.668,951,1.557,953,1.533,955,2.531,956,1.778,958,1.648,1014,1.387,1017,2.562,1020,1.693,1066,2.433,1108,2.112,1228,1.62,1315,3.355,1324,2.4,1343,3.111,1344,1.678,1345,2.791,1346,2.077,1363,3.355,1364,1.594,1366,3.729,1391,4.186,1392,1.44,1405,1.581,1483,2.077,1551,1.838,1558,2.077,1585,1.797,1598,1.404,1620,3.119,1621,2.888,1648,3.239,1687,4.049,1690,4.085,1781,3.511,1807,2.473,1808,1.76,1809,1.905,1819,1.678,1821,2.4,1831,4.045,1839,2.112,1843,3.951,1844,3.511,1845,5.765,1846,4.45,1847,4.174,1848,4.174,1849,5.119,1850,1.742,1851,2.473,1852,2.403,1853,2.556,1854,2.112,1855,2.473,1856,2.655,1857,2.818,1858,1.859,1859,2.946,1860,2.236,1861,2.655,1862,1.859,1863,4.81,1864,2.655,1865,2.286,1866,5.119,1867,4.81,1868,4.81,1869,2.013,1870,1.742,1871,1.956,1872,2.946,1873,2.341,1874,2.946,1875,2.946,1876,2.236,1877,2.946]],["title/archive/download/project/#self-contained-spark-projects",[26,0.61,383,2.895,538,2.034,847,1.763]],["text/archive/download/project/#self-contained-spark-projects",[6,3.132,13,3.256,23,0.441,26,1.167,59,2.939,97,3.766,101,1.657,126,2.574,383,6.703,452,3.611,476,2.891,535,6.373,538,4.709,576,2.971,753,5.473,776,6.253,847,4.082,941,4.217,945,4.563,946,4.752,1366,3.488,1392,4.19,1648,5.769]],["title/archive/download/project/#quick-start",[374,2.867,926,4.174]],["text/archive/download/project/#quick-start",[6,2.659,20,2.042,22,2.426,23,0.375,26,1.487,44,3.404,59,3.096,63,4.326,66,3.424,94,2.408,101,1.809,335,2.532,374,3.363,489,3.179,530,1.903,592,4.157,593,4.635,847,4.074,940,4.591,1066,3.679,1108,5.214,1228,4,1315,3.467,1363,4.046,1364,3.935,1366,3.809,1620,2.583,1621,3.445,1687,6.212,1690,4.352,1808,4.346,1821,3.628,1831,5.377,1843,3.705,1844,5.308,1845,6.118,1846,5.308,1847,6.31,1848,6.31,1849,6.106]],["title/archive/download/project/#how-to-use-geospark-in-an-ide",[59,1.474,101,1.005,1391,2.376]],["text/archive/download/project/#how-to-use-geospark-in-an-ide",[]],["title/archive/download/project/#select-an-ide",[115,0.981,1391,2.833]],["text/archive/download/project/#select-an-ide",[8,2.981,13,3.292,59,2.457,97,4.585,101,2.018,266,4.614,459,3.893,847,3.413,1017,4.614,1363,4.512,1366,3.528,1551,5.406,1648,5.834,1819,4.934,1844,6.324,1850,5.125,1851,7.275,1852,7.067,1853,7.518,1854,6.212,1855,7.275,1856,7.809]],["title/archive/download/project/#open-geospark-template-project",[59,1.269,847,1.763,1831,2.572,1857,2.621]],["text/archive/download/project/#open-geospark-template-project",[13,3.256,23,0.441,56,3.745,57,2.666,59,2.939,101,1.657,114,1.286,115,1.356,243,3.159,538,3.894,576,2.971,847,4.388,946,4.752,1017,4.563,1315,4.084,1324,4.274,1366,3.488,1391,4.736,1405,4.599,1598,4.084,1831,4.924,1857,5.019,1858,5.408]],["title/archive/download/project/#try-geospark-sql-functions",[50,0.709,51,1.444,59,1.269,1839,3.209]],["text/archive/download/project/#try-geospark-sql-functions",[50,1.445,114,1.37,334,4.938,349,2.529,476,3.08,576,3.732,878,3.866,955,3.789,1391,4.918,1620,3.822,1859,9.126,1860,6.928,1861,8.226]],["title/archive/download/project/#package-the-project",[847,2.442,1843,3.158]],["text/archive/download/project/#package-the-project",[20,1.457,21,2.589,23,0.646,26,1.466,50,0.822,52,2.443,62,3.011,63,3.438,66,3.501,75,1.807,96,2.319,101,1.438,102,1.99,281,2.016,334,2.808,450,3.04,457,2.054,476,2.932,489,2.269,557,2.643,562,3.758,591,2.458,592,2.306,593,2.571,604,2.625,776,3.788,823,2.764,847,3.956,878,2.198,938,2.332,944,1.946,945,3.96,946,4.124,949,2.903,950,4.124,951,2.742,953,2.701,955,2.155,956,3.133,958,2.903,1014,2.443,1066,2.625,1324,2.589,1343,4.809,1344,2.955,1345,4.313,1346,3.658,1363,2.245,1366,3.537,1391,3.398,1483,3.658,1558,3.658,1620,3.37,1621,2.458,1687,3.446,1690,4.414,1781,5.427,1807,4.357,1821,2.589,1843,4.426,1845,4.398,1862,3.276,1863,7.435,1864,4.677,1865,4.027,1866,7.295,1867,7.435,1868,7.435,1869,3.546,1870,3.07,1871,3.446]],["title/archive/download/project/#submit-the-compiled-jar",[63,2.404,1690,2.418,1845,3.075]],["text/archive/download/project/#submit-the-compiled-jar",[22,2.665,23,0.511,26,1.088,63,5.225,66,3.762,96,3.57,101,1.92,334,5.372,394,5.306,836,4.159,945,4.255,955,3.317,1020,4.592,1315,4.732,1585,4.875,1621,3.785,1809,5.168,1845,6.683,1846,7.246,1847,6.932,1848,6.932,1849,8.336,1872,7.99,1873,6.349,1874,7.99,1875,7.99,1876,6.065,1877,7.99]],["title/archive/download/scalashell/",[13,1.975,26,0.708,325,3.243]],["text/archive/download/scalashell/",[5,1.97,13,3.283,23,0.486,26,1.495,52,4.904,53,2.802,56,2.246,57,2.688,59,3.258,60,3.962,63,5.17,66,4.447,100,2.043,129,2.991,325,7.08,334,5.412,377,3.633,402,2.85,411,2.39,457,2.921,476,2.491,531,2.926,745,3.434,938,2.308,944,1.927,955,3.065,1066,2.598,1243,3.227,1257,2.636,1271,4.605,1280,3.9,1363,2.222,1364,2.78,1392,2.512,1498,3.787,1620,2.622,1621,4.934,1628,3.07,1690,3.434,1779,2.122,1781,5.388,1803,3.366,1811,3.169,1816,3.323,1817,3.683,1821,2.563,1822,3.412,1823,3.622,1824,3.564,1835,5.292,1843,4.811,1846,7.601,1878,5.137,1879,7.382,1880,7.382,1881,7.382,1882,6.198,1883,4.314,1884,5.137,1885,7.382,1886,7.382]],["title/archive/download/scalashell/#spark-scala-shell",[13,1.975,26,0.708,325,3.243]],["text/archive/download/scalashell/#spark-scala-shell",[13,4.061,26,1.229,57,2.806,59,2.558,100,3.586,325,5.627,334,4.88,402,5.003,411,4.196,531,5.137,938,4.053,944,3.383,1066,4.562,1257,4.627,1392,4.41,1803,5.91,1811,5.564]],["title/archive/download/scalashell/#download-geospark-jar-automatically",[52,2.107,59,1.269,60,2.402,63,2.07]],["text/archive/download/scalashell/#download-geospark-jar-automatically",[26,1.444,52,3.612,59,2.745,60,4.118,63,3.548,66,4.557,129,3.108,325,6.947,334,5.236,377,3.776,457,3.036,476,2.589,745,3.569,955,3.185,1271,4.786,1363,3.318,1364,4.151,1498,3.936,1620,2.725,1621,5.023,1781,5.599,1821,3.827,1835,5.5,1843,5.672,1846,7.739,1878,7.671,1879,9.678,1880,9.678,1881,9.678,1882,6.441]],["title/archive/download/scalashell/#download-geospark-jar-manually",[52,2.107,59,1.269,63,2.07,1628,2.674]],["text/archive/download/scalashell/#download-geospark-jar-manually",[5,2.687,23,0.361,26,1.384,52,4.784,53,3.823,56,3.064,57,2.841,59,3.246,63,5.293,66,4.3,129,2.84,325,6.716,334,4.941,377,3.45,457,2.773,476,2.365,745,3.26,955,2.91,1243,3.992,1271,4.372,1280,5.32,1498,3.595,1620,2.489,1621,4.813,1690,4.249,1779,2.895,1781,5.115,1816,4.533,1817,5.024,1822,4.654,1823,4.94,1824,4.862,1835,5.024,1846,7.415,1882,5.884,1883,5.884,1884,7.008,1885,9.133,1886,9.133]],["title/archive/download/zeppelin/",[59,1.474,1288,2.509,1779,2.147]],["text/archive/download/zeppelin/",[6,2.605,8,1.683,20,2.001,22,1.632,23,0.592,26,0.971,31,3.053,32,2.424,36,2.148,48,3.734,50,0.775,59,3.343,65,1.954,89,2.973,94,1.62,96,3.184,101,0.946,110,0.946,119,1.759,126,2.524,128,1.812,129,2.887,177,2.342,179,2.052,200,2.377,219,1.26,225,2.714,258,3.053,273,2.002,352,2.627,476,2.405,530,1.28,576,2.471,591,2.318,594,1.632,675,2.249,751,4.108,878,2.073,920,3.639,944,2.673,1051,1.945,1228,2.691,1240,4.575,1243,2.139,1257,3.655,1261,3.888,1267,3.449,1268,5.128,1269,3.343,1288,5.758,1315,4.401,1324,2.441,1366,1.992,1374,3.796,1405,3.825,1463,3.206,1466,3.053,1556,2.566,1733,3.018,1779,2.944,1800,3.126,1809,3.165,1843,2.492,1857,2.866,1887,4.41,1888,4.41,1889,3.343,1890,2.985,1891,4.41,1892,3.571,1893,3.714,1894,6.738,1895,4.869,1896,4.41,1897,3.206,1898,5.201,1899,4.893,1900,3.888,1901,4.41,1902,4.41,1903,4.41,1904,4.41,1905,3.765,1906,3.888,1907,3.249,1908,4.108,1909,4.108]],["title/archive/download/zeppelin/#install-geospark-zeppelin",[59,1.474,1288,2.509,1779,2.147]],["text/archive/download/zeppelin/#install-geospark-zeppelin",[20,2.303,23,0.422,48,4.856,59,2.326,65,3.277,89,4.21,101,1.586,110,1.586,119,2.95,128,3.037,179,3.44,200,3.366,258,5.118,591,3.886,944,3.077,1240,4.065,1257,4.208,1261,6.518,1267,5.783,1268,6.669,1288,4.871,1463,5.375,1733,5.06,1887,7.393,1888,7.393,1889,5.605,1890,5.005,1891,7.393]],["title/archive/download/zeppelin/#compatibility",[1892,5.604]],["text/archive/download/zeppelin/#compatibility",[26,1.258,31,5.762,36,3.266,50,1.462,59,3.365,944,3.464,1243,4.037,1288,4.458,1374,7.166,1893,7.011]],["title/archive/download/zeppelin/#installation",[1779,3.172]],["text/archive/download/zeppelin/#installation",[22,3.119,59,2.651,177,3.072,219,2.407,273,3.824,476,3.155,675,4.298,1288,5.268,1556,4.903,1843,4.762,1894,6.823]],["title/archive/download/zeppelin/#create-helium-folder-optional",[126,1.344,129,1.813,1315,2.133,1894,3.266]],["text/archive/download/zeppelin/#create-helium-folder-optional",[96,4.308,126,2.896,1228,5.302,1288,4.654,1315,5.296,1894,7.036]],["title/archive/download/zeppelin/#add-geospark-zeppelin-description-optional",[6,1.436,59,1.114,129,1.592,1288,1.897,1895,2.685]],["text/archive/download/zeppelin/#add-geospark-zeppelin-description-optional",[8,2.792,23,0.516,59,3.085,96,3.626,126,2.438,177,2.667,225,4.502,476,2.739,530,2.123,576,3.476,594,2.708,878,3.438,920,6.037,1051,3.227,1240,4.967,1269,5.546,1288,5.251,1315,3.869,1466,5.064,1895,5.546,1896,7.315,1897,5.318,1898,7.317,1899,8.116,1900,6.449,1901,7.315,1902,7.315,1903,7.315,1904,7.315]],["title/archive/download/zeppelin/#enable-geospark-zeppelin",[59,1.474,1288,2.509,1905,2.747]],["text/archive/download/zeppelin/#enable-geospark-zeppelin",[59,2.7,1288,5.621,1857,5.577,1894,6.949,1905,5.032,1906,7.566,1907,6.323]],["title/archive/download/zeppelin/#add-geospark-dependencies-in-zeppelin-spark-interpreter",[6,1.28,26,0.477,59,0.993,751,2.94,1288,1.69,1366,1.426]],["text/archive/download/zeppelin/#add-geospark-dependencies-in-zeppelin-spark-interpreter",[]],["title/archive/download/zeppelin/#visualize-geosparksql-results",[352,1.917,1240,2.576,1324,2.593]],["text/archive/download/zeppelin/#visualize-geosparksql-results",[]],["title/archive/download/zeppelin/#display-geosparkviz-results",[352,1.917,1257,2.667,1908,4.364]],["text/archive/download/zeppelin/#display-geosparkviz-results",[20,2.657,32,4.689,59,2.684,94,3.133,1288,4.568,1405,5.899,1800,6.045,1809,6.121,1909,7.945]],["title/archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/",[59,1.269,943,2.504,1238,1.686,1910,2.972]],["text/archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/",[5,0.881,8,0.791,12,2.579,17,2.389,20,1.434,22,1.703,23,0.595,26,1.001,36,1.539,47,1.351,51,0.742,55,1.527,56,1.005,58,1.451,59,2.73,61,2.556,65,1.563,72,3.02,75,3.279,89,0.959,94,0.761,96,1.027,99,1.388,100,2.396,101,1.862,102,1.5,108,1.197,109,1.993,114,0.766,121,0.932,124,3.491,128,1.449,129,0.932,177,0.756,200,0.767,234,2.174,241,1.388,243,2.891,248,3.747,257,1.171,264,1.286,266,2.719,273,0.941,281,0.893,349,2.808,365,1.334,370,2.185,374,1.063,383,1.487,397,2.53,403,1.089,412,1.43,417,3.109,431,2.314,446,1.224,452,1.649,474,2.036,476,1.723,481,2.758,491,2.27,530,1.023,531,1.309,533,2.314,534,1.298,538,2.738,558,2.606,559,4.534,563,2.499,585,1.451,592,1.738,593,1.938,604,1.979,620,1.853,641,1.461,696,1.788,698,1.527,699,1.875,700,2.499,702,1.197,720,1.678,752,1.571,831,2.909,833,2.134,834,3.26,837,2.256,860,2.598,878,3.322,882,3.088,919,1.388,927,3.346,928,1.527,938,2.294,943,2.189,955,0.955,973,1.451,980,2.673,982,1.506,984,2.362,1013,1.418,1014,1.083,1027,1.901,1068,2.719,1238,3.998,1272,1.827,1284,1.621,1300,4.076,1339,1.548,1380,3.285,1403,1.07,1404,1.027,1405,2.1,1437,1.487,1487,1.374,1527,4.398,1528,1.571,1529,1.469,1556,1.206,1569,3.091,1583,3.069,1593,1.451,1594,2.763,1598,1.096,1609,1.745,1617,2.601,1628,2.338,1633,1.347,1637,2.758,1643,1.487,1656,1.595,1664,3.6,1667,1.595,1668,3.489,1669,1.827,1670,1.93,1710,2.714,1720,5.181,1737,2.53,1743,1.827,1749,2.97,1820,1.388,1835,1.648,1839,1.648,1850,1.36,1858,2.469,1860,2.97,1862,1.451,1871,4.001,1893,2.97,1910,2.598,1911,1.827,1912,2.97,1913,2.072,1914,4.602,1915,2.299,1916,2.299,1917,2.072,1918,1.784,1919,2.299,1920,2.072,1921,2.072,1922,1.93,1923,4.057,1924,2.072,1925,1.93,1926,1.678,1927,1.621,1928,4.486,1929,2.673,1930,3.526,1931,3.526,1932,2.97,1933,2.97,1934,2.805,1935,3.109,1936,3.109,1937,3.526,1938,2.072,1939,1.678,1940,3.526,1941,2.072,1942,2.072,1943,1.595,1944,3.109,1945,2.072,1946,2.072,1947,4.602,1948,3.526,1949,3.109,1950,2.072,1951,2.072,1952,1.93,1953,1.571,1954,3.191,1955,2.855,1956,2.072,1957,2.072,1958,2.072,1959,2.072,1960,2.072,1961,2.072,1962,1.784,1963,2.072,1964,2.072,1965,2.072,1966,1.93,1967,2.072,1968,2.072,1969,2.072]],["title/archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application",[59,0.993,943,1.959,980,2.393,1238,1.319,1405,1.879,1910,2.325]],["text/archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application",[20,2.609,51,2.997,59,2.635,592,4.129,593,4.604,604,4.7,955,3.858,980,6.349,1405,4.987,1527,6.782,1820,5.61,1839,6.662,1911,7.383]],["title/archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version",[59,1.269,75,1.558,1858,2.825,1912,3.397]],["text/archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version",[5,2.282,8,2.048,12,4.033,20,1.671,22,1.986,26,0.811,55,3.952,58,3.757,59,3.097,75,4.114,94,1.971,99,3.593,100,3.255,102,2.282,241,3.593,273,2.435,412,2.993,476,2.008,538,4.58,585,3.757,592,2.645,593,2.949,604,3.01,696,2.72,698,3.952,720,4.344,833,4.465,834,5.063,878,4.626,982,3.9,1013,3.672,1300,6.057,1380,6.873,1403,2.769,1404,2.659,1487,3.556,1528,4.067,1637,5.771,1710,4.129,1835,4.267,1850,3.521,1871,6.692,1893,6.214,1912,4.518,1913,5.364,1914,8.434,1915,5.952,1916,5.952,1917,5.364,1918,4.618,1919,5.952,1920,5.364,1921,5.364,1922,4.997,1923,7.435,1924,5.364,1925,4.997,1926,4.344,1927,4.196]],["title/archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor",[17,0.893,124,2.03,1238,1.48,1656,2.726,1858,2.48]],["text/archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor",[17,1.635,23,0.63,26,0.98,36,2.168,47,1.712,56,2.166,59,2.634,61,1.875,65,1.98,72,5.008,96,2.214,101,1.391,108,2.58,109,3.663,114,1.079,121,2.008,124,4.374,128,2.663,129,2.008,200,1.653,234,2.11,248,5.47,257,2.524,281,1.926,349,1.993,374,2.292,397,2.456,431,4.254,452,2.089,474,2.58,481,5.07,491,4.172,530,1.881,533,2.931,558,2.931,559,4.437,563,4.595,700,4.595,831,2.534,837,2.19,882,3.287,928,3.291,938,3.804,984,2.992,1027,2.408,1068,2.639,1238,2.709,1339,3.337,1437,3.205,1527,5.249,1583,4.312,1598,2.362,1628,4.297,1633,2.903,1643,3.205,1664,5.968,1667,3.438,1668,5.784,1669,3.938,1670,4.161,1710,3.438,1720,3.493,1737,3.205,1743,3.938,1928,6.168,1929,3.386,1930,6.482,1931,6.482,1932,5.46,1933,5.46,1934,5.156,1935,5.715,1936,5.715,1937,6.482,1938,4.467,1939,3.617,1940,6.482,1941,4.467,1942,4.467,1943,3.438,1944,3.938,1945,4.467]],["title/archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used",[17,0.893,101,0.76,1238,1.48,1720,2.77,1946,3.541]],["text/archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used",[17,2.648,20,1.336,22,2.329,23,0.54,26,0.951,47,1.643,61,3.446,65,1.9,89,1.985,100,1.891,101,2.121,102,1.824,124,2.458,234,2.972,243,3.864,266,4.403,349,3.228,370,3.539,383,3.077,417,5.546,446,2.533,452,2.005,476,2.355,533,2.814,534,2.685,558,2.203,559,5.62,620,3.307,641,2.607,702,2.476,831,3.573,837,3.085,882,2.174,919,2.872,927,5.418,943,2.661,973,3.002,984,2.872,1027,2.311,1068,2.533,1238,4.35,1272,3.78,1284,3.353,1527,3.472,1569,3.581,1594,3.777,1609,3.611,1617,4.212,1720,5.829,1737,3.077,1749,5.299,1860,5.299,1928,3.159,1929,3.25,1947,7.453,1948,6.291,1949,5.546,1950,4.287,1951,4.287,1952,3.994,1953,3.25,1954,5.693,1955,5.095,1956,4.287,1957,4.287,1958,4.287,1959,4.287,1960,4.287,1961,4.287,1962,3.691,1963,4.287,1964,4.287,1965,4.287]],["title/archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions",[17,1.018,882,2.045,1238,1.686,1966,3.758]],["text/archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions",[26,1.088,36,2.408,100,3.177,101,1.545,114,1.199,177,2.626,264,4.47,365,4.635,397,4.919,403,3.785,474,4.159,531,4.55,558,3.133,696,3.652,699,6.517,752,5.459,834,4.323,860,6.593,878,3.385,882,3.652,1014,3.762,1068,4.255,1238,3.01,1529,5.104,1556,4.19,1569,5.093,1583,4.07,1593,5.043,1594,4.323,1720,5.632,1862,5.043,1910,5.306,1944,6.349,1967,7.202,1968,7.202,1969,7.202]],["title/archive/tutorial/GeoSpark-Runnable-DEMO/",[59,1.474,847,2.048,1831,2.987]],["text/archive/tutorial/GeoSpark-Runnable-DEMO/",[23,0.444,57,3.235,59,2.949,92,5.202,538,3.915,847,4.568,955,3.577,967,5.047,1257,4.42,1271,5.375,1324,4.298,1620,3.06,1690,4.008,1831,6.665,1843,4.389,1970,9.354,1971,6.288,1972,8.129]],["title/archive/tutorial/benchmark/",[1973,6.101]],["text/archive/tutorial/benchmark/",[8,2.601,20,2.957,23,0.389,55,5.019,59,3.141,75,3.338,89,3.154,101,2.142,243,2.787,403,3.581,556,4.884,775,5.019,823,4.025,833,5.23,834,4.09,860,5.019,944,2.835,1324,3.771,1463,4.952,1572,4.663,1594,4.09,1595,6.006,1621,3.581,1733,4.663,1738,4.889,1806,4.663,1857,4.427,1862,4.771,1973,8.367,1974,5.517,1975,6.006,1976,6.165,1977,6.346,1978,5.738,1979,6.346,1980,6.813,1981,4.716,1982,6.346]],["title/archive/tutorial/benchmark/#benchmark",[1973,6.101]],["text/archive/tutorial/benchmark/#benchmark",[8,2.626,20,2.97,55,5.069,59,3.152,75,3.359,89,3.185,101,2.15,243,2.814,403,3.616,556,4.914,775,5.069,823,4.065,833,5.263,834,4.13,860,5.069,944,2.863,1324,3.808,1463,5.002,1572,4.709,1594,4.13,1595,6.065,1621,3.616,1733,4.709,1738,4.938,1806,4.709,1857,4.471,1862,4.818,1973,7.666,1974,5.571,1975,6.065,1976,6.226,1977,6.409,1978,5.795,1979,6.409,1980,6.88,1981,4.763,1982,6.409]],["title/archive/tutorial/faq/",[1983,5.644,1984,3.794,1985,4.51]],["text/archive/tutorial/faq/",[20,2.657,23,0.487,32,4.689,53,5.162,59,2.684,89,3.948,94,3.133,103,7.945,1986,7.184,1987,10.274]],["title/archive/tutorial/geospark-core-python/",[15,1.975,17,1.182,1238,1.958]],["text/archive/tutorial/geospark-core-python/",[3,0.409,8,0.639,10,0.798,12,0.496,13,0.26,15,1.768,17,1.922,20,1.024,22,0.944,23,0.649,26,0.634,27,0.519,31,0.427,32,0.644,36,0.206,42,0.854,44,0.32,47,0.817,48,1.257,50,0.206,51,1.176,54,0.709,56,0.568,57,2.03,59,2.077,60,0.367,61,1.231,63,1.853,65,1.735,75,0.647,89,0.775,92,0.413,94,1.207,100,0.517,101,1.685,102,0.907,105,0.127,106,0.619,108,1.473,110,1.388,111,0.873,114,0.424,115,0.108,119,1.17,121,0.527,124,0.672,126,1.204,128,0.688,129,0.527,136,1.981,137,0.474,139,1.441,159,1.308,161,0.361,165,0.448,166,1.372,171,1.018,172,1.658,173,0.393,177,0.61,179,0.287,184,1.022,186,0.314,200,2.048,201,2.388,220,0.83,222,0.341,225,0.379,234,1.205,235,0.356,236,1.034,242,0.527,243,2.405,252,1.167,257,0.348,259,0.747,261,0.46,264,0.383,270,0.467,273,0.28,281,1.687,327,0.698,349,2.317,352,2.186,370,1.393,373,1.942,374,0.316,377,0.337,384,0.361,402,0.379,403,1.34,404,0.474,411,0.864,452,0.997,457,1.288,464,0.337,476,0.439,486,0.393,488,2.051,490,0.888,529,0.356,530,1.797,532,1.4,537,1.196,545,0.703,550,1.69,555,0.682,556,0.348,558,2.928,559,0.802,560,0.902,561,1.616,562,0.562,563,0.437,566,1.348,568,0.397,575,0.448,576,2.717,582,0.982,583,1.164,591,0.324,594,1.978,595,0.692,613,0.974,614,0.949,615,0.417,616,1.366,619,0.376,639,1.033,641,2.786,643,0.802,653,2.076,669,0.482,675,1.3,676,0.841,696,0.313,697,0.467,698,0.454,701,0.474,702,0.356,713,0.454,730,0.885,745,0.318,750,0.841,762,0.863,823,0.692,831,2.01,836,0.967,837,1.045,838,0.442,881,0.482,882,1.985,886,0.482,888,0.811,891,0.811,903,0.574,905,0.863,937,0.769,938,1.063,941,1.164,943,0.383,944,0.887,949,0.383,950,0.379,951,0.361,953,0.356,955,0.284,958,0.383,959,3.149,961,1.099,963,0.413,970,0.82,973,1.173,975,0.499,978,1.765,981,0.64,999,0.46,1001,0.46,1007,0.888,1013,0.802,1020,0.393,1027,1.771,1049,0.761,1050,0.916,1051,0.94,1055,3.194,1066,2.885,1070,1.187,1140,0.467,1228,0.376,1238,2.149,1269,0.467,1271,0.427,1300,1.03,1318,0.852,1319,0.852,1320,0.852,1324,1.411,1344,0.389,1345,0.754,1346,0.482,1363,0.562,1366,0.756,1370,0.49,1372,0.49,1391,0.313,1392,0.908,1401,0.875,1402,0.811,1406,0.437,1420,0.543,1422,0.543,1437,0.442,1465,0.386,1478,0.987,1479,1.033,1492,0.785,1498,0.667,1522,1.591,1525,0.949,1549,0.448,1552,0.467,1560,2.156,1561,0.82,1569,0.351,1582,1.443,1593,0.432,1594,0.37,1598,0.885,1615,0.499,1617,1.658,1620,0.84,1633,0.401,1638,0.474,1643,0.442,1664,0.916,1697,1.878,1703,2.105,1711,1.927,1719,1.972,1721,1.511,1724,2.937,1737,0.841,1738,0.442,1741,1.013,1751,0.49,1756,0.499,1779,1.655,1784,0.888,1785,1.428,1821,0.341,1836,0.721,1843,1.441,1862,0.432,1869,0.467,1870,0.769,1876,0.519,1905,0.687,1910,0.454,1911,0.543,1927,0.482,1928,2.161,1929,0.888,1932,0.519,1933,1.795,1934,1.696,1935,2.248,1936,0.543,1949,1.033,1971,0.499,1981,0.811,1988,1.06,1989,1.091,1990,0.967,1991,0.499,1992,0.616,1993,0.987,1994,2.028,1995,1.091,1996,1.674,1997,6.777,1998,0.616,1999,1.033,2000,1.091,2001,0.949,2002,1.202,2003,0.422,2004,0.616,2005,0.616,2006,0.616,2007,1.202,2008,0.684,2009,0.616,2010,0.593,2011,2.375,2012,0.519,2013,1.128,2014,1.128,2015,0.593,2016,0.474,2017,0.558,2018,0.519,2019,0.531,2020,0.474,2021,1.332,2022,0.574,2023,0.543,2024,1.172,2025,1.172,2026,1.172,2027,0.49,2028,0.509,2029,0.482,2030,0.427,2031,0.482,2032,0.499,2033,1.172,2034,0.987,2035,2.973,2036,2.132,2037,0.574,2038,0.574,2039,2.132,2040,0.499,2041,0.574,2042,0.574,2043,0.616,2044,1.172,2045,1.172,2046,0.616,2047,2.132,2048,3.054,2049,1.3,2050,0.684,2051,0.83,2052,2.365,2053,0.574,2054,0.543,2055,1.3,2056,0.742,2057,4.09,2058,1.06,2059,0.684,2060,0.742,2061,0.684,2062,0.616,2063,0.437,2064,0.467,2065,0.616,2066,4.931,2067,1.879,2068,1.226,2069,2.897,2070,1.726,2071,1.929,2072,0.932,2073,0.932,2074,0.932,2075,0.932,2076,2.981,2077,1.217,2078,3.841,2079,1.835,2080,1.289,2081,0.519,2082,0.46,2083,2.223,2084,2.586,2085,1.269,2086,0.519,2087,0.574,2088,0.616,2089,0.616,2090,0.616,2091,0.616,2092,1.172,2093,0.616,2094,0.616,2095,0.616,2096,0.902,2097,1.033,2098,0.987,2099,0.616,2100,0.543,2101,1.202,2102,0.543,2103,1.726,2104,0.841,2105,0.916,2106,0.916,2107,0.841,2108,0.916,2109,0.949,2110,2.626,2111,0.852,2112,2.954,2113,3.296,2114,1.807,2115,1.033,2116,0.543,2117,0.531,2118,0.949,2119,1.476,2120,0.543,2121,0.543,2122,0.543,2123,0.616,2124,2.454,2125,0.531,2126,2.132,2127,0.616,2128,0.616,2129,0.616,2130,0.616,2131,1.888,2132,0.616,2133,4.455,2134,0.616,2135,0.684,2136,1.172,2137,1.06,2138,0.616,2139,0.616,2140,0.543,2141,0.467,2142,2.028,2143,0.448,2144,0.616,2145,0.742,2146,2.829,2147,2.829,2148,0.574,2149,0.684,2150,1.858,2151,0.684,2152,1.674,2153,0.616,2154,2.052,2155,0.616,2156,0.616,2157,0.616,2158,1.091,2159,0.616,2160,0.616,2161,0.684,2162,0.616,2163,0.616,2164,0.616,2165,0.509,2166,0.684]],["title/archive/tutorial/geospark-core-python/#spatial-rdd-applications-in-python",[15,1.701,17,1.018,943,2.504,1238,1.686]],["text/archive/tutorial/geospark-core-python/#spatial-rdd-applications-in-python",[]],["title/archive/tutorial/geospark-core-python/#introduction",[105,1.423]],["text/archive/tutorial/geospark-core-python/#introduction",[12,2.547,15,3.361,23,0.344,47,2.305,51,2.153,59,3.203,100,2.654,101,1.291,110,1.291,124,3.449,128,2.471,136,3.766,177,2.193,259,5.083,270,4.56,403,3.162,452,2.813,558,3.131,583,3.285,614,4.871,641,3.705,730,4.216,750,4.317,938,3.974,944,3.317,959,2.514,973,4.213,1027,4.819,1049,3.909,1392,3.263,1402,4.164,1465,3.767,1522,4.325,1552,4.56,1582,5.397,1697,5.873,1737,4.317,1785,4.029,1836,3.702,1928,4.432,1929,4.56,1988,7.214,1989,5.604,1990,4.964,1991,4.871,1992,6.015,1993,5.066,1994,4.785,1995,5.604,1996,6.015,1997,6.235,1998,6.015,1999,7.028,2000,5.604,2001,4.871]],["title/archive/tutorial/geospark-core-python/#installing-the-package",[1779,2.561,1843,3.158]],["text/archive/tutorial/geospark-core-python/#installing-the-package",[3,3.349,13,2.13,15,2.984,20,2.205,22,1.87,23,0.602,26,1.235,50,0.887,51,3.168,54,3.057,59,2.785,60,3.008,63,5.193,101,1.899,114,0.841,177,1.842,225,3.109,261,3.774,273,2.293,411,2.607,476,2.65,530,1.466,562,3.396,576,3.894,702,2.918,823,2.985,944,2.102,949,3.136,950,3.109,958,3.136,959,3.414,963,3.384,973,3.538,1001,3.774,1070,3.581,1269,3.83,1271,3.497,1324,3.917,1363,3.396,1366,3.69,1406,3.581,1498,2.875,1569,2.875,1643,3.625,1836,3.109,1843,5.002,1905,2.962,1971,4.091,2002,3.625,2003,3.458,2004,5.052,2005,5.052,2006,5.052,2007,5.863,2008,5.605,2009,5.052,2010,4.863,2011,8.681,2012,4.255,2013,6.813,2014,6.813,2015,4.863,2016,3.888,2017,4.571,2018,4.255,2019,4.349]],["title/archive/tutorial/geospark-core-python/#installing-from-pypi-repositories",[54,2.835,1779,2.147,2020,3.606]],["text/archive/tutorial/geospark-core-python/#installing-from-pypi-repositories",[20,2.707,59,2.734,101,1.864,1070,6.159,1779,3.983,1821,4.809,2021,6.912]],["title/archive/tutorial/geospark-core-python/#installing-from-wheel-file",[576,1.803,1779,2.147,2022,4.364]],["text/archive/tutorial/geospark-core-python/#installing-from-wheel-file",[15,3.427,184,5.877,404,6.257,1525,7.799,1620,3.204,1779,4.415,2021,7.661,2023,7.167,2024,9.632,2025,9.632,2026,9.632]],["title/archive/tutorial/geospark-core-python/#installing-from-source",[56,2.71,1779,2.561]],["text/archive/tutorial/geospark-core-python/#installing-from-source",[1779,4.085,2027,7.089,2028,7.356]],["title/archive/tutorial/geospark-core-python/#geospark-serializers",[59,1.758,403,2.937]],["text/archive/tutorial/geospark-core-python/#geospark-serializers",[23,0.637,59,2.339,110,1.595,243,3.041,257,4.201,403,4.796,457,4.007,951,4.358,953,4.293,970,6.39,1049,4.83,1344,4.696,1345,5.873,1346,5.813,1594,4.462,1869,5.635,1870,4.878,1905,4.358,2029,5.813,2030,5.145,2031,5.813]],["title/archive/tutorial/geospark-core-python/#create-a-spatialrdd",[126,1.862,558,1.956]],["text/archive/tutorial/geospark-core-python/#create-a-spatialrdd",[]],["title/archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd",[126,1.561,558,1.641,594,1.734]],["text/archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd",[12,1.873,20,1.378,23,0.65,51,1.583,56,2.146,57,2.222,59,2.388,92,2.963,101,1.381,111,1.196,124,2.536,139,2.5,159,2.27,166,2.847,177,1.613,200,1.637,220,2.095,373,1.743,374,2.27,486,2.821,490,4.88,532,3.073,555,2.574,558,2.657,563,3.136,613,3.746,616,2.369,750,3.175,938,2.205,944,1.841,959,3.172,1013,3.028,1020,2.821,1300,4.67,1318,3.216,1392,3.492,1492,2.963,1582,4.358,1664,5.035,1719,2.656,1737,3.175,1785,2.963,1928,6.524,1929,3.354,1932,3.726,1933,7.019,1934,6.629,1935,7.807,1936,3.9,1989,4.121,1990,3.651,1993,3.726,1994,3.519,1995,4.121,1996,4.424,2002,4.62,2032,3.582,2033,6.437,2034,3.726,2035,4.003,2036,8.334,2037,4.121,2038,4.121,2039,8.334,2040,3.582,2041,4.121,2042,4.121,2043,4.424,2044,6.437,2045,6.437,2046,4.424,2047,7.589,2048,4.932]],["title/archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd",[94,1.721,558,1.641,1027,2.525]],["text/archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd",[17,1.762,23,0.621,48,3.443,57,2.411,65,3.891,100,3.081,101,1.499,110,1.499,128,2.869,201,5.357,373,2.752,457,3.067,530,2.027,558,2.446,559,4.78,595,4.127,713,5.146,837,3.424,886,5.462,1027,4.732,1050,6.866,1051,3.081,1140,5.294,1318,5.077,1319,5.077,1320,5.077,1697,6.468,1741,4.227,2001,5.655,2063,4.95,2064,5.294,2065,6.984,2066,5.218,2067,6.157]],["title/archive/tutorial/geospark-core-python/#write-a-spatial-range-query",[17,1.018,349,1.24,370,1.915,941,2.203]],["text/archive/tutorial/geospark-core-python/#write-a-spatial-range-query",[23,0.648,106,1.713,108,5.102,488,3.525,537,3.959,550,4.677,959,3.692,1711,4.136,2057,5.612,2068,7.385,2069,6.22,2070,7.154,2071,7.994,2072,5.612,2073,5.612,2074,5.612,2075,5.612,2076,7.291,2077,5.129,2078,6.6,2079,6.073,2080,5.43]],["title/archive/tutorial/geospark-core-python/#range-query-window",[349,1.441,370,2.225,1711,2.747]],["text/archive/tutorial/geospark-core-python/#range-query-window",[20,2.419,57,2.681,59,2.443,108,4.485,110,1.666,119,3.098,126,3.123,171,3.707,200,3.469,349,2.881,370,4.45,530,2.72,583,5.118,594,2.874,937,5.097,1401,5.802,1711,5.494,1784,5.887,2081,6.54]],["title/archive/tutorial/geospark-core-python/#use-spatial-indexes",[17,1.182,101,1.005,243,1.917]],["text/archive/tutorial/geospark-core-python/#use-spatial-indexes",[17,2.167,23,0.644,42,2.835,57,1.918,59,2.378,65,2.463,101,1.193,106,1.35,108,4.366,243,3.771,281,2.396,349,2.324,370,2.639,373,2.979,457,2.44,488,3.016,530,1.613,537,3.119,550,3.684,558,1.946,594,2.798,831,2.173,882,2.818,905,4.095,938,2.771,955,2.56,959,3.59,961,3.647,981,3.035,1498,3.163,1560,5.638,1561,3.892,1620,2.19,1711,3.259,2035,5.029,2057,6.013,2068,5.818,2069,4.9,2070,6.121,2071,6.84,2072,4.421,2073,4.421,2074,4.421,2075,4.421,2076,6.239,2077,4.04,2078,5.648,2079,4.784,2080,4.278,2082,4.152,2083,5.73,2084,6.664,2085,4.213]],["title/archive/tutorial/geospark-core-python/#output-format",[111,1.038,252,1.985]],["text/archive/tutorial/geospark-core-python/#output-format",[15,2.381,17,1.425,23,0.651,26,0.854,48,4.27,101,1.859,110,1.212,111,1.05,114,0.94,136,4.385,201,5.917,252,2.007,349,1.737,352,2.31,370,2.682,464,3.084,532,2.696,641,3.167,653,5.473,676,4.053,701,4.347,959,2.361,1238,3.62,1522,3.064,1697,4.161,1997,4.418,2067,6.738,2079,6.579,2080,4.347,2086,4.757,2087,5.261,2088,5.648,2089,5.648,2090,5.648,2091,5.648,2092,7.643,2093,5.648,2094,5.648,2095,5.648,2096,5.883,2097,6.738,2098,6.437,2099,5.648]],["title/archive/tutorial/geospark-core-python/#write-a-spatial-knn-query",[17,1.018,349,1.24,941,2.203,1617,2.28]],["text/archive/tutorial/geospark-core-python/#write-a-spatial-knn-query",[17,2.071,23,0.635,32,3.457,57,2.17,61,2.639,89,2.911,101,1.349,110,1.349,121,2.827,200,3.814,222,3.48,349,2.978,352,2.572,488,2.509,530,1.825,558,2.874,582,3.687,594,2.327,836,3.632,959,3.43,1238,2.628,1598,3.325,1617,3.553,1724,7.216,2066,4.698,2069,5.543,2078,6.132,2100,5.543,2101,5.89,2102,5.543,2103,6.646,2104,4.512,2105,4.918,2106,4.918,2107,4.512,2108,4.918]],["title/archive/tutorial/geospark-core-python/#query-center-geometry",[110,1.005,349,1.441,762,3.452]],["text/archive/tutorial/geospark-core-python/#query-center-geometry",[20,2.533,59,2.558,119,3.843,126,2.709,171,4.598,200,3.009,349,2.5,530,2.359,583,4.44,594,3.009,641,3.368,762,5.99,937,5.335,1401,6.074,1617,4.594,1784,6.163]],["title/archive/tutorial/geospark-core-python/#use-spatial-indexes_1",[17,1.182,101,1.005,243,1.917]],["text/archive/tutorial/geospark-core-python/#use-spatial-indexes_1",[8,2.306,17,2.26,23,0.646,42,3.082,57,2.085,101,1.296,186,3.082,200,3.53,243,3.27,349,2.755,352,2.471,373,3.151,457,2.653,488,2.41,530,1.753,591,3.175,831,2.362,959,3.745,961,3.965,975,4.892,1560,3.965,1617,4.518,1620,2.381,1724,6.275,2035,5.467,2057,6.359,2069,5.326,2078,5.973,2083,6.061,2084,7.048,2085,4.58,2101,4.336,2103,6.474,2104,4.336,2105,4.725,2106,4.725,2107,4.336,2108,4.725]],["title/archive/tutorial/geospark-core-python/#output-format_1",[111,1.038,252,1.985]],["text/archive/tutorial/geospark-core-python/#output-format_1",[17,1.959,23,0.628,111,1.443,114,1.293,252,2.759,349,2.388,352,3.177,641,3.883,675,4.78,1617,4.389,1724,5.438,1997,8.6]],["title/archive/tutorial/geospark-core-python/#write-a-spatial-join-query",[17,1.018,349,1.24,831,1.577,941,2.203]],["text/archive/tutorial/geospark-core-python/#write-a-spatial-join-query",[17,2.215,23,0.64,32,2.728,57,1.713,61,2.083,65,3.097,89,2.297,101,1.065,102,2.11,106,1.205,110,1.986,121,2.23,236,3.924,281,3.013,349,2.487,352,3.309,384,2.909,488,2.788,530,1.44,537,2.784,550,4.633,558,1.737,582,2.909,594,2.994,653,3.135,675,2.531,676,3.561,831,2.732,836,2.866,959,2.921,978,3.434,1238,2.921,1598,2.624,1703,5.015,1711,2.909,1721,3.517,1785,3.323,1981,4.837,1997,8.643,2035,4.49,2066,6.561,2069,4.374,2076,5.767,2078,5.221,2109,4.018,2110,5.08,2111,3.607,2112,4.633,2113,5.886,2114,3.517,2115,6.161]],["title/archive/tutorial/geospark-core-python/#use-spatial-partitioning",[17,1.182,101,1.005,882,2.376]],["text/archive/tutorial/geospark-core-python/#use-spatial-partitioning",[17,2.095,23,0.641,42,3.266,44,3.325,59,2.015,101,1.374,102,2.724,236,3.106,281,2.761,349,1.969,558,2.908,619,3.908,696,3.247,745,3.305,831,2.503,882,5.125,978,5.749,1013,4.383,1522,4.506,1560,6.05,1561,4.485,1593,4.485,1615,5.186,1638,4.929,2066,6.887,2110,6.038,2112,6.466,2113,7.764,2114,5.887,2116,5.646]],["title/archive/tutorial/geospark-core-python/#use-spatial-indexes_2",[17,1.182,101,1.005,243,1.917]],["text/archive/tutorial/geospark-core-python/#use-spatial-indexes_2",[17,2.005,23,0.648,57,2.067,61,2.514,101,1.285,243,3.252,281,2.582,349,2.444,352,2.45,373,3.745,452,2.801,457,2.63,530,1.738,558,2.783,831,3.107,905,4.413,959,3.729,961,3.931,978,4.146,981,3.271,999,4.475,1620,2.36,1703,5.705,1876,5.044,2035,7.193,2066,6.666,2069,5.28,2078,5.939,2083,6.026,2084,7.008,2085,4.54,2110,5.779,2112,5.27,2113,7.514,2114,4.245,2117,5.156]],["title/archive/tutorial/geospark-core-python/#output-format_2",[111,1.038,252,1.985]],["text/archive/tutorial/geospark-core-python/#output-format_2",[17,1.694,23,0.599,65,3.795,111,1.248,114,1.118,252,2.385,281,2.894,349,2.064,352,2.746,452,4.004,641,4.114,653,4.242,831,2.625,838,4.818,888,5.927,891,5.927,1997,8.795,2066,5.016,2109,5.437,2113,5.655,2118,6.933,2119,8.311,2120,5.919,2121,5.919,2122,5.919]],["title/archive/tutorial/geospark-core-python/#write-a-distance-join-query",[234,1.906,349,1.24,831,1.577,941,2.203]],["text/archive/tutorial/geospark-core-python/#write-a-distance-join-query",[17,1.323,23,0.645,57,1.81,65,2.324,89,2.427,101,1.558,102,2.23,106,1.273,110,1.788,119,2.092,126,1.747,179,2.439,200,1.941,234,4.25,242,3.265,281,3.131,349,2.562,352,2.145,488,2.897,530,1.522,537,2.942,545,3.147,550,3.476,582,3.074,594,2.688,831,2.839,836,3.028,959,3.483,978,3.629,1238,2.191,1598,2.773,1703,5.212,1711,3.074,1721,5.148,1751,4.17,1785,3.512,1994,6.628,1996,5.243,2035,4.744,2057,7.514,2066,6.721,2069,4.622,2076,5.994,2077,3.811,2078,5.426,2110,5.28,2111,3.811,2112,4.815,2114,3.716,2123,5.243,2124,9.093,2125,4.513]],["title/archive/tutorial/geospark-core-python/#output-format_3",[111,1.038,252,1.985]],["text/archive/tutorial/geospark-core-python/#output-format_3",[23,0.643,47,2.512,48,3.232,114,1.091,119,2.615,136,3.097,201,5.145,220,2.133,281,2.826,349,2.016,352,4.025,529,3.786,545,3.935,639,7.433,641,2.716,653,5.328,675,4.301,973,4.591,1238,3.524,1911,5.779,1997,7.963,2000,6.106,2034,5.521,2067,5.779,2126,9.841,2127,6.555,2128,6.555,2129,6.555,2130,6.555]],["title/archive/tutorial/geospark-core-python/#save-to-permanent-storage",[1055,2.362,1719,2.812,2131,3.016]],["text/archive/tutorial/geospark-core-python/#save-to-permanent-storage",[17,1.937,22,2.842,139,4.34,159,3.94,558,3.259,576,2.955,595,4.538,641,3.182,837,4.564,1027,4.139,1051,3.388,1055,4.693,1066,4.31,1319,5.583,1320,5.583,1437,5.511,1633,4.991,1719,5.588,1738,5.511,1741,4.648,1756,6.219,1862,5.378,2131,5.991]],["title/archive/tutorial/geospark-core-python/#save-an-spatialrdd-not-indexed",[243,1.917,558,1.641,1055,2.362]],["text/archive/tutorial/geospark-core-python/#save-an-spatialrdd-not-indexed",[61,3.648,558,3.506,594,3.216,1055,4.381,1719,5.216,2131,5.593]],["title/archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed",[243,1.917,558,1.641,1055,2.362]],["text/archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed",[61,3.494,243,3.995,558,3.63,576,3.203,594,3.081,641,3.449,1055,4.197,1066,4.671,1719,4.997,1741,5.038,2131,5.358]],["title/archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed",[243,1.449,558,1.24,1055,1.786,2112,2.348,2140,3.122]],["text/archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed",[17,1.993,26,1.194,102,3.36,264,4.903,349,2.428,352,3.231,411,4.076,831,3.088,881,6.177,882,4.801,1055,3.982,1238,4.237,1391,4.005,1549,5.742,1719,4.741,1870,5.184,1910,5.819,1927,6.177,2131,5.084,2141,5.987]],["title/archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd",[558,1.641,1055,2.362,2142,3.727]],["text/archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd",[23,0.493,558,3.024,576,3.322,641,3.578,1055,4.354,1066,4.846,2142,6.869,2143,6.278]],["title/archive/tutorial/geospark-core-python/#read-from-other-geometry-files",[94,1.721,110,1.005,576,1.803]],["text/archive/tutorial/geospark-core-python/#read-from-other-geometry-files",[17,2.481,51,3.015,101,1.808,106,2.046,558,2.95,641,3.491,669,6.59,831,3.294,837,4.131,1070,5.972,1522,4.571]],["title/archive/tutorial/geospark-core-python/#read-from-wkt-file",[94,1.721,159,2.404,576,1.803]],["text/archive/tutorial/geospark-core-python/#read-from-wkt-file",[23,0.633,220,2.63,373,3.185,488,3.224,561,6.127,959,3.378,1478,8.084,2048,5.252,2152,8.082,2153,8.082,2154,7.78,2155,8.082]],["title/archive/tutorial/geospark-core-python/#read-from-wkb-file",[94,1.721,166,3.016,576,1.803]],["text/archive/tutorial/geospark-core-python/#read-from-wkb-file",[23,0.633,220,2.63,373,3.185,488,3.224,561,6.127,959,3.378,1479,8.462,2048,5.252,2152,8.082,2154,7.78,2156,8.082,2157,8.082]],["title/archive/tutorial/geospark-core-python/#read-from-geojson-file",[94,1.721,139,2.648,576,1.803]],["text/archive/tutorial/geospark-core-python/#read-from-geojson-file",[23,0.612,561,6.349,959,3.5,2048,5.443,2152,8.375,2154,8.062,2158,9.13,2159,8.375,2160,8.375]],["title/archive/tutorial/geospark-core-python/#read-from-shapefile",[94,2.052,555,3.251]],["text/archive/tutorial/geospark-core-python/#read-from-shapefile",[23,0.612,560,7.544,561,6.349,959,3.5,2048,5.443,2154,8.062,2161,9.292,2162,8.375,2163,8.375]],["title/archive/tutorial/geospark-core-python/#supported-versions",[8,2.133,75,2.158]],["text/archive/tutorial/geospark-core-python/#supported-versions",[8,3.276,15,4.192,26,1.297,59,2.7,75,3.315,402,5.281,530,2.491,1402,5.941]],["title/archive/tutorial/geospark-core-python/#apache-spark",[26,0.844,36,1.869]],["text/archive/tutorial/geospark-core-python/#apache-spark",[27,7.507,1370,7.089,1372,7.089]],["title/archive/tutorial/geospark-core-python/#geospark",[59,2.177]],["text/archive/tutorial/geospark-core-python/#geospark",[31,6.209,184,5.474]],["title/archive/tutorial/geospark-core-python/#python",[15,2.918]],["text/archive/tutorial/geospark-core-python/#python",[22,3.216,75,3.356,377,4.745,411,4.485,2164,8.69,2165,7.171,2166,9.641]],["title/archive/tutorial/geospark-sql-python/",[15,1.975,17,1.182,50,0.823]],["text/archive/tutorial/geospark-sql-python/",[3,0.504,8,0.772,10,2.089,12,0.322,13,0.321,15,2.147,17,0.51,20,1.408,21,0.421,22,0.282,23,0.658,26,1.282,27,0.641,31,0.527,36,0.254,44,1.793,47,2.373,50,0.607,51,1.822,54,0.865,56,0.369,57,0.263,59,2.005,60,0.453,63,2.153,64,0.605,71,0.561,75,0.985,85,0.515,93,0.515,94,0.743,100,0.336,101,1.437,105,0.156,106,0.491,110,1.437,111,0.141,114,0.64,115,0.355,119,2.031,126,1.151,128,0.587,129,1.147,136,1.982,171,1.444,173,0.912,177,1.756,179,0.665,182,2.293,184,1.234,186,1.032,187,0.49,192,2.171,200,1.978,219,2.459,220,2.395,225,0.468,235,0.44,241,0.51,248,0.88,251,0.641,253,0.595,261,0.569,273,0.649,311,3.297,313,3.101,327,0.852,355,1.85,365,0.49,366,0.539,373,1.005,389,2.26,391,4.052,392,3.06,397,0.418,402,0.468,403,1.341,404,0.586,411,0.738,430,0.386,431,0.938,464,0.416,476,0.285,488,2.132,530,0.74,532,0.363,533,0.499,545,0.457,555,0.443,562,1.657,568,1.642,574,2.613,575,0.553,576,1.853,583,3.278,594,0.944,603,1.511,613,1.484,615,0.968,616,1.083,641,2.403,653,0.903,675,1.032,702,0.44,730,1.826,750,0.546,775,0.561,780,1.158,823,0.45,827,0.51,831,0.297,842,0.605,843,0.605,844,0.595,847,0.625,854,0.605,937,0.499,938,0.379,941,0.416,943,0.888,944,0.595,948,0.561,949,1.255,950,1.57,951,0.446,952,0.553,953,0.44,958,1.255,959,2.733,963,1.355,964,0.561,973,1.416,984,0.51,1001,0.569,1007,1.084,1019,0.533,1020,0.485,1041,0.641,1048,2.909,1051,0.336,1070,1.013,1228,0.464,1268,0.515,1269,0.577,1324,2.958,1344,0.481,1345,0.92,1346,0.595,1363,0.365,1366,1.152,1370,0.605,1372,0.605,1379,0.733,1391,2.292,1392,1.097,1401,0.569,1402,0.99,1406,1.433,1408,0.561,1413,0.641,1465,0.895,1498,0.814,1522,2.084,1525,1.158,1536,0.641,1569,0.433,1582,2.338,1594,0.457,1620,0.3,1628,0.504,1643,0.546,1779,1.923,1795,1.231,1808,0.504,1821,0.421,1836,0.468,1843,1.952,1907,0.561,1971,0.616,1981,1.4,1999,1.261,2002,1.026,2003,2.364,2004,0.761,2005,0.761,2006,0.761,2007,1.026,2009,0.761,2010,1.376,2011,3.217,2012,1.703,2013,2.456,2014,3.325,2015,1.376,2016,1.557,2017,1.294,2018,1.204,2019,0.655,2020,0.586,2021,1.609,2022,0.709,2023,0.671,2024,1.43,2025,1.43,2026,1.43,2027,0.605,2028,0.628,2034,0.641,2040,1.638,2051,3.609,2096,3.479,2097,1.783,2098,2.909,2104,2.478,2143,0.553,2164,0.761,2165,0.628,2167,0.844,2168,0.733,2169,1.376,2170,0.844,2171,1.497,2172,1.947,2173,0.844,2174,0.844,2175,0.468,2176,0.844,2177,0.844,2178,2.605,2179,1.332,2180,1.83,2181,1.294,2182,1.497,2183,0.844,2184,0.761,2185,0.844,2186,0.709,2187,1.332,2188,0.844,2189,0.761,2190,1.332,2191,0.709,2192,0.761,2193,0.761,2194,0.709,2195,1.332,2196,2.818,2197,2.022,2198,1.332,2199,0.761,2200,0.761,2201,0.761,2202,0.761,2203,0.761,2204,0.761,2205,0.761,2206,0.761,2207,0.761,2208,0.761,2209,1.884,2210,1.332,2211,2.022,2212,3.091,2213,2.818,2214,0.761,2215,1.332,2216,0.761,2217,1.332,2218,1.332,2219,0.761,2220,1.332,2221,1.332,2222,0.761,2223,2.376,2224,1.332,2225,0.761,2226,1.332,2227,0.761,2228,2.022,2229,2.022,2230,0.761,2231,0.761,2232,0.709,2233,0.761,2234,0.761,2235,1.43,2236,0.761,2237,0.761,2238,1.43,2239,0.761,2240,0.761,2241,0.761,2242,0.761,2243,0.761,2244,0.844,2245,0.761,2246,0.761,2247,0.761,2248,0.761,2249,1.43,2250,0.761,2251,0.761,2252,1.43,2253,0.761,2254,0.709,2255,0.761,2256,0.761,2257,0.761,2258,0.761,2259,0.761,2260,4.444,2261,0.761,2262,0.761,2263,0.761,2264,0.616,2265,0.761,2266,0.761,2267,0.761,2268,0.761,2269,0.761,2270,2.551,2271,0.761,2272,0.761,2273,0.761,2274,0.761,2275,0.761,2276,0.761,2277,0.761,2278,0.761,2279,0.761,2280,0.761,2281,0.761,2282,0.761,2283,0.641,2284,1.586,2285,0.761,2286,0.709,2287,1.231,2288,1.83,2289,1.231,2290,0.761,2291,0.761,2292,0.761,2293,0.761,2294,0.761,2295,0.761,2296,2.022,2297,0.761,2298,0.761,2299,0.709,2300,1.43,2301,1.43,2302,1.43,2303,1.43,2304,1.43,2305,1.43,2306,2.551,2307,2.551,2308,1.43,2309,1.43,2310,1.43,2311,1.43,2312,0.761,2313,1.43,2314,0.761,2315,1.43,2316,1.43,2317,3.797,2318,1.43]],["title/archive/tutorial/geospark-sql-python/#spatial-sql-application-in-python",[15,1.701,17,1.018,50,0.709,943,2.504]],["text/archive/tutorial/geospark-sql-python/#spatial-sql-application-in-python",[]],["title/archive/tutorial/geospark-sql-python/#introduction",[105,1.423]],["text/archive/tutorial/geospark-sql-python/#introduction",[10,3.711,15,3.599,17,1.686,20,2.081,23,0.488,26,1.421,44,3.469,47,2.561,50,1.174,51,2.391,54,4.043,59,2.959,85,4.523,100,2.947,101,1.434,110,1.831,114,1.112,126,2.227,241,4.475,464,3.649,576,3.284,583,5.136,616,3.578,641,3.537,730,4.514,938,3.331,1324,3.698,1392,4.631,1401,4.992,1402,4.625,1795,5.752,1843,3.776,1907,4.923,2003,4.573,2096,5.143,2143,4.857,2167,7.413,2168,6.432,2169,6.432]],["title/archive/tutorial/geospark-sql-python/#installation",[1779,3.172]],["text/archive/tutorial/geospark-sql-python/#installation",[3,3.556,13,2.262,15,3.111,20,2.299,22,1.986,23,0.608,26,1.275,50,0.942,51,3.018,59,2.858,60,3.195,63,5.049,101,1.81,114,0.893,177,1.956,225,3.301,261,4.008,273,2.435,411,2.769,476,2.008,530,1.557,562,3.541,576,3.787,823,3.17,949,3.33,950,3.301,958,3.33,959,3.525,963,3.593,973,3.757,1001,4.008,1070,3.802,1269,4.067,1324,2.969,1363,2.574,1366,3.81,1406,3.802,1498,3.053,1569,3.053,1643,3.85,1836,3.301,1843,5.133,1971,4.344,2002,3.85,2003,3.672,2004,5.364,2005,5.364,2006,5.364,2007,5.295,2009,5.364,2010,5.164,2011,8.462,2012,4.518,2013,7.103,2014,7.103,2015,5.164,2016,4.129,2017,4.854,2018,4.518,2019,4.618,2170,5.952]],["title/archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories",[54,2.835,1779,2.147,2020,3.606]],["text/archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories",[20,2.707,59,2.734,101,1.864,1070,6.159,1779,3.983,1821,4.809,2021,6.912]],["title/archive/tutorial/geospark-sql-python/#installing-from-wheel-file",[576,1.803,1779,2.147,2022,4.364]],["text/archive/tutorial/geospark-sql-python/#installing-from-wheel-file",[15,3.427,184,5.877,404,6.257,1525,7.799,1620,3.204,1779,4.415,2021,7.661,2023,7.167,2024,9.632,2025,9.632,2026,9.632]],["title/archive/tutorial/geospark-sql-python/#installing-from-source",[56,2.71,1779,2.561]],["text/archive/tutorial/geospark-sql-python/#installing-from-source",[1779,4.085,2027,7.089,2028,7.356]],["title/archive/tutorial/geospark-sql-python/#core-classes-and-methods",[944,1.95,1522,2.542,1582,3.172]],["text/archive/tutorial/geospark-sql-python/#core-classes-and-methods",[15,2.525,20,1.866,21,3.315,23,0.543,26,1.348,44,4.127,51,3.193,59,2.99,63,3.073,75,2.314,101,2.039,106,1.93,110,1.285,128,3.265,235,3.459,403,4.689,583,3.271,594,2.217,603,5.939,780,6.437,944,2.492,948,4.413,952,4.354,1324,4.938,1406,4.245,1413,5.044,1465,3.75,1522,3.249,1582,6.434,1843,3.385,1981,4.146,1999,7.008,2003,4.099,2010,5.766,2011,5.579,2015,5.766,2016,4.61,2017,5.42,2018,5.044,2171,6.27,2172,7.652,2173,6.645,2174,6.645,2175,3.686,2176,6.645,2177,6.645,2178,5.156,2179,5.579,2180,5.42,2181,5.42,2182,6.27,2183,6.645]],["title/archive/tutorial/geospark-sql-python/#writing-application",[941,3.051,943,3.468]],["text/archive/tutorial/geospark-sql-python/#writing-application",[10,3.446,20,2.349,23,0.612,26,1.296,44,2.874,51,3.068,57,1.911,59,1.742,63,2.84,93,3.748,101,2.181,106,1.344,110,1.188,114,0.922,126,1.845,273,2.513,355,2.965,530,1.607,583,4.682,603,4.136,641,3.552,653,3.498,775,4.078,950,5.276,951,3.246,953,3.197,984,3.708,1048,3.563,1324,4.173,1344,3.498,1345,4.852,1346,4.329,1406,3.923,1498,3.151,1522,4.651,1582,3.748,1594,3.323,1628,3.67,1981,5.218,2002,3.973,2003,3.789,2011,5.157,2016,4.261,2034,4.662,2096,4.261,2171,5.795,2172,5.329,2178,4.765,2180,5.009,2181,5.009,2182,5.795,2184,5.536,2185,6.141,2186,5.157,2187,7.023,2188,6.141,2189,5.536,2190,5.157,2191,5.157,2192,5.536,2193,5.536,2194,5.157]],["title/archive/tutorial/geospark-sql-python/#examples",[114,1.152]],["text/archive/tutorial/geospark-sql-python/#examples",[]],["title/archive/tutorial/geospark-sql-python/#geosparksql",[1324,3.83]],["text/archive/tutorial/geospark-sql-python/#geosparksql",[12,1.307,15,1.301,17,0.779,20,0.961,23,0.659,26,1.046,44,1.602,50,0.86,51,1.104,59,0.971,64,2.455,75,1.192,94,1.134,101,0.662,110,1.723,111,0.573,114,0.514,115,0.86,129,2.2,173,1.968,177,1.125,186,3.102,187,1.986,200,2.972,219,0.882,313,1.986,366,2.187,373,1.929,397,1.697,431,3.212,488,2.426,533,2.025,545,1.852,568,3.914,574,3.299,613,3.538,615,2.089,675,1.574,702,1.782,831,1.206,842,2.455,843,2.455,844,2.414,847,2.139,854,2.455,937,2.025,959,1.29,1324,3.366,1366,1.394,1408,2.274,1536,2.599,1808,2.046,2003,2.112,2040,2.499,2051,5.964,2096,2.375,2098,4.122,2195,2.875,2196,5.665,2197,6.081,2198,2.875,2199,3.086,2200,3.086,2201,3.086,2202,3.086,2203,3.086,2204,3.086,2205,3.086,2206,3.086,2207,3.086,2208,3.086,2209,2.875,2210,2.875,2211,6.081,2212,2.274,2213,6.447,2214,3.086,2215,2.875,2216,3.086,2217,2.875,2218,2.875,2219,3.086,2220,2.875,2221,2.875,2222,3.086,2223,5.665,2224,2.875,2225,3.086,2226,2.875,2227,3.086,2228,6.081,2229,6.081,2230,3.086,2231,3.086,2232,2.875,2233,3.086,2234,3.086,2235,4.894,2236,3.086,2237,3.086,2238,4.894,2239,3.086,2240,3.086,2241,3.086,2242,3.086,2243,3.086,2244,3.424,2245,3.086,2246,3.086,2247,3.086,2248,3.086,2249,4.894,2250,3.086,2251,3.086,2252,4.894,2253,3.086,2254,2.875,2255,3.086,2256,3.086,2257,3.086,2258,3.086,2259,3.086]],["title/archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely",[71,3.452,583,2.559,2096,3.606]],["text/archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely",[10,1.956,23,0.659,26,1.426,47,2.46,50,0.589,59,1.644,94,1.92,101,0.72,110,1.685,114,0.558,115,0.589,126,1.741,129,2.349,173,2.139,311,1.982,327,3.112,355,3.438,365,2.159,373,2.059,403,1.763,430,1.701,532,1.601,555,1.952,562,3.477,568,2.159,574,1.82,576,1.291,583,1.832,613,1.952,615,2.271,616,2.799,641,2.659,730,2.763,750,2.407,949,3.243,958,3.243,959,3.476,963,3.5,973,3.659,1051,1.48,1268,2.271,1392,1.82,1522,1.82,1795,2.888,2003,2.296,2012,4.401,2013,5.03,2014,6.975,2040,4.231,2051,5.136,2096,6.045,2097,5.659,2098,6.103,2169,3.229,2179,3.125,2180,3.036,2190,3.125,2195,3.125,2196,4.868,2198,3.125,2209,4.868,2210,3.125,2212,2.472,2213,3.125,2215,3.125,2217,3.125,2218,3.125,2220,3.125,2221,3.125,2223,3.125,2224,3.125,2226,3.125,2260,5.2,2261,3.355,2262,3.355,2263,3.355,2264,2.716,2265,3.355,2266,3.355,2267,3.355,2268,3.355,2269,3.355,2270,7.246,2271,3.355,2272,3.355,2273,3.355,2274,3.355,2275,3.355,2276,3.355,2277,3.355,2278,3.355,2279,3.355,2280,3.355,2281,3.355,2282,3.355]],["title/archive/tutorial/geospark-sql-python/#creating-spark-dataframe-based-on-shapely-objects",[10,1.182,26,0.477,126,1.052,355,1.69,583,1.724,641,1.308]],["text/archive/tutorial/geospark-sql-python/#creating-spark-dataframe-based-on-shapely-objects",[]],["title/archive/tutorial/geospark-sql-python/#supported-shapely-objects",[8,1.788,583,2.559,641,1.941]],["text/archive/tutorial/geospark-sql-python/#supported-shapely-objects",[10,2.976,20,1.866,23,0.634,26,1.201,44,3.11,101,1.285,110,1.914,119,2.389,126,1.996,136,2.83,171,2.859,182,4.54,192,4.298,200,2.217,248,3.686,355,3.208,389,4.475,411,3.091,488,3.171,530,1.738,583,4.872,594,3.302,641,3.697,653,3.784,675,4.054,730,4.204,827,4.012,959,3.322,1019,4.194,1020,3.819,1048,5.116,1391,4.031,1465,3.75,1522,3.249,2178,7.681,2283,5.044,2284,8.819,2285,5.99,2286,5.579,2287,6.843,2288,8.073,2289,6.843]],["title/archive/tutorial/geospark-sql-python/#example-usage-for-shapely-objects",[114,0.672,583,2.203,641,1.671,964,2.972]],["text/archive/tutorial/geospark-sql-python/#example-usage-for-shapely-objects",[]],["title/archive/tutorial/geospark-sql-python/#point",[200,2.561]],["text/archive/tutorial/geospark-sql-python/#point",[23,0.659,26,0.868,47,2.961,110,1.232,136,3.651,200,3.458,219,2.496,248,3.533,251,4.836,253,4.491,488,3.083,574,3.115,575,4.174,959,2.4,1007,5.858,1041,4.836,1048,3.696,1228,3.504,1391,3.919,2104,4.12,2212,4.23,2260,6.268,2290,5.742,2291,5.742,2292,5.742,2293,5.742,2294,5.742,2295,5.742,2296,8.735,2297,5.742,2298,5.742,2299,5.349]],["title/archive/tutorial/geospark-sql-python/#multipoint",[389,5.17]],["text/archive/tutorial/geospark-sql-python/#multipoint",[23,0.658,26,1.005,47,3.261,136,3.141,219,2.681,389,7.011,488,2.653,574,3.607,959,2.779,1048,4.28,1391,3.372,2104,4.772,2212,4.899,2260,4.772,2300,8.51,2301,8.51,2302,8.51,2303,8.51]],["title/archive/tutorial/geospark-sql-python/#linestring",[171,3.303]],["text/archive/tutorial/geospark-sql-python/#linestring",[23,0.659,26,0.925,47,3.091,136,2.892,171,4.305,179,3.752,219,2.577,311,5.664,313,5.805,391,7.267,392,6.106,488,2.442,574,3.321,959,2.558,1048,3.94,1391,3.104,2104,4.393,2212,4.51,2260,5.787]],["title/archive/tutorial/geospark-sql-python/#multilinestring",[182,5.246]],["text/archive/tutorial/geospark-sql-python/#multilinestring",[23,0.66,26,0.827,47,2.866,136,2.584,182,6.459,219,2.434,311,6.097,313,6.372,391,7.822,392,6.703,488,2.182,574,2.968,959,2.286,1048,3.521,1391,2.774,2104,3.926,2212,4.03,2260,5.366,2304,7.478,2305,7.478]],["title/archive/tutorial/geospark-sql-python/#polygon",[119,2.761]],["text/archive/tutorial/geospark-sql-python/#polygon",[23,0.66,26,0.879,47,2.986,119,3.907,136,2.747,219,2.511,488,2.319,574,3.154,959,2.43,1048,3.742,1391,2.948,2104,4.172,2212,4.283,2260,5.592,2306,9.391,2307,9.391,2308,7.793,2309,7.793,2310,7.793,2311,7.793,2312,5.814,2313,7.793,2314,5.814]],["title/archive/tutorial/geospark-sql-python/#multipolygon",[192,4.966]],["text/archive/tutorial/geospark-sql-python/#multipolygon",[23,0.661,26,0.646,47,2.406,119,3.271,136,2.019,177,3.529,192,5.339,219,3.135,220,3.581,488,1.705,574,2.319,959,1.786,1048,2.751,1391,2.167,2104,3.067,2212,3.149,2260,4.505,2315,6.277,2316,6.277,2317,8.759,2318,6.277]],["title/archive/tutorial/geospark-sql-python/#supported-versions",[8,2.133,75,2.158]],["text/archive/tutorial/geospark-sql-python/#supported-versions",[8,3.276,15,4.192,26,1.297,59,2.7,75,3.315,402,5.281,530,2.491,1402,5.941]],["title/archive/tutorial/geospark-sql-python/#apache-spark",[26,0.844,36,1.869]],["text/archive/tutorial/geospark-sql-python/#apache-spark",[27,7.507,1370,7.089,1372,7.089]],["title/archive/tutorial/geospark-sql-python/#geosparksql_1",[1324,3.83]],["text/archive/tutorial/geospark-sql-python/#geosparksql_1",[31,6.169,184,5.439,1379,8.58]],["title/archive/tutorial/geospark-sql-python/#python",[15,2.918]],["text/archive/tutorial/geospark-sql-python/#python",[2164,8.97,2165,7.403]],["title/archive/tutorial/rdd/",[17,1.182,943,2.908,1238,1.958]],["text/archive/tutorial/rdd/",[6,0.483,8,0.162,10,0.446,12,0.18,13,0.179,17,1.853,20,0.256,22,1.006,23,0.653,26,0.232,32,0.845,36,0.398,42,0.608,44,0.221,47,1.042,48,0.21,50,0.327,51,0.152,57,1.97,58,0.575,59,1.543,61,1.703,65,1.712,85,0.288,86,0.908,89,0.711,90,0.44,94,0.795,96,0.407,97,0.208,100,0.188,101,1.519,102,1.464,106,0.595,108,0.688,110,1.488,111,0.754,114,0.256,115,0.38,119,1.619,121,0.973,126,1.684,128,1.32,129,0.836,135,2.231,136,0.726,137,0.328,139,1.816,141,0.234,159,1.766,161,0.25,165,0.309,166,1.393,171,0.733,172,1.223,177,0.789,178,0.665,179,1.383,186,1.104,192,0.305,200,1.19,218,0.25,219,0.531,220,1.818,222,0.455,225,0.946,226,0.569,232,0.298,234,1.728,236,1.188,242,0.369,243,2.181,246,0.248,252,0.87,257,0.241,263,0.419,264,0.264,266,0.251,273,0.193,281,1.386,284,0.258,293,0.41,299,0.954,311,0.908,319,0.519,324,0.623,327,0.489,334,0.255,335,2.838,349,2.383,352,1.002,355,0.823,366,0.844,370,1.634,373,1.522,374,0.611,384,0.482,397,0.234,403,0.978,411,0.424,412,2.61,424,0.232,433,0.597,445,0.724,446,0.485,452,0.557,455,0.455,457,1.511,459,0.766,464,0.449,476,0.159,486,0.524,487,0.562,488,1.541,489,0.578,491,0.274,493,0.323,500,0.309,530,1.967,532,2.191,537,1.044,538,0.601,543,0.506,544,0.302,545,0.493,550,1.233,555,0.693,556,0.673,557,2.183,558,2.876,559,1.273,560,0.328,561,0.903,562,0.893,563,1.318,564,0.765,566,0.435,568,0.274,569,0.575,573,0.285,576,2.607,577,0.328,578,0.358,579,0.345,580,0.333,581,0.396,582,1.091,583,0.232,584,1.11,585,0.298,586,0.396,587,0.396,588,0.396,589,0.396,590,0.396,591,0.978,592,0.21,593,0.234,594,2.347,595,0.704,596,0.396,597,0.358,598,0.396,599,0.396,600,0.333,601,0.305,603,1.39,604,0.239,605,0.396,606,0.396,607,0.396,613,1.582,615,0.288,616,0.996,619,0.727,620,0.432,641,1.681,643,1.052,666,0.302,675,0.419,696,0.604,701,0.632,702,0.475,713,0.314,730,0.435,745,0.424,753,0.302,762,0.605,823,0.704,831,1.975,833,0.93,836,1.074,837,0.584,838,0.59,840,0.358,849,0.351,872,0.291,873,0.298,875,0.98,876,0.562,877,0.59,878,0.386,881,0.333,882,1.63,886,0.333,888,0.569,891,0.824,903,0.765,905,0.605,919,0.285,938,0.41,941,0.839,944,0.9,945,0.251,946,0.262,951,0.482,953,0.475,955,0.378,961,0.782,965,0.345,968,4.332,970,1.904,975,0.345,978,1.064,981,0.65,999,0.318,1003,0.323,1013,1.052,1014,0.222,1024,1.04,1027,0.828,1049,0.534,1050,0.643,1051,1.418,1055,2.619,1066,2.277,1069,0.947,1138,0.285,1140,0.323,1238,1.243,1257,0.242,1272,0.375,1318,0.866,1319,0.597,1320,0.597,1324,1.198,1325,0.86,1330,0.426,1343,1.103,1344,0.519,1345,0.989,1346,0.333,1360,0.375,1363,0.204,1364,0.255,1366,0.977,1391,0.779,1392,0.231,1408,0.314,1420,0.375,1422,0.375,1437,0.305,1478,0.358,1498,0.242,1522,0.446,1549,0.597,1556,0.478,1558,0.333,1560,1.608,1561,0.575,1563,0.707,1567,0.302,1569,0.468,1572,0.562,1583,0.241,1593,0.298,1594,0.255,1598,0.984,1600,0.291,1615,0.345,1617,1.384,1620,0.733,1621,0.224,1633,0.277,1638,0.328,1648,0.318,1683,0.345,1697,0.605,1703,0.855,1709,2.707,1711,2.018,1719,1.299,1721,0.582,1724,2.251,1733,0.291,1737,0.855,1738,0.305,1741,0.93,1751,0.339,1756,0.345,1784,0.623,1785,0.55,1806,0.291,1815,0.358,1818,0.358,1825,0.605,1837,0.41,1841,0.298,1850,0.539,1857,0.277,1858,0.298,1862,0.575,1869,0.323,1870,0.782,1876,0.358,1890,1.04,1905,0.698,1910,0.314,1927,0.333,1928,2.003,1929,1.41,1932,1.294,1933,1.003,1934,1.721,1949,0.375,1953,0.323,1978,0.358,1981,0.295,1991,0.345,1993,0.358,1994,1.721,2001,0.345,2029,0.333,2030,0.295,2031,0.333,2032,1.984,2037,0.765,2038,0.396,2040,0.964,2041,1.11,2042,1.11,2048,1.932,2062,0.426,2063,0.302,2064,1.64,2070,0.665,2072,0.654,2073,0.654,2074,0.654,2075,0.654,2077,1.117,2080,0.632,2081,0.358,2082,0.318,2083,0.903,2085,0.903,2086,0.358,2100,0.375,2101,1.103,2102,0.375,2103,0.665,2105,0.932,2106,0.932,2107,0.855,2108,0.643,2109,0.665,2110,1.117,2111,2.502,2112,2.282,2114,1.318,2115,0.375,2116,0.375,2117,0.366,2118,0.665,2119,1.05,2120,0.375,2121,0.375,2122,0.375,2125,0.366,2131,1.393,2132,0.426,2133,3.214,2134,0.426,2136,0.426,2137,0.743,2138,0.426,2139,0.426,2140,0.375,2141,0.323,2142,1.48,2143,0.309,2144,0.426,2158,0.396,2319,0.385,2320,0.426,2321,0.472,2322,0.426,2323,1.705,2324,1.705,2325,0.912,2326,0.912,2327,0.912,2328,0.912,2329,0.912,2330,1.191,2331,1.191,2332,1.536,2333,4.204,2334,0.472,2335,0.472,2336,0.912,2337,1.705,2338,1.705,2339,1.705,2340,1.705,2341,0.472,2342,0.912,2343,0.912,2344,0.912,2345,1.321,2346,0.472,2347,0.426,2348,0.912,2349,0.472,2350,0.426,2351,0.472,2352,0.912,2353,0.472,2354,0.472,2355,0.472,2356,0.472,2357,0.472,2358,0.472,2359,0.396,2360,0.396,2361,0.472,2362,1.733,2363,0.472,2364,0.912,2365,1.705,2366,1.705,2367,0.472,2368,0.472,2369,0.912,2370,1.705,2371,1.536,2372,1.705,2373,0.472,2374,1.705,2375,0.472,2376,1.705,2377,1.705,2378,0.472,2379,1.705,2380,0.472,2381,1.705,2382,1.705,2383,1.705,2384,0.472,2385,1.705,2386,0.472,2387,0.822,2388,0.822,2389,0.426,2390,0.426,2391,0.426,2392,0.426,2393,0.472,2394,0.472,2395,0.472,2396,0.472,2397,0.472,2398,0.472,2399,0.472,2400,0.472,2401,0.472,2402,0.472,2403,0.472,2404,0.472,2405,0.472,2406,0.472,2407,0.472,2408,0.472,2409,0.472,2410,0.472,2411,0.472,2412,0.472,2413,0.472,2414,0.472,2415,0.472,2416,0.472,2417,0.472,2418,0.472,2419,0.472,2420,0.472,2421,0.472,2422,0.472,2423,0.472,2424,0.472,2425,0.472,2426,0.472,2427,0.472,2428,0.472,2429,0.472,2430,0.472,2431,0.472,2432,0.472,2433,0.472,2434,0.472,2435,0.472,2436,0.472,2437,0.472,2438,0.472,2439,0.472,2440,0.472,2441,0.472,2442,0.472,2443,0.472,2444,0.472,2445,0.472,2446,0.472,2447,0.472,2448,0.822,2449,0.822,2450,0.426,2451,0.426,2452,0.426,2453,0.426,2454,0.472,2455,0.472,2456,0.472,2457,0.472,2458,0.472,2459,0.472,2460,0.472,2461,0.472,2462,0.472,2463,0.472,2464,0.472,2465,0.472,2466,0.472,2467,0.472,2468,0.472,2469,0.472,2470,0.472,2471,0.472,2472,0.472,2473,0.472,2474,0.472,2475,0.472,2476,0.472,2477,0.472,2478,0.472,2479,0.472,2480,0.472,2481,0.472,2482,0.472,2483,0.472,2484,0.472,2485,0.472,2486,0.472,2487,0.472,2488,0.472,2489,0.472,2490,0.472,2491,0.472,2492,0.472,2493,0.472,2494,0.472,2495,0.472,2496,0.472,2497,0.472,2498,0.472,2499,0.472,2500,0.472,2501,0.472,2502,0.472,2503,0.472,2504,0.472,2505,0.472,2506,0.472,2507,0.472,2508,0.472,2509,0.472,2510,0.472,2511,0.472,2512,0.472,2513,0.472,2514,0.472,2515,0.472,2516,0.472,2517,0.472,2518,0.472,2519,0.472,2520,0.472,2521,0.472,2522,0.472,2523,0.472,2524,0.472,2525,0.472,2526,0.472,2527,0.472,2528,0.472,2529,0.472,2530,0.472,2531,0.472,2532,0.472,2533,0.472,2534,0.472,2535,0.472,2536,0.822,2537,0.822,2538,0.426,2539,0.426,2540,0.426,2541,0.426,2542,0.472,2543,0.472,2544,0.472,2545,0.472,2546,0.472,2547,0.472,2548,0.472,2549,0.472,2550,0.472,2551,0.472,2552,0.472,2553,0.472,2554,0.472,2555,0.472,2556,0.472,2557,0.472,2558,0.472,2559,0.472,2560,0.472,2561,0.472,2562,0.472,2563,0.472,2564,0.472,2565,0.472,2566,0.472,2567,0.472,2568,0.472,2569,0.472,2570,0.472,2571,0.912,2572,0.912,2573,0.472,2574,0.472,2575,0.472,2576,0.472,2577,0.472,2578,0.472,2579,0.472,2580,0.472,2581,0.472,2582,0.472,2583,0.472,2584,0.472,2585,0.472,2586,0.472,2587,0.472,2588,0.472,2589,0.472,2590,0.472,2591,0.472,2592,0.472,2593,0.472,2594,0.472,2595,0.366,2596,0.472,2597,0.472,2598,0.912,2599,0.472,2600,0.472,2601,0.446,2602,0.318,2603,0.822,2604,0.597,2605,0.822,2606,0.358,2607,0.426,2608,0.358,2609,0.426,2610,0.692,2611,0.426,2612,1.431,2613,3.076,2614,0.765,2615,0.426,2616,0.426,2617,3.574,2618,1.64,2619,1.05,2620,0.375,2621,0.426,2622,0.396,2623,0.426,2624,0.426,2625,1.908,2626,0.375,2627,0.426,2628,0.426,2629,1.536,2630,0.426,2631,0.426,2632,0.358,2633,2.016,2634,2.016,2635,0.743,2636,0.765,2637,0.426,2638,0.822,2639,0.822,2640,0.375,2641,0.426,2642,0.472,2643,2.718,2644,2.064]],["title/archive/tutorial/rdd/#set-up-dependencies",[457,2.057,745,2.418,1366,2.116]],["text/archive/tutorial/rdd/#set-up-dependencies",[6,3.595,22,2.625,23,0.608,26,1.461,36,3.233,51,2.538,59,3.187,94,2.605,115,1.246,232,4.966,263,3.617,335,2.739,556,4.007,944,4.214,945,4.19,946,4.364,1257,4.036,1324,3.925,1363,3.403,1364,4.257,1366,4.367,1733,4.854,1850,4.654,1890,6]],["title/archive/tutorial/rdd/#initiate-sparkcontext",[563,3.96,1583,3.158]],["text/archive/tutorial/rdd/#initiate-sparkcontext",[6,2.064,20,1.585,23,0.652,59,2.794,101,1.092,110,1.092,179,2.368,243,2.082,257,2.876,281,2.194,334,3.055,403,4.667,412,2.886,457,3.899,530,1.477,563,3.607,591,2.675,823,3.007,878,2.392,919,3.409,951,4.171,953,4.108,955,2.344,965,4.121,968,3.716,970,7.101,1049,3.307,1051,2.245,1343,6.373,1344,4.495,1345,5.716,1346,3.98,1360,4.486,1366,2.299,1567,3.607,1572,4.869,1594,3.055,1600,3.483,1620,2.006,1621,2.675,1850,3.34,1858,3.564,1869,3.858,1870,3.34,1890,3.445,1905,4.809,2029,3.98,2030,3.523,2031,3.98,2048,3.307,2320,5.089,2321,5.646,2322,5.089]],["title/archive/tutorial/rdd/#create-a-spatialrdd",[126,1.862,558,1.956]],["text/archive/tutorial/rdd/#create-a-spatialrdd",[]],["title/archive/tutorial/rdd/#create-a-typed-spatialrdd",[126,1.561,558,1.641,594,1.734]],["text/archive/tutorial/rdd/#create-a-typed-spatialrdd",[23,0.462,59,2.543,111,1.502,139,4.567,159,4.147,166,5.202,555,4.703,558,2.83,613,4.703,616,4.329,938,4.029,944,3.363,1013,5.532,1683,6.545,1737,5.8,1928,5.955,1929,6.127,1993,6.807,2032,6.545]],["title/archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120",[61,1.325,126,1.052,141,1.735,558,1.105,878,1.483,2346,3.502]],["text/archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120",[23,0.53,47,2.927,61,3.206,110,1.991,119,3.047,121,3.433,159,3.918,171,3.646,192,5.481,538,4.678,558,2.674,576,3.569,594,3.847,840,6.433,1013,5.227,1014,3.99,1392,4.144,1815,6.433,1818,6.433,1857,4.963,1981,5.287,2347,7.638]],["title/archive/tutorial/rdd/#transform-the-coordinate-reference-system",[90,2.16,335,1.558,459,2.011,464,2.203]],["text/archive/tutorial/rdd/#transform-the-coordinate-reference-system",[23,0.637,57,1.903,59,2.366,65,2.444,85,3.733,90,2.953,101,1.613,102,2.345,110,1.613,126,1.838,234,2.605,284,3.337,335,2.904,349,1.695,352,2.255,355,4.921,412,2.236,459,2.749,464,3.011,486,4.794,487,5.146,489,2.674,491,3.549,493,4.18,530,1.6,557,3.116,558,3.218,591,2.898,730,2.916,872,3.774,873,3.861,875,5.455,876,5.146,877,5.395,891,3.817,968,3.927,1003,4.18,1024,6.221,1549,4.008,1563,6.472,1870,3.618,1928,4.062,2048,3.583,2064,4.18,2330,5.514,2331,5.514,2332,5.514,2333,6.303,2602,4.119,2603,7.518,2604,5.465,2605,7.518,2606,4.644,2607,5.514,2608,4.644]],["title/archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd",[94,1.721,558,1.641,1027,2.525]],["text/archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd",[17,1.694,23,0.635,48,3.31,57,2.317,65,3.795,100,2.962,101,1.441,110,1.441,128,3.873,373,2.646,457,2.948,530,1.949,558,2.351,559,4.595,595,3.967,713,4.946,837,3.292,886,5.251,968,3.507,1027,4.615,1050,6.697,1051,2.962,1140,5.089,1238,2.806,1318,4.881,1319,4.881,1320,4.881,1697,6.308,1741,4.063,2001,5.437,2063,4.759,2064,5.089,2333,4.946,2609,6.714,2610,7.211,2611,6.714]],["title/archive/tutorial/rdd/#write-a-spatial-range-query",[17,1.018,349,1.24,370,1.915,941,2.203]],["text/archive/tutorial/rdd/#write-a-spatial-range-query",[17,2.303,22,2.009,23,0.641,32,2.984,50,0.953,57,1.873,61,2.278,89,2.512,101,1.165,106,2.06,108,3.134,110,1.596,114,0.904,115,0.953,121,2.44,299,3.369,349,3.11,370,4.335,373,2.139,384,4.361,412,2.201,457,2.383,488,2.967,530,2.159,537,4.174,543,4.577,544,3.847,550,4.931,557,3.067,558,2.971,582,3.182,594,2.009,702,3.134,968,4.433,1598,2.87,1709,7.147,1711,5.352,2070,4.395,2072,4.317,2073,4.317,2074,4.317,2075,4.317,2077,3.945,2080,4.177,2362,6.929,2612,6.929,2613,5.638,2614,5.056,2615,5.427]],["title/archive/tutorial/rdd/#range-query-window",[349,1.441,370,2.225,1711,2.747]],["text/archive/tutorial/rdd/#range-query-window",[23,0.658,57,2.389,59,1.191,102,1.61,108,2.186,119,1.51,126,2.306,128,1.555,135,5.519,177,2.09,178,2.483,179,1.761,186,1.93,200,1.401,219,1.638,220,3.222,226,2.62,324,2.869,335,4.231,349,1.763,370,2.722,412,4.162,433,2.751,445,5.054,446,2.236,530,2.008,594,1.401,643,3.924,696,1.919,968,4.878,1711,3.361,1784,2.869,2081,3.187,2105,2.96,2106,2.96,2616,3.785,2617,8.052,2618,3.336,2619,3.336,2620,3.336,2621,3.785,2622,3.525,2623,3.785,2624,3.785]],["title/archive/tutorial/rdd/#use-spatial-indexes",[17,1.182,101,1.005,243,1.917]],["text/archive/tutorial/rdd/#use-spatial-indexes",[17,2.266,23,0.64,42,2.664,47,2.002,57,1.803,59,2.279,65,2.315,101,1.784,106,1.268,108,3.017,119,2.084,128,2.146,179,2.43,243,4.095,281,2.252,349,2.227,370,2.48,373,2.855,412,2.119,457,2.293,488,2.89,530,1.516,537,2.931,550,3.463,557,2.952,558,2.912,594,2.681,831,2.042,882,2.649,905,3.848,938,2.604,955,2.406,961,3.428,968,4.691,981,3.956,1498,2.973,1558,4.085,1560,5.458,1561,3.658,1569,4.123,1598,2.762,1620,2.058,1648,3.902,1709,6.101,1711,3.062,1978,4.399,2070,4.229,2072,4.155,2073,4.155,2074,4.155,2075,4.155,2077,3.797,2080,4.02,2082,3.902,2083,3.959,2085,3.959,2612,6.748,2613,5.491,2614,4.865,2625,6.386,2626,4.605,2627,5.223]],["title/archive/tutorial/rdd/#output-format",[111,1.038,252,1.985]],["text/archive/tutorial/rdd/#output-format",[17,2.192,111,1.615,252,3.087,349,2.672,370,4.126,558,3.043,2086,7.319]],["title/archive/tutorial/rdd/#write-a-spatial-knn-query",[17,1.018,349,1.24,941,2.203,1617,2.28]],["text/archive/tutorial/rdd/#write-a-spatial-knn-query",[17,2.258,22,1.919,23,0.643,32,2.85,50,0.911,57,1.789,61,2.176,89,2.4,101,1.112,106,1.259,110,1.112,115,0.911,121,2.33,186,3.675,200,2.667,222,2.869,234,3.404,299,3.218,319,3.275,335,2.002,349,2.893,352,2.121,412,2.923,446,3.063,488,2.068,530,2.091,558,2.523,582,3.039,594,1.919,702,2.994,836,2.994,968,4.914,1051,2.287,1238,2.167,1598,2.742,1617,4.072,1724,6.82,1806,3.548,2100,4.57,2101,5.944,2102,4.57,2103,4.198,2105,4.055,2106,4.055,2107,5.171,2108,4.055,2333,3.819,2362,4.829,2613,5.463,2617,6.976,2618,6.353,2619,4.57,2628,5.184,2629,8.952,2630,5.184,2631,5.184,2632,4.366]],["title/archive/tutorial/rdd/#query-center-geometry",[110,1.005,349,1.441,762,3.452]],["text/archive/tutorial/rdd/#query-center-geometry",[23,0.462,59,2.543,119,3.829,126,2.694,171,4.582,200,2.991,273,3.668,349,2.951,370,3.838,594,2.991,641,3.349,762,5.955,1617,4.567,1711,4.739,1784,6.127,1841,5.66]],["title/archive/tutorial/rdd/#use-spatial-indexes_1",[17,1.182,101,1.005,243,1.917]],["text/archive/tutorial/rdd/#use-spatial-indexes_1",[8,2.238,17,2.227,23,0.649,42,2.99,57,2.024,101,1.258,222,3.245,243,3.206,335,2.265,349,2.714,352,2.398,373,3.088,412,3.179,457,2.574,488,2.339,530,1.702,591,3.081,831,2.292,961,3.848,968,5.278,975,4.748,1560,3.848,1617,4.429,1620,2.311,1724,6.182,2083,4.444,2085,4.444,2101,4.207,2103,4.748,2105,4.586,2106,4.586,2107,4.207,2108,4.586,2333,5.774,2613,5.941,2617,7.435,2618,6.909,2619,5.169,2625,6.909]],["title/archive/tutorial/rdd/#output-format_1",[111,1.038,252,1.985]],["text/archive/tutorial/rdd/#output-format_1",[17,2.139,110,2.118,111,1.575,252,3.012,349,2.606,641,3.512,675,5.035,1617,4.791,1724,5.937]],["title/archive/tutorial/rdd/#write-a-spatial-join-query",[17,1.018,349,1.24,831,1.577,941,2.203]],["text/archive/tutorial/rdd/#write-a-spatial-join-query",[17,2.364,22,1.897,23,0.644,32,2.818,50,0.901,57,1.77,61,2.152,65,3.649,89,2.373,101,1.1,102,2.181,106,1.245,110,1.912,115,0.901,121,2.305,136,3.378,218,3.006,236,3.993,281,3.083,299,3.182,349,2.881,352,2.097,488,2.853,530,2.075,537,2.877,550,3.399,558,1.795,582,3.006,594,3.048,831,3.219,836,4.13,968,4.301,978,3.549,1051,2.261,1238,2.143,1598,2.711,1703,3.679,1709,6.022,1711,3.006,1721,3.634,1785,3.434,2077,3.727,2109,4.151,2110,3.727,2111,5.986,2112,4.74,2114,3.634,2115,4.519,2333,6.564,2613,5.42,2633,7.67,2634,7.67,2635,4.639,2636,4.776]],["title/archive/tutorial/rdd/#use-spatial-partitioning",[17,1.182,101,1.005,882,2.376]],["text/archive/tutorial/rdd/#use-spatial-partitioning",[17,2.095,23,0.641,42,3.266,44,3.325,59,2.015,101,1.374,102,2.724,236,3.106,281,2.761,349,1.969,558,2.908,619,3.908,696,3.247,745,3.305,831,2.503,882,5.125,978,5.749,1013,4.383,1522,4.506,1560,6.05,1561,4.485,1593,4.485,1615,5.186,1638,4.929,2110,6.038,2111,6.701,2112,6.466,2114,5.887,2116,5.646,2333,6.792]],["title/archive/tutorial/rdd/#use-spatial-indexes_2",[17,1.182,101,1.005,243,1.917]],["text/archive/tutorial/rdd/#use-spatial-indexes_2",[17,2.052,23,0.648,57,2.141,61,2.604,101,1.331,243,3.328,281,2.674,349,2.501,352,2.538,373,3.577,452,2.901,457,2.724,530,1.8,558,2.849,831,3.18,905,4.571,961,4.071,968,4.742,981,3.388,999,4.635,1620,2.445,1703,4.452,1709,5.225,1876,5.225,2083,4.703,2085,4.703,2111,6.599,2112,5.393,2114,4.397,2117,5.34,2333,6.688,2613,6.167,2625,7.172,2637,6.204]],["title/archive/tutorial/rdd/#output-format_2",[111,1.038,252,1.985]],["text/archive/tutorial/rdd/#output-format_2",[17,1.885,23,0.427,65,4.057,110,2.124,111,1.389,252,2.655,281,3.222,349,2.298,452,4.281,641,4.101,831,2.921,838,5.363,888,6.337,891,6.337,2109,6.051,2111,5.433,2118,7.413,2119,8.725,2120,6.588,2121,6.588,2122,6.588,2333,5.506]],["title/archive/tutorial/rdd/#write-a-distance-join-query",[234,1.906,349,1.24,831,1.577,941,2.203]],["text/archive/tutorial/rdd/#write-a-distance-join-query",[17,2.187,22,1.553,23,0.644,32,2.307,50,0.737,57,1.449,61,1.762,65,3.262,86,4.801,89,1.943,101,1.579,102,2.634,106,1.019,110,1.744,111,0.78,115,0.737,121,1.886,126,1.399,136,2.926,234,4.549,236,3.57,242,2.784,243,1.717,252,1.491,281,2.67,299,2.605,311,3.659,319,2.651,349,3.074,352,1.717,412,1.702,488,2.471,489,3.004,530,1.797,537,2.355,545,3.718,550,2.782,558,1.469,582,2.46,594,2.724,666,2.974,831,3.764,836,3.577,875,2.676,882,2.128,968,4.245,978,2.905,1051,1.851,1238,1.754,1408,3.092,1598,2.219,1703,3.012,1709,5.216,1711,2.46,1721,2.974,1751,3.338,1785,2.811,1994,7.215,2077,3.051,2110,3.051,2111,3.051,2112,4.106,2114,2.974,2125,3.613,2613,4.695,2633,6.857,2634,6.857,2635,3.797,2636,3.909,2638,6.193,2639,6.193,2640,3.7,2641,4.197]],["title/archive/tutorial/rdd/#save-to-permanent-storage",[1055,2.362,1719,2.812,2131,3.016]],["text/archive/tutorial/rdd/#save-to-permanent-storage",[17,1.937,22,2.842,139,4.34,159,3.94,558,3.259,576,2.955,595,4.538,641,3.182,837,4.564,1027,4.139,1051,3.388,1055,4.693,1066,4.31,1319,5.583,1320,5.583,1437,5.511,1633,4.991,1719,5.588,1738,5.511,1741,4.648,1756,6.219,1862,5.378,2131,5.991]],["title/archive/tutorial/rdd/#save-an-spatialrdd-not-indexed",[243,1.917,558,1.641,1055,2.362]],["text/archive/tutorial/rdd/#save-an-spatialrdd-not-indexed",[61,3.648,558,3.506,594,3.216,1055,4.381,1719,5.216,2131,5.593]],["title/archive/tutorial/rdd/#save-an-spatialrdd-indexed",[243,1.917,558,1.641,1055,2.362]],["text/archive/tutorial/rdd/#save-an-spatialrdd-indexed",[61,3.494,243,3.995,558,3.63,576,3.203,594,3.081,641,3.449,1055,4.197,1066,4.671,1719,4.997,1741,5.038,2131,5.358]],["title/archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed",[243,1.449,558,1.24,1055,1.786,2112,2.348,2140,3.122]],["text/archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed",[17,1.993,26,1.194,102,3.36,264,4.903,349,2.428,352,3.231,411,4.076,831,3.088,881,6.177,882,4.801,1055,3.982,1238,4.237,1391,4.005,1549,5.742,1719,4.741,1870,5.184,1910,5.819,1927,6.177,2131,5.084,2141,5.987]],["title/archive/tutorial/rdd/#reload-a-saved-spatialrdd",[558,1.641,1055,2.362,2142,3.727]],["text/archive/tutorial/rdd/#reload-a-saved-spatialrdd",[23,0.493,558,3.024,576,3.322,641,3.578,1055,4.354,1066,4.846,2142,6.869,2143,6.278]],["title/archive/tutorial/sql/",[17,1.182,50,0.823,943,2.908]],["text/archive/tutorial/sql/",[6,1.282,8,0.377,10,3.037,12,1.568,13,0.417,17,1.258,18,0.598,20,1.153,22,1.37,23,0.651,26,0.276,31,2.187,36,1.057,44,0.947,47,0.973,50,0.876,51,1.784,56,0.479,57,1.839,59,2.085,60,0.588,64,0.786,65,0.438,66,0.516,70,0.692,85,0.669,86,1.077,90,0.977,94,1.957,96,0.49,97,0.482,100,1.12,101,1.465,102,0.776,106,0.24,110,1.803,111,0.184,114,0.304,115,0.809,119,2.989,121,0.444,122,0.43,124,1.456,126,1.535,128,2.316,129,0.82,139,1.03,159,0.936,161,0.579,173,0.63,179,0.848,186,0.93,218,1.069,225,0.608,232,0.692,234,1.975,235,0.571,239,1.212,242,0.82,243,0.404,252,1.315,257,0.558,263,0.93,266,1.077,273,0.828,281,0.426,311,0.584,319,0.624,334,0.593,335,1.43,349,2.099,352,0.746,355,1.692,370,0.866,373,1.815,403,1.66,411,0.941,412,0.401,424,0.54,446,0.584,452,0.462,457,0.434,459,0.909,463,1.634,464,0.996,476,0.683,486,1.619,487,1.738,488,0.727,489,1.232,490,1.382,491,0.636,493,0.749,523,0.749,524,0.749,525,0.738,529,1.467,530,1.718,532,3.577,533,0.648,543,0.608,544,0.7,545,0.593,555,1.061,556,1.03,557,3.011,558,2.455,559,0.676,562,3.365,566,2.637,567,1.426,568,2.383,569,5.604,571,1.846,572,2.02,573,2.48,574,2.008,575,0.718,576,0.977,582,0.579,591,0.958,594,2.191,595,1.077,604,1.773,613,0.575,614,0.8,615,0.669,616,2.67,620,0.519,641,0.409,696,1.288,698,0.728,730,2.637,745,0.51,754,0.871,823,0.584,827,0.662,831,1.634,832,0.655,836,0.571,837,1.549,872,0.676,873,0.692,875,1.619,876,1.248,877,1.309,878,1.193,886,0.773,919,0.662,927,0.718,928,1.343,929,0.709,930,0.728,931,0.92,932,0.851,938,0.909,944,1.315,945,0.584,946,0.608,947,0.728,949,0.613,950,1.944,951,1.069,953,1.053,955,0.455,956,0.662,958,0.613,963,0.662,981,0.54,1003,0.749,1007,3.779,1014,0.953,1017,0.584,1019,1.277,1020,0.63,1024,2.83,1027,1.995,1048,0.636,1049,1.185,1051,1.12,1055,1.593,1100,0.786,1138,0.662,1228,0.603,1238,1.32,1247,0.8,1254,0.655,1257,0.562,1316,0.76,1319,1.326,1320,1.326,1324,4.065,1343,2.267,1344,1.152,1345,2.034,1346,0.773,1348,0.871,1360,0.871,1363,0.474,1364,0.593,1366,1.672,1392,0.536,1498,1.038,1522,0.536,1554,0.786,1556,0.575,1567,0.7,1572,1.248,1583,1.03,1594,0.593,1600,0.676,1617,0.558,1620,1.245,1621,0.519,1633,0.642,1680,0.8,1711,0.579,1719,1.524,1733,0.676,1738,1.822,1797,0.749,1806,0.676,1819,0.624,1825,0.728,1841,0.692,1850,1.197,1858,0.692,1869,0.749,1870,0.648,1890,1.719,1905,1.489,1910,0.728,1927,0.773,1953,0.749,2003,0.676,2029,0.773,2030,0.684,2031,0.773,2051,5.092,2053,0.92,2054,1.608,2058,0.894,2063,1.292,2064,1.382,2101,0.709,2107,0.709,2118,0.8,2131,1.634,2175,1.563,2264,3.729,2319,0.894,2601,1.034,2602,0.738,2604,1.326,2608,0.832,2620,0.871,2632,0.832,2645,0.786,2646,0.92,2647,0.871,2648,0.92,2649,2.539,2650,1.824,2651,4.06,2652,4.06,2653,4.06,2654,4.06,2655,0.92,2656,3.448,2657,0.988,2658,3.055,2659,3.263,2660,3.263,2661,1.699,2662,1.699,2663,1.699,2664,1.699,2665,1.699,2666,1.699,2667,1.699,2668,1.699,2669,2.239,2670,5.444,2671,3.894,2672,3.894,2673,1.699,2674,1.699,2675,1.699,2676,2.239,2677,1.699,2678,1.699,2679,1.699,2680,2.239,2681,1.699,2682,1.699,2683,1.699,2684,2.239,2685,1.699,2686,1.699,2687,1.699,2688,1.699,2689,0.988,2690,0.988,2691,0.773,2692,1.699,2693,0.92,2694,2.096,2695,0.988,2696,0.988,2697,0.988,2698,0.988,2699,0.988,2700,0.988,2701,0.92,2702,0.92,2703,0.92,2704,0.92,2705,0.894,2706,0.988,2707,1.824,2708,0.988,2709,2.023,2710,1.096,2711,0.988,2712,1.096,2713,0.92,2714,1.096,2715,0.786,2716,1.824,2717,2.298,2718,1.096,2719,0.988,2720,0.988,2721,0.988]],["title/archive/tutorial/sql/#set-up-dependencies",[457,2.057,745,2.418,1366,2.116]],["text/archive/tutorial/sql/#set-up-dependencies",[6,3.539,22,2.559,23,0.626,26,1.318,36,3.356,51,2.475,59,3.158,94,2.54,115,1.215,232,4.842,263,3.527,335,2.671,556,4.93,944,4.176,945,4.085,946,4.255,1257,3.936,1324,4.828,1363,3.318,1364,4.151,1366,4.317,1733,4.733,1850,4.538,1890,5.906]],["title/archive/tutorial/sql/#initiate-sparksession",[562,2.681,1583,3.158]],["text/archive/tutorial/sql/#initiate-sparksession",[6,2.095,20,1.609,23,0.653,57,1.783,59,2.812,66,2.698,101,1.542,110,1.108,179,2.403,243,2.113,257,2.919,281,2.227,334,3.1,403,4.697,530,2.086,557,2.919,562,3.967,591,2.714,823,3.052,878,2.427,919,3.46,949,3.206,950,5.5,951,4.214,953,4.151,955,2.379,956,3.46,958,3.206,1049,3.356,1051,2.278,1343,6.414,1344,4.541,1345,5.753,1346,4.039,1360,4.553,1366,2.333,1567,3.661,1572,4.919,1583,2.919,1594,3.1,1600,3.535,1620,2.035,1621,2.714,1850,3.39,1858,3.617,1869,3.915,1870,3.39,1890,3.497,1905,4.847,2029,4.039,2030,3.575,2031,4.039,2645,4.108,2646,4.811]],["title/archive/tutorial/sql/#register-geosparksql",[1324,3.093,2175,3.438]],["text/archive/tutorial/sql/#register-geosparksql",[6,3.186,23,0.578,51,3.377,59,2.471,100,4.162,179,3.654,349,2.415,530,2.279,562,4.528,594,2.907,831,3.07,832,5.206,947,5.786,963,5.261,1019,6.607,1348,6.924,2175,4.833,2647,6.924]],["title/archive/tutorial/sql/#load-data-from-files",[47,1.795,576,1.803,616,2.509]],["text/archive/tutorial/sql/#load-data-from-files",[10,1.646,23,0.653,47,1.685,57,1.517,94,1.615,101,0.943,111,0.817,119,3.892,126,1.465,129,2.88,159,2.255,173,2.803,225,2.705,252,1.562,266,2.597,488,1.754,530,1.86,532,2.098,557,2.484,562,2.109,568,2.829,574,2.385,576,2.465,582,2.577,613,2.558,614,3.56,615,2.976,616,3.432,1051,1.939,2051,6.915,2264,6.123,2648,4.095,2649,7.561,2650,6.408,2651,6.666,2652,6.666,2653,6.666,2654,6.666,2655,4.095,2656,7.74,2657,4.396,2658,3.628,2659,3.875,2660,3.875,2661,4.095,2662,4.095,2663,4.095,2664,4.095,2665,4.095,2666,4.095,2667,4.095,2668,4.095,2669,3.875,2670,7.325,2671,7.043,2672,7.043,2673,4.095,2674,4.095,2675,4.095,2676,3.875,2677,4.095,2678,4.095,2679,4.095,2680,3.875,2681,4.095,2682,4.095,2683,4.095,2684,3.875,2685,4.095,2686,4.095,2687,4.095,2688,4.095]],["title/archive/tutorial/sql/#create-a-geometry-type-column",[110,0.866,126,1.344,532,1.925,594,1.493]],["text/archive/tutorial/sql/#create-a-geometry-type-column",[10,2.116,12,1.573,20,1.157,22,1.375,23,0.65,50,0.652,51,1.329,57,1.282,70,2.601,94,1.364,101,0.797,102,1.58,110,1.765,115,0.993,119,3.05,121,1.669,124,2.129,126,1.883,128,3.7,239,3.265,252,2.008,266,2.194,311,2.194,349,1.142,373,3.55,476,1.39,488,1.482,529,2.145,530,1.078,532,3.265,557,2.099,562,1.782,568,2.39,569,5.76,571,4.108,572,4.495,573,2.488,574,2.015,575,2.7,594,2.83,604,2.084,620,1.952,641,1.539,878,1.745,928,2.736,938,1.851,1007,7.037,1014,1.94,1027,2.002,1048,2.39,1100,2.954,1228,2.266,1254,2.462,1324,3.786,1680,3.007,1953,2.815,2003,2.542,2051,5.419,2053,3.459,2054,3.274,2264,4.576,2608,3.128,2620,3.274,2651,4.982,2652,4.982,2653,4.982,2654,4.982,2656,3.459,2658,4.664,2659,4.982,2660,4.982,2661,3.459,2662,3.459,2663,3.459,2664,3.459,2665,3.459,2666,3.459,2667,3.459,2668,3.459,2669,3.274,2670,6.74,2671,6.372,2672,6.372,2673,3.459,2674,3.459,2675,3.459,2676,3.274,2677,3.459,2678,3.459,2679,3.459,2680,3.274,2681,3.459,2682,3.459,2683,3.459,2684,3.274,2685,3.459,2686,3.459,2687,3.459,2688,3.459,2689,3.714,2690,3.714,2691,2.905,2692,3.459]],["title/archive/tutorial/sql/#load-shapefile-and-geojson",[139,2.648,555,2.726,616,2.509]],["text/archive/tutorial/sql/#load-shapefile-and-geojson",[10,3.619,20,2.548,23,0.588,94,3.004,101,1.755,139,4.621,555,4.758,558,3.384,566,4.325,616,5.176,730,4.325,1238,3.418]],["title/archive/tutorial/sql/#transform-the-coordinate-reference-system",[90,2.16,335,1.558,459,2.011,464,2.203]],["text/archive/tutorial/sql/#transform-the-coordinate-reference-system",[23,0.644,50,0.77,56,2.125,57,2.605,59,1.379,85,2.967,90,2.347,101,0.94,102,1.864,110,2.041,115,0.77,119,3.519,126,1.46,234,2.07,252,1.557,335,2.915,355,4.443,459,2.184,463,4.858,464,2.393,486,4.812,487,5.166,489,2.125,490,4.846,491,2.82,493,3.322,530,1.272,532,3.603,562,2.103,568,2.82,569,6.178,571,3.186,572,3.486,573,2.935,574,2.377,604,2.459,696,2.222,698,3.228,730,2.317,754,3.863,872,2.999,873,3.069,875,4.812,876,4.376,877,4.588,878,2.06,1003,3.322,1020,2.794,1024,6.236,1324,2.425,2051,5.88,2054,3.863,2264,5.177,2602,3.274,2604,4.647,2651,5.636,2652,5.636,2653,5.636,2654,5.636,2658,5.276,2659,5.636,2660,5.636,2669,3.863,2670,7.314,2676,3.863,2680,3.863,2684,3.863,2692,4.082,2693,4.082,2694,3.616,2695,4.382,2696,4.382,2697,4.382,2698,4.382,2699,4.382,2700,4.382]],["title/archive/tutorial/sql/#run-spatial-queries",[17,1.182,349,1.441,1620,1.846]],["text/archive/tutorial/sql/#run-spatial-queries",[17,2.192,110,1.864,126,2.896,349,2.672,532,4.148,594,3.216,1620,3.424]],["title/archive/tutorial/sql/#range-query",[349,1.718,370,2.653]],["text/archive/tutorial/sql/#range-query",[12,2.802,22,2.449,23,0.641,50,1.162,94,2.431,101,1.42,110,1.42,114,1.102,115,1.162,119,2.64,124,3.794,126,2.206,218,4.974,242,2.975,349,2.608,370,3.143,424,3.614,530,1.921,532,3.159,543,4.072,544,4.69,545,3.973,562,3.176,568,4.26,569,7.151,573,4.433,574,3.59,594,2.449,836,3.822,1324,3.663,1620,2.608,1711,3.88,1797,5.017,1841,4.634,2051,4.69,2694,5.462,2701,6.165]],["title/archive/tutorial/sql/#knn-query",[349,1.718,1617,3.158]],["text/archive/tutorial/sql/#knn-query",[23,0.638,50,1.227,57,2.411,101,1.499,106,1.696,115,1.227,119,2.786,186,4.478,234,4.758,242,3.14,319,4.413,446,4.127,530,2.027,533,4.584,562,3.351,568,4.495,569,7.268,573,4.678,574,3.789,1806,4.78,2101,5.012,2107,5.012,2632,5.882,2694,5.764,2702,6.506,2703,6.506,2704,6.506]],["title/archive/tutorial/sql/#join-query",[349,1.718,831,2.184]],["text/archive/tutorial/sql/#join-query",[23,0.493,44,4.484,86,5.102,349,3.068,489,4.188,831,3.901]],["title/archive/tutorial/sql/#other-queries",[349,2.128]],["text/archive/tutorial/sql/#other-queries",[18,5.099,20,2.625,23,0.481,51,3.728,94,3.095,349,2.591,886,6.59,1324,5.444,2705,7.624]],["title/archive/tutorial/sql/#save-to-permanent-storage",[1055,2.362,1719,2.812,2131,3.016]],["text/archive/tutorial/sql/#save-to-permanent-storage",[10,3.58,17,1.369,22,2.009,23,0.636,50,0.953,51,1.942,57,1.873,65,2.405,100,2.394,101,1.821,110,2.17,115,0.953,122,2.361,128,3.486,159,2.785,161,3.182,252,1.928,411,2.801,530,1.575,532,4.358,557,3.067,562,3.569,573,3.635,594,2.753,616,3.983,696,2.752,730,3.933,827,3.635,837,3.647,938,2.706,981,2.964,1014,2.835,1017,3.207,1055,4.278,1247,4.395,1522,2.944,1554,4.317,1633,3.527,1719,4.465,1738,6.09,1825,3.999,1910,3.999,1927,4.245,2131,4.787,2175,3.34,2706,5.427,2707,7.438,2708,5.427,2709,8.252,2710,6.021,2711,5.427,2712,6.021,2713,5.056,2714,6.021,2715,4.317]],["title/archive/tutorial/sql/#convert-between-dataframe-and-spatialrdd",[10,1.51,235,2.33,558,1.412,730,2.133]],["text/archive/tutorial/sql/#convert-between-dataframe-and-spatialrdd",[]],["title/archive/tutorial/sql/#dataframe-to-spatialrdd",[10,2.092,558,1.956]],["text/archive/tutorial/sql/#dataframe-to-spatialrdd",[10,3.528,12,2.483,17,1.977,20,1.826,22,2.17,23,0.629,31,6.523,59,2.965,60,3.491,64,4.664,94,2.154,101,1.682,110,2.022,124,3.361,412,2.378,452,2.742,476,2.195,532,4.688,557,4.429,558,3.613,559,4.013,566,4.668,569,5.488,591,3.081,594,2.17,595,4.63,604,4.398,696,2.973,730,3.101,1051,2.586,1238,2.45,1316,4.513,1324,4.337,1392,3.181,2058,5.305,2601,6.137,2716,7.837,2717,5.305,2718,6.505]],["title/archive/tutorial/sql/#spatialrdd-to-dataframe",[10,2.092,558,1.956]],["text/archive/tutorial/sql/#spatialrdd-to-dataframe",[10,3.706,23,0.615,94,2.745,101,1.603,273,3.392,557,4.223,558,3.466,562,3.586,566,4.842,567,5.845,569,5.233,730,3.952,837,3.664,1027,4.935,1238,3.123,1319,5.433,1320,5.433,1324,4.136,1498,4.253,2063,5.297,2064,5.665,2717,6.762]],["title/archive/tutorial/sql/#spatialpairrdd-to-dataframe",[10,2.092,2719,5.587]],["text/archive/tutorial/sql/#spatialpairrdd-to-dataframe",[10,3.645,17,1.817,23,0.61,94,2.645,234,3.402,273,3.269,349,2.751,352,3.66,557,4.07,558,2.522,562,3.456,566,4.732,567,5.632,730,3.809,831,3.498,837,3.531,1027,4.823,1238,3.01,1319,5.235,1320,5.235,1324,3.986,1498,4.099,2063,5.104,2064,5.459,2118,5.832,2717,6.517,2720,7.202,2721,7.202]],["title/archive/tutorial/viz/",[10,1.754,17,1.182,1240,2.576]],["text/archive/tutorial/viz/",[6,1.096,8,0.582,10,2.082,11,1.14,12,2.13,13,0.643,17,1.962,18,3.641,20,1.133,22,0.565,23,0.643,26,0.231,31,1.056,32,1.486,33,1.81,35,1.068,36,0.904,47,2.132,48,4.298,51,0.546,57,0.933,59,1.583,61,2.526,66,0.797,85,1.033,94,1.336,97,0.744,100,1.94,101,1.449,102,2.139,104,1.056,109,1.527,110,0.327,111,0.283,114,0.45,115,1.286,126,2.521,143,1.791,178,1.17,179,0.71,199,0.916,206,3.895,246,0.888,263,0.778,266,1.597,268,1.235,273,0.692,278,1.056,284,0.923,313,1.739,334,0.916,335,1.044,355,1.447,369,0.991,374,0.783,403,1.42,411,0.787,412,0.619,424,3.038,431,1.001,438,1.193,452,1.701,455,3.548,456,1.85,457,1.186,459,0.761,463,2.341,475,0.916,476,2.082,486,1.723,487,2.49,489,1.311,529,0.881,530,1.46,532,1.736,538,0.769,556,0.862,557,2.056,558,0.534,562,2.887,571,1.964,583,2.402,591,0.802,594,1,616,0.817,619,0.931,620,1.42,628,2.08,629,2.048,630,2.113,641,1.507,696,2.23,702,0.881,730,0.807,745,0.787,749,1.313,753,1.081,825,1.85,826,4.229,832,1.011,837,1.783,847,0.667,876,1.044,878,0.717,938,1.347,941,0.833,942,2.276,943,0.947,944,1.124,947,1.124,949,0.947,950,1.663,951,0.894,953,0.881,955,0.703,956,1.022,958,0.947,963,1.81,982,1.109,1000,4.615,1002,3.207,1014,0.797,1017,0.901,1019,1.068,1049,0.991,1051,1.605,1068,0.901,1138,1.022,1139,1.14,1162,2.113,1205,5.417,1238,1.129,1240,3.713,1248,2.113,1249,4.504,1250,4.387,1251,2.188,1252,1.345,1253,1.345,1257,4.169,1260,1.345,1261,1.345,1263,1.345,1267,1.193,1268,1.829,1269,1.156,1282,1.285,1290,2.717,1291,2.644,1296,2.382,1297,1.193,1298,5.014,1299,2.845,1300,2.238,1305,3.197,1306,2.945,1308,3.334,1324,2.013,1339,1.14,1343,1.939,1344,0.964,1345,1.739,1348,1.345,1360,1.345,1362,1.526,1363,0.732,1364,0.916,1366,0.689,1392,0.828,1405,1.609,1408,2.68,1497,0.991,1498,0.868,1522,0.828,1539,2.757,1540,1.285,1556,1.572,1558,1.193,1567,1.915,1569,0.868,1572,1.044,1583,1.527,1598,0.807,1600,1.044,1620,1.982,1621,0.802,1634,1.285,1667,1.174,1668,1.156,1678,1.345,1721,1.081,1732,1.068,1741,2.662,1757,3.878,1760,2.188,1796,1.345,1806,1.044,1815,1.285,1821,2.784,1831,0.973,1850,1.001,1858,1.068,1871,1.124,1889,1.156,1895,1.156,1905,0.894,1926,1.235,2003,1.044,2030,1.87,2141,1.156,2175,2.238,2319,1.38,2359,1.421,2360,1.421,2645,1.213,2646,1.421,2722,1.421,2723,1.526,2724,1.526,2725,1.693,2726,1.693,2727,1.838,2728,1.838,2729,1.421,2730,1.526,2731,1.38,2732,1.421,2733,1.526,2734,1.526,2735,1.526,2736,2.945,2737,1.345,2738,1.421,2739,1.526,2740,1.526,2741,1.526,2742,1.526,2743,1.285,2744,1.526,2745,1.526,2746,1.526,2747,1.526,2748,1.693,2749,1.421,2750,1.526,2751,1.526,2752,1.526,2753,4.387,2754,3.063,2755,1.693,2756,1.526,2757,1.526,2758,1.526,2759,1.526,2760,1.526,2761,5.191,2762,1.526,2763,2.517,2764,1.526,2765,1.526,2766,1.526,2767,1.526,2768,1.526,2769,1.526,2770,1.526,2771,1.526,2772,1.526,2773,2.517]],["title/archive/tutorial/viz/#why-scalable-map-visualization",[48,2.31,1240,2.576,1889,3.552]],["text/archive/tutorial/viz/#why-scalable-map-visualization",[11,4.573,17,1.544,18,3.705,33,5.402,35,4.287,47,3.673,48,4.911,61,2.57,100,3.557,268,4.957,438,4.788,456,5.52,457,2.688,475,3.675,489,2.969,529,3.535,753,4.339,837,3.001,1205,3.459,1240,5.27,1257,3.484,1291,4.45,1299,4.788,1300,3.767,1308,4.64,1339,4.573,1392,3.321,1497,3.978,1540,5.156,1556,3.562,1567,4.339,1569,3.484,1598,3.237,1620,2.412,1678,5.397,1721,4.339,1732,4.287,1760,4.957,1796,5.397,1806,4.19,1815,5.156,1871,4.51,2030,4.237,2141,4.64,2729,5.702,2730,6.122,2731,5.539,2732,5.702,2733,6.122,2734,6.122,2735,6.122,2736,4.957,2737,5.397,2738,5.702,2739,6.122,2740,6.122,2741,6.122,2742,6.122,2743,5.156,2744,6.122,2745,6.122]],["title/archive/tutorial/viz/#visualize-spatialrdd",[558,1.956,1240,3.072]],["text/archive/tutorial/viz/#visualize-spatialrdd",[12,3.525,23,0.476,59,2.619,85,5.636,114,1.386,847,3.638,942,7.011,1238,3.479,1257,4.738,1405,4.957,1408,6.133,1831,5.308,2746,8.325,2747,8.325]],["title/archive/tutorial/viz/#set-up-dependencies",[457,2.057,745,2.418,1366,2.116]],["text/archive/tutorial/viz/#set-up-dependencies",[6,3.278,23,0.605,26,1.221,36,3.21,59,3.02,94,2.969,335,3.122,556,4.567,944,3.994,1257,4.6,1324,4.473,1363,3.878,1364,4.852]],["title/archive/tutorial/viz/#initiate-sparksession",[562,2.681,1583,3.158]],["text/archive/tutorial/viz/#initiate-sparksession",[23,0.653,57,2.19,59,1.996,66,3.315,101,1.362,334,3.809,403,4.339,530,1.842,557,3.586,562,4.404,878,2.982,949,3.939,950,5.081,951,3.72,953,3.665,955,2.923,956,4.25,958,3.939,1051,2.799,1343,5.925,1344,4.009,1345,5.314,1360,5.594,1567,4.497,1572,4.343,1583,3.586,1600,4.343,1620,2.501,1621,3.335,1858,4.444,1905,3.72,2175,3.905,2645,5.047,2646,5.911,2748,7.04]],["title/archive/tutorial/viz/#register-geosparksql-and-geosparkviz",[1257,2.667,1324,2.593,2175,2.883]],["text/archive/tutorial/viz/#register-geosparksql-and-geosparkviz",[6,3.168,23,0.622,51,2.795,100,3.445,179,3.633,530,2.266,562,4.842,832,5.177,947,5.754,963,6.299,1019,5.469,1257,4.445,1324,4.322,1348,6.885,1362,7.809,2175,4.806,2749,7.275]],["title/archive/tutorial/viz/#create-spatial-dataframe",[10,1.754,17,1.182,126,1.561]],["text/archive/tutorial/viz/#create-spatial-dataframe",[10,3.002,17,2.023,20,1.89,23,0.648,47,2.325,59,1.909,94,2.229,110,1.302,111,1.128,115,1.066,126,2.672,143,5.315,199,3.642,206,6.69,266,3.585,313,5.161,455,3.359,476,2.272,530,1.761,532,2.897,571,5.829,583,3.314,594,2.246,616,3.25,620,3.189,628,6.171,629,6.078,630,6.271,696,3.077,826,3.8,938,3.025,941,3.314,943,3.766,1260,5.349,1522,3.292,1667,4.671,2359,5.653,2360,5.653,2750,6.068,2751,6.068,2752,6.068,2753,4.153]],["title/archive/tutorial/viz/#generate-a-single-image",[61,1.967,424,2.559,1000,2.418]],["text/archive/tutorial/viz/#generate-a-single-image",[17,2.179,273,3.92,369,5.612,424,4.716,1000,4.457,1017,5.102,1068,5.102,1668,6.546]],["title/archive/tutorial/viz/#pixelize-spatial-objects",[17,1.182,641,1.941,1205,2.648]],["text/archive/tutorial/viz/#pixelize-spatial-objects",[17,1.923,23,0.632,48,3.757,101,1.635,104,3.894,109,3.179,115,1.518,126,2.54,206,5.337,246,3.273,284,3.404,335,2.173,455,4.218,463,5.564,476,2.106,486,4.86,487,5.916,532,2.685,583,4.721,591,2.957,641,2.331,696,3.865,730,2.975,825,3.85,826,5.413,837,2.758,1000,3.934,1002,6.719,1139,4.203,1205,5.472,1240,3.093,1269,4.264,1290,5.694,1291,4.089,1296,6.719,1305,4.089,1405,3.35,1620,2.217,1634,4.738,1850,3.692,1926,4.555,2003,3.85,2736,4.555,2753,5.217,2754,6.419,2755,6.241,2756,5.625,2757,5.625,2758,5.625,2759,5.625,2760,5.625]],["title/archive/tutorial/viz/#aggregate-pixels",[18,3.381,1205,3.158]],["text/archive/tutorial/viz/#aggregate-pixels",[17,2.55,18,5.837,23,0.578,32,3.879,102,3.001,115,1.239,126,2.351,266,4.168,355,3.778,431,4.63,455,3.905,476,2.641,641,2.923,702,4.075,825,4.829,826,4.418,837,3.459,876,4.829,982,5.129,1205,6.002,1249,7.154,1250,4.829,1251,7.154,1252,6.22,1253,6.22,1306,5.713,2753,4.829,2761,5.713,2762,7.055]],["title/archive/tutorial/viz/#colorize-pixels",[1205,3.158,1250,3.824]],["text/archive/tutorial/viz/#colorize-pixels",[12,3.114,20,2.291,23,0.621,94,2.701,115,1.592,126,2.451,355,3.939,455,4.07,489,3.567,530,2.134,826,4.605,1205,5.123,1248,7.09,1249,7.958,1250,6.205,1263,6.483,1620,2.898,1821,4.07,1895,5.575,2753,5.034,2761,7.958,2763,6.851]],["title/archive/tutorial/viz/#render-the-image",[1000,2.884,1308,4.236]],["text/archive/tutorial/viz/#render-the-image",[10,2.739,23,0.627,101,1.57,109,4.134,115,1.587,126,2.438,278,5.064,424,3.995,452,3.421,455,4.049,532,3.492,538,3.688,594,2.708,826,4.581,1000,5.43,1002,6.449,1205,5.106,1250,5.007,1268,4.953,1305,6.569,2753,5.007,2754,6.161,2761,5.924]],["title/archive/tutorial/viz/#store-the-image-on-disk",[1000,2.418,1539,3.552,1741,2.835]],["text/archive/tutorial/viz/#store-the-image-on-disk",[10,2.724,23,0.642,101,1.561,412,2.952,459,3.628,557,5.09,749,6.265,1000,5.275,1162,5.692,1257,4.142,1282,6.129,1539,5.516,1741,4.404,1757,9.011,2764,7.277,2765,7.277,2766,7.277,2767,7.277,2768,7.277,2769,7.277]],["title/archive/tutorial/viz/#generate-map-tiles",[48,2.31,61,1.967,1298,3.106]],["text/archive/tutorial/viz/#generate-map-tiles",[48,5.097,61,3.474,126,2.758,476,3.098,620,4.349,1298,6.855,1299,6.472,1300,5.092,2770,8.275,2771,8.275,2772,8.275]],["title/archive/tutorial/viz/#pixelization-and-pixel-aggregation",[18,2.835,1205,3.792]],["text/archive/tutorial/viz/#pixelization-and-pixel-aggregation",[18,4.949,20,2.548,61,3.433,101,1.755,102,3.478,424,4.466,476,3.062,696,4.147,1000,4.221,1205,5.462,1290,6.109,1291,5.945,1498,4.654,1558,6.396,1821,4.526,2030,5.661]],["title/archive/tutorial/viz/#create-tile-name",[126,1.561,1051,2.067,1298,3.106]],["text/archive/tutorial/viz/#create-tile-name",[23,0.608,48,3.745,115,1.334,126,2.531,178,4.004,455,4.204,530,2.204,826,4.756,1051,3.351,1205,5.634,1249,6.151,1297,5.941,1298,6.13,1299,5.941,1300,4.674,1620,2.993,1821,4.204,2736,6.151,2753,5.199,2761,7.487,2773,7.076]],["title/archive/tutorial/viz/#colorize-pixels_1",[1205,3.158,1250,3.824]],["text/archive/tutorial/viz/#colorize-pixels_1",[61,3.602,101,1.841,102,3.65,424,4.687,1000,4.429,1250,5.874,1408,6.323,1821,4.75,2763,7.994]],["title/archive/tutorial/viz/#render-map-tiles",[48,2.31,1298,3.106,1308,3.552]],["text/archive/tutorial/viz/#render-map-tiles",[23,0.575,32,4.269,48,3.828,115,1.364,126,2.588,455,4.298,476,2.907,826,4.863,1000,5.195,1205,5.296,1250,5.315,1298,6.213,1305,5.645,1306,7.589,1308,5.887,1760,6.288,2753,5.315,2761,6.288,2773,7.234]],["title/archive/tutorial/viz/#store-map-tiles-on-disk",[48,1.989,1298,2.674,1539,3.058,1741,2.441]],["text/archive/tutorial/viz/#store-map-tiles-on-disk",[48,4.154,61,3.537,101,1.808,102,3.584,424,4.601,452,4.6,1000,4.349,1162,6.59,1298,5.586,1741,5.099,1821,4.663]],["title/archive/tutorial/zeppelin/",[59,1.269,601,2.895,1288,2.16,1620,1.59]],["text/archive/tutorial/zeppelin/",[10,1.975,13,2.224,17,2.109,20,2.272,23,0.593,26,1.194,31,2.35,33,3.533,36,1.764,47,3.343,48,3.894,50,1.387,51,1.215,52,1.774,59,2.63,61,1.425,94,2.376,101,1.794,109,2.981,110,1.132,115,1.532,121,1.526,126,2.431,128,1.395,136,1.604,159,1.742,200,1.257,206,2.378,219,0.97,222,1.879,225,2.09,235,1.961,246,1.976,281,1.464,374,1.742,377,1.854,397,1.867,452,1.588,455,2.92,459,1.693,476,1.975,530,0.985,532,3.088,573,3.533,576,1.306,582,1.991,600,2.656,619,2.072,641,2.68,696,2.675,698,2.502,730,1.796,762,2.502,826,3.303,837,1.665,938,2.63,959,1.419,1000,4.655,1014,1.774,1056,2.802,1062,5.702,1066,1.905,1104,2.437,1162,4.126,1240,4.796,1257,5.133,1268,3.571,1271,2.35,1288,5.522,1366,1.534,1392,1.842,1471,2.537,1497,3.428,1528,3.999,1621,1.785,1708,2.701,1732,5.108,1779,2.418,1821,1.879,1831,2.165,1841,2.378,1865,2.923,1871,2.502,1889,2.574,1890,2.299,1894,2.75,1984,2.75,2141,2.574,2143,2.468,2595,2.923,2753,3.611,2754,2.86,2774,4.65,2775,3.767,2776,3.767,2777,3.767,2778,3.767,2779,3.767,2780,4.914,2781,3.396,2782,3.396,2783,2.86,2784,3.396,2785,2.86,2786,5.67,2787,6.794,2788,5.275,2789,3.396,2790,3.396,2791,3.396,2792,3.396,2793,3.396,2794,3.396,2795,2.802,2796,3.396,2797,3.163,2798,2.994]],["title/archive/tutorial/zeppelin/#small-scale-without-geosparkviz",[1257,2.296,1271,2.792,1528,3.058,1732,2.825]],["text/archive/tutorial/zeppelin/#small-scale-without-geosparkviz",[10,2.223,13,2.504,17,1.994,20,1.85,23,0.601,26,1.194,33,3.978,36,1.986,47,3.029,50,1.561,94,2.181,101,1.696,110,1.696,115,1.561,126,2.634,128,2.439,136,2.805,159,3.047,200,2.198,206,4.159,222,3.287,246,3.455,397,3.265,455,3.287,476,2.223,530,1.723,532,4.241,573,3.978,582,3.482,641,2.46,730,3.14,826,3.718,837,2.911,1056,4.901,1062,5.235,1162,4.644,1240,4.345,1257,3.38,1268,4.02,1288,4.758,1471,4.436,1497,3.859,1528,4.502,1732,4.159,1821,3.287,1889,4.502,2141,4.502,2753,4.064,2781,5.938,2782,5.938,2783,5.001,2784,5.938,2785,5.001,2786,3.859,2787,7.363,2788,7.904,2789,5.938]],["title/archive/tutorial/zeppelin/#large-scale-with-geosparkviz",[1257,2.667,1497,3.045,1732,3.281]],["text/archive/tutorial/zeppelin/#large-scale-with-geosparkviz",[10,2.242,13,2.525,17,2.005,20,1.866,23,0.565,26,0.905,33,4.012,47,3.046,48,3.919,50,1.396,59,1.884,94,2.2,101,1.706,109,4.492,115,1.669,126,2.649,219,1.711,455,3.315,459,2.986,573,4.012,600,4.684,619,3.655,641,2.482,696,3.037,762,4.413,826,3.75,1000,5.354,1014,3.129,1066,3.361,1104,4.298,1162,4.684,1240,4.905,1257,5.409,1288,4.778,1366,2.705,1392,3.249,1621,3.148,1732,4.194,1871,4.413,1984,4.85,2143,4.354,2753,4.099,2754,5.044,2780,5.579,2786,3.892,2787,7.405,2790,5.99,2791,5.99,2792,5.99,2793,5.99,2794,5.99]],["title/archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo",[26,0.61,1288,2.16,1865,3.472,2786,2.621]],["text/archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo",[20,2.366,23,0.434,26,1.148,47,3.544,51,2.718,52,3.968,59,2.39,101,1.63,121,3.415,225,4.674,377,4.148,476,2.844,576,2.922,938,3.786,959,3.174,1288,5.339,1831,4.843,1890,5.142,2595,6.539,2786,6.742,2795,6.269,2796,7.596,2797,7.076,2798,6.696]],["title/asf/asf/",[2799,5.957]],["text/asf/asf/",[2,1.784,4,5.12,23,0.543,36,3.654,76,5.266,847,3.472,2175,4.888,2799,6.838,2800,7.4,2801,8.813,2802,10.54,2803,9.5,2804,6.114]],["title/asf/asf/#copyright",[2800,6.446]],["text/asf/asf/#copyright",[2,1.805,4,5.156,23,0.459,36,3.664,76,5.327,847,3.512,2175,4.945,2799,6.917,2801,8.915,2802,10.612,2803,9.565,2804,6.185]],["title/asf/disclaimer/",[2805,5.957]],["text/asf/disclaimer/",[2,1.561,4,5.419,23,0.5,35,4.867,36,3.203,57,2.399,76,6.35,475,4.171,537,3.9,592,3.426,676,4.987,847,4.186,982,6.362,1487,4.607,1646,5.435,2799,5.982,2804,5.349,2805,5.982,2806,7.71,2807,7.71,2808,7.71,2809,6.473,2810,6.126,2811,6.949,2812,6.288,2813,6.949,2814,4.925,2815,6.473,2816,9.709,2817,7.71,2818,6.473,2819,6.949,2820,7.71,2821,6.949,2822,7.71]],["title/asf/disclaimer/#disclaimer",[2805,5.957]],["text/asf/disclaimer/#disclaimer",[2,1.576,4,5.439,23,0.401,35,4.916,36,3.218,57,2.423,76,6.379,475,4.214,537,3.939,592,3.46,676,5.037,847,4.206,982,6.402,1487,4.653,1646,5.49,2799,6.043,2804,5.403,2806,7.788,2807,7.788,2808,7.788,2809,6.539,2810,6.188,2811,7.019,2812,6.352,2813,7.019,2814,4.975,2815,6.539,2816,9.77,2817,7.788,2818,6.539,2819,7.019,2820,7.788,2821,7.019,2822,7.788]],["title/community/contact/",[2814,4.905]],["text/community/contact/",[2,2.14,5,1.876,20,2.36,23,0.586,36,2.533,56,2.139,57,1.522,61,1.851,70,4.498,85,4.348,89,4.273,101,1.625,304,2.954,412,1.789,492,3.343,530,1.28,604,2.475,675,3.864,695,3.714,696,2.236,781,3.249,831,1.724,833,3.887,847,3.637,860,3.249,937,2.894,938,3.202,984,4.302,1014,2.304,1068,2.606,1108,3.508,1175,4.245,1274,4.869,1284,5.023,1403,5.04,1404,2.186,1529,3.126,1534,5.409,1551,4.446,1569,2.51,1630,4.108,1637,3.449,1656,3.394,1845,4.971,1883,4.108,1897,3.206,1943,4.943,1974,3.571,1975,3.888,1985,4.245,2732,4.108,2785,3.714,2814,5.369,2823,4.893,2824,4.893,2825,4.245,2826,3.449,2827,5.812,2828,4.893,2829,4.893,2830,7.575,2831,6.867,2832,4.669,2833,4.41,2834,4.893,2835,4.893,2836,6.678,2837,5.409,2838,6.182,2839,4.893,2840,5.184,2841,5.662,2842,4.893,2843,3.295,2844,3.508,2845,4.41,2846,6.723,2847,5.812,2848,4.41,2849,4.893,2850,4.893,2851,4.893,2852,4.893,2853,4.893,2854,4.893,2855,6.025,2856,4.893,2857,4.893,2858,4.41,2859,4.893,2860,4.893]],["title/community/contact/#community",[2814,4.905]],["text/community/contact/#community",[57,2.651,101,1.997,530,2.229,847,4.068,937,5.04,938,4.64,1068,4.538,1108,6.109,1403,3.964,1534,6.468,1656,5.911,1845,5.04,1975,6.77,2814,5.443,2823,8.52,2824,8.52,2825,7.393,2826,6.006,2827,8.423,2828,8.52,2829,8.52,2830,7.68,2831,6.338,2832,5.583]],["title/community/contact/#feedback",[2830,6.92]],["text/community/contact/#feedback",[2,1.964,36,2.924,304,5.857,1529,6.198,2732,8.146,2830,8.744]],["title/community/contact/#twitter",[2833,6.92]],["text/community/contact/#twitter",[36,3,2834,9.952]],["title/community/contact/#discord-server",[1284,4.37,2835,6.199]],["text/community/contact/#discord-server",[2,1.964,23,0.5,36,2.924,831,3.418,1284,6.839,2814,6.198]],["title/community/contact/#mailing-list",[675,2.85,2836,4.926]],["text/community/contact/#mailing-list",[2,2.063,20,2.862,23,0.525,61,3.154,101,1.612,675,4.685,696,3.81,847,4.014,1551,5.201,1630,6.999,1897,5.462,1943,5.783,1985,7.233,2832,5.462,2836,8.098,2837,6.328,2838,8.842,2839,8.336,2840,6.287,2841,6.624,2842,8.336,2843,5.613,2844,5.976,2845,7.514]],["title/community/contact/#issue-tracker",[89,2.587,2846,5.849]],["text/community/contact/#issue-tracker",[]],["title/community/contact/#bug-reports",[1403,2.884,2831,4.611]],["text/community/contact/#bug-reports",[2,1.972,20,2.176,56,3.387,70,6.148,85,5.943,89,4.663,492,5.294,604,3.919,695,5.882,781,5.146,860,5.146,984,5.88,1274,5.294,1403,5.467,1404,3.462,1534,5.882,1551,4.834,1569,3.975,1845,5.761,1883,6.506,1943,5.376,2785,5.882,2831,7.245,2846,7.311,2847,6.32,2848,6.984,2849,7.749,2850,7.749,2851,7.749,2852,7.749,2853,7.749,2854,7.749]],["title/community/contact/#feature-requests",[833,3.381,2855,4.444]],["text/community/contact/#feature-requests",[2,1.794,5,3.398,89,3.698,412,3.241,833,4.835,1014,4.173,1175,7.691,1274,6.056,1637,6.249,1974,6.469,2837,6.729,2840,5.468,2841,7.043,2847,7.229,2855,7.582,2856,8.864,2857,8.864,2858,7.989,2859,8.864,2860,8.864]],["title/community/contributor/",[847,2.048,1819,2.96,2861,4.364]],["text/community/contributor/",[2,1.942,4,3.414,5,0.478,6,2.188,20,1.423,21,0.622,22,0.759,23,0.508,26,0.17,32,0.617,35,1.436,36,2.719,44,0.583,53,3.265,54,1.241,57,0.977,60,0.669,61,1.188,68,1.604,70,1.983,72,0.737,74,1.693,75,0.434,76,4.662,83,0.967,86,2.065,89,1.311,90,0.601,94,0.413,96,1.017,99,0.752,100,1.249,101,0.98,114,0.187,126,0.944,129,0.505,135,0.617,138,1.092,177,1.032,178,1.514,219,1.64,220,0.921,226,1.96,241,0.752,244,1.661,246,1.194,257,1.159,263,1.444,266,0.664,273,1.285,281,0.484,304,1.896,352,2.048,355,0.601,369,0.73,374,0.576,377,0.613,392,0.76,394,0.827,402,1.262,408,1.046,411,1.804,412,3.576,433,0.816,438,0.878,446,1.212,452,1.324,457,0.901,459,1.023,475,0.674,476,1.874,485,0.893,489,0.545,491,0.723,527,1.081,530,1.453,545,1.231,574,0.609,576,0.432,582,0.658,583,0.613,592,1.723,601,0.806,604,0.63,619,0.685,620,0.59,628,1.579,666,1.454,669,0.878,671,0.967,672,0.946,675,2.33,700,2.007,715,0.796,717,0.99,745,1.059,781,1.511,825,0.769,826,1.284,847,3.697,860,0.827,887,1.046,933,0.99,937,0.737,938,0.56,941,0.613,959,0.857,961,0.737,967,0.73,984,0.752,1014,0.587,1017,0.664,1028,1.123,1051,3.009,1136,1.856,1138,1.374,1139,1.532,1214,1.046,1256,0.946,1274,1.555,1300,1.262,1318,0.816,1339,1.532,1390,1.016,1391,2.539,1401,0.839,1406,1.454,1438,3.427,1441,1.046,1442,1.046,1447,0.99,1448,0.99,1451,1.046,1452,1.046,1456,0.864,1457,0.864,1464,1.081,1466,1.42,1487,3.028,1533,0.99,1534,2.944,1551,0.777,1556,1.647,1569,1.167,1593,0.787,1598,0.594,1611,6.251,1620,0.443,1656,0.864,1667,1.579,1686,2.78,1701,1.532,1708,0.893,1731,2.384,1774,0.927,1775,1.046,1778,0.946,1782,2.252,1794,1.046,1797,0.851,1800,0.796,1803,2.058,1805,0.909,1808,0.745,1809,0.806,1819,2.571,1825,0.827,1826,0.893,1831,1.308,1841,0.787,1845,1.858,1905,2.385,1939,2.292,1943,3.516,1953,0.851,1955,0.909,1974,1.661,1975,1.808,1977,1.046,1984,0.909,2082,2.612,2186,1.046,2350,1.123,2606,2.384,2640,1.808,2713,1.046,2715,0.893,2722,1.046,2724,1.123,2737,1.808,2743,0.946,2795,0.927,2803,1.123,2810,0.99,2812,1.016,2813,1.123,2814,4.489,2815,1.046,2818,1.046,2825,1.975,2826,4.491,2827,3.163,2831,0.927,2832,4.174,2836,1.808,2837,2.384,2838,1.975,2840,4.335,2841,4.413,2843,3.412,2844,2.78,2845,2.051,2848,1.123,2855,3.236,2861,3.79,2862,1.353,2863,6.496,2864,2.147,2865,1.766,2866,7.285,2867,2.147,2868,1.246,2869,1.246,2870,1.246,2871,1.246,2872,1.246,2873,1.246,2874,1.246,2875,1.246,2876,1.246,2877,1.246,2878,1.246,2879,1.123,2880,2.276,2881,2.276,2882,1.246,2883,1.246,2884,1.246,2885,1.016,2886,1.856,2887,1.246,2888,1.246,2889,1.246,2890,1.246,2891,1.246,2892,1.246,2893,1.246,2894,2.051,2895,1.123,2896,1.246,2897,1.246,2898,1.123,2899,1.081,2900,1.081,2901,1.246,2902,1.246,2903,3.916,2904,1.246,2905,1.246,2906,1.246,2907,1.246,2908,1.246,2909,1.246,2910,1.246,2911,1.246,2912,1.246,2913,1.246,2914,1.246,2915,1.246,2916,1.246,2917,1.246,2918,1.246,2919,1.246,2920,1.246,2921,1.246,2922,3.682,2923,1.246,2924,1.246,2925,1.246,2926,1.246,2927,2.147,2928,1.246,2929,1.246,2930,1.123,2931,1.246,2932,1.975,2933,2.725,2934,1.246,2935,6.221,2936,1.123,2937,3.659,2938,1.246,2939,2.147,2940,1.081,2941,1.081,2942,2.964,2943,1.246,2944,3.659,2945,5.348,2946,1.246,2947,1.246,2948,1.016,2949,3.009,2950,2.276,2951,1.246,2952,1.808,2953,1.246,2954,1.353,2955,2.637,2956,1.353,2957,2.276,2958,1.353,2959,1.353,2960,1.176,2961,2.276,2962,1.246,2963,1.246,2964,5.195,2965,1.246,2966,2.725,2967,6.766,2968,1.246,2969,1.246,2970,3.496,2971,1.123,2972,3.365,2973,1.081,2974,1.246,2975,2.179,2976,1.246,2977,1.081,2978,1.081,2979,1.123,2980,1.246,2981,1.123,2982,1.246,2983,1.246,2984,2.147,2985,1.246,2986,1.246,2987,2.276,2988,2.276,2989,3.496,2990,1.246,2991,1.808,2992,0.99,2993,1.246,2994,2.276,2995,3.659,2996,2.147,2997,2.637,2998,1.123,2999,1.246,3000,1.246,3001,2.276,3002,1.246,3003,3.878,3004,1.246,3005,1.246,3006,2.276,3007,1.246,3008,1.246,3009,1.246,3010,1.246,3011,1.246,3012,1.123,3013,1.081,3014,1.246,3015,1.246,3016,1.123,3017,2.147,3018,1.123,3019,1.246,3020,3.878,3021,1.246,3022,1.246,3023,1.246,3024,1.246,3025,1.123,3026,1.246,3027,1.246,3028,1.246,3029,1.246,3030,6.054,3031,0.946,3032,0.99,3033,1.246,3034,1.123,3035,1.246,3036,1.246,3037,1.246,3038,1.246,3039,1.246,3040,1.081,3041,1.246,3042,1.246,3043,1.246,3044,1.123,3045,1.246,3046,1.975,3047,1.046,3048,1.123,3049,1.246,3050,1.246,3051,1.246,3052,1.123,3053,0.946,3054,2.051,3055,1.123,3056,1.123,3057,1.123,3058,2.051,3059,1.123,3060,1.046,3061,1.046,3062,1.046,3063,1.123,3064,1.766,3065,1.123,3066,1.246,3067,1.046,3068,1.123,3069,1.246,3070,1.123]],["title/community/contributor/#committers",[2863,5.098]],["text/community/contributor/#committers",[2,2.201,54,5.068,57,2.891,941,4.574,1438,7.054,1794,7.801,2743,7.054,2832,6.088,2863,7.221,2864,8.767,2865,7.21]],["title/community/contributor/#project-management-committee-pmc",[847,1.763,1819,2.549,2861,3.758,2866,3.014]],["text/community/contributor/#project-management-committee-pmc",[2,1.425,36,2.122,53,3.84,402,3.905,530,1.842,672,5.344,847,2.773,1051,2.799,1391,4.187,1441,5.911,1442,5.911,1447,5.594,1448,5.594,1451,5.911,1452,5.911,1456,4.884,1457,4.884,1611,6.259,1701,4.741,2814,4.497,2863,4.675,2864,6.642,2866,6.168,2867,6.642,2868,7.04,2869,7.04,2870,7.04,2871,7.04,2872,7.04,2873,7.04,2874,7.04,2875,7.04,2876,7.04,2877,7.04,2878,7.04,2879,6.346,2880,9.16,2881,9.16,2882,7.04,2883,7.04,2884,7.04,2885,5.742,2886,7.471,2887,7.04,2888,7.04,2889,7.04,2890,7.04,2891,7.04,2892,7.04,2893,7.04,2894,8.256,2895,6.346,2896,7.04,2897,7.04,2898,6.346,2899,6.108,2900,6.108,2901,7.04,2902,7.04]],["title/community/contributor/#mentors",[2903,6.662]],["text/community/contributor/#mentors",[4,4.05,36,3.318,530,2.181,583,4.103,619,4.585,847,3.284,1051,3.314,1391,3.81,1533,6.624,1800,5.325,1943,5.783,2186,6.999,2903,8.842,2904,8.336,2905,8.336,2906,8.336,2907,8.336,2908,8.336,2909,8.336,2910,8.336,2911,8.336,2912,8.336,2913,8.336,2914,8.336,2915,8.336,2916,8.336,2917,8.336,2918,8.336,2919,8.336]],["title/community/contributor/#become-a-committer",[1686,4.444,2863,4.117]],["text/community/contributor/#become-a-committer",[2,1.988,5,2.149,6,3.314,23,0.404,26,0.763,36,2.732,60,3.008,89,2.339,100,2.229,114,0.841,138,2.689,241,3.384,257,4,263,3.61,355,2.706,369,3.283,374,2.592,377,2.759,402,3.109,412,3.314,485,4.018,530,1.466,574,2.741,592,2.491,675,2.577,781,3.722,847,3.869,937,3.316,1014,2.639,1136,4.571,1318,3.673,1438,5.961,1466,3.497,1534,6.88,1598,2.672,1611,6.71,1701,3.774,1803,3.673,1841,3.538,1845,4.645,1943,6.288,2713,4.706,2724,5.052,2803,5.052,2812,4.571,2814,5.79,2825,4.863,2832,7.022,2836,4.454,2844,4.018,2863,7.307,2866,7.561,2903,4.863,2920,5.605,2921,5.605,2922,7.392,2923,5.605,2924,5.605,2925,5.605,2926,5.605,2927,5.288,2928,5.605,2929,5.605,2930,5.052,2931,5.605,2932,4.863,2933,6.813,2934,5.605,2935,3.384,2936,5.052,2937,5.288,2938,5.605,2939,5.288,2940,4.863,2941,4.863]],["title/community/contributor/#nominate-a-committer-or-pmc-member",[1611,3.058,2863,2.972,2866,3.014,2942,4.223]],["text/community/contributor/#nominate-a-committer-or-pmc-member",[96,4.127,177,3.035,219,2.378,226,5.762,244,6.741,352,3.405,412,3.377,530,2.416,1556,4.844,2826,6.511,2863,6.133,2935,6.542,2943,9.236]],["title/community/contributor/#call-for-a-vote",[96,2.77,2935,3.743]],["text/community/contributor/#call-for-a-vote",[4,4.117,20,2.379,76,5.063,94,2.806,178,3.308,219,2.182,244,6.185,352,3.124,412,3.098,452,3.571,1620,3.01,1905,4.478,1977,7.115,2863,5.627,2935,6.693,2944,10.46,2945,7.115,2946,8.474,2947,8.474,2948,6.911,2949,6.575,2950,8.474,2951,8.474,2952,6.733,2953,8.474]],["title/community/contributor/#close-a-vote",[226,3.868,2935,3.743]],["text/community/contributor/#close-a-vote",[32,3.879,83,6.073,219,2.888,220,3.138,226,4.884,246,4.105,352,3.614,412,3.584,700,6.836,847,3.083,1051,3.112,2818,6.572,2831,5.822,2840,4.829,2843,5.271,2866,6.6,2935,7.298,2945,6.572,2949,6.073,2955,6.572,2962,7.827,2963,7.827,2964,9.148,2965,7.827]],["title/community/contributor/#send-a-notice-to-ipmc",[1939,3.794,2841,4.13,2966,4.51]],["text/community/contributor/#send-a-notice-to-ipmc",[2,1.849,22,2.338,23,0.47,35,4.424,36,2.753,90,3.383,304,4.231,352,3.746,412,3.715,530,1.833,666,4.477,959,2.64,1051,3.631,1611,6.942,1939,6.666,1975,5.569,2825,6.081,2826,4.94,2841,7.257,2843,4.719,2866,6.15,2935,6.499,2939,6.612,2942,6.612,2949,7.087,2966,7.924,2967,8.148,2968,7.008,2969,7.008,2970,8.232,2971,6.317,2972,6.081,2973,6.081,2974,7.008,2975,4.862,2976,7.008,2977,6.081,2978,6.081,2979,6.317,2980,7.008,2981,6.317,2982,7.008,2983,7.008,2984,6.612]],["title/community/contributor/#send-the-invitation",[2826,4.37,2841,4.926]],["text/community/contributor/#send-the-invitation",[2,1.899,4,4.558,6,1.605,20,1.233,22,1.465,36,2.377,57,1.366,61,1.661,68,3.095,72,2.597,75,1.529,76,2.623,89,1.832,126,1.319,138,2.106,263,2.018,266,2.338,304,2.651,411,3.06,412,2.405,438,3.095,476,1.482,545,2.375,582,2.32,620,2.08,628,3.046,825,2.708,826,2.478,847,4.23,860,2.915,959,1.654,1051,1.746,1256,3.333,1274,3,1300,3.648,1339,2.956,1401,2.956,1487,3.93,1569,2.252,1593,2.771,1611,7.175,1667,3.046,1708,3.148,1782,4.716,1797,3,1803,4.31,1819,3.746,1825,2.915,1953,3,1974,3.204,2640,5.226,2722,3.686,2795,3.266,2814,5.994,2815,3.686,2826,3.095,2827,6.433,2840,4.058,2848,3.957,2861,5.523,2863,2.915,2866,7.364,2867,4.142,2922,5.365,2927,4.142,2932,3.809,2933,3.809,2935,6.34,2937,7.442,2945,5.523,2957,4.39,2964,7.652,2967,8.208,2972,3.809,2984,4.142,2985,4.39,2986,4.39,2987,6.578,2988,6.578,2989,5.929,2990,4.39,2991,5.226,2992,3.489,2993,4.39,2994,6.578,2995,7.442,2996,6.206,2997,6.622,2998,3.957,2999,4.39,3000,4.39,3001,6.578,3002,4.39,3003,8.759,3004,4.39,3005,4.39,3006,6.578,3007,4.39,3008,4.39,3009,4.39,3010,4.39,3011,4.39,3012,3.957,3013,3.809,3014,4.39,3015,4.39,3016,3.957]],["title/community/contributor/#pmc-accept-and-icla-instruction",[74,3.329,1487,2.674,2866,3.014,3017,4.223]],["text/community/contributor/#pmc-accept-and-icla-instruction",[2,1.516,4,3.639,20,2.103,36,2.634,44,2.453,57,1.631,61,1.983,76,6.265,86,2.792,89,2.187,99,3.165,100,2.978,101,1.69,177,1.723,219,1.35,273,2.145,394,3.481,408,4.402,411,3.484,412,2.738,446,2.792,475,2.836,476,2.527,491,3.041,545,2.836,592,3.328,604,2.652,671,4.068,675,4.017,781,3.481,826,2.959,847,2.95,887,4.402,933,4.166,938,2.355,1028,4.725,1051,2.084,1136,4.276,1391,2.396,1406,3.349,1438,3.98,1466,3.271,1551,3.271,1556,2.749,1569,2.689,1656,3.637,1686,5.369,1731,3.98,1782,3.759,1808,3.132,1845,3.101,1905,2.77,1974,3.826,1984,3.826,2350,4.725,2606,5.685,2715,3.759,2737,5.951,2814,3.349,2826,3.696,2827,4.276,2832,3.435,2837,5.685,2838,4.549,2840,5.39,2841,6.943,2843,3.53,2844,5.369,2845,6.75,2863,5.802,2866,5.884,2944,4.946,2945,7.336,2961,5.242,2970,6.75,2972,4.549,3018,4.725,3019,5.242,3020,9.532,3021,5.242,3022,5.242,3023,5.242,3024,5.242,3025,4.725,3026,5.242,3027,5.242,3028,5.242,3029,5.242,3030,4.068,3031,3.98,3032,4.166,3033,5.242,3034,4.725,3035,5.242,3036,5.242,3037,5.242,3038,5.242,3039,5.242,3040,4.549,3041,5.242,3042,5.242]],["title/community/contributor/#create-asf-account",[76,3.106,126,1.561,3030,4.033]],["text/community/contributor/#create-asf-account",[2,2.133,61,3.334,76,5.266,101,1.704,304,5.321,412,3.222,576,3.056,592,3.916,2082,7.097,2855,8.377,2866,5.935,2903,7.647,2995,8.315,3017,8.315,3030,8.178,3043,8.813]],["title/community/contributor/#add-to-the-system",[6,2.266,459,2.785]],["text/community/contributor/#add-to-the-system",[2,1.784,6,3.222,23,0.543,76,5.266,101,1.704,412,3.853,452,3.714,459,3.96,476,2.974,675,4.052,2082,5.935,2836,7.003,2838,7.647,2967,8.23,3030,6.838,3044,7.944,3045,8.813,3046,7.647]],["title/community/contributor/#pmc-annoucement",[2866,4.174,3047,5.205]],["text/community/contributor/#pmc-annoucement",[2,1.888,6,2.647,20,2.033,23,0.48,35,4.569,36,2.182,86,3.855,126,2.174,412,3.985,476,2.443,489,3.164,527,6.281,601,4.682,717,5.752,847,4.065,1051,3.708,1139,4.874,1487,4.325,1534,5.495,1611,4.946,1686,5.19,1731,7.08,1778,5.495,1809,4.682,1819,5.311,1905,4.929,1943,5.022,1955,5.283,2082,4.874,2826,5.103,2832,4.743,2837,5.495,2840,4.466,2843,4.874,2844,5.19,2861,6.078,2863,7.237,2866,6.949,2967,5.283,2989,6.524,3030,5.617,3048,6.524,3049,7.239,3050,7.239]],["title/community/contributor/#committer-done-template",[1831,2.987,2606,3.946,2863,3.452]],["text/community/contributor/#committer-done-template",[2,1.792,20,1.508,21,2.679,23,0.524,36,2.905,53,5.929,54,2.929,68,3.786,70,5.589,74,3.995,76,5.291,86,2.86,101,1.039,129,2.176,135,2.661,177,1.765,178,2.974,219,1.383,273,2.197,281,2.087,392,3.277,412,3.237,457,3.015,476,1.812,530,1.993,666,3.431,669,3.786,715,3.431,745,3.544,847,2.116,961,3.177,967,3.146,1017,2.86,1051,3.029,1139,3.616,1214,4.509,1274,3.669,1390,4.38,1391,4.047,1406,3.431,1487,4.553,1556,2.817,1611,3.669,1667,3.726,1774,3.995,1775,4.509,1805,3.92,1826,3.85,1905,2.838,2813,4.841,2826,6.242,2840,5.463,2843,3.616,2855,3.85,2861,4.509,2863,5.88,2865,4.167,2866,5.963,2945,4.509,2967,5.561,2972,4.66,2975,5.286,2989,4.841,3030,8.618,3046,4.66,3051,5.37,3052,4.841,3053,4.077,3054,6.867,3055,4.841,3056,4.841,3057,4.841,3058,6.867,3059,4.841,3060,4.509,3061,4.509,3062,4.509,3063,4.841,3064,5.912,3065,4.841,3066,5.37,3067,4.509,3068,4.841,3069,5.37,3070,4.841]],["title/community/develop/",[1551,4.79]],["text/community/develop/",[2,1.985,4,2.109,13,1.65,15,1.65,20,1.219,23,0.631,42,1.996,63,2.007,85,2.649,92,2.621,114,0.651,115,0.687,179,1.82,225,2.408,369,2.543,377,5.151,411,2.019,424,2.137,450,2.543,476,1.465,478,4.219,480,2.568,489,3.425,530,2.049,539,3.54,574,2.123,585,4.117,592,1.929,593,2.151,796,3.54,823,2.312,847,4.007,875,4.502,878,2.763,891,4.069,945,4.638,959,2.951,967,2.543,981,2.137,984,2.621,1001,2.923,1014,4.101,1068,4.638,1070,2.773,1228,4.309,1315,4.45,1363,1.878,1391,4.783,1404,1.94,1465,2.45,1551,5.434,1598,2.069,1620,3.717,1648,2.923,1656,4.525,1690,2.019,1708,3.112,1710,3.012,1717,5.353,1779,3.236,1809,5.067,1811,2.678,1822,4.331,1823,4.598,1824,3.012,1826,3.112,1845,2.568,1851,3.645,1852,3.54,1857,3.82,1984,3.168,1986,4.951,2142,5.616,2715,4.676,2774,3.449,2940,3.766,2941,3.766,2996,4.096,3071,7.081,3072,4.713,3073,3.645,3074,3.766,3075,6.154,3076,4.713,3077,4.713,3078,4.713,3079,4.713,3080,5.353,3081,3.645,3082,4.713,3083,4.096,3084,4.096,3085,4.341,3086,4.341]],["title/community/develop/#develop-sedona",[2,1.255,1551,3.868]],["text/community/develop/#develop-sedona",[]],["title/community/develop/#scalajava-developers",[92,3.743,1551,3.868]],["text/community/develop/#scalajava-developers",[]],["title/community/develop/#ide",[1391,3.509]],["text/community/develop/#ide",[13,3.687,1717,6.629,1779,4.008,1851,8.146,1852,7.913,2774,7.709]],["title/community/develop/#import-the-project",[847,2.442,959,2.335]],["text/community/develop/#import-the-project",[]],["title/community/develop/#run-unit-tests",[377,2.559,875,2.987,1620,1.846]],["text/community/develop/#run-unit-tests",[]],["title/community/develop/#python-developers",[15,2.356,1551,3.868]],["text/community/develop/#python-developers",[489,4.323,1014,4.656,1986,7.507]],["title/community/develop/#ide_1",[1391,3.509]],["text/community/develop/#ide_1",[1717,6.8,3085,9.952]],["title/community/develop/#import-the-project_1",[847,2.442,959,2.335]],["text/community/develop/#import-the-project_1",[]],["title/community/develop/#r-developers",[42,2.85,1551,3.868]],["text/community/develop/#r-developers",[489,4.323,1014,4.656,1986,7.507]],["title/community/develop/#ide_2",[1391,3.509]],["text/community/develop/#ide_2",[1717,6.8,3086,9.952]],["title/community/develop/#import-the-project_2",[847,2.442,959,2.335]],["text/community/develop/#import-the-project_2",[]],["title/community/publication/",[72,4.542]],["text/community/publication/",[2,0.547,8,0.93,17,2.087,20,1.612,22,0.902,23,0.487,26,1.323,33,4.471,35,2.829,36,2.853,47,3.551,48,1.201,59,2.915,69,1.973,72,3.396,73,1.847,96,1.208,107,1.82,202,1.568,219,0.696,226,1.686,234,1.151,267,2.148,349,1.242,355,1.305,411,2.67,459,4.125,491,1.568,530,0.707,577,1.875,630,1.905,720,1.973,831,0.952,834,1.462,859,5.695,918,3.888,944,1.681,980,1.847,981,2.206,999,1.82,1066,1.367,1068,1.439,1240,3.956,1257,3.426,1405,3.081,1456,6.369,1457,6.369,1497,1.583,1568,2.269,1571,2.269,1581,1.771,1583,1.377,1608,5.307,1620,0.96,1621,2.123,1646,1.905,1679,2.269,1690,1.257,1732,1.706,1760,1.973,1800,1.727,1802,5.448,1819,4.547,1820,1.632,1865,3.477,1871,1.795,1889,4.564,1890,4.076,1978,2.052,1979,2.269,1986,2.052,2283,4.358,2648,2.269,2736,3.271,2783,5.07,2795,3.333,2885,7.488,2886,7.488,2894,4.039,2895,4.039,2899,3.888,2900,3.888,2991,2.148,2998,2.436,3084,2.55,3087,2.703,3088,2.703,3089,5.416,3090,2.703,3091,4.228,3092,4.228,3093,6.928,3094,8.871,3095,5.741,3096,6.02,3097,5.741,3098,6.302,3099,6.302,3100,7.622,3101,7.622,3102,6.02,3103,2.436,3104,2.703,3105,2.703,3106,2.703,3107,2.436,3108,2.703,3109,4.228,3110,2.703,3111,2.703,3112,2.703,3113,2.703,3114,2.703,3115,2.703,3116,2.703,3117,2.703,3118,2.703,3119,2.703,3120,2.703,3121,2.703,3122,5.416,3123,2.703,3124,4.039,3125,2.703,3126,2.703,3127,2.703,3128,2.703,3129,2.703,3130,2.703,3131,2.703,3132,2.703,3133,2.436,3134,2.703,3135,2.703,3136,2.703,3137,4.228,3138,6.425,3139,6.928,3140,2.703,3141,6.928,3142,4.82,3143,5.174,3144,4.481,3145,2.703,3146,2.436,3147,2.148,3148,4.481,3149,2.703,3150,4.481,3151,2.703,3152,2.703,3153,2.703,3154,2.703,3155,2.703,3156,2.703,3157,2.436,3158,2.703,3159,2.703,3160,2.703,3161,2.703,3162,2.703,3163,2.703,3164,5.741,3165,5.741,3166,2.703,3167,2.703,3168,2.703,3169,2.703,3170,2.703,3171,2.703,3172,2.703,3173,2.703]],["title/community/publication/#publication",[72,4.542]],["text/community/publication/#publication",[2,1.881,23,0.479,36,2.801,47,3.209,59,2.635,96,4.152,459,4.175,1583,4.733,1979,7.801,3087,9.292,3088,9.292,3089,8.767,3090,9.292]],["title/community/publication/#key-publications",[72,3.667,73,4.236]],["text/community/publication/#key-publications",[17,1.565,20,2.828,26,1.372,33,4.155,36,3.036,47,3.118,48,3.058,59,3.23,107,4.635,411,4.685,459,4.525,944,2.581,981,3.388,1240,4.99,1257,3.531,1802,5.614,1819,3.92,1889,4.703,1890,6.145,2283,7.645,2783,5.225,3091,6.494,3092,6.494,3093,8.738,3094,9.564,3095,10.071,3096,8.135,3097,10.071,3098,6.494,3099,6.494,3100,9.078,3101,9.078,3102,6.204]],["title/community/publication/#third-party-evaluation",[720,3.794,918,4.51,3103,4.685]],["text/community/publication/#third-party-evaluation",[17,2.406,22,2.236,26,0.913,59,2.819,202,3.889,219,1.726,226,4.182,234,2.854,349,2.458,459,3.985,530,1.753,577,4.65,630,4.725,831,2.362,834,3.627,918,5.816,944,2.514,1068,3.57,1568,5.628,1571,5.628,1581,4.392,1608,5.326,1620,2.381,1646,4.725,1690,3.118,1800,4.282,1820,4.047,1978,5.088,1986,5.088,2991,5.326,2998,6.042,3084,6.324,3089,8.369,3094,8.347,3104,6.703,3105,6.703,3106,6.703,3107,6.042,3108,6.703,3109,6.324,3110,6.703,3111,6.703,3112,6.703,3113,6.703,3114,6.703,3115,6.703,3116,6.703,3117,6.703,3118,6.703,3119,6.703,3120,6.703,3121,6.703,3122,6.324,3123,6.703,3124,7.995,3125,6.703,3126,6.703,3127,6.703,3128,6.703,3129,6.703,3130,6.703,3131,6.703,3132,6.703,3133,6.042,3134,6.703,3135,6.703]],["title/community/publication/#full-publications",[72,3.667,1890,3.783]],["text/community/publication/#full-publications",[]],["title/community/publication/#geospark-ecosystem",[59,1.758,3096,5.587]],["text/community/publication/#geospark-ecosystem",[17,2.241,26,0.897,35,5.535,36,1.986,47,3.63,59,2.795,267,5.235,459,2.96,491,3.822,859,5.905,980,4.502,1456,6.838,1457,6.838,1497,3.859,1621,4.154,1679,5.532,1732,4.159,1819,3.752,1865,5.112,1871,4.375,2648,5.532,2736,6.4,2783,6.657,2795,4.901,2885,8.039,2886,8.039,2894,7.904,2895,7.904,2899,5.716,2900,5.716,3091,6.216,3092,6.216,3093,5.716,3094,8.276,3136,6.588,3137,6.216,3138,5.716,3139,7.608,3140,6.588,3141,7.608,3142,5.532,3143,5.938,3144,8.769,3145,6.588,3146,5.938,3147,5.235,3148,8.769,3149,6.588,3150,8.769,3151,6.588,3152,6.588,3153,6.588]],["title/community/publication/#geosparkviz-visualization-system",[459,2.336,1240,2.576,1257,2.667]],["text/community/publication/#geosparkviz-visualization-system",[8,2.563,26,1.015,33,5.735,36,2.245,47,3.613,69,5.437,459,3.347,859,6.397,999,5.016,1240,4.707,1257,4.873,1456,6.59,1457,6.59,1608,5.919,1819,4.242,1865,5.78,1889,5.089,2783,5.655,2885,7.748,2886,7.748,2899,6.463,2900,6.463,3093,6.463,3094,7.976,3096,6.714,3122,8.963,3138,6.463,3139,8.242,3141,8.242,3142,6.254,3143,6.714,3154,7.449,3155,7.449,3156,7.449,3157,6.714,3158,7.449,3159,7.449,3160,7.449,3161,7.449,3162,7.449]],["title/community/publication/#geosparksim-traffic-simulator",[3100,4.685,3101,4.685,3102,4.685]],["text/community/publication/#geosparksim-traffic-simulator",[17,1.544,23,0.35,26,1.363,36,3.016,47,2.346,355,3.278,859,6.025,981,3.343,1066,3.435,1456,6.942,1457,6.942,1608,7.109,1760,4.957,1802,8.161,1819,3.868,1889,6.113,2795,5.052,2885,8.161,2886,8.161,3093,5.893,3094,7.512,3098,9.441,3099,9.441,3100,9.019,3101,9.019,3102,8.065,3109,6.408,3137,6.408,3138,7.763,3139,5.893,3141,5.893,3163,6.792,3164,10.006,3165,10.006,3166,6.792,3167,6.792,3168,6.792,3169,6.792,3170,6.792,3171,6.792,3172,6.792,3173,6.792]],["title/community/publication/#a-tutorial-about-geospatial-data-management-in-spark",[26,0.535,33,2.372,47,1.357,1405,2.109,1819,2.238]],["text/community/publication/#a-tutorial-about-geospatial-data-management-in-spark",[26,1.229,33,5.445,36,2.719,47,3.691,859,6.074,1405,5.736,1456,6.257,1457,6.257,1819,5.137,2885,7.356,2886,7.356,3138,7.826,3139,7.826,3141,7.826,3142,7.573,3143,8.13]],["title/community/publish/",[5,2.377,592,2.755]],["text/community/publish/",[2,2.328,4,5.649,5,3.571,6,1.579,13,0.893,14,0.895,15,1.068,17,0.154,20,1.771,21,1.172,22,0.784,23,0.606,26,0.32,32,1.164,35,0.428,36,3.207,42,1.831,45,1.504,47,0.234,50,0.204,52,1.522,53,1.977,54,0.704,56,1.888,57,1.239,60,0.364,61,1.507,62,0.748,63,0.853,65,0.271,66,1.106,67,2.598,68,0.478,70,0.814,72,0.763,73,0.881,74,1.747,75,0.818,76,2.765,77,1.001,78,2.09,79,3.658,81,1.6,82,4.221,89,0.283,90,1.357,93,1.125,94,0.427,95,2.181,96,0.576,97,0.298,101,0.701,107,0.457,126,1.477,135,0.336,172,0.346,177,0.923,178,1.262,184,6.306,186,0.312,187,0.394,188,0.445,219,1.462,220,0.541,226,1.753,236,0.297,241,0.41,245,3.072,246,0.967,263,0.593,264,0.722,273,0.278,281,0.264,304,0.41,311,0.361,352,0.866,365,0.748,366,0.433,369,0.397,373,0.998,374,0.314,378,0.433,402,0.716,404,3.939,424,0.334,431,0.763,450,0.397,455,1.172,456,0.419,459,0.305,476,0.622,488,1.011,489,0.564,500,0.445,501,0.471,530,0.735,531,0.386,566,0.615,576,2.666,591,0.321,592,1.249,593,0.914,595,0.687,601,0.439,615,0.787,628,0.895,675,1.292,696,0.31,737,0.515,738,1.539,749,1.001,834,0.367,836,0.353,837,0.3,847,0.267,878,1.535,881,0.478,884,1.178,929,0.439,938,0.305,939,2.233,944,0.692,945,0.687,955,1.343,959,1.954,981,1.383,987,3.525,1001,0.869,1017,0.361,1051,0.513,1054,1.001,1056,0.505,1066,0.343,1068,0.361,1069,0.486,1070,0.433,1105,0.611,1117,0.57,1119,1.465,1138,1.697,1228,0.71,1243,0.806,1262,1.001,1288,0.89,1314,0.428,1315,1.727,1339,0.869,1363,0.293,1391,1.284,1395,1.973,1403,0.316,1404,0.576,1405,0.364,1465,0.383,1471,0.869,1487,0.405,1492,2.188,1497,0.397,1500,0.505,1533,0.539,1556,1.232,1560,1.389,1569,0.348,1581,2.374,1585,1.433,1600,0.419,1620,1.415,1621,0.321,1628,0.405,1690,1.307,1702,2.092,1717,0.464,1731,0.979,1732,0.428,1747,0.515,1774,1.372,1779,1.161,1808,2.165,1811,0.419,1816,2.092,1817,1.322,1820,0.41,1822,2.406,1823,1.3,1824,2.514,1828,1.465,1832,1.783,1843,0.657,1845,0.401,1852,0.553,1857,1.08,1897,2.119,1898,3.786,1906,0.539,1918,0.526,1923,0.539,1943,0.471,1962,1.001,2007,2.092,2016,2.995,2027,0.486,2028,0.505,2082,0.869,2086,0.515,2604,0.445,2606,1.4,2610,1.783,2715,0.925,2736,0.495,2737,0.539,2786,0.397,2800,0.57,2805,1.431,2810,1.025,2814,1.501,2831,0.96,2833,0.611,2836,0.539,2837,0.979,2840,2.664,2843,1.892,2844,0.925,2866,0.869,2930,0.611,2935,5.469,2948,1.052,2949,4.025,2952,1.465,2955,2.715,2960,2.216,2964,1.916,2966,0.589,2967,0.495,2971,0.611,2973,1.119,2975,1.95,2977,1.119,2978,1.119,2992,0.539,2997,0.57,3013,1.119,3025,0.611,3032,0.539,3047,0.57,3052,1.662,3053,4.31,3062,0.57,3064,4.895,3073,1.972,3075,1.217,3080,0.881,3146,0.611,3174,0.678,3175,0.678,3176,0.678,3177,0.678,3178,0.611,3179,3.236,3180,0.471,3181,4.631,3182,2.908,3183,2.117,3184,0.57,3185,0.57,3186,0.611,3187,0.611,3188,0.57,3189,1.025,3190,0.611,3191,0.611,3192,0.57,3193,3.522,3194,3.166,3195,0.678,3196,2.117,3197,0.678,3198,1.29,3199,4.355,3200,2.038,3201,1.119,3202,2.806,3203,0.678,3204,1.29,3205,1.844,3206,5.837,3207,2.36,3208,0.678,3209,0.678,3210,0.678,3211,0.678,3212,0.505,3213,0.678,3214,1.217,3215,1.217,3216,0.678,3217,0.678,3218,1.662,3219,0.57,3220,0.57,3221,0.515,3222,0.611,3223,2.438,3224,4.993,3225,0.611,3226,1.001,3227,0.611,3228,2.438,3229,2.438,3230,2.438,3231,1.916,3232,1.483,3233,0.834,3234,2.216,3235,2.216,3236,2.216,3237,2.216,3238,0.611,3239,1.052,3240,1.052,3241,2.038,3242,5.12,3243,0.678,3244,1.844,3245,4.129,3246,1.29,3247,4.016,3248,3.378,3249,1.163,3250,1.29,3251,3.677,3252,1.29,3253,1.29,3254,1.74,3255,1.163,3256,1.29,3257,1.163,3258,1.163,3259,3.457,3260,3.457,3261,2.09,3262,1.74,3263,4.894,3264,3.144,3265,3.144,3266,1.217,3267,2.533,3268,1.217,3269,1.662,3270,1.217,3271,1.662,3272,1.119,3273,3.144,3274,0.678,3275,0.457,3276,0.611,3277,0.678,3278,0.678,3279,0.678,3280,1.217,3281,1.119,3282,1.025,3283,1.217,3284,4.767,3285,3.345,3286,1.217,3287,1.217,3288,1.217,3289,1.217,3290,1.217,3291,1.217,3292,0.678,3293,0.678,3294,0.678,3295,0.678,3296,0.678,3297,0.611,3298,0.678,3299,0.678,3300,0.678,3301,0.678,3302,0.678,3303,0.678,3304,0.678,3305,0.678,3306,0.678,3307,0.678,3308,0.611,3309,3.624,3310,3.234,3311,1.29,3312,0.678,3313,2.349,3314,0.678,3315,0.678,3316,1.823,3317,2.038,3318,0.611,3319,3.984,3320,1.6,3321,0.678,3322,0.678,3323,0.678,3324,0.678,3325,1.29,3326,1.29,3327,1.163,3328,1.119,3329,0.553,3330,0.611,3331,0.678,3332,0.678,3333,0.678,3334,0.678,3335,0.678,3336,0.678,3337,0.678,3338,0.678,3339,1.29,3340,0.678,3341,2.349,3342,0.611,3343,0.678,3344,0.737,3345,0.737,3346,0.737,3347,0.737,3348,0.64,3349,0.678,3350,0.57,3351,0.553,3352,0.57,3353,0.611,3354,0.678,3355,0.678,3356,0.678,3357,0.678,3358,1.29,3359,0.678,3360,0.678,3361,0.678,3362,0.678,3363,0.678,3364,0.678,3365,0.611]],["title/community/publish/#make-a-sedona-release",[2,1.052,5,1.993,592,2.31]],["text/community/publish/#make-a-sedona-release",[2,2.166,4,4.762,5,4.103,66,3.685,67,5.612,76,6.702,94,2.592,177,2.572,178,3.055,219,2.016,424,3.853,576,2.714,591,3.708,601,5.063,955,3.25,1066,3.959,1138,5.918,1395,4.776,1581,5.129,1585,4.776,1620,2.78,1816,5.063,2935,4.726,2960,10.583,2967,5.713,3174,7.827,3175,7.827,3176,7.827,3177,7.827,3178,7.055,3179,6.115]],["title/community/publish/#0-prepare-an-empty-script-file",[220,1.152,378,2.51,576,1.363,3179,2.451,3180,2.726]],["text/community/publish/#0-prepare-an-empty-script-file",[2,1.493,23,0.486,65,2.947,66,3.473,67,5.289,101,1.427,126,3.408,172,3.758,455,3.68,531,4.201,576,3.274,837,3.26,929,4.772,955,3.063,1068,3.929,1138,4.454,1395,4.502,1403,3.432,1569,3.785,1585,4.502,1620,3.354,1811,4.551,1816,4.772,1857,4.321,1897,6.186,2007,6.107,2975,5.118,3032,5.862,3179,6.848,3181,6.017,3182,4.968,3183,9.893,3184,6.194,3185,6.194,3186,6.65,3187,6.65,3188,6.194,3189,5.862,3190,6.65,3191,6.65,3192,6.194]],["title/community/publish/#1-check-asf-copyright-in-all-file-headers",[21,1.747,76,2.092,219,0.902,576,1.214,615,2.137,2800,2.94]],["text/community/publish/#1-check-asf-copyright-in-all-file-headers",[2,2.084,23,0.371,36,3.103,56,3.15,57,2.242,61,3.518,63,3.332,66,3.392,67,5.165,76,4.305,79,7.659,94,2.385,97,3.167,530,1.885,576,3.57,592,3.201,593,3.57,615,4.396,1600,4.445,1620,2.559,1816,4.66,1817,6.666,1962,5.59,2831,5.359,3053,5.469,3179,4.495,3182,6.261,3193,5.876,3194,5.725,3195,7.205,3196,9.806,3197,7.205,3198,9.298,3199,7.807,3200,6.251,3201,6.251,3202,6.251,3203,7.205,3204,7.205,3205,10.296,3206,7.059,3207,6.049]],["title/community/publish/#2-update-sedona-python-r-and-zeppelin-versions",[2,0.639,15,1.2,42,1.452,75,1.099,177,1.038,1288,1.524,1702,2.043]],["text/community/publish/#2-update-sedona-python-r-and-zeppelin-versions",[2,1.805,4,5.156,15,3.388,22,2.974,42,4.099,75,3.695,184,4.903,530,2.332,576,3.092,592,3.961,593,4.418,3053,8.602,3208,8.915,3209,8.915,3210,8.915,3211,8.915]],["title/community/publish/#3-update-mkdocsyml",[178,2.029,1702,3.362,1832,3.946]],["text/community/publish/#3-update-mkdocsyml",[20,2.379,23,0.436,61,3.206,74,6.303,75,2.95,273,3.467,476,2.859,530,2.217,675,3.896,878,3.59,955,3.518,1017,4.513,1138,5.116,1581,6.744,1690,3.942,1747,6.433,1808,6.15,1828,6.733,1832,6.433,3179,5.287,3212,6.303,3213,8.474,3214,7.995,3215,7.995,3216,8.474,3217,8.474,3218,7.638]],["title/community/publish/#4-stage-and-upload-release-candidates",[5,1.506,135,1.947,987,2.817,2016,2.726,2955,3.299]],["text/community/publish/#4-stage-and-upload-release-candidates",[2,2.443,4,5.926,5,3.331,13,1.312,14,1.379,23,0.572,26,0.47,32,0.985,36,3.546,42,0.914,52,0.936,53,1.883,56,2,57,1.074,66,0.936,68,1.401,76,1.188,79,5.045,82,7.11,126,1.374,177,1.503,178,0.776,184,6.702,219,1.178,236,0.869,245,3.941,281,0.772,373,1.625,404,5.054,450,1.164,488,1.645,501,1.379,576,2.803,945,1.838,955,1.899,959,2.555,987,2.475,1119,1.579,1314,1.255,1315,1.645,1395,1.213,1500,1.478,1556,2.399,1690,0.925,1779,1.426,1816,2.233,1822,4.108,1823,3.225,1824,4.291,2016,3.174,2610,4.148,2955,3.841,3053,1.509,3064,6.272,3181,6.855,3182,1.338,3193,1.621,3194,4.915,3199,5.695,3200,3.97,3201,1.724,3202,2.995,3206,7.109,3207,3.841,3219,1.669,3220,1.669,3221,1.509,3222,1.791,3223,3.97,3224,5.317,3225,1.791,3226,2.678,3227,1.791,3228,3.97,3229,3.97,3230,3.97,3231,1.621,3232,2.179,3233,1.286,3234,3.257,3235,3.257,3236,3.257,3237,3.257,3238,1.791,3239,1.621,3240,1.621,3241,3.97,3242,6.321,3243,1.988,3244,4.575,3245,7.295,3246,3.452,3247,5.885,3248,3.988,3249,3.111,3250,3.452,3251,6.679,3252,3.452,3253,3.452,3254,3.257,3255,3.111,3256,3.452,3257,3.111,3258,3.111,3259,4.741,3260,4.741,3261,2.568,3262,3.257,3263,6.4,3264,3.97,3265,3.97]],["title/community/publish/#5-vote-in-dev-sedonaapacheorg",[186,2.057,2844,3.209,2935,2.702,2973,3.883]],["text/community/publish/#5-vote-in-dev-sedonaapacheorg",[]],["title/community/publish/#vote-email",[2840,3.824,2935,3.743]],["text/community/publish/#vote-email",[2,1.501,4,5.071,5,3.845,6,1.891,20,2.66,21,2.58,22,1.725,23,0.608,36,2.236,52,2.435,53,2.821,56,3.242,57,2.308,62,3,70,3.265,72,3.059,73,3.534,74,5.517,77,4.013,78,3.847,90,3.58,96,2.311,101,1,178,2.019,184,5.516,219,2.233,220,1.517,246,2.712,263,2.378,264,2.894,402,2.869,476,1.745,489,2.261,628,3.588,675,2.378,738,4.86,749,4.013,834,2.798,878,3.674,884,3.304,938,2.324,981,2.546,1051,2.056,1054,4.013,1119,4.11,1262,4.013,1339,3.483,1717,3.534,1857,3.029,1898,3.775,2786,3.029,2805,4.013,2810,4.11,2840,3.191,2843,3.483,2866,3.483,2935,6.302,2948,4.218,2952,4.11,2975,3.588,2977,4.488,2978,4.488,2992,4.11,3013,4.488,3053,6.583,3073,6.228,3218,4.662,3224,6.914,3242,4.488,3261,3.847,3266,4.88,3267,6.685,3268,4.88,3269,4.662,3270,4.88,3271,4.662,3272,4.488,3273,8.22,3274,5.172,3275,3.483,3276,4.662,3277,5.172,3278,5.172,3279,5.172,3280,4.88,3281,4.488,3282,4.11,3283,4.88,3284,4.342,3285,4.342]],["title/community/publish/#pass-email",[1492,3.743,2840,3.824]],["text/community/publish/#pass-email",[2,1.545,4,3.709,5,3.699,6,2.791,20,2.143,23,0.497,32,4.781,36,2.301,184,4.198,219,1.966,226,4.763,246,4.003,431,4.515,595,4.065,1487,4.561,1492,6.387,1581,5.002,1918,5.923,2843,5.14,2935,7.263,2949,7.486,2952,6.065,2964,7.869,2966,6.623,3224,5.571,3284,8.101,3285,6.409,3286,7.202,3287,7.202,3288,7.202,3289,7.202,3290,7.202,3291,7.202,3292,7.633]],["title/community/publish/#6-vote-in-general-incubatorapacheorg",[61,1.693,187,2.596,2935,2.702,2971,4.034]],["text/community/publish/#6-vote-in-general-incubatorapacheorg",[]],["title/community/publish/#vote-email_1",[2840,3.824,2935,3.743]],["text/community/publish/#vote-email_1",[2,2.075,4,4.981,5,3.767,6,3.078,20,2.879,22,1.637,23,0.603,36,2.153,52,2.311,53,2.677,56,3.122,57,2.222,62,2.847,70,3.098,72,2.903,73,3.354,74,3.651,77,3.808,78,3.651,90,4.064,96,2.193,178,1.916,184,5.404,219,2.168,220,1.439,246,2.574,263,2.256,264,2.746,352,2.633,402,2.722,476,1.656,489,2.146,628,3.405,675,2.256,738,4.68,749,3.808,878,3.567,884,3.136,981,2.416,1051,1.951,1054,3.808,1119,3.9,1262,3.808,1339,3.305,1857,2.875,1898,3.582,2805,5.542,2810,3.9,2814,5.907,2840,3.028,2843,3.305,2866,3.305,2935,6.675,2948,4.003,2949,7.174,2952,3.9,2975,3.405,2977,4.259,2978,4.259,3013,4.259,3053,6.391,3073,5.997,3218,4.424,3224,6.748,3242,4.259,3261,3.651,3266,4.631,3267,6.437,3268,4.631,3269,4.424,3270,4.631,3271,4.424,3272,4.259,3273,7.305,3280,4.631,3281,4.259,3282,3.9,3283,4.631,3284,8.249,3285,7.069,3293,4.908,3294,4.908]],["title/community/publish/#pass-email_1",[1492,3.743,2840,3.824]],["text/community/publish/#pass-email_1",[2,1.593,4,3.822,5,3.77,6,2.876,20,2.209,23,0.506,32,3.898,36,2.371,184,4.327,219,2.026,226,4.909,431,4.654,592,3.496,595,4.19,1492,5.937,1581,5.155,2082,5.298,2606,5.972,2843,5.298,2935,7.123,2949,7.63,2964,8.02,3047,6.606,3224,5.742,3284,8.256,3285,6.606,3286,7.423,3287,7.423,3288,7.423,3289,7.423,3290,7.423,3291,7.423]],["title/community/publish/#announce-email",[1731,4.706,2840,3.824]],["text/community/publish/#announce-email",[2,2.106,4,5.635,5,3.731,6,3.152,17,1.461,20,2.421,22,2.143,35,4.054,36,3.135,47,2.219,52,3.024,184,5.721,241,3.878,352,3.179,374,2.97,459,2.886,675,2.953,1405,3.448,1497,3.762,1533,5.104,1621,3.043,1731,4.876,1732,4.054,1808,3.838,1943,4.456,2736,4.688,2737,5.104,2831,4.778,2833,5.79,2836,5.104,2837,6.545,2840,3.963,2843,4.325,2930,5.79,2935,6.28,2949,8.071,2975,4.456,3053,6.545,3062,5.393,3267,5.79,3269,5.79,3271,5.79,3284,8.733,3285,7.239,3295,6.423,3296,6.423,3297,5.79,3298,6.423,3299,6.423,3300,6.423,3301,6.423,3302,6.423,3303,6.423,3304,6.423]],["title/community/publish/#7-failed-vote",[188,3.406,1471,3.5,2935,3.138]],["text/community/publish/#7-failed-vote",[4,4.028,5,3.894,20,2.328,23,0.523,61,3.137,126,2.491,178,3.236,184,4.56,456,5.115,530,2.169,675,3.812,1391,3.79,1471,5.583,1556,4.348,1702,6.57,1832,7.711,1906,6.588,2086,6.294,2840,5.115,2935,6.132,2955,8.528,3179,5.173,3214,7.823,3215,7.823,3305,8.291,3306,8.291,3307,8.291]],["title/community/publish/#8-release-source-code-and-maven-package",[5,1.342,56,1.531,57,1.089,365,2.031,1363,1.515,1843,1.784]],["text/community/publish/#8-release-source-code-and-maven-package",[]],["title/community/publish/#upload-releases",[5,2.377,2016,4.301]],["text/community/publish/#upload-releases",[2,2.419,4,5.916,5,2.73,13,2.203,14,2.582,23,0.572,26,0.79,36,3.265,101,0.72,184,6.572,245,5.214,373,2.059,404,6.685,488,2.085,576,3.342,959,3.476,987,2.668,1315,1.774,1822,3.85,1824,4.022,1923,2.957,2715,2.668,3064,7.733,3181,4.728,3182,2.506,3193,7.527,3194,4.607,3199,6.75,3202,5.03,3206,7.006,3223,5.03,3224,4.231,3228,5.03,3229,5.03,3230,5.03,3231,3.036,3232,3.659,3233,2.407,3234,5.47,3235,5.47,3236,5.47,3237,5.47,3239,3.036,3240,3.036,3241,3.229,3242,8.007,3247,6.975,3259,6.975,3260,6.975,3263,8.707,3264,6.975,3265,6.975,3308,3.355,3309,9.636,3310,9.229]],["title/community/publish/#fix-signature-issues",[78,3.867,89,2.169,1404,2.323]],["text/community/publish/#fix-signature-issues",[2,1.674,4,4.426,15,2.652,20,1.336,23,0.649,36,2.104,50,1.105,54,2.595,63,3.228,78,5.192,81,7.174,184,5.577,455,3.482,530,1.244,566,3.327,576,1.649,737,3.611,836,2.476,884,3.039,944,2.618,987,5.004,1243,3.051,1391,4.164,1404,2.125,1585,2.902,1620,1.69,1774,6.151,1898,8.138,2016,4.843,2604,3.117,2606,5.299,2715,3.41,2997,3.994,3052,7.453,3075,6.586,3146,4.287,3179,2.968,3181,3.879,3182,3.203,3193,3.879,3206,6.277,3231,3.879,3261,3.538,3262,4.488,3311,6.98,3312,4.757,3313,9.109,3314,4.757,3315,4.757,3316,7.068,3317,7.904,3318,4.287,3319,10.749,3320,7.174,3321,4.757,3322,4.757,3323,4.757,3324,4.757,3325,6.98,3326,6.98,3327,6.291,3328,4.127,3329,3.879,3330,4.287]],["title/community/publish/#manually-close-and-release-the-package",[5,1.716,226,2.792,1628,2.674,1843,2.28]],["text/community/publish/#manually-close-and-release-the-package",[2,1.847,5,3.499,54,4.978,226,6.714,987,8.204,1395,6.983,1585,5.569,2082,6.146,3080,7.352,3231,7.444]],["title/community/publish/#9-release-sedona-python-and-zeppelin",[2,0.795,5,1.506,15,1.493,366,2.51,1288,1.897]],["text/community/publish/#9-release-sedona-python-and-zeppelin",[2,2.352,4,5.342,23,0.608,36,3.146,67,5.315,79,7.044,184,6.048,881,5.226,1288,3.578,1581,4.857,1816,4.795,1817,5.315,1962,5.752,2016,5.143,2027,5.315,2028,5.514,3053,5.627,3182,4.992,3202,6.432,3206,5.627,3207,6.224,3224,5.41,3248,8.025,3254,6.994,3331,7.413,3332,7.413,3333,7.413,3334,7.413,3335,7.413,3336,7.413,3337,7.413,3338,7.413]],["title/community/publish/#10-release-sedona-r-to-cran",[2,0.795,5,1.506,42,1.806,45,3.205,311,2.092]],["text/community/publish/#10-release-sedona-r-to-cran",[21,4.553,23,0.554,42,4.947,45,8.776,101,1.765,304,5.51,981,4.492,1845,5.399,3182,6.146,3189,7.252,3339,10.761,3340,9.126]],["title/community/publish/#11-publish-the-doc-website",[93,2.731,500,2.932,1581,2.932,1808,2.674]],["text/community/publish/#11-publish-the-doc-website",[2,1.953,4,3.709,5,2.926,6,2.791,21,3.808,52,4.543,53,5.77,60,4.097,67,7.584,76,6.321,101,1.476,126,2.293,369,4.471,455,3.808,981,3.757,987,6.917,1001,5.14,1138,4.609,1228,4.198,1315,3.639,1620,2.711,1702,6.241,1808,5.765,1828,6.065,1897,7.283,2007,6.241,2016,5.296,2973,6.623,2975,5.296,3341,10.579,3342,6.88,3343,7.633]],["title/community/publish/#javadoc-and-scaladoc",[95,4.81,939,4.926]],["text/community/publish/#javadoc-and-scaladoc",[]],["title/community/publish/#compile-r-html-docs",[42,2.057,93,2.731,1117,3.758,1690,2.082]],["text/community/publish/#compile-r-html-docs",[2,1.935,23,0.569,42,3.458,61,2.846,126,2.259,219,1.937,365,4.364,592,3.342,593,3.727,1001,5.065,1070,4.805,1105,6.779,1228,4.137,1315,3.585,1560,6.539,1620,2.672,1779,4.341,1820,4.541,2844,5.393,3025,6.779,3179,4.693,3182,5.065,3248,6.976,3328,6.526,3349,7.522,3350,6.315,3351,6.135,3352,6.315,3353,6.779,3354,7.522,3355,7.522,3356,7.522,3357,7.522,3358,9.558,3359,7.522,3360,7.522,3361,7.522,3362,7.522,3363,7.522,3364,7.522,3365,6.779]],["title/community/release-manager/",[5,1.993,1686,3.727,1819,2.96]],["text/community/release-manager/",[2,1.772,5,2.123,6,1.698,20,1.304,21,2.317,22,0.676,23,0.571,32,1.004,36,1.887,53,4.622,54,1.106,61,2.369,68,3.274,70,3.496,72,3.704,73,7.613,74,1.508,75,2.18,76,1.211,83,1.573,88,1.759,97,0.891,100,0.806,101,1.693,115,1.086,126,1.055,135,1.004,172,1.788,177,0.666,178,0.791,179,1.947,186,1.614,187,1.176,200,1.549,219,0.522,220,0.594,235,1.828,246,2.436,263,0.932,273,1.436,281,0.788,304,2.12,352,1.294,365,3.632,369,1.187,378,2.243,392,1.237,404,2.436,407,1.429,411,0.943,412,1.698,450,1.187,455,1.011,456,1.25,457,2.714,467,1.079,475,1.097,476,1.567,480,1.199,491,1.176,530,1.449,576,2.7,592,2.461,593,2.301,594,0.676,603,2.364,604,1.025,666,1.295,675,2.135,696,0.926,701,1.406,702,1.828,715,1.295,717,1.61,738,1.328,745,0.943,753,1.295,825,1.25,834,1.097,836,1.055,878,1.487,884,1.295,888,2.19,889,3.784,928,1.346,941,0.998,955,0.841,961,1.199,984,1.224,1017,1.87,1051,1.396,1055,0.921,1104,1.311,1108,1.453,1214,1.702,1274,5.028,1284,5.748,1286,1.199,1315,1.673,1363,2.708,1390,5.107,1391,3.727,1395,2.142,1487,2.098,1498,1.801,1551,1.265,1556,2.436,1569,1.801,1581,1.328,1585,1.237,1611,1.385,1620,2.224,1634,2.665,1686,1.453,1689,3.004,1691,5.474,1701,1.365,1702,3.004,1706,1.653,1741,1.106,1774,3.455,1779,2.833,1782,1.453,1805,1.479,1811,2.166,1816,1.311,1819,1.999,1820,1.224,1821,1.751,1822,3.678,1826,1.453,1857,2.056,1862,1.279,1866,1.702,1890,1.237,1895,1.385,1897,3.043,1905,1.071,1906,1.61,1907,1.346,1954,3.788,1984,1.479,2007,2.271,2063,2.967,2645,3.97,2691,3.274,2731,4.517,2785,1.539,2804,1.406,2826,3.274,2840,2.166,2844,2.517,2863,1.346,2865,4.858,2967,2.562,2975,1.406,3018,1.827,3030,3.603,3046,1.759,3054,3.164,3055,1.827,3056,1.827,3057,1.827,3058,3.164,3059,1.827,3060,1.702,3061,1.702,3062,1.702,3063,1.827,3064,6.575,3067,1.702,3068,1.827,3070,1.827,3074,1.759,3080,3.784,3147,1.61,3180,1.406,3182,2.364,3188,1.702,3206,2.665,3207,2.948,3212,1.508,3219,1.702,3220,2.948,3240,1.653,3261,6.304,3282,4.975,3297,1.827,3308,1.827,3329,3.788,3350,1.702,3351,2.863,3352,1.702,3366,2.027,3367,2.027,3368,6.261,3369,2.027,3370,2.027,3371,3.511,3372,3.511,3373,3.511,3374,3.511,3375,4.382,3376,2.027,3377,1.827,3378,1.827,3379,3.511,3380,3.511,3381,2.027,3382,2.027,3383,2.027,3384,4.644,3385,1.827,3386,3.511,3387,2.027,3388,5.908,3389,2.027,3390,2.027,3391,2.027,3392,3.511,3393,2.724,3394,5.225,3395,2.027,3396,4.805,3397,2.027,3398,2.027,3399,2.027,3400,3.511,3401,2.027,3402,3.511,3403,3.511,3404,4.382,3405,2.027,3406,4.382,3407,8.496,3408,3.511,3409,2.027,3410,2.027,3411,2.027,3412,2.027,3413,1.827,3414,2.027,3415,2.027,3416,2.027,3417,2.027,3418,2.027,3419,2.027,3420,2.027,3421,3.511,3422,3.511,3423,2.027,3424,2.027,3425,2.027,3426,3.511,3427,2.027]],["title/community/release-manager/#become-a-release-manager",[5,1.993,1686,3.727,1819,2.96]],["text/community/release-manager/#become-a-release-manager",[5,3.673,476,3.233,696,4.379,717,7.613,834,5.184,1556,5.025,1569,4.915,1819,5.456]],["title/community/release-manager/#0-software-requirement",[220,1.524,475,2.812,2804,3.606]],["text/community/release-manager/#0-software-requirement",[21,3.165,23,0.573,32,3.144,75,3.761,97,2.788,200,3.226,263,2.916,273,2.595,352,3.152,365,6.268,476,2.141,530,1.66,702,4.451,753,4.053,836,3.302,878,3.622,1363,4.476,1556,3.327,1620,3.037,1689,6.255,1691,8.461,1779,3.995,1811,3.914,1816,4.103,1820,3.83,1822,6.872,1857,3.716,1897,4.157,2691,4.472,3064,4.922,3182,5.757,3297,5.718,3329,7.887,3351,5.174,3352,5.327,3366,6.344,3367,6.344,3368,10.804,3369,6.344,3370,6.344,3371,8.55,3372,8.55,3373,8.55,3374,8.55]],["title/community/release-manager/#1-obtain-write-access-to-sedona-github-repo",[2,0.639,53,1.723,219,0.813,941,1.554,1108,2.264,1395,1.927,2865,2.45]],["text/community/release-manager/#1-obtain-write-access-to-sedona-github-repo",[2,1.877,21,3.578,36,3.274,53,6.134,70,6.484,101,1.387,186,3.297,273,2.934,281,2.787,392,4.376,666,4.581,715,4.581,961,4.242,1214,6.021,1274,4.9,1390,5.849,1391,4.695,1487,5.539,1611,4.9,1805,5.234,1826,5.141,1905,3.79,2826,7.242,2840,4.424,2863,4.762,2967,6.766,2975,4.975,3030,7.971,3046,6.222,3054,8.356,3055,6.464,3056,6.464,3057,6.464,3058,8.356,3059,6.464,3060,6.021,3061,6.021,3062,6.021,3063,6.464,3067,6.021,3068,6.464,3070,6.464]],["title/community/release-manager/#2-prepare-secret-gpg-key",[73,2.685,177,1.291,3180,2.726,3261,2.923,3375,3.707]],["text/community/release-manager/#2-prepare-secret-gpg-key",[23,0.511,36,1.513,61,2.747,70,3.169,72,5.045,73,8.288,88,4.356,100,1.996,101,1.917,115,1.149,179,2.105,235,2.613,246,3.808,304,4.383,378,3.207,411,2.335,412,1.835,456,3.097,467,2.674,491,2.912,592,3.226,593,2.488,594,1.675,604,2.539,675,3.921,701,3.483,738,3.289,825,3.097,884,3.207,928,3.334,1017,3.866,1051,1.996,1104,3.247,1274,6.774,1284,3.539,1391,3.898,1498,3.724,1569,2.575,1581,3.289,1620,3.029,1701,3.381,1706,4.094,1779,3.523,1782,3.599,1821,2.504,1890,3.063,1954,5.921,2007,4.696,2063,5.448,2645,6.114,2691,3.539,2840,3.097,3074,4.356,3261,8.27,3282,6.776,3350,4.215,3351,4.094,3375,6.85,3376,5.02,3377,4.525,3378,4.525,3379,7.26,3380,7.26,3381,5.02,3382,5.02,3383,5.02,3384,8.528,3385,4.525,3386,7.26,3387,5.02,3388,4.737,3389,5.02,3390,5.02,3391,5.02,3392,7.26,3393,3.895,3394,6.85,3395,5.02,3396,7.399,3397,5.02]],["title/community/release-manager/#3-use-svn-to-update-keys",[73,2.685,101,0.76,178,1.534,1702,2.541,3064,3.049]],["text/community/release-manager/#3-use-svn-to-update-keys",[2,2.315,5,3.172,21,3.016,22,2.017,23,0.486,68,6.65,72,4.894,73,7.927,76,3.612,83,4.691,101,1.6,172,3.079,179,2.535,235,3.147,246,3.17,369,3.541,378,3.862,404,5.74,450,3.541,480,3.576,576,3.684,592,2.686,593,2.995,889,6.931,955,2.51,1274,4.13,1315,2.881,1391,3.782,1702,5.352,1741,3.297,1774,6.155,1857,3.541,1862,3.816,1984,4.412,2645,4.334,2691,4.261,2844,5.932,3064,8.874,3188,5.076,3206,6.281,3207,6.947,3220,6.947,3240,4.93,3282,6.575,3308,5.449,3394,7.807,3396,5.245,3398,6.045,3399,6.045,3400,8.274,3401,6.045,3402,8.274,3403,8.274]],["title/community/release-manager/#4-add-gpg_tty-environment-variable",[6,1.436,135,1.947,1286,2.324,3212,2.923,3404,3.707]],["text/community/release-manager/#4-add-gpg_tty-environment-variable",[6,3.377,23,0.592,530,2.416,576,3.203,1811,5.698,1897,6.052,1906,7.339,3219,7.755,3393,7.166,3404,10.224,3405,9.236]],["title/community/release-manager/#5-get-github-personal-access-token-classic",[53,1.91,186,1.61,2731,2.856,2865,2.717,3406,3.304,3407,3.304]],["text/community/release-manager/#5-get-github-personal-access-token-classic",[20,1.834,23,0.562,53,5.354,54,3.563,61,3.713,74,4.859,101,1.686,115,1.658,126,1.962,179,2.739,407,4.605,412,3.188,457,3.884,476,2.204,530,1.709,592,2.903,593,3.237,888,5.44,1051,2.597,1055,2.969,1395,3.986,1551,4.076,1556,3.426,1585,3.986,1634,6.619,1821,3.259,1866,5.485,1895,4.463,1907,4.338,1954,5.328,2731,8.005,2785,4.959,2865,7.615,3018,5.888,3080,7.155,3147,5.191,3388,9.881,3406,8.227,3407,11.33,3408,8.719,3409,6.532,3410,6.532,3411,6.532,3412,6.532]],["title/community/release-manager/#6-set-up-credentials-for-maven",[187,2.279,457,1.555,745,1.828,1363,1.699,3413,3.541]],["text/community/release-manager/#6-set-up-credentials-for-maven",[6,2.819,20,2.726,126,2.316,172,3.927,455,3.846,457,3.842,530,2.017,576,3.367,603,6.538,984,4.655,1284,8.497,1315,3.675,1390,9.098,1391,3.524,1774,5.735,1897,5.052,3414,7.71,3415,7.71,3416,7.71,3417,7.71,3418,7.71,3419,7.71,3420,7.71,3421,9.709,3422,9.709,3423,7.71,3424,7.71,3425,7.71,3426,9.709,3427,7.71]],["title/community/rule/",[1597,5.957]],["text/community/rule/",[2,2.004,13,2.027,17,0.762,20,2.325,21,2.662,22,1.117,23,0.534,36,2.286,51,1.08,53,3.627,56,1.464,57,3.081,60,1.798,65,1.338,67,3.825,68,2.361,69,2.445,76,2.001,94,1.767,97,1.472,101,1.032,102,1.284,107,2.255,114,0.503,126,1.603,177,1.101,219,1.712,245,2.887,263,3.057,296,2.255,352,1.235,377,4.556,412,1.225,413,4.688,475,3.598,476,1.13,489,2.332,491,1.943,530,1.74,576,1.162,592,2.955,615,2.044,619,1.842,666,2.14,715,3.408,752,2.289,776,2.445,831,1.18,837,1.48,839,2.543,847,1.319,868,2.195,875,3.822,878,4.07,881,2.361,884,4.248,889,2.289,937,5.219,940,2.114,944,1.256,959,1.262,981,1.649,984,2.022,1014,3.571,1051,1.332,1068,1.784,1069,2.401,1315,1.597,1391,1.531,1392,1.638,1395,3.256,1403,2.482,1404,2.971,1406,2.14,1410,6.326,1466,2.09,1483,4.688,1487,2.001,1519,2.732,1522,1.638,1537,2.812,1551,4.149,1582,2.044,1611,2.289,1646,2.361,1690,2.482,1702,2.166,1708,2.401,1785,3.221,1808,2.001,1809,2.166,1825,2.224,1831,1.925,1832,2.543,1841,2.114,1845,3.156,1850,1.981,1858,2.114,1909,2.812,1912,4.05,1974,3.894,1985,2.906,2602,2.255,2795,3.969,2799,5.16,2804,2.324,2809,2.812,2810,2.661,2812,6.185,2814,4.248,2815,2.812,2819,3.019,2827,2.732,2831,2.491,2832,6.79,2837,2.543,2843,3.593,2847,6.185,2855,5.437,2863,5.036,2922,2.732,2932,2.906,2952,2.661,2979,3.019,2991,2.661,2992,2.661,3016,3.019,3032,2.661,3034,3.019,3040,5.77,3047,2.812,3065,3.019,3073,2.812,3133,3.019,3221,6.287,3281,2.906,3342,4.809,3428,3.349,3429,3.019,3430,2.906,3431,7.156,3432,3.349,3433,3.349,3434,3.349,3435,3.349,3436,3.349,3437,3.349,3438,6.274,3439,3.349,3440,3.349,3441,3.349,3442,3.349,3443,3.349,3444,3.349,3445,2.661,3446,3.349,3447,3.349,3448,3.349,3449,3.019,3450,3.349,3451,3.349,3452,3.349,3453,3.349,3454,3.349,3455,3.349]],["title/community/rule/#contributing-to-apache-sedona",[2,1.052,36,1.567,2832,3.406]],["text/community/rule/#contributing-to-apache-sedona",[2,2.148,23,0.459,53,4.863,57,2.774,530,2.332,592,3.961,847,3.512,937,5.274,1395,5.44,1406,5.695,1646,6.285,1974,6.507,2832,7.425,2855,6.392,3221,6.768,3428,8.915,3429,8.036]],["title/community/rule/#pick-annouce-a-task-using-jira",[23,0.18,101,0.677,1912,2.658,2847,2.856,2992,2.782,3047,2.94]],["text/community/rule/#pick-annouce-a-task-using-jira",[60,4.899,126,2.741,412,3.337,959,3.438,984,5.51,1487,5.453,1912,6.928,2832,5.98,2837,6.928,2847,8.776,3430,7.919,3431,10.797,3432,9.126]],["title/community/rule/#develop-a-code-contribution",[57,1.617,1551,3.243,2832,3.406]],["text/community/rule/#develop-a-code-contribution",[2,1.923,13,3.61,36,2.245,51,2.403,57,3.254,65,2.975,97,3.274,263,4.367,377,5.727,476,2.514,489,3.256,530,1.949,576,2.583,615,4.545,868,4.881,875,6.011,881,5.251,884,4.759,889,5.089,937,5.619,1068,3.967,1069,5.34,1392,3.642,1403,4.419,1404,4.244,1466,4.647,1522,3.642,1582,4.545,1702,4.818,1785,4.497,1809,4.818,2795,7.066,2832,6.224,2991,5.919,3065,6.714,3433,7.449,3434,7.449]],["title/community/rule/#develop-a-document-contribution",[937,3.075,1551,3.243,2832,3.406]],["text/community/rule/#develop-a-document-contribution",[2,1.734,20,2.406,22,2.858,56,3.745,57,2.666,94,2.837,114,1.286,245,4.636,475,4.636,489,3.745,530,2.241,776,6.253,839,6.504,878,3.63,937,6.13,940,5.408,1315,4.084,1690,4.82,1785,5.173,1808,5.12,1832,6.504,1841,5.408,1858,5.408,2809,7.194,2832,5.614]],["title/community/rule/#make-a-pull-request",[592,2.31,2855,3.727,3221,3.946]],["text/community/rule/#make-a-pull-request",[2,1.584,20,3.005,21,4.89,23,0.403,53,5.346,69,5.713,101,1.514,126,2.351,219,2.016,619,4.305,837,3.459,884,5,981,3.853,1051,3.112,1391,3.578,1395,4.776,1404,3.497,1410,7.527,1551,4.884,1831,4.499,1845,5.798,1985,6.792,2819,7.055,2831,5.822,2832,5.129,2843,5.271,2847,6.384,2855,5.612,3016,7.055,3221,5.942,3431,7.385,3435,7.827,3436,7.827,3437,7.827]],["title/community/rule/#review-a-pull-request",[2812,4.239,2855,3.727,3221,3.946]],["text/community/rule/#review-a-pull-request",[2,1.74,17,1.454,67,6.164,68,4.509,102,2.452,107,4.307,177,2.102,219,2.214,245,3.461,263,2.941,352,2.358,377,3.149,413,6.846,475,4.652,592,2.842,666,4.086,715,5.492,752,4.371,831,2.254,878,4.829,884,4.086,944,2.399,1014,4.889,1410,6.204,1483,6.846,1519,5.217,1611,4.371,1708,4.586,1825,4.248,1850,3.784,1909,5.371,1974,4.669,2810,5.083,2812,7.921,2814,5.492,2815,5.371,2843,4.307,2863,6.896,2952,5.083,3032,5.083,3073,5.371,3133,5.766,3221,4.856,3281,5.55,3342,7.749,3438,8.112,3439,6.397,3440,6.397,3441,6.397,3442,6.397,3443,6.397,3444,6.397,3445,5.083,3446,6.397,3447,6.397,3448,6.397,3449,5.766,3450,6.397,3451,6.397,3452,6.397]],["title/community/rule/#code-of-conduct",[57,1.929,3040,5.379]],["text/community/rule/#code-of-conduct",[20,2.392,23,0.439,36,3.113,57,3.213,76,5.091,94,2.821,296,5.738,491,4.943,1537,7.154,2602,5.738,2799,8.623,2804,5.911,2814,5.443,2827,6.949,2922,6.949,2932,7.393,2979,7.68,3034,7.68,3040,8.961,3438,8.039,3453,8.52,3454,8.52,3455,8.52]],["title/community/snapshot/",[75,1.81,1314,3.281,1581,3.406]],["text/community/snapshot/",[2,1.8,4,4.566,5,3.156,13,2.28,14,2.699,23,0.626,26,0.817,53,2.122,56,1.701,65,1.554,66,3.449,67,4.302,75,2.089,76,2.325,101,0.753,126,2.672,172,3.057,177,1.279,184,3.3,219,2.29,220,1.141,236,2.623,369,2.279,373,2.924,378,2.486,424,1.915,455,1.941,475,2.105,488,2.158,489,1.701,531,2.216,576,2.855,591,1.843,601,2.517,837,1.72,929,2.517,945,3.901,955,2.491,1068,2.072,1138,3.623,1314,6.55,1363,1.683,1395,4.469,1403,1.81,1500,2.894,1556,2.041,1569,1.996,1581,3.932,1585,3.662,1620,2.924,1800,2.486,1808,2.325,1811,2.4,1816,5.325,1819,2.216,1822,5.467,1823,4.23,1824,5.711,1839,2.79,1857,2.279,1897,3.932,2007,3.882,2016,2.699,2194,3.267,2610,7.134,2975,2.699,3032,3.092,3044,3.507,3179,6.11,3180,5.711,3181,3.174,3182,2.62,3183,7.42,3184,3.267,3185,3.267,3186,3.507,3187,3.507,3188,3.267,3189,3.092,3190,3.507,3191,3.507,3192,3.267,3194,6.542,3206,7.134,3219,3.267,3220,3.267,3221,2.954,3222,5.409,3223,5.207,3224,4.38,3225,5.409,3226,6.388,3227,5.409,3228,5.207,3229,5.207,3230,5.207,3231,3.174,3232,3.788,3233,2.517,3239,3.174,3249,3.507,3348,7.768,3413,3.507,3456,3.019,3457,3.891,3458,6.001]],["title/community/snapshot/#publish-a-snapshot-version",[75,1.81,1314,3.281,1581,3.406]],["text/community/snapshot/#publish-a-snapshot-version",[2,1.669,5,3.162,66,3.883,67,5.912,76,4.928,369,4.83,424,4.059,475,4.462,489,3.605,576,2.86,591,3.907,601,5.334,955,3.424,1138,4.979,1314,5.205,1363,3.567,1395,5.032,1556,4.325,1581,5.403,1585,5.032,1620,2.929,1800,5.268,1808,4.928,1816,5.334,1819,4.696,1839,5.912,2194,6.924,3044,7.433,3179,6.316,3231,6.726,3413,7.433,3456,6.399,3457,8.247]],["title/community/snapshot/#0-prepare-an-empty-script-file",[220,1.152,378,2.51,576,1.363,3179,2.451,3180,2.726]],["text/community/snapshot/#0-prepare-an-empty-script-file",[2,1.486,23,0.564,65,2.933,66,3.457,67,5.264,101,1.42,126,3.403,172,4.794,455,3.663,531,4.181,576,3.264,837,3.245,929,4.749,955,3.048,1068,3.91,1138,4.433,1395,4.48,1403,3.416,1569,3.767,1585,4.48,1620,3.343,1811,4.53,1816,4.749,1857,4.301,1897,6.167,2007,6.088,2975,5.094,3032,5.834,3179,6.481,3181,5.988,3183,9.876,3184,6.165,3185,6.165,3186,6.618,3187,6.618,3188,6.165,3189,5.834,3190,6.618,3191,6.618,3192,6.165]],["title/community/snapshot/#1-upload-snapshot-versions",[75,1.558,219,1.152,1314,2.825,2016,3.105]],["text/community/snapshot/#1-upload-snapshot-versions",[2,1.782,4,5.117,5,3.375,13,2.874,14,3.687,23,0.635,26,1.03,53,2.899,56,2.323,66,2.502,177,1.747,184,4.16,219,2.47,236,3.306,373,3.407,488,2.72,945,4.689,1314,6.649,1395,3.243,1500,3.953,1620,1.888,1816,4.892,1822,6.369,1823,5.332,1824,6.654,2610,7.996,3179,3.316,3180,6.108,3182,3.579,3194,7.621,3206,7.996,3219,4.462,3220,4.462,3221,4.035,3222,6.817,3223,6.562,3224,5.52,3225,6.817,3226,7.442,3227,6.817,3228,6.562,3229,6.562,3230,6.562,3232,4.774,3233,3.438,3239,4.335,3249,4.79,3348,9.05,3458,7.563]],["title/community/vote/",[5,2.377,2935,3.743]],["text/community/vote/",[2,2.22,4,3.896,5,2.722,20,1.622,21,3.79,23,0.557,31,4.43,35,1.362,36,3.182,47,1.28,52,2.293,56,3.104,57,2.209,60,1.158,65,0.862,70,4.106,73,5.192,75,2.645,77,3.778,78,6.672,79,1.605,83,1.674,94,0.714,96,0.964,97,1.628,100,1.473,101,1.117,135,2.413,172,1.099,177,1.218,179,2.042,219,1.488,232,1.362,245,1.167,246,1.131,252,1.85,263,2.239,266,1.149,273,1.992,281,0.838,377,1.062,397,1.069,402,1.197,446,1.149,450,1.264,455,1.076,467,1.149,475,1.167,530,1.702,531,1.229,576,2.462,582,1.958,591,1.755,592,0.959,593,1.069,604,1.091,620,1.022,621,2.875,700,1.378,738,2.428,745,1.004,838,1.395,847,1.459,878,2.063,884,3.111,887,1.811,919,1.303,938,2.188,955,1.538,959,0.813,981,1.062,982,2.428,1051,0.858,1054,2.875,1070,2.367,1138,1.303,1286,1.276,1315,1.766,1363,1.602,1391,1.693,1456,1.497,1457,1.497,1462,1.547,1471,1.453,1492,2.237,1556,3.411,1620,2.052,1628,1.289,1689,1.395,1690,2.265,1691,1.605,1708,1.547,1778,1.638,1779,3.139,1785,1.303,1800,3.111,1810,1.811,1811,3.564,1820,2.237,1822,2.46,1823,1.521,1824,1.497,1839,1.547,1857,1.264,1897,3.19,1898,1.575,1939,2.704,1986,1.638,1991,1.575,2007,1.395,2027,3.491,2063,1.378,2283,1.638,2608,1.638,2715,1.547,2786,2.17,2804,2.57,2805,2.875,2814,1.378,2818,3.111,2840,2.286,2879,5.863,2898,1.945,2935,4.587,2948,1.76,2967,1.575,2975,1.497,3048,1.945,3080,1.474,3083,2.036,3179,4.741,3182,2.495,3184,1.811,3185,1.811,3192,1.811,3193,6.197,3194,6.037,3199,5.461,3200,1.872,3201,1.872,3224,1.575,3226,2.875,3240,5.791,3247,6.161,3248,1.575,3257,3.339,3258,3.339,3259,3.215,3260,3.215,3261,7.987,3264,3.215,3265,3.215,3272,1.872,3273,3.215,3275,1.453,3276,1.945,3282,1.714,3350,4.088,3351,3.022,3377,1.945,3378,1.945,3385,3.339,3459,3.496,3460,2.157,3461,2.157,3462,2.157,3463,2.157,3464,2.157,3465,2.157,3466,1.945,3467,8.019,3468,9.951,3469,5.777,3470,2.157,3471,2.157,3472,2.157,3473,3.339,3474,2.157,3475,2.157,3476,4.869,3477,2.157,3478,3.705,3479,3.705,3480,3.705,3481,3.705,3482,2.157,3483,3.705,3484,3.705,3485,3.705,3486,3.705,3487,3.705,3488,3.705,3489,3.705,3490,3.705,3491,3.705,3492,3.705,3493,3.705,3494,3.705,3495,3.705,3496,3.705,3497,3.705,3498,3.705,3499,3.705,3500,3.705,3501,3.705,3502,3.705,3503,3.705,3504,2.157,3505,3.705,3506,3.705,3507,2.157,3508,2.157,3509,1.811]],["title/community/vote/#vote-a-sedona-release",[2,1.052,5,1.993,2935,3.138]],["text/community/vote/#vote-a-sedona-release",[2,1.978,5,4.001,20,2.435,23,0.334,52,3.05,56,3.79,57,2.697,70,4.089,77,5.026,78,4.818,94,2.145,101,1.253,219,2.233,232,4.089,263,2.978,377,3.188,402,3.593,446,3.45,475,3.505,530,1.694,592,2.878,738,5.681,847,2.552,884,4.138,887,5.439,919,3.911,938,4.391,955,2.689,1051,2.575,1054,5.026,1070,5.539,1138,3.911,1492,3.911,1556,5.126,1620,2.301,1690,3.013,1820,3.911,1857,3.794,1898,4.728,1939,4.728,2283,4.917,2786,5.078,2805,5.026,2814,4.138,2840,5.349,2935,6.76,2948,5.283,2975,4.494,3048,5.838,3080,4.426,3083,6.112,3179,4.041,3273,7.523,3275,4.362,3276,5.838,3282,5.147,3459,6.112,3460,6.477,3461,6.477,3462,6.477,3463,6.477,3464,6.477]],["title/community/vote/#install-necessary-software",[1779,2.147,1785,3.138,2804,3.606]],["text/community/vote/#install-necessary-software",[21,5.437,23,0.595,36,2.182,75,3.927,97,4.099,101,1.4,266,3.855,467,3.855,593,3.587,604,3.661,620,3.429,1363,4.034,1462,5.19,1492,4.37,1556,3.796,1689,4.682,1691,5.385,1779,4.66,1811,6.723,1820,4.37,1822,4.807,1839,5.19,1986,5.495,2027,7.398,2804,5.022,3261,6.938,3350,8.664,3351,7.607,3377,6.524,3378,6.524,3459,6.83,3465,7.239,3466,6.524]],["title/community/vote/#run-the-verify-script",[70,3.281,1620,1.846,3179,3.243]],["text/community/vote/#run-the-verify-script",[2,2.283,4,4.404,5,1.1,20,1.322,23,0.53,31,5.128,35,1.811,36,3.353,47,1.626,52,1.351,56,2.617,57,1.862,60,1.54,65,1.146,70,3.779,73,5.932,75,0.999,77,3.653,78,7.186,79,2.134,83,2.226,96,1.282,100,1.872,101,0.91,135,2.966,172,1.461,177,1.547,179,2.51,219,1.212,245,1.552,246,1.505,252,2.218,263,1.319,273,2.449,281,1.115,397,1.422,450,1.68,455,1.431,530,1.812,531,1.634,576,2.076,582,2.488,591,2.23,621,3.653,700,1.833,838,1.856,847,1.13,878,2.536,884,1.833,955,1.191,959,1.081,981,1.412,982,3.084,1054,2.226,1286,1.697,1315,1.368,1391,2.152,1456,1.99,1457,1.99,1471,1.932,1556,1.505,1620,1.672,1690,2.19,1708,2.057,1778,2.178,1779,1.185,1800,3.824,1810,2.409,1822,1.905,1823,2.022,1824,1.99,1897,3.922,1991,2.094,2007,1.856,2063,1.833,2608,2.178,2715,2.057,2818,3.952,2879,6.894,2898,2.586,2967,2.094,3179,4.772,3182,3.17,3184,2.409,3185,2.409,3192,2.409,3193,7.081,3194,6.898,3199,6.422,3200,2.489,3201,2.489,3224,2.094,3226,3.653,3240,6.703,3247,7.131,3248,2.094,3257,4.243,3258,4.243,3259,4.084,3260,4.084,3261,8.334,3264,4.084,3265,4.084,3272,2.489,3385,4.243,3467,9.064,3468,10.717,3469,6.927,3470,2.869,3471,2.869,3472,2.869,3473,4.243,3474,2.869,3475,2.869,3476,5.986,3477,2.869,3478,4.707,3479,4.707,3480,4.707,3481,4.707,3482,2.869,3483,4.707,3484,4.707,3485,4.707,3486,4.707,3487,4.707,3488,4.707,3489,4.707,3490,4.707,3491,4.707,3492,4.707,3493,4.707,3494,4.707,3495,4.707,3496,4.707,3497,4.707,3498,4.707,3499,4.707,3500,4.707,3501,4.707,3502,4.707,3503,4.707,3504,2.869,3505,4.707,3506,4.707,3507,2.869]],["title/community/vote/#check-files-manually",[21,2.593,576,1.803,1628,3.106]],["text/community/vote/#check-files-manually",[21,5.368,52,4.297,56,3.99,57,2.839,75,3.177,263,4.196,576,3.732,745,4.246,884,5.83,1315,4.35,1939,6.661,2805,7.081,3508,9.126,3509,7.663]],["title/setup/cluster/",[26,0.61,457,1.771,745,2.082,1772,4.475]],["text/setup/cluster/",[2,1.429,6,2.581,17,1.605,20,1.357,23,0.503,26,1.562,36,2.128,47,2.439,52,3.324,65,2.82,66,2.275,69,3.526,179,2.026,221,2.515,222,2.41,243,1.781,284,2.635,298,4.51,349,1.957,352,3.076,369,2.83,374,3.265,394,3.208,403,2.289,457,3.632,467,2.573,470,3.125,474,3.675,476,2.382,478,5.397,489,2.112,526,5.61,529,2.515,530,1.264,576,2.448,592,2.147,593,2.394,601,3.125,653,2.751,675,2.221,700,3.086,745,3.284,752,4.824,781,3.208,825,2.98,831,1.702,838,3.125,882,2.208,883,3.526,967,2.83,977,3.526,981,2.378,1014,2.275,1066,2.444,1104,4.567,1138,2.917,1228,2.657,1251,3.526,1315,3.365,1497,4.135,1569,2.478,1594,4.514,1598,2.303,1621,4.347,1643,3.125,1658,3.594,1689,3.125,1710,3.352,1748,4.977,1773,4.355,1774,5.252,1775,5.928,1776,6.364,1777,4.355,1778,3.667,1779,1.996,1780,4.355,1781,3.526,1782,3.464,1783,4.355,1784,3.301,1785,2.917,1786,4.355,1787,4.355,1788,6.364,1789,4.355,1790,6.364,1791,6.364,1792,4.355,1793,4.355,1794,5.928,1795,5.478,1796,3.839,1797,3.301,1798,6.364,1799,4.355,1800,3.086,1801,4.355,1802,3.94,1803,3.166,1804,4.355,1805,3.526,1806,2.98,1807,4.056,1808,2.887,1809,3.125,1810,4.056,1811,2.98,1812,4.355,1813,4.355]],["title/setup/cluster/#set-up-your-apache-spark-cluster",[26,0.535,36,1.184,457,1.555,745,1.828,1621,1.861]],["text/setup/cluster/#set-up-your-apache-spark-cluster",[23,0.496,26,1.513,52,5.231,1066,4.876,1138,5.821]],["title/setup/cluster/#preliminary",[1773,6.92]],["text/setup/cluster/#preliminary",[2,1.542,6,2.786,17,1.732,20,1.508,23,0.277,26,1.481,47,2.632,65,3.044,66,2.529,69,3.92,179,2.252,221,2.796,222,2.679,243,1.98,284,2.929,298,4.867,349,2.112,352,3.265,369,3.146,394,3.566,403,2.544,457,3.504,467,2.86,470,3.474,474,3.966,476,2.571,478,5.728,489,2.348,526,6.054,529,2.796,530,1.405,576,2.642,592,2.386,593,2.661,653,3.058,675,2.469,700,3.431,745,2.498,752,5.206,781,3.566,825,3.313,831,1.892,838,3.474,882,2.455,883,3.92,967,3.146,977,3.92,981,2.643,1014,2.529,1104,4.928,1251,3.92,1497,4.463,1569,2.755,1594,4.791,1598,2.56,1621,2.544,1643,3.474,1658,3.995,1689,3.474,1710,3.726,1748,5.371,1774,5.668,1775,6.397,1776,6.867,1777,4.841,1778,4.077,1779,2.219,1780,4.841,1781,3.92,1782,3.85,1783,4.841,1784,3.669,1785,3.242,1786,4.841,1787,4.841,1788,6.867,1789,4.841,1790,6.867,1791,6.867,1792,4.841,1793,4.841,1794,6.397,1795,5.912,1796,4.267,1797,3.669,1798,6.867,1799,4.841,1800,3.431,1801,4.841,1802,4.38,1803,3.519,1804,4.841,1805,3.92,1806,3.313,1807,4.509,1808,3.209]],["title/setup/cluster/#start-your-cluster",[374,2.867,1621,2.937]],["text/setup/cluster/#start-your-cluster",[26,1.476,36,2.784,374,4.271,601,5.974,1228,5.08,1315,5.165,1621,4.375,1809,5.974,1810,7.755,1811,5.698,1812,8.325,1813,8.325]],["title/setup/compile/",[57,1.929,1690,2.884]],["text/setup/compile/",[2,1.943,3,1.683,13,2.878,14,1.954,15,3.888,20,1.659,22,0.94,23,0.517,26,0.805,36,1.398,50,0.446,52,2.782,53,1.536,54,1.536,56,3.311,57,2.679,58,1.778,60,2.489,61,1.066,62,1.634,63,4.161,64,2.019,65,1.852,68,3.269,69,2.056,75,1.614,82,2.185,86,2.469,92,2.799,93,1.719,94,0.932,97,2.597,101,0.545,102,1.08,114,0.423,129,1.141,135,1.396,177,0.926,178,1.81,186,1.295,187,1.634,202,1.634,263,1.295,270,1.924,377,4.589,392,1.719,424,1.386,457,1.835,467,1.5,476,0.95,480,1.666,530,1.213,566,3.265,576,1.608,592,2.626,593,2.928,620,1.334,696,1.287,745,2.749,847,1.826,875,3.937,927,1.845,937,3.496,944,1.056,955,1.925,967,1.65,987,2.019,999,3.979,1020,1.619,1049,1.65,1119,2.238,1228,3.25,1243,1.231,1271,1.757,1274,3.168,1286,1.666,1315,3.883,1363,2.556,1366,1.147,1405,2.489,1462,2.019,1465,5.078,1598,1.342,1600,1.737,1620,2.69,1681,2.365,1687,1.87,1689,1.822,1690,4.76,1711,1.488,1747,2.138,1779,4.579,1808,4.868,1809,1.822,1811,1.737,1816,1.822,1818,2.138,1819,1.604,1820,3.568,1821,4.064,1822,5.41,1823,5.743,1824,5.254,1825,1.87,1826,2.019,1827,2.539,1828,8.13,1829,2.539,1830,6.174,1831,1.619,1832,2.138,1836,1.562,1843,2.362,1898,2.056,2002,1.822,2007,1.822,2019,3.598,2021,5.429,2022,2.365,2023,6.473,2027,3.324,2165,3.449,2626,2.238,2774,3.684,2844,4.237,3080,1.924,3147,2.238,3212,2.095,3232,3.73,3233,2.999,3238,4.179,3239,2.297,3245,2.365,3248,4.313,3251,2.238,3255,2.539,3330,6.174,3352,6.359,3353,2.539,3393,3.598,3466,2.539,3509,2.365,3510,2.816,3511,4.237,3512,6.174,3513,2.816,3514,2.816,3515,2.238,3516,2.365,3517,2.816,3518,2.539,3519,2.539,3520,2.816,3521,2.816,3522,2.816,3523,6.85,3524,2.816,3525,2.816,3526,2.444,3527,2.297,3528,2.816,3529,2.816,3530,2.816,3531,2.816]],["title/setup/compile/#compile-sedona-source-code",[2,0.906,56,1.956,57,1.392,1690,2.082]],["text/setup/compile/#compile-sedona-source-code",[]],["title/setup/compile/#compile-scala-java-source-code",[13,1.331,23,0.18,56,1.531,57,1.089,97,1.539,1690,1.629]],["text/setup/compile/#compile-scala-java-source-code",[2,1.868,13,2.202,15,2.202,20,2.257,22,1.933,26,0.789,36,2.422,50,0.917,57,1.803,58,3.658,62,3.362,63,4.267,65,2.315,92,4.852,97,2.547,102,2.222,178,2.262,270,3.959,377,5.152,392,3.536,424,2.852,467,3.086,530,1.516,566,2.762,576,2.01,592,4.1,593,4.572,696,2.649,745,2.696,847,3.166,875,5.727,927,3.797,944,2.173,1228,3.187,1243,2.533,1271,3.615,1274,5.491,1315,3.831,1363,3.991,1462,4.155,1465,6.39,1598,2.762,1600,3.575,1687,3.848,1689,3.748,1690,5.038,1711,3.062,1779,3.812,1811,3.575,1818,4.399,1819,3.3,1820,4.852,1821,4.971,1822,6.127,1823,6.504,1824,5.575,1826,4.155,1843,4.094,2027,4.155,3232,3.658,3233,3.748,3466,5.223,3510,5.795,3511,5.762,3512,5.223]],["title/setup/compile/#compile-with-different-targets",[620,2.462,1020,2.987,1690,2.418]],["text/setup/compile/#compile-with-different-targets",[2,1.617,13,3.773,14,5.543,15,3.036,23,0.511,26,1.352,63,4.591,129,3.237,263,3.673,480,4.726,566,3.809,1779,4.462,1821,3.986,1822,7.173,1823,7.614,1824,7.494,1825,5.306,2626,6.349,3232,6.267,3233,5.168,3238,8.948,3239,6.517,3511,5.728,3512,8.948,3513,7.99]],["title/setup/compile/#download-staged-jars",[52,2.447,63,2.404,987,3.727]],["text/setup/compile/#download-staged-jars",[2,1.837,52,4.272,53,4.949,60,4.87,61,3.433,63,4.959,64,6.505,68,6.396,69,6.622,86,4.832,101,1.755,1119,7.209,1809,5.868,1898,6.622,3080,6.199,3514,9.073]],["title/setup/compile/#run-python-test",[15,1.975,377,2.559,1620,1.846]],["text/setup/compile/#run-python-test",[2,1.648,3,3.529,13,2.244,15,4.44,57,1.837,75,2.835,82,4.583,97,2.596,114,0.886,135,2.926,177,1.941,178,2.305,186,2.715,187,3.426,202,3.426,377,4.008,457,3.223,530,1.545,566,3.881,745,3.788,1286,3.494,1315,2.815,1366,2.405,1620,2.892,1681,4.959,1690,2.747,1779,4.769,1836,3.276,2002,3.82,2007,3.82,2019,6.318,2021,4.234,2022,4.959,2023,8.656,2027,4.234,2165,6.057,2844,6.682,3212,4.393,3245,4.959,3248,6.802,3251,4.693,3255,5.323,3330,9.054,3352,8.848,3353,5.323,3393,6.318,3512,5.323,3515,4.693,3516,4.959,3517,5.906,3518,5.323,3519,5.323,3520,5.906,3521,5.906,3522,5.906,3523,10.045,3524,5.906,3525,5.906,3526,5.124,3527,4.817,3528,5.906,3529,5.906]],["title/setup/compile/#compile-the-documentation",[937,3.667,1690,2.884]],["text/setup/compile/#compile-the-documentation",[52,4.483,60,5.111,65,3.803,68,6.712,86,5.071,999,7.428,1808,6.591]],["title/setup/compile/#mkdocs-website",[1808,3.704,1828,4.926]],["text/setup/compile/#mkdocs-website",[2,1.796,20,1.882,23,0.457,54,3.656,56,4.346,57,3.093,93,4.09,94,2.219,377,3.299,476,2.262,576,2.324,937,5.247,955,3.683,967,3.926,999,4.514,1049,3.926,1228,4.879,1315,4.739,1405,4.761,1620,3.151,1690,4.126,1747,5.088,1779,4.546,1808,5.94,1816,4.336,1820,4.047,1821,3.344,1827,6.042,1828,9.647,1829,6.042,1830,9.536,1831,3.852,1832,5.088,2021,7.585,2774,7.048,3147,5.326,3509,5.628,3530,6.703,3531,6.703]],["title/setup/databricks/",[1779,2.561,3532,5.205]],["text/setup/databricks/",[2,2.285,3,4.272,4,3.474,5,0.838,6,1.369,8,1.289,12,0.834,13,0.83,15,3.202,22,0.729,23,0.621,26,1.316,36,1.482,38,4.892,39,3.906,41,2.976,44,1.023,50,0.922,51,2.467,52,1.764,57,1.165,61,1.417,63,3.73,75,2.282,89,1.563,101,1.479,110,0.724,126,2.297,129,1.992,177,0.718,178,0.853,179,0.916,188,2.454,219,0.563,245,2.66,311,1.164,335,0.761,366,2.393,374,1.732,403,2.76,411,1.016,432,1.736,446,2.618,467,3.103,476,2.212,500,2.454,530,0.98,531,2.133,566,2.777,576,0.758,577,1.516,580,3.465,594,1.64,601,4.24,616,1.055,620,1.035,702,1.137,717,1.736,736,1.566,745,2.287,782,1.835,821,1.782,936,3.25,950,2.078,951,2.598,952,2.454,953,2.559,954,2.786,959,1.411,960,1.969,961,1.292,962,2.843,963,2.261,967,4.479,972,1.969,980,3.981,1001,3.923,1050,1.54,1054,2.906,1056,1.625,1068,1.164,1070,1.396,1136,3.055,1137,1.736,1243,2.149,1271,1.363,1286,1.292,1363,1.62,1366,0.89,1402,2.337,1463,1.432,1498,1.121,1522,1.068,1569,1.121,1572,2.311,1582,3,1583,1.113,1620,1.33,1621,3.992,1628,1.306,1638,2.598,1645,3.906,1690,2.71,1717,2.559,1779,3.911,1836,4.474,1892,1.595,1905,1.979,1912,1.659,1953,1.493,1955,1.595,1966,1.835,2007,1.413,2020,2.598,2175,1.212,2179,1.835,2232,3.145,2371,1.969,2785,1.659,2786,2.194,2809,1.835,2811,1.969,2814,1.396,2922,4.009,2970,1.969,2981,1.969,3012,1.969,3031,1.659,3074,1.896,3081,5.503,3107,1.969,3179,5.623,3182,1.471,3189,3.906,3226,1.695,3232,1.379,3241,3.25,3245,1.835,3251,4.629,3316,4.521,3327,5.251,3328,4.265,3365,4.431,3473,1.969,3532,6.773,3533,2.185,3534,2.185,3535,5.908,3536,1.835,3537,7.595,3538,3.534,3539,2.185,3540,2.185,3541,2.185,3542,2.185,3543,2.185,3544,2.372,3545,2.372,3546,7.127,3547,2.372,3548,2.372,3549,2.372,3550,2.372,3551,4.638,3552,1.566,3553,1.695,3554,1.835,3555,1.695,3556,1.595,3557,4.638,3558,2.185,3559,2.185,3560,3.055,3561,1.736,3562,2.185,3563,3.534,3564,3.746,3565,6.554,3566,2.185,3567,3.746,3568,2.185,3569,2.185,3570,2.185,3571,3.746,3572,3.746,3573,3.746,3574,2.185,3575,2.185,3576,4.916,3577,3.746,3578,2.185,3579,2.185,3580,2.185,3581,3.746,3582,4.431,3583,3.376,3584,2.185,3585,2.185,3586,2.185]],["title/setup/databricks/#community-edition-free-tier",[2814,2.859,3081,3.758,3533,4.475,3534,4.475]],["text/setup/databricks/#community-edition-free-tier",[2,2.194,15,3.51,63,4.271,101,1.786,411,4.296,467,4.919,476,3.117,1779,3.816,3031,7.011,3189,7.339,3532,9.098,3535,8.325]],["title/setup/databricks/#advanced-editions",[980,4.236,3081,5.205]],["text/setup/databricks/#advanced-editions",[2,2.221,4,3.228,5,2.548,23,0.593,26,1.568,38,7.405,39,7.008,41,5.28,50,1.052,51,2.845,61,3.337,75,3.446,89,3.68,101,1.285,188,4.354,245,3.595,311,3.539,366,4.245,432,5.28,500,4.354,531,3.784,620,3.148,717,5.28,736,4.764,821,5.42,972,5.99,1050,4.684,1068,3.539,1137,5.28,1582,5.381,1645,7.865,1690,4.905,1717,4.54,1892,4.85,1966,5.579,2981,5.99,3012,5.99,3226,5.156,3232,4.194,3532,5.579,3536,5.579,3537,8.922,3538,6.27,3539,6.645,3540,6.645,3541,6.645,3542,6.645,3543,6.645]],["title/setup/databricks/#install-sedona-from-the-web-ui",[2,0.906,1779,1.849,3189,3.556,3535,4.034]],["text/setup/databricks/#install-sedona-from-the-web-ui",[2,1.445,4,3.468,8,2.456,15,3.512,23,0.592,26,0.972,36,2.152,101,1.38,110,1.38,129,2.892,177,2.346,178,2.786,179,2.993,219,1.838,245,3.862,335,2.485,403,3.381,530,1.867,566,3.402,594,2.381,745,4.3,951,3.772,952,4.677,953,3.716,954,5.31,967,5.414,980,4.877,1136,5.822,1363,3.087,1522,3.49,1621,3.381,1638,4.952,1779,3.818,1836,5.127,1905,3.772,2020,4.952,2785,5.419,2811,6.434,3081,5.993,3179,4.453,3537,8.331,3538,6.735,3546,5.822,3551,8.721,3552,5.118,3553,5.539,3554,5.993,3555,5.539,3556,5.21,3557,8.721]],["title/setup/databricks/#initialise",[3558,7.678]],["text/setup/databricks/#initialise",[2,2.01,13,3.036,15,3.036,23,0.638,26,1.352,36,2.408,50,1.265,51,2.577,57,2.486,374,3.695,594,2.665,936,6.932,959,3.74,960,7.202,961,4.726,962,7.537,963,5.994,1583,4.07,1620,2.838,1621,3.785,1779,3.301,1836,4.432,3559,7.99,3560,8.097]],["title/setup/databricks/#pure-sql-environment",[50,0.823,1286,3.075,3561,4.13]],["text/setup/databricks/#pure-sql-environment",[2,2.288,50,1.403,51,3.412,101,1.714,446,4.72,476,2.991,530,2.319,782,7.442,936,7.691,1271,5.53,1621,4.199,1779,3.662,1836,4.916,2175,4.916,3179,5.53,3546,7.229,3562,8.864,3563,8.363]],["title/setup/databricks/#install-sedona-via-init-script-for-dbrs-73",[2,0.582,601,1.86,1779,1.188,3179,1.794,3537,2.592,3546,2.346,3557,2.713,3587,3.122]],["text/setup/databricks/#install-sedona-via-init-script-for-dbrs-73",[2,2.187,3,5.633,4,1.905,6,2.207,8,1.349,15,3.141,22,1.308,23,0.619,26,1.003,36,1.182,44,1.835,51,1.947,52,2.842,57,1.22,63,4.359,126,2.95,129,2.446,245,2.121,374,1.813,403,1.857,446,2.088,467,3.215,476,1.323,500,2.569,531,2.233,566,3.508,576,1.36,577,2.72,580,5.188,601,4.76,616,1.893,702,2.041,950,3.348,951,3.19,952,2.569,953,3.142,954,2.917,967,5.228,980,4.124,1001,5.566,1056,2.917,1243,3.217,1363,1.696,1366,1.596,1402,3.766,1498,2.011,1569,2.011,1572,2.419,1582,2.392,1620,1.393,1621,4.466,1628,2.343,1779,3.415,1836,4.082,1905,2.072,1953,2.679,2007,2.536,2020,2.72,2232,5.068,2371,3.534,2786,3.536,2809,3.292,2922,4.923,3074,3.402,3081,5.068,3107,3.534,3179,6.127,3182,2.64,3241,5.237,3245,3.292,3251,6.568,3316,6.414,3327,7.45,3328,6.386,3365,6.633,3473,3.534,3535,5.441,3546,7.688,3551,3.699,3563,3.699,3564,6.036,3565,8.925,3566,3.921,3567,6.036,3568,3.921,3569,3.921,3570,3.921,3571,6.036,3572,6.036,3573,6.036,3574,3.921,3575,3.921,3576,7.36,3577,6.036,3578,3.921,3579,3.921,3580,3.921,3581,6.036,3582,6.633,3583,5.441,3584,3.921,3585,3.921,3586,3.921]],["title/setup/install-python/",[2,1.052,15,1.975,1779,2.147]],["text/setup/install-python/",[2,2.299,3,2.074,4,1.686,5,2.104,13,2.085,15,4.244,20,0.974,23,0.632,26,1.278,36,2.332,51,2.196,52,1.634,53,2.993,54,1.893,55,2.304,56,2.975,57,1.08,62,2.013,63,3.148,75,1.911,82,2.693,89,1.448,96,3.041,101,1.733,114,1.021,129,1.406,178,1.355,219,0.894,241,2.095,258,2.165,261,2.337,263,1.595,266,1.848,273,1.42,281,1.348,335,1.208,411,1.614,452,2.869,459,1.559,464,1.708,476,2.297,489,1.517,526,2.757,530,1.435,545,1.878,560,2.407,562,1.501,566,4.017,576,1.203,583,1.708,591,1.644,592,1.542,593,1.72,695,2.634,703,2.407,733,1.848,836,1.806,847,1.367,859,2.337,884,2.217,949,1.941,950,3.775,951,1.834,953,1.806,956,3.313,958,1.941,1001,2.337,1014,1.634,1024,2.117,1137,2.757,1280,2.634,1286,3.246,1315,3.688,1344,1.976,1345,3.184,1363,1.501,1364,1.878,1366,2.234,1466,2.165,1522,2.683,1585,2.117,1620,2.418,1628,2.074,1690,1.614,1779,4.238,1785,2.095,1803,2.274,1809,3.55,1811,3.385,1817,2.488,1821,3.396,1836,3.044,1843,2.795,1971,2.533,1972,3.274,1986,2.634,2002,5.004,2007,4.403,2019,5.281,2020,3.807,2021,3.934,2027,2.488,2028,2.581,2743,2.634,2786,3.214,3080,2.371,3180,2.407,3212,4.082,3232,2.19,3233,2.245,3248,2.533,3251,2.757,3275,3.695,3316,2.693,3393,4.258,3456,4.258,3511,2.488,3515,5.408,3516,4.607,3518,3.128,3519,3.128,3552,2.488,3553,2.693,3554,2.914,3555,2.693,3556,2.533,3588,4.946,3589,2.83,3590,3.768,3591,3.768,3592,3.47,3593,3.47,3594,3.47,3595,2.533,3596,3.47,3597,3.011,3598,3.47]],["title/setup/install-python/#install-sedona",[2,1.255,1779,2.561]],["text/setup/install-python/#install-sedona",[2,2.417,15,4.236,23,0.553,26,1.464,36,2.745,53,3.805,54,3.805,55,4.633,56,3.981,57,2.17,75,2.429,89,2.911,101,1.349,129,2.827,258,4.353,266,3.715,452,2.94,530,1.825,695,5.296,703,4.84,733,3.715,836,3.632,1137,5.543,1280,5.296,1366,2.84,1620,2.478,1779,4.811,1809,4.512,1817,5.002,1821,3.48,1972,6.582,1986,5.296,2002,5.89,2020,6.317,2021,6.529,2027,5.002,2028,5.189,3248,5.092,3592,6.976]],["title/setup/install-python/#prepare-python-adapter-jar",[15,1.701,63,2.07,566,2.133,3180,3.105]],["text/setup/install-python/#prepare-python-adapter-jar",[2,2.036,3,3.111,4,2.53,5,2.857,13,2.832,15,3.976,20,1.462,23,0.643,26,1.186,36,1.57,51,2.404,52,2.452,53,2.84,56,2.276,62,3.021,63,2.408,75,1.813,96,3.889,101,1.945,114,0.781,178,2.032,219,1.341,241,3.144,263,2.394,335,1.813,411,2.422,452,3.141,464,2.563,476,1.757,489,2.276,526,4.137,530,1.362,545,2.817,560,3.612,562,2.252,566,4.149,576,1.806,591,2.467,592,2.314,593,2.58,847,2.051,859,3.506,884,3.326,949,2.913,950,4.828,951,2.752,953,2.711,956,4.5,958,2.913,1001,3.506,1014,2.452,1024,3.177,1315,4.149,1344,2.965,1345,4.324,1363,2.252,1364,2.817,1466,3.249,1522,3.645,1585,3.177,1690,2.422,1809,3.368,1836,2.888,1971,3.8,2007,4.821,2019,5.783,2743,3.953,3232,3.287,3233,3.368,3251,4.137,3316,4.04,3511,3.733,3552,3.733,3553,4.04,3554,4.372,3555,4.04,3556,3.8,3593,5.207,3594,5.207,3595,3.8,3596,5.207,3597,4.518]],["title/setup/install-python/#setup-environment-variables",[1286,3.075,3212,3.867,3456,4.033]],["text/setup/install-python/#setup-environment-variables",[2,1.617,15,4.105,23,0.556,63,3.695,82,6.2,114,1.49,281,3.105,476,2.696,566,3.809,1286,4.726,1315,3.809,1620,3.527,1628,4.774,1811,6.125,1821,4.953,2007,5.168,2019,6.2,2786,4.68,3212,5.943,3275,5.38,3393,7.703,3456,6.2,3515,8.583,3516,8.336,3518,7.202,3519,7.202,3588,7.202,3598,7.99]],["title/setup/install-r/",[2,1.052,42,2.39,1779,2.147]],["text/setup/install-r/",[2,2.1,4,2.856,10,1.984,12,1.067,17,2.359,21,1.395,22,0.933,23,0.633,26,1.391,36,2.447,42,3.135,44,1.308,47,2.606,50,0.931,51,1.897,61,1.058,66,2.17,71,3.061,100,1.112,101,1.137,105,0.518,110,0.541,111,0.468,114,0.42,126,2.049,129,1.133,135,1.385,138,1.341,139,1.424,159,1.293,166,1.622,177,0.919,178,1.091,186,1.285,187,1.622,188,1.832,219,1.187,232,1.765,235,2.399,243,1.699,273,2.405,281,1.791,334,3.181,349,2.091,355,1.35,370,1.973,403,1.325,411,1.301,452,3.421,455,1.395,456,4.207,476,0.943,489,1.222,491,1.622,529,1.455,530,1.206,532,1.983,545,1.513,555,1.466,577,3.197,585,1.765,592,1.242,604,1.414,641,1.044,669,1.971,672,2.122,675,2.703,676,1.809,750,1.809,781,1.857,831,0.985,833,1.525,873,1.765,882,2.107,917,2.122,930,1.857,944,1.049,948,3.061,953,1.455,955,1.913,959,1.736,970,1.765,981,2.894,1001,1.883,1014,2.17,1066,1.414,1238,2.569,1240,1.385,1243,1.222,1244,2.041,1254,2.754,1285,2.348,1300,1.551,1366,1.876,1412,2.041,1499,6.038,1554,5.82,1583,2.995,1598,1.333,1613,2.348,1617,1.424,1620,0.993,1635,2.348,1656,1.94,1668,1.91,1680,2.041,1717,1.91,1759,2.222,1797,1.91,1825,1.857,1836,3.783,1843,1.424,1856,2.52,1870,1.654,1905,1.478,1907,3.061,1922,2.348,1926,2.041,1952,2.348,1971,3.364,1981,1.744,2048,3.995,2143,3.02,2168,3.999,2175,1.551,2602,3.959,2640,2.222,2713,2.348,2722,2.348,2738,3.87,2783,2.122,2941,2.426,3429,2.52,3515,5.419,3552,4.215,3553,4.562,3554,2.348,3555,2.169,3556,2.041,3599,6.299,3600,2.796,3601,2.796,3602,6.811,3603,2.796,3604,2.796,3605,2.796,3606,2.796,3607,4.795,3608,2.796,3609,2.796,3610,2.796,3611,4.795,3612,2.796,3613,2.796,3614,2.52,3615,2.796,3616,2.796,3617,2.796,3618,5.299,3619,2.796,3620,2.52,3621,2.52,3622,5.547,3623,4.609,3624,4.609,3625,2.796,3626,2.796,3627,2.796,3628,2.796,3629,2.796,3630,2.796,3631,2.796,3632,2.796,3633,3.662,3634,4.609,3635,2.796,3636,2.796,3637,2.796,3638,2.796,3639,2.796,3640,2.796,3641,2.796,3642,2.796,3643,2.796]],["title/setup/install-r/#introduction",[105,1.423]],["text/setup/install-r/#introduction",[2,2.165,10,2.639,12,1.652,17,2.603,23,0.504,26,1.065,36,2.622,42,3.999,44,2.026,47,3.221,50,1.03,51,2.523,61,1.638,71,4.322,100,1.721,101,1.512,110,0.837,111,0.725,126,1.3,129,1.754,138,2.076,139,2.205,159,2.002,166,2.511,235,3.388,243,2.4,273,1.771,281,2.529,334,3.521,349,2.584,355,2.09,370,2.786,411,2.014,452,3.666,456,4.825,489,1.892,529,2.253,530,1.702,532,2.8,545,2.342,555,2.27,577,3.003,585,2.732,592,1.923,669,3.051,672,3.286,675,1.99,676,2.8,750,2.8,831,1.525,833,2.361,873,2.732,882,2.975,917,3.286,930,2.874,959,2.452,981,3.849,1014,2.038,1066,2.189,1238,3.276,1240,2.145,1300,2.401,1412,3.159,1499,3.22,1554,6.686,1613,3.634,1617,2.205,1656,3.003,1668,2.958,1680,3.159,1759,3.44,1797,2.958,1856,3.902,1870,2.561,1905,2.288,1907,4.322,1926,3.159,2143,2.836,2168,3.756,2602,4.382,2713,3.634,2722,3.634,2738,5.464,2783,3.286,2941,3.756,3429,3.902,3599,5.05,3600,4.329,3601,4.329,3602,6.603,3603,4.329,3604,4.329,3605,4.329,3606,4.329,3607,6.378,3608,4.329,3609,4.329,3610,4.329,3611,5.308,3612,4.329,3613,4.329,3614,3.902,3615,4.329,3616,4.329,3617,4.329,3618,7.049,3619,4.329,3620,3.902,3621,3.902,3622,4.084,3623,6.508,3624,6.508,3625,4.329,3626,4.329,3627,4.329,3628,4.329]],["title/setup/install-r/#connect-to-spark",[26,0.844,1499,4.611]],["text/setup/install-r/#connect-to-spark",[2,1.918,4,3.885,21,2.241,22,1.499,23,0.649,26,1.472,36,2.017,50,0.711,66,3.151,114,0.674,126,2.402,135,2.226,177,1.476,178,1.754,186,2.065,187,2.607,188,2.944,219,1.723,232,2.836,273,2.738,334,2.431,403,2.128,452,2.82,455,2.241,456,2.772,476,1.516,491,2.607,577,3.117,604,2.272,641,1.678,675,3.076,781,2.984,944,1.685,948,4.444,953,2.339,955,2.778,970,2.836,1001,3.025,1014,2.115,1243,1.964,1244,3.279,1254,3.999,1285,3.772,1366,2.725,1499,6.591,1554,3.221,1583,4.073,1598,2.142,1620,1.596,1635,3.772,1717,3.07,1825,2.984,1836,4.915,1843,2.288,1922,3.772,1952,3.772,1971,4.884,1981,2.803,2048,5.19,2143,2.944,2168,3.898,2175,2.492,2602,3.025,2640,3.57,3515,7.04,3552,5.733,3553,6.205,3554,3.772,3555,3.486,3556,3.279,3599,6.875,3602,6.726,3611,3.664,3622,6.314,3629,4.493,3630,4.493,3631,4.493,3632,4.493,3633,5.317,3634,6.692,3635,4.493,3636,4.493,3637,4.493,3638,4.493,3639,4.493,3640,4.493,3641,4.493,3642,4.493,3643,4.493]],["title/setup/install-scala/",[2,1.052,92,3.138,1779,2.147]],["text/setup/install-scala/",[2,2.286,5,1.29,6,1.957,13,3.154,15,2.889,20,1.503,22,1.122,23,0.523,26,1.526,36,1.614,44,1.574,50,1.056,51,1.085,52,4.162,56,1.471,57,1.666,60,2.874,63,4.798,66,3.908,94,1.114,97,2.931,100,1.338,101,1.605,126,1.011,129,2.169,273,2.19,281,1.307,325,6.473,334,4.113,335,1.171,374,3.084,377,2.635,383,4.918,412,1.23,452,2.257,457,2.119,476,2.565,485,2.412,489,1.471,530,0.88,535,2.502,538,3.455,566,3.624,576,1.167,592,2.963,593,3.305,604,1.702,619,1.85,745,2.491,753,2.149,776,2.455,847,3.791,940,2.123,941,1.656,945,1.792,946,1.866,955,2.223,1066,1.702,1108,2.412,1228,1.85,1243,3.323,1271,3.34,1280,2.554,1286,1.99,1315,1.604,1363,2.316,1364,2.897,1366,2.715,1392,1.645,1497,1.97,1498,2.747,1620,2.7,1621,4.559,1628,2.01,1648,2.265,1687,3.555,1690,3.861,1781,3.908,1800,3.42,1803,2.204,1808,2.01,1816,2.176,1817,2.412,1819,1.916,1821,2.671,1831,3.077,1834,3.032,1835,4.781,1836,1.866,1837,2.919,1838,3.174,1839,2.412,1840,3.174,1841,2.123,1842,3.174,1843,4.503,1844,2.455,1845,3.945,1846,6.767,1847,2.919,1848,2.919,1849,2.825,1882,4.495,1883,2.825,3552,5.451,3553,7.467,3555,5.899,3556,5.549,3561,2.673,3644,3.364,3645,7.173,3646,6.596,3647,3.364]],["title/setup/install-scala/#spark-scala-shell",[13,1.975,26,0.708,325,3.243]],["text/setup/install-scala/#spark-scala-shell",[]],["title/setup/install-scala/#download-sedona-jar-automatically",[2,0.906,52,2.107,60,2.402,63,2.07]],["text/setup/install-scala/#download-sedona-jar-automatically",[2,1.877,15,3.523,26,1.399,52,3.376,60,3.849,63,3.316,66,4.365,129,2.906,325,6.776,334,5.016,377,3.53,457,2.838,476,2.42,566,4.419,745,3.336,955,2.977,1243,4.053,1271,4.474,1363,3.102,1364,3.88,1498,3.679,1620,2.547,1621,4.867,1781,5.234,1821,3.578,1835,5.141,1843,5.532,1846,7.498,1882,6.021,3552,6.646,3553,8.427,3555,7.193,3556,6.766,3644,7.171,3645,8.747,3646,8.044]],["title/setup/install-scala/#download-sedona-jar-manually",[2,0.906,52,2.107,63,2.07,1628,2.674]],["text/setup/install-scala/#download-sedona-jar-manually",[2,2.224,5,2.559,15,3.361,23,0.455,26,1.351,52,4.671,56,2.917,57,2.752,63,5.222,66,4.164,129,2.704,273,2.73,325,6.59,334,4.785,377,3.285,457,2.641,476,2.252,566,4.216,745,3.105,955,2.771,1243,3.866,1271,4.164,1280,5.066,1498,3.424,1620,2.371,1621,4.699,1690,4.615,1781,4.871,1816,4.317,1817,4.785,1835,4.785,1846,7.24,1882,5.604,1883,5.604,3552,6.341,3553,8.195,3555,6.863,3556,6.455,3645,8.345,3646,7.674,3647,6.674]],["title/setup/install-scala/#spark-sql-shell",[26,0.708,50,0.823,325,3.243]],["text/setup/install-scala/#spark-sql-shell",[2,1.952,20,2.707,50,1.526,101,1.864,273,3.944,1286,5.703,3561,7.66]],["title/setup/install-scala/#self-contained-spark-projects",[26,0.61,383,2.895,538,2.034,847,1.763]],["text/setup/install-scala/#self-contained-spark-projects",[2,2.267,6,3.17,13,2.461,20,1.819,22,2.161,23,0.446,26,1.482,44,3.031,63,4.009,66,3.05,94,2.145,97,2.847,101,1.89,126,1.946,335,2.255,374,2.995,383,5.608,452,2.73,476,2.186,489,2.832,530,1.694,535,4.818,538,3.94,576,2.246,592,3.853,593,4.296,753,4.138,776,4.728,847,4.286,940,4.089,941,3.188,945,3.45,946,3.593,1066,3.276,1108,4.644,1228,3.563,1315,3.088,1363,2.802,1364,3.505,1366,3.979,1392,3.167,1620,2.301,1621,3.068,1648,4.362,1687,5.758,1690,4.033,1808,3.87,1821,3.231,1831,4.983,1843,3.299,1844,4.728,1845,5.781,1846,4.728,1847,5.62,1848,5.62,1849,5.439]],["title/setup/maven-coordinates/",[335,1.81,1363,2.248,1364,2.812]],["text/setup/maven-coordinates/",[2,2.299,3,5.635,4,4.263,5,2.025,6,2.328,8,1.581,11,1.05,12,1.754,13,2.732,14,1.933,15,2.732,19,3.66,20,0.782,23,0.572,26,0.979,29,2.34,36,1.92,50,1.008,51,1.483,52,0.734,54,4.786,57,0.485,61,1.054,63,3.748,72,2.235,75,4.004,94,1.251,97,2.321,100,1.108,101,1.39,102,0.598,103,2.34,114,0.234,129,1.862,178,1.088,184,2.528,263,1.281,284,0.85,335,0.543,373,0.554,402,1.546,413,1.099,446,0.83,452,0.657,464,1.372,475,2.487,476,0.94,488,0.561,516,1.183,530,0.988,538,0.708,560,1.933,566,3.427,576,0.966,591,0.738,592,0.693,593,0.772,604,1.409,619,0.857,720,1.138,752,1.065,823,0.83,837,0.689,868,2.475,920,2.073,927,1.826,944,3.291,945,2.448,946,1.546,1011,1.353,1014,1.779,1017,3.124,1024,1.7,1051,0.62,1056,1.16,1066,0.788,1238,1.05,1243,2.564,1286,0.922,1314,3.702,1363,1.634,1364,1.508,1366,4.713,1367,7.456,1368,3.95,1369,7.456,1384,1.405,1391,1.274,1395,2.305,1396,2.512,1397,1.405,1398,1.405,1399,1.405,1400,1.405,1401,3.095,1402,4.698,1406,0.996,1465,1.573,1466,4.698,1467,1.309,1482,3.566,1483,1.099,1552,1.904,1585,3.579,1684,2.273,1687,2.509,1716,2.273,1771,2.273,1836,3.532,1843,1.419,1855,2.34,1860,1.183,1892,2.034,1900,3.002,1918,2.162,1976,2.273,1988,2.273,2604,1.021,2715,1.998,2799,1.21,2804,1.082,2858,1.405,2997,1.309,3103,1.405,3232,2.901,3233,2.973,3316,5.579,3317,4.583,3318,1.405,3320,2.418,3511,5.616,3556,3.354,3597,2.418,3648,1.035,3649,1.559,3650,1.559,3651,2.629,3652,2.629,3653,2.629,3654,2.629,3655,2.629,3656,8.279,3657,4.336,3658,2.629,3659,3.988,3660,5.534,3661,2.629,3662,2.629,3663,2.629,3664,2.629,3665,2.629,3666,2.629,3667,2.629,3668,2.629,3669,4.336,3670,2.629,3671,2.629,3672,1.559,3673,1.559,3674,2.629,3675,1.559,3676,1.559,3677,2.629,3678,2.34,3679,2.418,3680,1.405,3681,1.559,3682,1.559,3683,1.559,3684,5.865,3685,1.559,3686,1.309,3687,1.405,3688,1.559,3689,1.559,3690,1.559,3691,2.629]],["title/setup/maven-coordinates/#maven-coordinates",[335,2.158,1363,2.681]],["text/setup/maven-coordinates/#maven-coordinates",[2,2.531,15,4.28,19,5.344,23,0.58,26,0.981,50,1.722,57,2.242,63,4.761,101,1.393,263,3.312,452,3.037,566,5.368,927,6.093,944,4.08,1014,3.392,1017,3.837,1243,4.065,1465,5.248,1687,6.175,3648,4.784]],["title/setup/maven-coordinates/#use-sedona-fat-jars",[2,0.906,63,2.07,101,0.866,1687,2.972]],["text/setup/maven-coordinates/#use-sedona-fat-jars",[2,2.251,3,6.323,4,4.69,5,1.597,13,2.903,14,2.889,15,3.241,19,3.633,23,0.497,26,1.041,29,3.497,36,1.905,54,2.272,61,1.576,63,3.533,72,2.464,75,4.077,100,1.656,101,1.477,129,3.456,464,2.05,475,2.253,476,1.405,538,1.893,560,2.889,566,4.066,591,1.973,619,2.291,1017,2.218,1024,2.541,1056,3.098,1243,2.763,1286,2.464,1363,1.801,1364,2.253,1366,4.795,1367,7.575,1368,5.144,1369,7.575,1401,4.257,1402,6.258,1466,3.944,1483,2.936,1552,2.846,1585,2.541,1836,4.237,1843,2.121,1918,3.232,1976,3.397,2604,2.729,2715,2.986,3232,3.99,3233,4.089,3316,5.928,3317,5.485,3318,3.754,3511,6.921,3556,5.576,3597,3.614,3649,4.165,3650,4.165,3651,3.93,3652,3.93,3653,3.93,3654,3.93,3655,3.93,3656,9.108,3657,7.208]],["title/setup/maven-coordinates/#netcdf-java-542",[97,2.285,3658,4.904,3659,4.51]],["text/setup/maven-coordinates/#netcdf-java-542",[2,1.755,5,2.483,6,3.573,8,2.983,12,3.309,13,2.461,23,0.503,26,0.882,36,1.952,51,2.797,54,5.693,75,3.634,94,2.145,97,2.847,103,5.439,178,2.528,184,4.769,402,3.593,475,3.505,576,2.246,604,3.276,868,4.244,920,4.818,944,3.252,945,3.45,1014,3.05,1017,3.45,1238,2.44,1366,4.559,1367,6.751,1368,4.362,1369,6.751,1395,3.952,1466,4.041,1585,3.952,1684,5.283,1716,5.283,1771,5.283,1892,4.728,1900,5.147,1988,5.283,3320,5.62,3659,5.62,3660,9.221,3661,6.112,3662,6.112,3663,6.112,3664,6.112,3665,6.112,3666,6.112,3667,6.112,3668,6.112,3669,8.18,3670,6.112,3671,6.112]],["title/setup/maven-coordinates/#use-sedona-and-third-party-jars-separately",[2,0.709,63,1.619,101,0.677,720,2.556,1552,2.393,3103,3.156]],["text/setup/maven-coordinates/#use-sedona-and-third-party-jars-separately",[2,2.297,3,6.585,4,5.354,13,3.493,14,3.362,19,4.804,20,1.361,23,0.25,26,1.139,29,4.069,36,2.133,50,1.323,63,3.272,75,4.169,94,1.605,97,2.13,100,1.927,101,1.369,263,2.228,284,2.644,530,1.268,823,2.581,944,3.135,1017,2.581,1243,3.093,1366,4.897,1367,7.745,1369,7.745,1406,3.096,1860,3.679,2858,4.368,2997,4.069,3232,4.467,3233,4.577,3316,7.92,3317,7.252,3656,10.398,3672,4.846]],["title/setup/maven-coordinates/#locationtech-jts-core-1180",[944,1.679,1482,3.472,3673,4.475,3674,4.223]],["text/setup/maven-coordinates/#locationtech-jts-core-1180",[11,5.706,23,0.53,72,5.012,75,3.584,516,6.433,868,5.552,944,3.861,1066,4.286,1366,4.191,1367,6.658,1369,6.658,1466,6.917,1482,6.575,1585,5.171,1855,8.642,1900,6.733,3674,7.995,3675,8.474,3676,8.474,3677,7.995]],["title/setup/maven-coordinates/#jts2geojson-0161",[3678,5.205,3679,5.379]],["text/setup/maven-coordinates/#jts2geojson-0161",[20,2.209,23,0.552,75,3.423,592,3.496,593,3.898,944,2.951,1366,4.003,1367,7.631,1369,7.631,1466,4.909,1467,6.606,1482,7.63,1585,4.801,1836,4.364,3677,7.423,3678,6.606,3679,6.826,3680,7.091,3681,7.867,3682,7.867,3683,7.867,3684,11.798,3685,7.867]],["title/setup/maven-coordinates/#geotools-240",[3511,4.444,3686,5.205]],["text/setup/maven-coordinates/#geotools-240",[2,1.508,3,4.451,5,2.856,23,0.489,54,4.063,61,2.818,63,4.393,72,4.406,75,3.307,101,1.441,464,3.666,475,4.03,560,5.168,1017,3.967,1024,4.545,1363,3.222,1364,4.03,1366,3.867,1367,6.144,1368,5.016,1369,6.144,1401,6.397,1402,6.525,1466,5.927,1585,4.545,1836,5.801,1843,3.794,1918,5.78,1976,6.075,2715,5.34,3511,7.897,3556,5.437,3597,6.463,3651,7.028,3652,7.028,3653,7.028,3654,7.028,3655,7.028,3657,7.028]],["title/setup/maven-coordinates/#netcdf-java-542_1",[97,2.285,3658,4.904,3659,4.51]],["text/setup/maven-coordinates/#netcdf-java-542_1",[2,1.755,5,2.483,6,3.573,8,2.983,12,3.309,13,2.461,23,0.503,26,0.882,36,1.952,51,2.797,54,5.693,75,3.634,94,2.145,97,2.847,103,5.439,178,2.528,184,4.769,402,3.593,475,3.505,576,2.246,604,3.276,868,4.244,920,4.818,944,3.252,945,3.45,1014,3.05,1017,3.45,1238,2.44,1366,4.559,1367,6.751,1368,4.362,1369,6.751,1395,3.952,1466,4.041,1585,3.952,1684,5.283,1716,5.283,1771,5.283,1892,4.728,1900,5.147,1988,5.283,3320,5.62,3659,5.62,3660,9.221,3661,6.112,3662,6.112,3663,6.112,3664,6.112,3665,6.112,3666,6.112,3667,6.112,3668,6.112,3669,8.18,3670,6.112,3671,6.112]],["title/setup/maven-coordinates/#snapshot-versions",[75,2.158,1314,3.913]],["text/setup/maven-coordinates/#snapshot-versions",[2,1.715,5,3.249,6,3.098,23,0.53,52,3.99,54,4.622,75,3.584,102,3.249,114,1.272,446,4.513,476,2.859,530,2.693,752,5.79,837,3.745,945,4.513,946,4.7,1011,7.352,1051,3.369,1314,6.998,1384,7.638,3687,7.638,3688,8.474,3689,8.474,3690,8.474]],["title/setup/maven-coordinates/#buildsbt",[946,4.259]],["text/setup/maven-coordinates/#buildsbt",[23,0.6,36,2.87,413,6.712,1314,6.01,2799,7.388,2804,6.606,3691,8.984]],["title/setup/maven-coordinates/#pomxml",[945,4.089]],["text/setup/maven-coordinates/#pomxml",[54,6.434,373,3.223,488,3.262,1314,5.727,1391,4.901,1395,5.536,1396,9.665,1397,8.178,1398,8.178,1399,8.178,1400,8.178,3691,8.56]],["title/setup/modules/",[1465,4.333]],["text/setup/modules/",[2,1.935,10,2.538,12,3.648,15,2.858,17,1.71,23,0.628,26,1.025,36,3.167,42,3.458,44,3.52,50,1.663,92,4.541,105,1.394,349,2.084,529,3.915,558,2.374,942,7.256,944,3.585,1051,2.991,1238,3.958,1239,6.315,1240,3.727,1243,4.178,1288,5.072,1465,4.245,1893,5.71,1907,4.995,2774,5.977,3692,7.522,3693,7.522]],["title/setup/modules/#sedona-modules-for-apache-spark",[2,0.906,26,0.61,36,1.349,1465,2.526]],["text/setup/modules/#sedona-modules-for-apache-spark",[2,1.725,10,2.875,12,3.252,17,1.937,36,3.113,50,1.635,105,1.579,349,2.361,529,4.435,558,2.689,942,7.84,944,3.874,1051,3.388,1238,4.186,1240,4.222,1243,3.725,1288,5.365,1893,6.468,1907,5.658,2774,6.77]],["title/setup/modules/#api-availability",[12,2.366,44,2.901]],["text/setup/modules/#api-availability",[15,3.468,23,0.64,42,4.196,50,1.445,92,5.51,1239,7.663,1243,3.99,3692,9.126,3693,9.126]],["title/setup/overview/",[521,7.678]],["text/setup/overview/",[2,1.657,5,2.282,8,2.048,13,2.262,15,2.262,17,2.709,19,4.705,23,0.587,26,1.115,36,2.468,42,3.763,45,4.854,46,4.008,48,3.637,49,4.518,52,2.802,59,1.688,61,2.252,71,3.952,84,5.364,90,3.952,97,2.616,110,1.151,111,0.997,121,2.411,139,3.032,159,2.752,166,3.453,234,2.534,243,2.194,268,4.344,335,2.072,349,3.026,370,3.504,459,3.678,464,2.93,555,3.121,613,3.121,641,2.223,831,2.884,997,3.556,1000,2.769,1066,4.14,1238,2.242,1239,4.997,1240,2.949,1241,4.997,1260,4.729,1288,2.873,1291,3.9,1363,2.574,1560,4.842,1561,3.757,1648,4.008,1668,4.067,1683,4.344,1724,3.757,1763,4.518,2020,4.129,2030,3.713,2032,4.344,2101,3.85,2107,3.85,3124,5.364,3157,5.364,3694,5.952,3695,5.952,3696,4.067,3697,5.952,3698,5.952,3699,5.952]],["title/setup/overview/#download-statistics",[52,2.919,3157,5.587]],["text/setup/overview/#download-statistics",[2,1.916,5,3.628,36,2.852,45,7.718,59,2.684,84,8.529,1363,4.093,2020,6.565,3694,9.463,3695,9.463]],["title/setup/overview/#what-can-sedona-do",[2,1.554]],["text/setup/overview/#what-can-sedona-do",[]],["title/setup/overview/#distributed-spatial-datasets",[17,1.182,1066,2.629,1668,3.552]],["text/setup/overview/#distributed-spatial-datasets",[17,2.708,19,6.272,26,1.487,1238,3.521,1239,7.849,3696,6.387,3697,9.348]],["title/setup/overview/#complex-spatial-objects",[17,1.182,641,1.941,1648,3.5]],["text/setup/overview/#complex-spatial-objects",[23,0.462,46,6.038,48,3.984,49,6.807,110,1.734,111,1.502,121,3.633,139,4.567,159,4.147,166,5.202,555,4.703,613,4.703,997,5.358,1000,4.171,1260,7.125,1683,6.545,1763,6.807,2032,6.545,3698,8.967]],["title/setup/overview/#distributed-spatial-queries",[17,1.182,349,1.441,1066,2.629]],["text/setup/overview/#distributed-spatial-queries",[17,2.413,42,4.099,234,3.796,243,3.287,349,3.32,370,4.542,831,3.739,1560,6.277,1561,5.627,1724,5.627,2101,5.767,2107,5.767]],["title/setup/overview/#rich-spatial-analytics-tools",[17,1.018,268,3.266,3124,4.034,3699,4.475]],["text/setup/overview/#rich-spatial-analytics-tools",[8,3.015,13,3.33,15,3.33,17,2.388,23,0.451,36,2.641,42,4.029,48,3.894,61,3.315,71,5.819,90,5.07,97,3.851,335,3.051,459,4.719,464,4.313,1240,4.342,1241,7.357,1288,4.23,1291,5.742,2030,5.467]],["title/setup/platform/",[1402,3.868,1854,4.444]],["text/setup/platform/",[2,2.118,3,4.453,5,2.857,8,1.792,13,4.46,14,5.171,15,3.821,16,4.372,23,0.617,26,1.631,27,6.608,28,7.1,39,6.917,42,2.394,56,2.276,57,1.62,62,4.324,92,3.144,97,2.289,377,6.141,450,3.05,530,1.362,591,2.467,666,3.326,889,3.558,1100,3.733,1286,3.08,1365,4.137,1603,4.247,1689,3.368,1690,2.422,1873,7.551,1892,3.8,2165,3.873,3226,6.754,3232,5.495,3233,6.968,3526,4.518,3527,4.247,3700,5.653]],["title/setup/release-notes/",[5,2.377,22,2.068]],["text/setup/release-notes/",[2,2.299,3,1.762,4,0.562,5,1.845,6,3.522,7,0.551,8,2.568,9,0.878,10,0.614,11,0.778,12,2.878,13,1.549,14,0.551,15,1.764,16,0.667,17,1.536,18,0.817,19,3.64,20,0.678,21,0.577,22,0.137,23,0.616,25,0.344,26,0.847,27,0.603,28,0.943,31,0.934,32,1.461,33,0.698,34,0.344,35,0.501,36,1.229,38,0.344,39,0.631,41,0.919,42,0.977,44,0.192,46,1.008,47,1.337,48,0.353,49,0.603,50,0.905,51,2.686,53,0.223,55,0.272,56,0.505,57,0.661,58,1.149,59,2.553,60,0.426,61,0.689,62,0.238,63,0.535,65,0.462,71,0.527,73,0.79,75,2.037,85,0.25,86,1.132,89,3.267,90,0.383,93,0.914,94,1.058,95,0.318,96,0.949,97,0.658,100,2.043,101,1.052,102,0.157,106,0.398,108,0.213,109,0.404,110,0.788,111,0.648,113,0.193,114,0.581,115,0.065,118,0.294,119,0.538,121,1.195,124,1.773,125,0.616,126,0.347,128,0.294,129,0.468,135,0.203,137,0.284,139,1.229,141,0.203,145,0.311,153,0.311,159,0.367,161,0.216,165,0.757,166,0.238,170,0.318,171,0.342,172,0.209,177,1.272,178,0.451,179,1.012,181,0.325,183,0.739,184,0.225,188,0.268,191,0.325,199,0.43,200,0.386,209,0.216,218,0.216,219,0.884,220,0.12,221,0.413,225,0.44,230,0.325,234,1.361,235,0.413,240,0.58,241,0.479,243,0.991,245,1.978,246,0.215,252,0.861,253,0.289,256,0.878,258,0.255,260,0.616,261,0.276,262,0.344,263,1.355,264,0.647,266,0.218,269,0.311,270,0.28,271,0.844,273,2.393,274,0.305,275,0.56,278,0.721,279,0.305,281,0.582,283,1.399,289,0.58,294,0.305,297,0.325,298,0.262,299,0.444,301,0.245,302,0.616,307,0.325,313,0.238,321,0.305,322,0.305,327,0.22,328,0.311,332,0.616,333,0.325,334,0.222,335,1.348,347,1.114,349,1.951,352,0.991,354,0.58,355,0.383,356,0.284,365,0.869,367,0.305,368,0.305,370,1.469,372,0.289,373,0.145,376,0.616,377,1.046,378,0.739,379,0.305,380,0.28,384,0.611,385,0.569,388,0.325,392,0.485,393,0.325,396,0.294,397,0.573,398,0.325,403,1.514,407,0.815,409,0.344,411,0.847,412,2.728,413,0.289,415,0.268,416,0.535,422,0.305,424,0.391,425,0.305,427,0.616,430,0.971,431,0.684,437,0.631,438,0.289,444,0.616,446,0.423,449,0.829,450,1.872,452,0.767,454,0.325,455,0.396,456,0.49,459,0.357,462,0.325,463,0.869,464,0.896,467,0.616,468,0.344,470,0.265,471,0.501,472,0.311,473,0.311,474,1.535,475,0.43,476,1.158,478,0.969,480,0.242,481,0.289,486,0.235,487,0.253,488,0.147,489,0.179,492,0.28,494,0.305,497,0.616,500,0.268,501,0.284,504,0.305,507,0.616,508,0.616,510,0.325,513,0.325,517,0.325,523,0.28,524,0.28,525,0.535,530,0.208,532,0.497,533,0.242,534,1.027,537,0.207,538,0.68,540,0.616,543,0.44,544,0.262,546,0.325,549,0.325,551,0.325,552,0.158,553,0.311,554,0.325,555,1.41,556,0.589,558,1.083,559,0.253,566,0.867,576,0.401,578,0.311,579,0.58,580,0.815,583,0.391,585,0.258,591,0.376,592,0.353,594,1.22,595,0.616,597,0.311,603,0.276,608,0.299,613,0.416,616,1.165,619,0.437,620,0.709,621,0.318,630,0.289,635,0.369,641,1.282,651,0.355,653,0.452,661,0.311,665,0.355,666,0.507,667,0.325,674,0.325,675,0.188,676,0.265,678,0.325,682,0.569,684,0.591,685,0.325,686,0.591,689,0.311,693,0.355,695,0.311,696,0.363,697,0.28,700,0.739,701,0.284,702,0.413,703,1.039,705,0.667,706,0.603,707,0.591,708,0.334,711,0.325,713,0.272,715,0.957,716,0.355,729,0.355,733,0.218,736,0.569,737,0.311,738,0.268,745,0.538,748,2.48,750,0.265,753,0.262,755,0.355,760,0.355,765,0.355,774,0.311,775,0.527,779,0.311,780,0.58,786,0.325,789,0.344,795,0.369,796,0.334,797,0.344,814,0.355,815,0.667,821,0.334,822,1.008,823,0.969,827,0.479,830,0.355,831,2.449,832,0.474,833,1.872,834,1.729,837,0.351,839,0.311,844,0.289,847,0.313,859,0.535,865,0.919,868,0.268,872,1.123,873,0.258,875,0.664,876,0.253,877,0.265,878,2.242,879,1.19,880,0.829,882,1.569,883,0.58,884,0.507,888,0.495,889,0.79,891,0.255,917,0.603,921,0.325,929,0.265,933,0.325,937,0.242,938,0.955,940,0.258,941,0.391,944,1.673,955,0.17,959,0.154,961,0.242,964,0.768,965,0.299,967,0.677,969,0.369,970,0.258,977,0.299,981,0.737,988,0.311,992,0.311,993,0.311,995,0.591,997,0.895,1000,1.896,1003,0.28,1013,0.253,1014,1.136,1017,0.218,1019,0.258,1020,0.235,1022,0.344,1023,0.689,1024,1.64,1027,1.173,1035,0.245,1041,0.311,1048,0.238,1051,0.163,1055,0.361,1068,0.616,1100,0.294,1104,0.748,1107,0.294,1140,0.28,1205,0.209,1238,1.748,1240,0.573,1243,1.599,1247,0.58,1248,0.289,1254,0.474,1256,0.311,1257,1.09,1262,0.318,1263,0.325,1267,0.56,1268,0.705,1281,0.311,1286,0.242,1288,0.558,1290,0.535,1291,0.268,1297,0.289,1298,0.245,1300,0.227,1305,0.52,1308,0.28,1315,0.195,1316,0.284,1318,0.52,1326,0.334,1328,0.344,1350,0.667,1363,1.044,1364,0.625,1365,0.919,1366,1.66,1370,0.569,1372,0.294,1374,0.318,1382,2.426,1383,0.344,1391,0.187,1392,1.314,1401,0.276,1402,1.326,1403,3.873,1404,4.317,1405,0.22,1406,0.262,1407,0.369,1408,0.272,1409,0.369,1410,4.912,1411,0.369,1412,1.762,1413,1.832,1414,0.369,1415,0.369,1416,0.369,1417,0.369,1418,0.369,1419,0.369,1420,0.325,1421,0.369,1422,0.325,1423,0.369,1424,0.369,1425,0.369,1426,0.369,1427,0.369,1428,0.369,1429,0.369,1430,1.221,1431,0.369,1432,0.369,1433,0.344,1434,0.369,1435,0.369,1436,0.369,1437,0.514,1438,0.603,1439,0.369,1440,0.369,1441,0.344,1442,0.344,1443,0.369,1444,0.369,1445,0.369,1446,0.369,1447,0.631,1448,0.631,1449,0.369,1450,0.369,1451,0.344,1452,0.344,1453,0.369,1454,0.369,1455,0.667,1456,0.551,1457,0.551,1458,0.369,1459,0.369,1460,0.369,1461,0.369,1462,0.829,1463,1.192,1464,0.355,1465,0.652,1466,0.721,1467,0.344,1468,0.369,1469,0.369,1470,0.369,1471,1.625,1472,0.369,1473,0.369,1474,0.369,1475,0.369,1476,0.369,1477,0.369,1478,0.311,1479,0.325,1480,0.369,1481,0.369,1482,0.897,1483,0.56,1484,0.369,1485,0.369,1486,0.369,1487,0.474,1488,0.369,1489,0.369,1490,1.484,1491,0.971,1492,0.698,1493,0.369,1494,0.369,1495,0.369,1496,0.369,1497,0.677,1498,0.593,1499,0.591,1500,0.305,1501,0.369,1502,0.369,1503,0.369,1504,0.369,1505,0.369,1506,0.369,1507,0.369,1508,0.369,1509,0.369,1510,0.369,1511,0.369,1512,0.369,1513,0.369,1514,0.369,1515,0.369,1516,0.369,1517,0.369,1518,0.369,1519,0.648,1520,0.369,1521,0.667,1522,1.18,1523,0.369,1524,0.369,1525,1.093,1526,0.369,1527,0.58,1528,0.543,1529,2.192,1530,0.369,1531,0.716,1532,0.716,1533,0.631,1534,0.878,1535,0.716,1536,0.603,1537,0.344,1538,0.667,1539,0.79,1540,0.311,1541,0.369,1542,0.689,1543,0.369,1544,1.221,1545,0.689,1546,0.369,1547,0.369,1548,0.689,1549,1.192,1550,0.369,1551,0.255,1552,0.79,1553,0.369,1554,0.294,1555,0.344,1556,0.416,1557,0.369,1558,0.289,1559,0.667,1560,1.89,1561,1.341,1562,0.369,1563,0.616,1564,1.299,1565,0.369,1566,0.689,1567,0.739,1568,0.344,1569,0.768,1570,0.369,1571,0.344,1572,0.713,1573,0.689,1574,0.689,1575,0.689,1576,0.648,1577,0.689,1578,0.369,1579,0.689,1580,0.689,1581,0.268,1582,0.914,1583,0.927,1584,0.369,1585,0.25,1586,0.369,1587,1.257,1588,0.369,1589,0.369,1590,0.369,1591,0.369,1592,0.689,1593,0.73,1594,0.625,1595,0.325,1596,0.369,1597,0.318,1598,0.551,1599,0.689,1600,0.253,1601,0.369,1602,0.369,1603,0.943,1604,0.369,1605,0.369,1606,0.369,1607,0.369,1608,0.325,1609,0.603,1610,0.344,1611,0.28,1612,0.369,1613,0.667,1614,0.716,1615,0.299,1616,0.667,1617,0.763,1618,0.369,1619,0.369,1620,0.145,1621,0.194,1622,0.369,1623,0.369,1624,0.716,1625,0.667,1626,0.667,1627,0.369,1628,0.691,1629,0.369,1630,0.344,1631,0.369,1632,0.369,1633,0.677,1634,0.311,1635,0.344,1636,0.369,1637,1.702,1638,0.802,1639,0.369,1640,0.369,1641,0.369,1642,0.369,1643,0.514,1644,0.369,1645,1.19,1646,0.56,1647,0.689,1648,0.276,1649,0.369,1650,0.369,1651,0.369,1652,0.369,1653,0.369,1654,0.716,1655,0.369,1656,0.284,1657,1.528,1658,1.354,1659,0.369,1660,0.369,1661,0.344,1662,0.369,1663,0.369,1664,0.815,1665,0.369,1666,0.919,1667,0.551,1668,0.79,1669,0.325,1670,0.344,1671,0.369,1672,0.971,1673,0.369,1674,0.369,1675,0.667,1676,0.369,1677,0.369,1678,0.325,1679,0.344,1680,0.299,1681,0.344,1682,0.369,1683,0.844,1684,0.334,1685,0.369,1686,0.294,1687,0.272,1688,0.716,1689,0.514,1690,0.988,1691,0.591,1692,0.369,1693,0.369,1694,0.943,1695,0.667,1696,0.667,1697,0.768,1698,0.369,1699,0.369,1700,0.369,1701,2.462,1702,2.22,1703,0.265,1704,0.369,1705,0.369,1706,0.334,1707,0.369,1708,0.294,1709,0.311,1710,0.284,1711,0.216,1712,0.369,1713,0.369,1714,0.369,1715,0.369,1716,0.334,1717,0.28,1718,0.716,1719,0.43,1720,0.289,1721,0.262,1722,0.369,1723,0.716,1724,0.258,1725,0.689,1726,0.369,1727,0.369,1728,0.369,1729,0.369,1730,0.369,1731,0.311,1732,0.258,1733,0.253,1734,0.369,1735,1.257,1736,0.369,1737,0.265,1738,0.265,1739,0.369,1740,0.369,1741,0.223,1742,0.369,1743,0.325,1744,0.369,1745,0.369,1746,0.369,1747,0.311,1748,1.702,1749,0.311,1750,0.369,1751,0.294,1752,0.369,1753,0.369,1754,0.369,1755,0.369,1756,0.299,1757,0.325,1758,0.716,1759,0.325,1760,0.299,1761,0.369,1762,0.369,1763,0.878,1764,0.369,1765,0.369,1766,0.369,1767,0.369,1768,0.369,1769,0.369,1770,1.003,1771,0.334,1779,0.878,1782,0.294,1797,0.28,1800,0.262,1819,0.233,1820,0.247,1836,0.831,1843,0.589,1844,0.299,1850,0.242,1854,0.294,1870,0.242,1871,0.272,1873,1.19,1892,0.58,1895,0.28,1897,0.268,1905,0.611,1907,0.272,1923,0.325,1925,0.344,1944,0.325,1955,0.299,1981,0.255,1984,0.299,1990,0.591,2002,1.177,2020,0.284,2021,0.829,2028,0.86,2087,0.344,2108,0.289,2112,0.245,2137,0.648,2165,0.305,2254,0.344,2299,0.344,2604,0.268,2647,0.325,2786,0.24,2798,0.325,2800,0.344,2936,0.369,2992,0.325,3142,0.344,3178,0.369,3180,0.284,3196,0.369,3232,0.258,3233,0.748,3275,0.276,3445,0.325,3511,1.305,3526,0.355,3527,0.334,3532,0.344,3536,0.344,3546,0.334,3561,0.325,3678,0.971,3679,0.355,3680,0.369,3686,0.344,3687,0.369,3696,0.28,3701,0.409,3702,0.409,3703,0.648,3704,0.409,3705,0.409,3706,0.409,3707,0.409,3708,0.409,3709,0.409,3710,0.409,3711,0.409,3712,0.409,3713,0.409,3714,0.409,3715,0.409,3716,0.409,3717,0.409,3718,0.409,3719,0.386,3720,0.369,3721,0.409,3722,0.409,3723,0.409,3724,0.409,3725,0.409,3726,0.409,3727,0.409,3728,0.409,3729,0.409,3730,0.409,3731,0.409,3732,0.409,3733,0.409,3734,0.409,3735,0.409,3736,0.409,3737,0.409,3738,0.409,3739,0.409,3740,0.409,3741,0.409,3742,0.409,3743,0.409,3744,0.409,3745,0.409,3746,0.409,3747,0.409,3748,0.409,3749,0.409,3750,0.409,3751,0.409,3752,0.409,3753,0.369,3754,1.042,3755,0.409,3756,0.409,3757,0.409,3758,0.749,3759,0.648,3760,0.409,3761,0.409,3762,0.409,3763,0.409,3764,0.409,3765,0.409,3766,0.409,3767,0.409,3768,0.409,3769,0.409,3770,0.409,3771,0.409,3772,0.409,3773,0.409,3774,0.409,3775,0.409,3776,0.794,3777,0.409,3778,0.409,3779,0.409,3780,0.409,3781,0.409,3782,0.409,3783,0.409,3784,0.409,3785,0.409,3786,0.409,3787,0.409,3788,0.409,3789,0.409,3790,0.409,3791,0.409,3792,0.369,3793,0.409,3794,0.409,3795,0.409,3796,0.409,3797,0.409,3798,0.409,3799,1.042,3800,0.369,3801,0.409,3802,0.409,3803,0.409,3804,0.409,3805,0.749,3806,0.409,3807,0.409,3808,0.409,3809,0.409,3810,0.409,3811,0.409,3812,0.409,3813,0.749,3814,0.749,3815,0.749,3816,0.689,3817,0.409,3818,0.369,3819,0.409,3820,0.749,3821,0.689,3822,0.689,3823,0.749,3824,0.689,3825,0.409,3826,0.369,3827,0.749,3828,0.409,3829,0.409,3830,0.409,3831,0.409,3832,0.409,3833,0.409,3834,0.409,3835,0.749,3836,0.409,3837,0.409,3838,0.409,3839,0.971,3840,0.409,3841,0.409,3842,0.409,3843,0.409,3844,0.409,3845,0.409,3846,0.409,3847,0.409,3848,0.409,3849,0.409,3850,0.409,3851,0.409,3852,0.369,3853,0.409,3854,0.409,3855,0.369,3856,0.409,3857,0.409,3858,0.409,3859,0.409,3860,0.409,3861,0.409,3862,0.409,3863,0.409,3864,0.409,3865,0.749,3866,0.409,3867,0.689,3868,0.409,3869,0.794,3870,1.35,3871,1.091,3872,0.409,3873,0.409,3874,0.369,3875,0.749,3876,0.369,3877,0.749,3878,0.409,3879,0.369,3880,0.409,3881,0.749,3882,0.409,3883,0.409,3884,0.409,3885,0.409,3886,0.369,3887,0.369,3888,0.409,3889,0.409,3890,0.409,3891,0.794,3892,0.409,3893,0.409,3894,0.409,3895,0.409,3896,0.409,3897,0.409,3898,0.409,3899,0.409,3900,0.409,3901,0.409,3902,0.409,3903,0.409]],["title/setup/release-notes/#sedona-131",[2,1.255,184,3.41]],["text/setup/release-notes/#sedona-131",[3,6.838,5,3.499,75,3.746,100,3.629,179,3.827,1403,4.246,1404,4.078,1519,7.444,1850,5.399,3701,9.126,3702,9.126,3703,7.444,3704,9.126]],["title/setup/release-notes/#bug-fixes",[1403,2.884,1404,2.77]],["text/setup/release-notes/#bug-fixes",[2,2.359,3,5.971,4,4.855,5,3.095,13,3.068,101,1.561,181,6.415,191,6.415,365,4.684,411,3.756,430,3.69,463,4.684,750,5.222,834,4.368,847,3.18,872,4.981,1263,6.415,1522,3.948,1542,7.005,1548,7.005,1691,6.006,1819,4.598,1844,5.893,2936,7.277,3233,5.222,3546,6.585,3705,8.074,3706,8.074,3707,8.074,3708,8.074,3709,8.074,3710,8.074]],["title/setup/release-notes/#new-feature",[412,2.266,833,3.381]],["text/setup/release-notes/#new-feature",[2,2.473,6,4.184,398,7.252,513,7.252,517,7.252,3711,9.126,3712,9.126,3713,9.126,3714,9.126]],["title/setup/release-notes/#improvement",[1529,4.905]],["text/setup/release-notes/#improvement",[2,2.346,26,1.281,101,1.819,715,6.008,969,8.477,1574,8.161,3715,9.405,3716,9.405,3717,9.405]],["title/setup/release-notes/#sedona-130",[2,1.255,3,3.704]],["text/setup/release-notes/#sedona-130",[2,1.847,3,5.453,5,3.499,51,2.944,75,3.177,179,3.827,263,4.196,266,4.86,412,3.337,676,5.903,705,7.663,832,5.453,1403,4.246,1404,4.078,1410,5.83,1701,6.146]],["title/setup/release-notes/#highlights",[3718,7.678]],["text/setup/release-notes/#highlights",[2,1.78,5,3.371,7,4.59,8,3.398,9,6.676,10,2.233,11,5.922,12,3.357,13,2.514,15,2.514,16,5.555,18,3.609,19,5.677,23,0.564,26,1.345,28,5.396,94,2.191,111,1.108,159,3.06,234,2.817,245,4.758,327,3.551,370,2.832,450,5.151,463,3.839,831,3.099,884,4.227,941,3.257,1024,4.037,1068,3.524,1365,5.257,1392,3.235,1404,2.956,1645,6.988,1690,4.091,1873,5.257,3719,6.243,3720,5.964,3721,6.617,3722,6.617,3723,6.617,3724,6.617,3725,6.617,3726,6.617,3727,6.617,3728,6.617,3729,6.617,3730,6.617,3731,6.617,3732,6.617,3733,6.617,3734,6.617,3735,6.617,3736,6.617,3737,6.617,3738,6.617,3739,6.617,3740,6.617,3741,6.617,3742,6.617]],["title/setup/release-notes/#bug-fixes_1",[1403,2.884,1404,2.77]],["text/setup/release-notes/#bug-fixes_1",[2,2.44,12,3.282,15,3.267,17,1.454,19,5.581,23,0.329,63,2.958,85,3.903,89,2.669,93,3.903,106,1.882,115,1.013,119,2.3,183,4.086,234,2.724,256,4.856,262,5.371,270,4.371,278,3.991,283,3.33,294,4.758,297,5.083,347,4.758,349,2.691,352,2.358,354,4.669,368,4.758,373,2.272,384,3.38,403,3.03,411,3.999,449,4.586,478,4.138,591,3.03,653,3.643,822,4.307,831,3.422,884,4.086,937,3.784,995,4.758,1262,4.963,1404,4.64,1471,5.789,1545,5.55,1549,4.191,1575,5.55,1579,5.55,1587,5.371,1895,4.371,1905,3.38,3445,5.083,3743,6.397,3744,6.397,3745,6.397,3746,6.397,3747,6.397,3748,6.397,3749,6.397,3750,6.397,3751,6.397,3752,6.397,3753,5.766,3754,5.766]],["title/setup/release-notes/#new-features",[412,2.266,833,3.381]],["text/setup/release-notes/#new-features",[2,2.479,6,3.738,8,2.884,9,6.362,10,2.828,11,5.644,12,3.199,36,3.082,393,6.66,454,6.66,463,4.862,594,2.796,706,6.362,938,3.766,1024,5.114,1392,4.098,1567,5.354,1580,7.272,1925,7.037,3755,8.381,3756,8.381,3757,8.381]],["title/setup/release-notes/#improvement_1",[1529,4.905]],["text/setup/release-notes/#improvement_1",[2,2.492,6,4.295,8,2.148,12,4.17,15,1.557,16,3.441,17,0.932,18,2.235,19,6.57,26,0.558,36,1.882,42,1.884,50,0.649,51,3.317,100,1.629,110,1.208,124,2.118,126,1.231,129,1.661,145,3.111,153,3.111,159,1.895,183,3.989,218,2.166,240,2.991,252,1.312,271,2.991,275,2.889,283,2.133,289,2.991,321,3.049,335,2.174,356,2.843,377,3.723,384,2.166,388,3.256,416,2.76,431,2.424,446,2.183,449,2.938,481,2.889,525,2.76,534,4.269,549,3.256,551,3.256,555,2.149,592,1.821,594,1.367,685,3.256,686,3.049,697,2.8,738,2.685,748,3.18,831,1.444,875,3.589,879,3.256,888,2.557,981,2.017,1019,2.587,1048,2.378,1366,1.669,1392,2.004,1404,3.38,1412,2.991,1413,4.74,1430,3.343,1465,2.313,1471,2.76,1491,3.441,1549,2.685,1564,3.556,1566,3.556,1573,3.556,1577,3.556,1582,2.501,1587,5.243,1599,3.556,1702,2.651,1797,2.8,1843,2.087,1955,2.991,2087,3.441,2604,2.685,3180,2.843,3196,3.694,3758,3.867,3759,3.343,3760,4.098,3761,4.098,3762,4.098,3763,4.098,3764,4.098,3765,4.098,3766,4.098,3767,4.098,3768,4.098,3769,4.098,3770,4.098,3771,4.098,3772,4.098,3773,4.098,3774,4.098,3775,4.098,3776,6.244,3777,4.098,3778,4.098,3779,4.098,3780,4.098,3781,4.098,3782,4.098,3783,4.098,3784,4.098,3785,4.098,3786,4.098,3787,4.098,3788,4.098,3789,4.098,3790,4.098,3791,4.098,3792,3.694,3793,4.098,3794,4.098,3795,4.098,3796,4.098,3797,4.098,3798,4.098]],["title/setup/release-notes/#task",[2992,6.101]],["text/setup/release-notes/#task",[2,1.939,8,3.296,13,3.641,26,1.305,27,7.273,407,6.754,707,7.127,1873,7.613]],["title/setup/release-notes/#sedona-121",[2,1.255,25,5.205]],["text/setup/release-notes/#sedona-121",[2,2.156,5,3.438,26,1.547,28,7.314,31,5.595,32,4.443,39,7.125,75,3.122,179,3.76,263,4.122,823,4.775,1403,4.171,1404,4.007,1645,7.125,1690,4.171,3799,8.082]],["title/setup/release-notes/#sql-for-spark",[26,0.844,50,0.981]],["text/setup/release-notes/#sql-for-spark",[2,2.487,6,4.348,8,2.552,21,2.58,23,0.633,26,0.705,28,4.218,51,2.393,94,1.712,101,1,165,3.389,170,4.013,271,3.775,283,2.692,302,4.013,332,4.013,347,3.847,352,1.907,376,4.013,412,1.891,427,4.013,430,2.364,437,4.11,444,4.013,468,4.342,497,4.013,507,4.013,508,4.013,532,2.225,534,2.919,540,4.013,544,3.304,546,4.11,651,4.488,736,3.708,737,3.926,748,4.013,815,4.342,833,2.821,941,2.546,997,4.432,1000,3.45,1035,3.09,1366,2.106,1403,3.45,1404,3.875,1529,3.304,1549,3.389,1592,4.488,1672,4.342,1735,4.342,1990,3.847,2137,4.218,3800,4.662,3801,5.172,3802,5.172,3803,5.172,3804,5.172,3805,4.88,3806,5.172,3807,5.172,3808,5.172,3809,5.172,3810,5.172,3811,5.172,3812,5.172,3813,4.88,3814,4.88,3815,4.88,3816,4.488,3817,5.172,3818,4.662,3819,5.172,3820,4.88,3821,4.488,3822,4.488,3823,4.88,3824,4.488,3825,5.172,3826,4.662]],["title/setup/release-notes/#flink",[19,4.413]],["text/setup/release-notes/#flink",[2,2.473,6,4.412,19,3.869,23,0.629,51,2.87,124,3.479,125,5.224,165,4.411,271,4.914,302,5.224,332,5.224,376,5.224,412,2.461,427,5.224,437,5.349,444,5.224,497,5.224,507,5.224,508,5.224,532,2.897,534,3.8,540,5.224,815,5.653,833,3.672,1014,3.17,1491,5.653,1576,5.491,1672,5.653,1990,5.008,2137,5.491,3758,6.352,3805,6.352,3813,6.352,3814,6.352,3815,6.352,3816,5.841,3820,6.352,3821,5.841,3822,5.841,3823,6.352,3824,5.841]],["title/setup/release-notes/#sedona-120",[2,1.255,31,3.868]],["text/setup/release-notes/#sedona-120",[2,2.194,5,3.541,19,5.308,31,5.762,36,2.784,75,3.216,179,3.873,263,4.246,412,3.377,833,5.038,1403,4.296,1404,4.127,1701,6.219]],["title/setup/release-notes/#rdd",[1238,2.892]],["text/setup/release-notes/#rdd",[2,2.223,13,3.86,17,1.885,19,4.765,23,0.566,51,2.675,94,2.745,101,1.603,111,1.389,478,5.363,555,4.348,635,7.473,653,4.722,882,3.79,1403,3.857,1404,4.538,1412,6.051,1529,5.297,1735,6.961,1836,5.634,1892,6.051,3680,7.473,3827,7.823,3828,8.291,3829,8.291,3830,8.291]],["title/setup/release-notes/#sql",[50,1.216]],["text/setup/release-notes/#sql",[2,2.411,6,3.908,8,3.105,23,0.613,50,1.09,51,3.581,110,1.948,126,2.711,135,3.41,221,3.583,230,5.469,256,5.225,260,5.34,278,4.294,283,3.583,299,3.851,307,5.469,335,2.396,377,3.388,378,4.397,403,3.261,409,5.779,412,2.516,416,4.635,510,5.469,641,2.57,665,5.972,765,5.972,830,5.972,833,3.754,1403,3.202,1404,3.075,1413,5.225,2254,5.779,3759,5.614,3831,6.883,3832,6.883,3833,6.883,3834,6.883,3835,6.494,3836,6.883,3837,6.883,3838,6.883,3839,5.779]],["title/setup/release-notes/#flink_1",[19,4.413]],["text/setup/release-notes/#flink_1",[2,2.325,6,3.064,8,3.518,12,3.199,19,6.341,23,0.592,33,5.06,34,7.037,35,5.29,51,2.704,137,5.815,347,6.234,684,6.234,814,7.272,827,6.173,1701,5.644,1702,5.421,3687,7.554,3696,5.727,3840,8.381,3841,8.381]],["title/setup/release-notes/#sedona-111",[2,1.255,38,5.205]],["text/setup/release-notes/#sedona-111",[2,1.892,5,3.584,51,3.015,75,3.255,179,3.92,263,4.298,412,3.418,1403,4.349,1404,4.177,3703,7.624,3799,8.426,3842,9.348]],["title/setup/release-notes/#global",[1748,5.412]],["text/setup/release-notes/#global",[2,1.904,8,3.236,13,4.162,14,6.525,23,0.484,56,4.111,57,2.926,412,3.439,833,5.13,3827,8.874]],["title/setup/release-notes/#sql_1",[50,1.216]],["text/setup/release-notes/#sql_1",[2,2.334,6,4.053,8,2.915,23,0.594,26,1.154,39,6.733,125,6.575,256,6.433,260,6.575,274,6.303,347,6.303,412,3.098,462,6.733,729,7.352,795,7.638,833,4.622,1403,3.942,1404,3.786,3843,8.474,3844,8.474,3845,8.474]],["title/setup/release-notes/#sedona-110",[2,1.255,41,4.926]],["text/setup/release-notes/#sedona-110",[2,1.815,5,3.438,8,3.085,12,3.423,41,7.125,42,4.122,46,6.038,47,3.097,48,3.984,49,6.807,75,3.122,179,3.76,263,4.122,412,3.278,833,4.891,1403,4.171,1404,4.007,1701,6.038,1854,6.429]],["title/setup/release-notes/#global_1",[1748,5.412]],["text/setup/release-notes/#global_1",[2,2.262,23,0.576,41,6.157,50,1.227,89,3.233,101,1.499,263,3.562,349,2.147,377,3.814,378,4.95,392,4.728,446,4.127,748,6.012,831,2.73,834,4.192,878,3.283,879,6.157,882,3.542,944,2.906,997,4.63,1023,6.723,1366,3.155,1402,4.834,1462,5.555,1490,6.32,1529,6.222,1633,4.539,1643,5.012,1694,6.32,1836,4.298,2800,6.506,3511,6.983,3846,7.749,3847,7.749,3848,7.749,3849,7.749,3850,7.749,3851,7.749]],["title/setup/release-notes/#core",[944,2.88]],["text/setup/release-notes/#core",[2,2.171,23,0.552,488,3.262,1403,4.988,1404,5.1,2108,6.396,3852,8.178,3853,9.073,3854,9.073,3855,8.178,3856,9.073,3857,9.073]],["title/setup/release-notes/#sql_2",[50,1.216]],["text/setup/release-notes/#sql_2",[2,2.324,6,3.539,23,0.591,46,5.166,48,3.409,49,5.824,51,3.42,349,2.682,392,4.681,412,2.805,452,4.079,556,3.908,566,3.657,682,5.5,789,6.441,821,6.257,822,6.517,831,3.41,879,6.096,880,5.5,997,4.584,1403,3.569,1404,4.738,1701,5.166,1702,4.962,1905,4.054,3142,6.441,3858,7.671,3859,7.671,3860,7.671,3861,7.671]],["title/setup/release-notes/#viz",[1243,3.356]],["text/setup/release-notes/#viz",[3862,10.017]],["title/setup/release-notes/#python",[15,2.918]],["text/setup/release-notes/#python",[2,2.233,15,3.185,23,0.568,26,1.142,89,3.497,129,3.396,450,4.909,478,5.421,592,3.724,705,7.037,967,4.909,970,5.29,1366,4.163,1403,3.899,1404,4.568,1529,5.354,1647,7.272,1870,4.958,2002,5.421,2028,6.234,3532,7.037,3754,7.554,3863,8.381,3864,8.381,3865,7.908]],["title/setup/release-notes/#r",[42,3.53]],["text/setup/release-notes/#r",[2,2.233,6,3.481,23,0.49,42,4.377,1701,6.412,1702,6.159,1907,6.323,3866,9.521]],["title/setup/release-notes/#sedona-101",[2,1.255,3536,5.205]],["text/setup/release-notes/#sedona-101",[2,1.87,5,3.541,12,3.525,75,3.216,179,3.873,263,4.246,412,3.377,452,3.893,833,5.038,878,3.913,1403,4.296,1404,4.127,3799,8.325,3867,8.014]],["title/setup/release-notes/#known-issue",[89,2.587,258,3.868]],["text/setup/release-notes/#known-issue",[2,2.388,15,2.803,23,0.486,26,1.005,36,3.138,53,4.024,55,4.899,75,2.568,619,4.058,703,7.223,967,4.321,1013,4.551,1366,3.844,1404,3.296,1628,4.408,1779,4.794,1820,4.454,1984,5.384,2002,7.1,2020,5.118,2021,7.465,2028,7.023,3754,6.65,3865,6.961,3868,7.377,3869,9.441,3870,8.51,3871,8.908,3872,7.377,3873,7.377]],["title/setup/release-notes/#global_2",[1748,5.412]],["text/setup/release-notes/#global_2",[2,2.25,23,0.572,26,1.161,75,2.966,101,1.648,114,1.279,748,8.013,1363,3.685,1364,4.61,1366,3.469,1402,5.316,1404,3.807,1471,5.738,2786,4.991,3275,5.738,3511,6.109,3678,7.154,3679,7.393,3870,7.68,3874,7.68,3875,8.039,3876,7.68,3877,8.039]],["title/setup/release-notes/#core_1",[944,2.88]],["text/setup/release-notes/#core_1",[2,1.904,23,0.484,47,3.249,89,3.924,100,3.739,797,7.897,1403,4.375,1404,4.202,1430,7.671,1782,6.743,3878,9.405]],["title/setup/release-notes/#sql_3",[50,1.216]],["text/setup/release-notes/#sql_3",[2,2.402,6,3.748,8,2.456,10,2.409,23,0.603,26,0.972,50,1.463,51,2.981,101,1.38,243,2.632,253,5.032,299,3.993,313,4.141,411,3.321,412,2.61,594,2.381,613,3.744,621,5.539,630,5.032,641,2.666,693,6.193,716,6.193,755,6.193,760,6.193,796,5.822,831,3.257,879,5.672,1055,3.244,1068,3.801,1286,4.222,1392,3.49,1403,3.321,1404,3.189,1463,4.677,1471,4.807,1748,5.032,1981,4.453,2299,5.993,3561,5.672,3839,7.76,3871,6.735,3879,6.434,3880,7.138,3881,6.735]],["title/setup/release-notes/#viz_1",[1243,3.356]],["text/setup/release-notes/#viz_1",[2,2.171,12,3.463,23,0.552,26,1.236,745,4.221,748,7.04,878,3.843,1041,6.887,1290,6.109,1305,5.945,1404,4.054,1529,5.796,1638,6.294,3870,8.178,3875,8.56]],["title/setup/release-notes/#python_1",[15,2.918]],["text/setup/release-notes/#python_1",[2,1.916,23,0.487,50,1.498,243,3.489,411,4.402,831,3.334,1403,4.402,1404,4.228,1748,6.671,3881,8.929]],["title/setup/release-notes/#sedona-100",[2,1.255,3867,5.379]],["text/setup/release-notes/#sedona-100",[2,1.858,4,4.46,5,3.52,12,3.504,23,0.473,36,2.767,51,2.962,75,3.196,263,4.221,412,3.357,696,4.196,831,3.235,878,3.889,1403,4.271,1404,4.102]],["title/setup/release-notes/#global_3",[1748,5.412]],["text/setup/release-notes/#global_3",[2,2.26,6,2.562,13,2.663,15,2.663,23,0.575,26,0.955,27,5.32,36,2.112,56,3.064,57,2.18,63,3.241,73,6.942,86,4.864,100,2.786,178,2.735,188,4.592,219,1.805,225,3.887,246,3.675,273,3.736,476,2.365,748,8.353,878,4.304,981,3.45,1020,4.028,1051,2.786,1366,3.718,1482,7.087,1582,4.276,1628,4.187,1658,5.213,1690,3.26,1843,4.652,1873,5.569,2165,5.213,2647,5.569,3232,4.424,3233,4.533,3511,6.548,3526,6.081,3527,5.716,3678,7.668,3686,5.884,3877,6.612,3882,7.008]],["title/setup/release-notes/#sedona-core",[2,1.255,944,2.325]],["text/setup/release-notes/#sedona-core",[2,1.917,12,3.615,23,0.598,32,3.673,51,2.391,94,2.454,101,1.434,106,1.622,110,1.831,121,3.004,252,2.374,264,4.147,365,4.301,412,2.71,450,4.342,576,2.571,583,3.649,675,3.408,753,4.736,823,3.948,878,4.012,889,5.065,1023,6.432,1238,2.792,1403,3.448,1404,3.312,1410,6.666,1490,6.046,1544,7.724,1563,5.752,1658,5.514,2798,5.89,3835,6.994,3883,7.413,3884,7.413,3885,7.413,3886,6.682,3887,6.682,3888,7.413,3889,7.413,3890,7.413,3891,9.47]],["title/setup/release-notes/#sedona-sql",[2,1.255,50,0.981]],["text/setup/release-notes/#sedona-sql",[2,1.933,12,3.645,18,4.587,21,3.088,23,0.607,32,3.068,51,3.305,57,1.926,61,2.342,86,3.297,101,1.197,110,1.197,161,3.272,199,3.35,209,3.272,240,4.519,273,2.533,275,4.364,279,4.605,289,4.519,301,3.699,322,4.605,328,4.7,354,4.519,365,4.879,367,4.605,372,4.364,379,4.605,412,3.075,422,4.605,425,4.605,449,4.439,463,3.592,476,2.089,494,4.605,500,4.056,504,4.605,532,2.664,594,3.418,667,4.919,674,4.919,678,4.919,711,4.919,786,4.919,878,4.046,929,4.004,1392,3.027,1403,2.88,1404,2.766,1410,7.059,1430,5.049,1463,4.056,1490,5.049,1569,3.176,1658,4.605,1690,2.88,1897,4.056,1905,3.272,1944,4.919,3178,5.58,3892,6.191,3893,6.191,3894,6.191,3895,6.191,3896,6.191,3897,6.191,3898,6.191]],["title/setup/release-notes/#sedona-viz",[2,1.255,1243,2.71]],["text/setup/release-notes/#sedona-viz",[12,3.443,47,3.115,51,2.91,61,3.412,407,6.358,475,4.88,878,3.821,1000,4.971,1268,5.504,1466,5.627,1725,7.826,1763,6.847,1770,9.272,1800,5.762,1836,5.003,1871,5.99]],["title/setup/release-notes/#sedona-python",[2,1.255,15,2.356]],["text/setup/release-notes/#sedona-python",[2,2.105,6,3.15,8,2.964,15,3.951,23,0.444,51,3.354,86,4.588,101,1.666,273,3.525,397,4.269,412,3.15,566,4.107,878,3.65,882,3.938,1410,5.504,1465,4.863,1552,5.887,1923,6.846,2112,5.148,3899,8.616,3900,8.616,3901,8.616,3902,8.616]],["title/setup/release-notes/#geospark-legacy-release-notes",[5,1.716,22,1.493,59,1.269,3903,4.475]],["text/setup/release-notes/#geospark-legacy-release-notes",[]],["title/setup/release-notes/#v131",[415,5.031]],["text/setup/release-notes/#v131",[5,1.774,6,1.692,12,1.766,15,3.416,23,0.638,50,1.083,51,2.9,59,2.946,71,3.073,75,1.611,89,4.45,101,0.895,110,0.895,139,3.484,263,2.128,283,2.409,396,3.318,397,2.293,412,3.287,413,3.262,430,2.115,501,3.211,538,2.103,553,3.513,566,2.206,603,3.116,689,3.513,736,3.318,779,3.513,834,3.701,938,2.079,944,1.736,964,3.073,981,2.278,1238,1.743,1243,2.023,1257,2.374,1363,2.002,1366,1.884,1391,2.115,1401,3.116,1402,5.077,1403,4.462,1404,4.286,1405,2.484,1406,2.956,1407,4.171,1408,3.073,1409,4.171,1410,7.339,1411,4.171,1412,3.378,1413,5.193,1414,4.171,1415,4.171,1416,4.171,1417,4.171,1418,4.171,1419,4.171,1420,3.677,1421,4.171,1422,3.677,1423,4.171,1424,4.171,1425,4.171,1426,4.171,1427,4.171,1428,4.171,1429,4.171,1430,3.775,1431,4.171,1432,4.171,1433,3.886,1434,4.171,1435,4.171,1436,4.171,1437,2.993,1438,3.513,1439,4.171,1440,4.171,1441,3.886,1442,3.886,1443,4.171,1444,4.171,1445,4.171,1446,4.171,1447,3.677,1448,3.677,1449,4.171,1450,4.171,1451,3.886,1452,3.886,1453,4.171,1454,4.171,1455,3.886,1456,3.211,1457,3.211,1458,4.171,1459,4.171,1460,4.171,1461,4.171]],["title/setup/release-notes/#v130",[113,3.615]],["text/setup/release-notes/#v130",[5,3.696,15,3.664,59,2.734,1402,6.015,1403,4.485,1462,6.912,1463,6.317]],["title/setup/release-notes/#v120",[141,3.804]],["text/setup/release-notes/#v120",[6,3.282,8,2.552,10,2.057,12,2.327,17,0.903,20,2.083,23,0.595,26,0.541,31,2.478,36,1.197,47,1.372,50,1.175,51,3.056,59,3.074,60,2.132,75,2.122,89,4.356,93,4.527,94,2.755,100,1.579,101,0.768,114,0.596,118,2.847,139,4.239,199,2.149,235,2.067,273,1.625,278,2.478,283,3.173,335,2.122,380,2.714,385,4.37,407,2.8,412,3.464,430,2.786,476,2.057,538,1.805,566,2.906,594,1.325,595,2.115,613,2.083,616,2.943,702,2.067,774,3.015,868,2.602,872,3.761,878,3.525,880,2.847,944,1.49,964,2.637,988,3.015,992,3.015,993,3.015,995,2.954,1000,1.847,1027,3.604,1205,2.023,1238,1.496,1243,1.736,1248,2.8,1257,3.127,1281,3.015,1288,3.581,1290,2.674,1297,2.8,1305,2.602,1316,2.755,1318,2.602,1326,3.239,1363,2.637,1403,4.176,1404,3.718,1410,5.316,1412,5.415,1413,4.628,1438,3.015,1447,3.156,1448,3.156,1455,3.334,1456,2.755,1457,2.755,1464,3.446,1465,2.241,1466,3.803,1467,3.334,1468,3.58,1469,3.58,1470,3.58,1471,4.105,1472,3.58,1473,3.58,1474,3.58,1475,3.58,1476,3.58,1477,3.58,1478,3.015,1479,3.156,1480,3.58,1481,3.58,1482,3.082,1483,2.8,1484,3.58,1485,3.58,1486,3.58,1487,2.373,1488,3.58,1489,3.58,1490,4.972,1491,3.334,1492,2.398,1493,3.58,1494,3.58,1495,3.58,1496,3.58,1497,2.326,1498,2.037,1499,4.534,1500,2.954,1501,3.58,1502,3.58,1503,3.58,1504,3.58,1505,3.58,1506,3.58,1507,3.58,1508,3.58,1509,3.58,1510,3.58,1511,3.58,1512,3.58,1513,3.58,1514,3.58,1515,3.58,1516,3.58,1517,3.58,1518,3.58]],["title/setup/release-notes/#v113",[1328,6.446]],["text/setup/release-notes/#v113",[12,3.165,17,1.885,23,0.566,50,1.313,59,3.246,75,2.887,89,3.459,110,1.603,273,3.392,538,3.768,595,4.415,944,3.81,1027,4.028,1238,3.123,1243,3.624,1403,3.857,1404,4.538,1410,5.297,1519,6.762,1520,7.473,1521,6.961,1522,4.054,1523,7.473,1524,7.473,1525,7.413]],["title/setup/release-notes/#v112",[1526,6.92]],["text/setup/release-notes/#v112",[8,1.822,23,0.633,26,0.721,50,0.839,59,2.492,65,2.116,75,2.627,89,4.223,100,2.106,101,1.459,110,1.459,111,0.887,121,2.146,124,2.737,128,1.961,165,3.47,166,3.073,177,2.479,220,1.553,245,4.755,273,4.429,352,1.953,378,3.384,397,2.624,538,2.407,543,2.938,558,2.773,594,2.517,616,2.557,620,2.509,666,3.384,715,3.384,780,3.866,844,3.734,882,2.421,917,5.727,944,1.987,1017,2.821,1238,1.995,1243,2.315,1254,3.165,1403,2.464,1404,4.279,1410,6.916,1521,4.447,1522,2.59,1525,3.866,1527,5.506,1528,3.619,1529,3.384,1530,4.774,1531,6.8,1532,6.8,1533,5.995,1534,6.671,1535,6.8,1536,5.727,1537,4.447,1538,4.447,1539,3.619,1540,4.021,1541,4.774,1542,4.596,1543,4.774,1544,4.32,1545,4.596,1546,4.774,1547,4.774,1548,4.596,1549,3.47,1550,4.774,1551,3.305,1552,3.619,1553,4.774,1554,3.797,1555,4.447,1556,2.778,1557,4.774]],["title/setup/release-notes/#v111",[608,5.604]],["text/setup/release-notes/#v111",[5,3.696,967,5.647,1363,4.17,1364,5.216,1462,6.912,1463,6.317,1549,6.317]],["title/setup/release-notes/#v110",[733,4.089]],["text/setup/release-notes/#v110",[6,3.219,8,3.029,23,0.633,26,1.199,36,2.28,42,3.477,50,0.841,51,1.714,59,2.874,75,2.633,89,4.395,110,1.028,121,2.153,177,1.747,243,3.536,273,4.434,335,1.85,403,4.99,470,3.438,471,3.355,472,4.035,473,4.035,474,2.767,543,2.948,555,2.787,556,2.707,594,1.773,597,4.035,661,4.035,702,2.767,708,4.335,872,4.666,944,1.993,1104,3.438,1107,3.81,1243,2.323,1257,2.727,1363,2.299,1364,2.876,1370,5.422,1404,4.529,1410,6.729,1412,3.879,1483,3.747,1487,3.176,1558,3.747,1559,4.462,1560,5.674,1561,4.774,1562,4.79,1563,4.124,1564,7.639,1565,4.79,1566,4.611,1567,3.395,1568,4.462,1569,2.727,1570,4.79,1571,4.462,1572,3.279,1573,4.611,1574,4.611,1575,4.611,1576,4.335,1577,4.611,1578,4.79,1579,4.611]],["title/setup/release-notes/#v101",[703,5.326]],["text/setup/release-notes/#v101",[8,2.915,23,0.594,26,1.154,50,1.63,59,3.27,89,4.295,245,4.585,335,2.95,556,4.316,686,6.303,944,3.178,1243,3.704,1363,3.665,1372,6.075,1374,6.575,1404,4.599,1525,6.185,1552,5.79,1580,7.352,1581,5.552]],["title/setup/release-notes/#v100",[552,2.97]],["text/setup/release-notes/#v100",[5,3.213,6,3.064,8,2.884,17,1.906,50,1.619,59,3.258,94,2.775,128,3.103,455,4.181,523,5.727,524,5.727,525,5.644,537,4.239,944,3.144,965,6.117,1243,4.47,1257,5.245,1315,3.995,1350,8.585,1382,6.362,1582,5.114,1583,4.269,1584,7.554,1585,5.114]],["title/setup/release-notes/#v091-geospark-core",[59,1.474,944,1.95,1586,4.685]],["text/setup/release-notes/#v091-geospark-core",[6,2.673,8,2.516,12,1.935,17,1.153,23,0.583,47,1.751,51,1.635,59,1.438,61,1.918,65,2.025,89,3.051,90,2.447,94,1.679,101,0.98,106,1.11,110,0.98,119,1.823,121,2.054,200,2.439,234,4.415,243,1.869,245,2.743,273,2.991,281,1.97,298,3.239,349,3.263,352,1.869,370,4.438,403,3.464,412,1.854,430,2.317,438,3.574,450,2.97,452,2.137,467,2.7,530,1.913,555,3.835,558,1.6,583,2.495,619,2.788,701,3.517,706,3.849,707,3.771,775,3.367,822,3.414,831,3.855,834,2.743,880,3.635,882,2.317,883,3.7,888,3.163,891,3.163,1014,3.443,1403,2.358,1404,3.832,1410,4.671,1522,2.479,1529,3.239,1544,4.135,1559,4.257,1560,4.325,1561,3.2,1567,3.239,1572,4.511,1587,4.257,1588,4.57,1589,4.57,1590,4.57,1591,4.57,1592,4.399,1593,3.2,1594,3.956,1595,4.028,1596,4.57,1597,3.934,1598,2.417,1599,4.399,1600,3.128,1601,4.57,1602,4.57,1603,4.135,1604,4.57,1605,4.57,1606,4.57,1607,4.57,1608,4.028,1609,3.849,1610,4.257,1611,3.464,1612,4.57,1613,6.139,1614,6.59,1615,3.7,1616,4.257,1617,2.582]],["title/setup/release-notes/#v082-geospark-core",[59,1.474,944,1.95,1618,4.685]],["text/setup/release-notes/#v082-geospark-core",[17,1.836,23,0.515,51,2.604,89,3.369,96,3.607,100,3.21,245,4.368,273,3.303,283,4.203,334,4.368,412,2.952,474,4.203,555,4.234,558,3.154,873,5.096,882,3.69,938,3.628,961,4.776,1104,5.222,1238,3.041,1403,4.648,1404,4.465,1498,4.142,1619,7.277,1620,2.868,1621,3.825,1622,7.277,1623,7.277,1624,9.007,1625,6.779,1626,6.779,1627,7.277,1628,4.824]],["title/setup/release-notes/#v081-geospark-core",[59,1.474,944,1.95,1629,4.685]],["text/setup/release-notes/#v081-geospark-core",[23,0.444,51,2.779,59,2.443,96,3.85,100,3.426,124,4.452,177,2.831,219,2.219,464,4.241,478,5.573,576,2.988,579,6.288,580,7.33,616,4.159,695,6.54,1024,5.257,1027,4.186,1392,5.084,1403,4.008,1404,4.646,1569,4.42,1630,7.234,1631,7.766]],["title/setup/release-notes/#v080-geospark-core",[59,1.474,944,1.95,1632,4.685]],["text/setup/release-notes/#v080-geospark-core",[6,1.371,8,1.29,12,2.225,13,2.216,17,2.429,20,1.053,21,1.87,23,0.579,26,0.511,51,1.881,58,3.68,59,2.91,61,1.418,75,1.305,89,2.433,96,1.675,97,2.563,100,4.08,101,1.561,108,1.952,109,2.97,111,1.352,114,1.312,121,2.362,124,3.697,177,1.916,219,1.501,221,1.952,225,2.079,234,2.483,241,2.263,245,3.155,273,1.534,281,1.457,333,2.979,349,2.907,370,1.605,412,2.132,431,3.449,450,3.415,452,1.58,474,4.818,476,3.26,480,2.218,492,2.562,533,2.218,554,2.979,555,3.058,558,2.258,578,2.846,579,2.736,580,2.643,594,1.251,616,1.81,641,3.014,696,1.714,700,4.57,745,2.712,823,3.105,831,3.52,834,3.871,859,2.525,878,1.588,882,3.27,883,2.736,933,2.979,938,2.62,955,1.556,977,2.736,981,1.845,1014,1.765,1140,2.562,1238,3.04,1403,2.712,1404,2.605,1492,3.52,1522,2.851,1539,2.562,1560,4.774,1561,4.516,1583,2.97,1603,3.058,1617,1.91,1633,2.196,1634,2.846,1635,3.148,1636,3.379,1637,5.043,1638,4.045,1639,3.379,1640,3.379,1641,3.379,1642,3.379,1643,2.425,1644,3.379,1645,2.979,1646,2.643,1647,3.253,1648,2.525,1649,3.379,1650,3.379,1651,3.379,1652,3.379,1653,3.379,1654,5.255,1655,3.379,1656,2.601,1657,6.776,1658,4.337,1659,3.379,1660,3.379,1661,3.148,1662,3.379,1663,3.379,1664,5.043,1665,3.379,1666,2.979,1667,4.045,1668,4.888,1669,2.979,1670,3.148,1671,3.379,1672,3.148]],["title/setup/release-notes/#v01-v07",[1673,5.587,1674,5.587]],["text/setup/release-notes/#v01-v07",[5,0.996,6,2.862,7,1.802,8,2.858,12,2.988,13,0.987,17,2.312,20,1.218,23,0.539,26,0.591,32,3.229,33,2.618,35,1.64,36,0.783,44,1.216,47,2.869,51,1.8,57,1.349,58,1.64,59,2.78,60,1.394,63,1.201,65,1.038,71,1.725,75,1.943,86,2.309,89,2.719,90,1.254,95,2.016,96,2.494,97,1.142,100,1.724,101,0.502,102,0.996,106,0.569,111,1.091,114,0.978,119,1.559,121,2.261,124,3.367,129,1.053,139,1.323,171,1.866,172,1.323,177,2.573,178,1.693,200,0.867,219,2.016,235,1.352,241,1.568,243,0.958,245,2.346,252,1.787,261,1.749,264,2.426,269,1.972,273,1.063,281,1.009,335,2.726,349,2.17,352,2.403,355,2.093,370,2.389,377,1.279,384,1.373,412,2.383,450,2.54,455,1.296,456,2.675,459,1.948,464,3.208,467,2.309,471,1.64,474,1.352,475,1.406,486,1.493,487,1.603,489,1.136,558,1.369,559,1.603,576,0.901,585,1.64,595,1.383,616,2.093,620,2.054,641,2.706,682,1.862,713,1.725,715,1.66,775,1.725,780,1.896,823,1.383,831,2.758,832,1.552,834,1.406,837,1.916,839,1.972,847,1.023,859,1.749,865,4.435,875,1.493,876,1.603,877,1.68,878,1.837,882,1.982,889,1.775,921,2.064,938,1.167,940,1.64,959,0.979,964,1.725,1003,1.775,1014,2.628,1022,2.181,1024,4.421,1027,2.107,1055,1.181,1068,1.383,1104,1.68,1238,2.949,1240,2.149,1247,3.165,1254,1.552,1256,1.972,1300,1.441,1318,1.702,1365,2.064,1366,2.272,1382,4.947,1392,1.27,1403,4.207,1404,4.467,1463,1.702,1497,2.54,1498,1.333,1522,1.27,1528,1.775,1529,1.66,1538,2.181,1539,1.775,1556,1.362,1569,1.333,1583,1.323,1593,1.64,1594,1.406,1598,2.067,1609,1.972,1616,2.181,1617,2.209,1625,2.181,1626,2.181,1637,3.934,1646,1.831,1657,2.181,1666,2.064,1675,2.181,1676,2.342,1677,2.342,1678,2.064,1679,2.181,1680,1.896,1681,2.181,1682,2.342,1683,3.165,1684,2.119,1685,2.342,1686,1.862,1687,1.725,1688,3.908,1689,2.805,1690,1.208,1691,1.932,1692,2.342,1693,2.342,1694,2.119,1695,2.181,1696,2.181,1697,3.706,1698,2.342,1699,2.342,1700,2.342,1701,4.388,1702,4.215,1703,1.68,1704,2.342,1705,2.342,1706,2.119,1707,2.342,1708,1.862,1709,1.972,1710,1.802,1711,1.373,1712,2.342,1713,2.342,1714,2.342,1715,2.342,1716,2.119,1717,1.775,1718,3.908,1719,1.406,1720,1.831,1721,1.66,1722,2.342,1723,3.908,1724,1.64,1725,2.254,1726,2.342,1727,2.342,1728,2.342,1729,2.342,1730,2.342,1731,1.972,1732,1.64,1733,1.603,1734,2.342,1735,3.641,1736,2.342,1737,1.68,1738,1.68,1739,2.342,1740,2.342,1741,1.417,1742,2.342,1743,2.064,1744,2.342,1745,2.342,1746,2.342,1747,1.972,1748,1.831,1749,1.972,1750,2.342,1751,1.862]],["title/setup/release-notes/#geospark-viz-old",[58,3.281,59,1.474,1243,2.272]],["text/setup/release-notes/#geospark-viz-old",[6,2.095,8,3.156,12,3.044,13,2.177,20,1.609,23,0.556,32,3.951,46,5.37,47,1.979,58,3.617,61,2.168,75,2.776,89,2.391,97,2.518,100,2.278,101,1.542,111,1.336,114,1.197,177,1.883,219,1.476,252,2.937,281,2.227,412,3.625,424,3.925,620,2.714,684,4.262,715,3.661,833,3.126,834,3.1,1000,5.334,1240,2.839,1267,5.621,1268,4.866,1291,3.755,1298,3.424,1308,3.915,1382,7.913,1383,4.811,1403,3.71,1404,3.563,1437,3.706,1582,3.497,1583,2.919,1593,3.617,1633,3.356,1637,4.039,1666,4.553,1675,4.811,1683,4.182,1694,4.674,1695,4.811,1696,4.811,1701,5.37,1702,5.932,1719,3.1,1752,5.165,1753,5.165,1754,5.165,1755,5.165,1756,4.182,1757,4.553,1758,7.187,1759,4.553,1760,4.182,1761,5.165,1762,5.165,1763,6.053,1764,5.165,1765,5.165,1766,5.165,1767,5.165,1768,5.165,1769,5.165,1770,4.972,1771,4.674]],["title/setup/zeppelin/",[2,1.052,1288,2.509,1779,2.147]],["text/setup/zeppelin/",[2,2.385,6,2.599,8,1.678,20,1.996,22,1.627,23,0.592,26,0.968,32,2.417,36,2.529,48,3.727,50,0.772,59,1.383,65,1.948,89,2.966,94,1.615,96,3.176,101,0.943,110,0.943,119,1.754,126,2.52,128,1.806,129,2.88,177,2.336,179,2.045,200,2.372,219,1.256,225,2.705,258,3.043,273,1.995,352,2.621,476,2.399,522,2.558,530,1.276,576,2.465,591,2.31,594,1.627,675,2.242,751,4.095,878,2.066,920,3.628,944,1.829,1051,1.939,1228,2.682,1240,4.568,1243,2.132,1261,3.875,1267,3.438,1268,5.119,1269,3.332,1288,5.724,1315,4.394,1366,1.986,1370,3.497,1405,3.816,1463,3.196,1466,3.043,1556,2.558,1733,3.009,1779,2.937,1800,3.116,1809,3.155,1843,2.484,1857,2.857,1887,4.396,1888,4.396,1889,3.332,1890,2.976,1891,4.396,1892,3.56,1893,3.702,1894,6.728,1895,4.857,1896,4.396,1897,3.196,1898,5.189,1900,3.875,1901,4.396,1902,4.396,1903,4.396,1904,4.396,1905,3.757,1906,3.875,1907,3.239,1908,4.095,1909,4.095,3648,4.721,3867,4.232,3904,4.877,3905,4.877]],["title/setup/zeppelin/#install-sedona-zeppelin",[2,1.052,1288,2.509,1779,2.147]],["text/setup/zeppelin/#install-sedona-zeppelin",[2,1.669,20,2.316,23,0.425,48,4.868,65,3.294,89,4.224,101,1.595,110,1.595,119,2.965,128,3.053,179,3.458,200,3.377,258,5.145,591,3.907,1240,4.086,1261,6.553,1267,5.813,1268,6.685,1288,4.887,1463,5.403,1733,5.087,1887,7.433,1888,7.433,1889,5.635,1890,5.032,1891,7.433,3648,5.476]],["title/setup/zeppelin/#compatibility",[1892,5.604]],["text/setup/zeppelin/#compatibility",[2,2.402,26,1.258,36,3.266,50,1.462,944,3.464,1243,4.037,1288,4.458,1370,6.622,1893,7.011,3867,8.014]],["title/setup/zeppelin/#installation",[1779,3.172]],["text/setup/zeppelin/#installation",[2,1.87,22,3.081,36,2.784,59,2.619,177,3.035,219,2.378,273,3.779,476,3.117,675,4.246,1288,5.231,1556,4.844,1843,4.704,1894,6.741]],["title/setup/zeppelin/#create-helium-folder-optional",[126,1.344,129,1.813,1315,2.133,1894,3.266]],["text/setup/zeppelin/#create-helium-folder-optional",[96,4.308,126,2.896,1228,5.302,1288,4.654,1315,5.296,1894,7.036]],["title/setup/zeppelin/#add-sedona-zeppelin-description-optional",[2,0.795,6,1.436,129,1.592,1288,1.897,1895,2.685]],["text/setup/zeppelin/#add-sedona-zeppelin-description-optional",[2,2.202,8,2.792,23,0.516,96,3.626,126,2.438,177,2.667,225,4.502,476,2.739,530,2.123,576,3.476,594,2.708,878,3.438,920,6.037,1051,3.227,1240,4.967,1269,5.546,1288,4.839,1315,3.869,1466,5.064,1895,5.546,1896,7.315,1897,5.318,1898,7.317,1900,6.449,1901,7.315,1902,7.315,1903,7.315,1904,7.315,3904,8.116,3905,8.116]],["title/setup/zeppelin/#enable-sedona-zeppelin",[2,1.052,1288,2.509,1905,2.747]],["text/setup/zeppelin/#enable-sedona-zeppelin",[2,1.927,1288,5.621,1857,5.577,1894,6.949,1905,5.032,1906,7.566,1907,6.323]],["title/setup/zeppelin/#add-sedona-dependencies-in-zeppelin-spark-interpreter",[2,0.709,6,1.28,26,0.477,751,2.94,1288,1.69,1366,1.426]],["text/setup/zeppelin/#add-sedona-dependencies-in-zeppelin-spark-interpreter",[]],["title/setup/zeppelin/#visualize-sedonasql-results",[352,1.917,522,2.726,1240,2.576]],["text/setup/zeppelin/#visualize-sedonasql-results",[]],["title/setup/zeppelin/#display-sedonaviz-results",[352,1.917,1908,4.364,3648,3.452]],["text/setup/zeppelin/#display-sedonaviz-results",[2,1.916,20,2.657,32,4.689,94,3.133,1288,4.568,1405,5.899,1800,6.045,1809,6.121,1909,7.945]],["title/setup/flink/install-scala/",[2,1.052,92,3.138,1779,2.147]],["text/setup/flink/install-scala/",[2,2.33,6,3.083,13,3.204,19,6.166,20,1.745,23,0.434,36,1.874,63,3.9,94,2.792,97,3.706,101,1.851,126,2.533,335,2.164,374,3.9,383,6.191,452,2.62,476,2.846,527,5.393,530,1.626,535,4.624,538,4.349,576,2.156,592,4.253,593,4.742,604,3.144,753,3.971,776,4.537,847,4.358,941,3.06,945,3.31,946,3.448,1066,3.144,1108,4.456,1228,3.419,1315,2.963,1363,3.647,1364,3.363,1366,3.896,1392,3.04,1620,2.995,1621,3.995,1648,4.186,1687,5.6,1690,3.923,1821,3.101,1831,4.847,1834,5.603,1835,4.456,1843,3.166,1845,3.677,1849,5.219,3906,6.749]],["title/setup/flink/modules/",[1465,4.333]],["text/setup/flink/modules/",[2,1.678,12,3.165,15,3.151,17,2.497,19,5.838,23,0.589,36,2.499,42,3.812,44,3.88,47,2.864,50,1.608,51,2.675,92,5.006,105,1.537,349,2.298,750,6.57,827,6.132,944,3.11,1051,3.296,1465,4.679,3449,7.473,3696,6.94,3907,8.291]],["title/setup/flink/modules/#sedona-modules-for-apache-flink",[2,0.906,19,2.572,36,1.349,1465,2.526]],["text/setup/flink/modules/#sedona-modules-for-apache-flink",[17,2.589,19,5.184,47,3.115,50,1.692,51,2.91,105,1.672,349,2.5,750,6.912,827,5.445,944,3.383,1051,3.586,3449,8.13,3696,6.163,3907,9.02]],["title/setup/flink/modules/#api-availability",[12,2.366,44,2.901]],["text/setup/flink/modules/#api-availability",[15,3.664,23,0.572,42,4.432,92,5.821,827,5.821,3696,6.587]],["title/setup/flink/platform/",[1402,3.868,1854,4.444]],["text/setup/flink/platform/",[2,2.077,5,3.231,13,4.203,19,6.615,23,0.618,29,7.076,62,4.889,92,5.088,97,3.704,377,4.148,530,2.204,1286,4.985,1689,5.451,1690,3.92,1873,6.696,3233,5.451,3719,7.951,3908,9.15,3909,9.15]],["title/tutorial/Advanced-Tutorial-Tune-your-Application/",[943,2.908,1238,1.958,1910,3.452]],["text/tutorial/Advanced-Tutorial-Tune-your-Application/",[2,1.873,5,0.9,12,2.611,17,2.401,20,1.456,22,1.73,23,0.597,26,0.932,36,1.563,47,1.376,51,0.757,55,1.559,56,1.027,58,1.482,61,2.588,65,1.591,72,3.068,75,3.222,89,0.98,94,0.777,96,1.049,99,1.418,100,2.429,101,1.874,102,1.527,108,1.222,109,2.029,114,0.778,121,0.951,124,3.534,128,1.475,129,0.951,177,0.772,200,0.783,234,2.208,243,2.921,248,3.794,257,1.196,264,1.314,266,2.762,281,0.912,349,2.824,365,1.362,370,2.22,374,1.086,383,1.519,397,2.57,403,1.112,412,1.456,417,3.165,431,2.356,446,1.251,452,1.679,474,2.073,476,1.75,481,2.808,491,2.311,530,1.042,531,1.337,533,2.356,534,1.325,538,2.776,558,2.63,559,4.585,563,2.544,585,1.482,592,1.77,593,1.974,604,2.015,620,1.887,641,1.487,696,1.82,698,1.559,699,1.915,700,2.544,702,1.222,720,1.714,752,1.604,831,2.937,833,2.173,834,3.305,837,2.292,860,2.645,878,3.148,882,3.126,919,1.418,927,3.398,928,1.559,938,2.33,943,2.228,955,0.975,973,1.482,980,2.721,982,1.539,984,2.405,1013,1.449,1014,1.106,1027,1.935,1068,2.762,1238,4.017,1272,1.866,1284,1.655,1300,4.122,1339,1.581,1403,1.092,1404,1.049,1405,2.138,1437,1.519,1487,1.403,1527,4.459,1528,1.604,1529,1.5,1556,1.232,1569,3.134,1583,3.112,1593,1.482,1594,2.806,1598,1.119,1609,1.783,1617,2.642,1628,2.38,1633,1.375,1637,2.808,1643,1.519,1656,1.629,1664,3.656,1667,1.629,1668,3.544,1669,3.165,1710,2.763,1720,5.239,1737,2.576,1743,1.866,1749,3.024,1820,1.418,1835,1.684,1839,1.684,1850,1.389,1858,2.514,1860,3.024,1862,1.482,1871,3.444,1893,3.024,1910,2.645,1911,1.866,1912,3.024,1913,2.117,1914,4.675,1917,2.117,1918,1.822,1920,2.117,1921,2.117,1922,1.972,1923,4.121,1924,2.117,1925,1.972,1926,1.714,1927,1.655,1928,4.542,1929,2.721,1930,3.59,1931,3.59,1932,3.024,1933,3.024,1934,2.856,1935,3.165,1936,3.165,1937,3.59,1938,2.117,1939,1.714,1940,3.59,1941,2.117,1942,2.117,1943,1.629,1944,3.165,1945,2.117,1946,2.117,1947,4.675,1948,3.59,1949,3.165,1950,2.117,1951,2.117,1952,1.972,1953,1.604,1954,3.248,1955,2.907,1956,2.117,1957,2.117,1958,2.117,1959,2.117,1960,2.117,1961,2.117,1962,1.822,1963,2.117,1964,2.117,1965,2.117,1966,1.972,1967,2.117,1968,2.117,1969,2.117]],["title/tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application",[2,0.709,943,1.959,980,2.393,1238,1.319,1405,1.879,1910,2.325]],["text/tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application",[2,1.881,20,2.609,51,2.997,592,4.129,593,4.604,604,4.7,955,3.858,980,6.349,1405,4.987,1527,6.782,1820,5.61,1839,6.662,1911,7.383]],["title/tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version",[2,0.906,75,1.558,1858,2.825,1912,3.397]],["text/tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version",[2,2.088,5,2.412,12,4.112,20,1.767,22,2.099,55,4.178,58,3.972,75,4.117,94,2.083,99,3.799,100,3.381,102,2.412,412,3.109,476,2.123,538,4.687,585,3.972,592,2.796,593,3.118,604,3.182,696,2.876,698,4.178,720,4.592,833,4.638,834,5.211,878,4.564,982,4.123,1013,3.882,1300,6.158,1403,2.927,1404,2.811,1487,3.76,1528,4.299,1637,5.994,1710,4.365,1835,4.511,1850,3.722,1871,6.395,1893,6.455,1912,4.777,1913,5.671,1914,8.68,1917,5.671,1918,4.882,1920,5.671,1921,5.671,1922,5.283,1923,7.652,1924,5.671,1925,5.283,1926,4.592,1927,4.436]],["title/tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor",[17,0.893,124,2.03,1238,1.48,1656,2.726,1858,2.48]],["text/tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor",[2,1.88,17,1.635,23,0.63,26,0.98,36,2.168,47,1.712,56,2.166,61,1.875,65,1.98,72,5.008,96,2.214,101,1.391,108,2.58,109,3.663,114,1.079,121,2.008,124,4.374,128,2.663,129,2.008,200,1.653,234,2.11,248,5.47,257,2.524,281,1.926,349,1.993,374,2.292,397,2.456,431,4.254,452,2.089,474,2.58,481,5.07,491,4.172,530,1.881,533,2.931,558,2.931,559,4.437,563,4.595,700,4.595,831,2.534,837,2.19,882,3.287,928,3.291,938,3.804,984,2.992,1027,2.408,1068,2.639,1238,2.709,1339,3.337,1437,3.205,1527,5.249,1583,4.312,1598,2.362,1628,4.297,1633,2.903,1643,3.205,1664,5.968,1667,3.438,1668,5.784,1669,5.715,1710,3.438,1720,3.493,1737,3.205,1743,3.938,1928,6.168,1929,3.386,1930,6.482,1931,6.482,1932,5.46,1933,5.46,1934,5.156,1935,5.715,1936,5.715,1937,6.482,1938,4.467,1939,3.617,1940,6.482,1941,4.467,1942,4.467,1943,3.438,1944,3.938,1945,4.467]],["title/tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used",[17,0.893,101,0.76,1238,1.48,1720,2.77,1946,3.541]],["text/tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used",[17,2.648,20,1.336,22,2.329,23,0.54,26,0.951,47,1.643,61,3.446,65,1.9,89,1.985,100,1.891,101,2.121,102,1.824,124,2.458,234,2.972,243,3.864,266,4.403,349,3.228,370,3.539,383,3.077,417,5.546,446,2.533,452,2.005,476,2.355,533,2.814,534,2.685,558,2.203,559,5.62,620,3.307,641,2.607,702,2.476,831,3.573,837,3.085,882,2.174,919,2.872,927,5.418,943,2.661,973,3.002,984,2.872,1027,2.311,1068,2.533,1238,4.35,1272,3.78,1284,3.353,1527,3.472,1569,3.581,1594,3.777,1609,3.611,1617,4.212,1720,5.829,1737,3.077,1749,5.299,1860,5.299,1928,3.159,1929,3.25,1947,7.453,1948,6.291,1949,5.546,1950,4.287,1951,4.287,1952,3.994,1953,3.25,1954,5.693,1955,5.095,1956,4.287,1957,4.287,1958,4.287,1959,4.287,1960,4.287,1961,4.287,1962,3.691,1963,4.287,1964,4.287,1965,4.287]],["title/tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions",[17,1.018,882,2.045,1238,1.686,1966,3.758]],["text/tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions",[26,1.088,36,2.408,100,3.177,101,1.545,114,1.199,177,2.626,264,4.47,365,4.635,397,4.919,403,3.785,474,4.159,531,4.55,558,3.133,696,3.652,699,6.517,752,5.459,834,4.323,860,6.593,878,3.385,882,3.652,1014,3.762,1068,4.255,1238,3.01,1529,5.104,1556,4.19,1569,5.093,1583,4.07,1593,5.043,1594,4.323,1720,5.632,1862,5.043,1910,5.306,1944,6.349,1967,7.202,1968,7.202,1969,7.202]],["title/tutorial/benchmark/",[1973,6.101]],["text/tutorial/benchmark/",[2,2.31,8,2.588,20,2.95,23,0.387,50,1.191,55,4.995,75,3.328,89,3.138,101,2.138,243,2.773,403,3.563,556,4.869,775,4.995,823,4.006,833,5.214,834,4.07,860,4.995,944,2.821,1463,4.928,1572,4.64,1594,4.07,1595,5.977,1621,3.563,1733,4.64,1738,4.865,1806,4.64,1857,4.406,1862,4.748,1973,8.348,1974,5.49,1975,5.977,1976,6.135,1977,6.315,1978,5.71,1979,6.315,1980,6.779,1981,4.693,1982,6.315]],["title/tutorial/benchmark/#benchmark",[1973,6.101]],["text/tutorial/benchmark/#benchmark",[2,2.317,8,2.613,20,2.964,50,1.203,55,5.044,75,3.349,89,3.169,101,2.146,243,2.801,403,3.598,556,4.899,775,5.044,823,4.045,833,5.246,834,4.11,860,5.044,944,2.849,1463,4.977,1572,4.686,1594,4.11,1595,6.036,1621,3.598,1733,4.686,1738,4.913,1806,4.686,1857,4.449,1862,4.794,1973,7.642,1974,5.544,1975,6.036,1976,6.195,1977,6.378,1978,5.766,1979,6.378,1980,6.846,1981,4.739,1982,6.378]],["title/tutorial/core-python/",[15,2.918]],["text/tutorial/core-python/",[2,1.31,7,0.423,8,0.21,10,1.349,12,0.444,15,1.632,17,1.898,20,1.032,22,0.989,23,0.652,26,0.544,32,0.577,36,1.005,42,0.769,44,0.285,47,0.739,48,1.141,50,0.184,51,0.69,56,0.266,57,1.848,61,1.122,65,1.827,89,0.698,90,0.294,92,0.368,93,0.71,94,1.217,100,0.463,101,1.661,102,1.41,105,0.113,106,0.94,108,2.08,110,1.367,111,0.81,114,0.552,115,0.184,119,1.066,121,0.472,124,0.602,126,1.201,128,0.619,129,0.472,136,1.829,137,0.423,139,1.308,159,1.188,161,0.322,165,0.399,166,1.241,171,0.92,172,1.511,173,0.35,177,0.383,179,0.255,186,0.28,200,1.916,201,2.198,220,0.753,222,0.304,234,1.566,235,0.606,236,0.935,242,0.866,243,2.258,252,1.068,257,0.31,259,0.669,264,0.341,270,0.416,281,1.553,327,0.625,349,2.265,352,2.386,355,0.294,370,1.269,373,1.806,374,0.538,384,0.322,403,1.405,411,0.283,452,0.901,457,1.174,464,0.3,474,0.317,486,0.35,488,2.439,490,0.795,522,0.877,529,0.606,530,1.554,532,1.276,537,1.86,545,0.63,550,2.388,555,0.611,556,0.31,558,2.821,559,0.718,560,0.808,561,1.461,563,0.744,566,2.534,567,1.508,568,0.353,575,0.399,576,2.124,582,0.884,583,1.053,591,0.552,594,1.916,595,0.62,613,0.877,614,0.85,615,0.372,616,1.24,619,0.335,639,0.925,641,2.689,643,0.718,653,1.899,669,0.429,675,1.181,676,0.753,696,0.278,697,0.416,698,0.405,701,0.423,713,0.405,730,1.753,745,0.283,750,0.753,762,0.773,823,0.62,831,1.95,834,0.63,836,0.87,837,1.135,838,0.394,881,0.429,882,1.827,886,0.429,888,0.726,891,0.726,903,0.511,905,0.773,926,0.41,938,0.961,941,1.053,943,0.341,944,0.802,951,0.322,953,0.317,955,0.253,959,3.291,961,0.989,970,1.35,973,0.735,975,0.445,978,2.08,981,0.573,999,0.41,1007,0.795,1013,0.718,1017,0.324,1020,0.35,1027,1.62,1049,0.682,1050,0.821,1051,0.85,1055,3.013,1062,0.484,1066,2.689,1070,0.389,1140,0.416,1228,0.335,1238,2.163,1271,0.38,1300,0.927,1318,0.763,1319,0.763,1320,0.763,1344,0.347,1345,0.675,1391,0.278,1392,1.046,1401,0.784,1402,0.38,1405,0.327,1420,0.484,1422,0.484,1437,0.394,1465,1.207,1478,0.884,1479,0.925,1492,0.703,1498,0.313,1522,1.63,1549,0.399,1552,0.416,1560,1.972,1561,0.735,1582,1.305,1593,0.385,1594,0.33,1598,1.019,1615,0.445,1617,1.511,1620,0.594,1633,0.357,1638,0.423,1643,0.753,1664,0.821,1697,1.706,1703,1.918,1711,2.418,1719,1.804,1721,2.349,1724,2.711,1733,0.376,1737,0.753,1738,0.394,1741,0.912,1751,1.199,1756,0.445,1779,0.481,1784,0.795,1785,1.291,1803,0.399,1805,0.445,1826,0.437,1836,0.338,1853,1.855,1862,0.385,1869,0.416,1870,0.689,1876,0.462,1905,0.322,1910,0.405,1911,0.484,1927,0.429,1928,1.969,1929,0.795,1932,0.462,1933,1.623,1934,1.533,1935,2.041,1936,0.484,1949,0.925,1955,0.85,1981,0.726,1988,0.95,1989,0.977,1990,0.866,1991,0.445,1992,0.549,1993,0.884,1994,3.28,1995,0.977,1997,6.552,1998,0.549,1999,0.925,2000,0.977,2001,0.85,2002,0.753,2029,0.429,2030,0.38,2031,0.429,2032,0.445,2033,1.049,2034,0.884,2036,1.927,2037,0.511,2038,0.511,2039,1.927,2040,0.445,2041,0.511,2042,0.511,2043,0.549,2044,1.049,2045,1.049,2046,0.549,2047,1.927,2048,2.978,2049,1.164,2050,0.609,2051,0.744,2052,2.138,2053,0.511,2054,0.484,2055,1.164,2057,4.639,2058,0.95,2059,0.609,2061,0.609,2062,0.549,2063,0.389,2064,0.416,2065,0.549,2066,5.015,2067,1.699,2070,1.875,2071,2.999,2072,1.533,2073,1.533,2074,1.533,2075,1.533,2076,4.272,2077,2.185,2078,4.567,2079,2.853,2080,1.782,2081,0.462,2082,0.41,2083,2.026,2084,2.357,2085,1.142,2086,0.462,2087,0.511,2088,0.549,2089,0.549,2090,0.549,2091,0.549,2092,1.049,2093,0.549,2094,0.549,2095,0.549,2096,0.808,2097,0.925,2098,0.884,2099,0.549,2100,0.484,2101,1.082,2102,0.484,2103,1.561,2104,0.753,2105,0.821,2106,0.821,2107,0.753,2108,0.821,2109,0.85,2110,3.169,2111,1.401,2112,3.308,2113,3.034,2114,2.13,2115,0.925,2116,0.484,2117,0.903,2118,0.85,2119,1.329,2120,0.484,2121,0.484,2122,0.484,2123,0.549,2124,4.803,2125,1.659,2126,1.927,2127,0.549,2128,0.549,2129,0.549,2130,0.549,2131,1.721,2132,0.549,2133,4.123,2134,0.549,2135,0.609,2136,1.049,2137,0.95,2138,0.549,2139,0.549,2140,0.484,2141,0.416,2142,1.841,2143,0.399,2144,0.549,2146,2.568,2147,2.568,2148,0.511,2149,0.609,2150,1.672,2151,0.609,2153,0.549,2155,0.549,2156,0.549,2157,0.549,2158,0.977,2159,0.549,2160,0.549,2162,0.549,2163,0.549,2260,1.383,2626,0.484,2786,0.979,3080,0.416,3275,0.784,3589,0.497,3595,0.445,3703,0.497,3753,1.049,3792,0.549,3910,2.228,3911,0.511,3912,3.176,3913,1.578,3914,0.661,3915,1.927,3916,3.55,3917,3.146,3918,1.098,3919,1.098,3920,0.549,3921,3.146,3922,0.609,3923,0.609,3924,1.098,3925,1.098,3926,1.098,3927,1.098,3928,0.661,3929,1.507,3930,1.855,3931,0.609,3932,0.609,3933,0.609,3934,0.609]],["title/tutorial/core-python/#spatial-rdd-applications-in-python",[15,1.701,17,1.018,943,2.504,1238,1.686]],["text/tutorial/core-python/#spatial-rdd-applications-in-python",[]],["title/tutorial/core-python/#introduction",[105,1.423]],["text/tutorial/core-python/#introduction",[2,2.315,12,2.307,15,3.585,22,2.017,23,0.426,36,1.822,47,2.088,51,1.95,100,2.403,101,1.169,110,1.169,114,0.907,115,0.957,124,3.124,128,2.238,136,3.523,177,1.987,259,4.755,270,4.13,355,2.918,403,2.864,452,2.548,558,2.977,583,2.976,614,4.412,641,3.523,730,3.944,750,3.91,938,3.718,944,3.538,959,2.277,973,3.816,1027,4.583,1049,3.541,1392,2.956,1402,3.772,1405,3.245,1465,3.412,1522,4.046,1552,4.13,1582,5.049,1697,5.495,1733,3.729,1737,3.91,1785,3.65,1803,3.961,1805,4.412,1826,4.334,1836,3.353,1928,4.014,1929,4.13,1988,6.748,1989,5.076,1990,4.497,1991,4.412,1992,5.449,1993,4.589,1994,4.334,1995,5.076,1997,5.833,1998,5.449,1999,6.575,2000,5.076,2001,4.412,2786,5.526,3080,4.13,3275,5.572,3589,4.93,3703,4.93,3910,5.245,3911,5.076]],["title/tutorial/core-python/#installation",[1779,3.172]],["text/tutorial/core-python/#installation",[2,1.952,15,3.664,20,2.707,94,3.192,374,4.458,926,6.492,1779,3.983]],["title/tutorial/core-python/#apache-sedona-serializers",[2,1.052,36,1.567,403,2.462]],["text/tutorial/core-python/#apache-sedona-serializers",[2,1.601,23,0.645,110,1.529,243,2.916,257,4.028,403,4.673,457,3.904,563,5.052,951,4.179,953,4.116,970,7.105,1049,4.632,1344,4.503,1345,5.723,1594,4.279,1869,5.403,1870,4.678,1905,4.179,2029,5.575,2030,4.934,2031,5.575,2048,4.632,3595,5.772]],["title/tutorial/core-python/#create-a-spatialrdd",[126,1.862,558,1.956]],["text/tutorial/core-python/#create-a-spatialrdd",[]],["title/tutorial/core-python/#create-a-typed-spatialrdd",[126,1.561,558,1.641,594,1.734]],["text/tutorial/core-python/#create-a-typed-spatialrdd",[2,1.698,12,1.862,20,1.369,23,0.65,36,2.143,51,1.573,56,2.132,57,2.212,92,2.945,101,1.375,111,1.191,124,2.52,139,2.484,159,2.255,166,2.829,177,1.603,200,1.627,220,2.085,373,1.732,374,2.255,486,2.803,490,4.857,532,3.059,555,2.558,558,2.648,563,3.116,613,3.728,616,2.354,750,3.155,938,2.191,944,1.829,959,3.16,1013,3.009,1020,2.803,1300,4.653,1318,3.196,1392,3.476,1492,2.945,1582,4.338,1664,5.012,1719,2.639,1737,3.155,1785,2.945,1928,6.508,1929,3.332,1932,3.702,1933,6.998,1934,6.609,1935,7.787,1936,3.875,1989,4.095,1990,3.628,1993,3.702,1994,3.497,1995,4.095,2002,4.598,2032,3.56,2033,6.408,2034,3.702,2036,8.309,2037,4.095,2038,4.095,2039,8.309,2040,3.56,2041,4.095,2042,4.095,2043,4.396,2044,6.408,2045,6.408,2046,4.396,2047,7.561,2048,4.914,3910,4.232,3912,3.875]],["title/tutorial/core-python/#read-other-attributes-in-an-spatialrdd",[94,1.721,558,1.641,1027,2.525]],["text/tutorial/core-python/#read-other-attributes-in-an-spatialrdd",[17,1.762,23,0.621,48,3.443,57,2.411,65,3.891,100,3.081,101,1.499,110,1.499,128,2.869,201,5.357,373,2.752,457,3.067,530,2.027,558,2.446,559,4.78,595,4.127,713,5.146,837,3.424,886,5.462,1027,4.732,1050,6.866,1051,3.081,1140,5.294,1318,5.077,1319,5.077,1320,5.077,1697,6.468,1741,4.227,2001,5.655,2063,4.95,2064,5.294,2065,6.984,2066,5.218,2067,6.157]],["title/tutorial/core-python/#write-a-spatial-range-query",[17,1.018,349,1.24,370,1.915,941,2.203]],["text/tutorial/core-python/#write-a-spatial-range-query",[10,2.54,15,2.86,17,1.2,20,1.482,22,1.761,23,0.652,26,0.719,90,2.548,101,1.456,102,2.885,106,1.92,108,4.977,114,0.792,474,2.748,488,3.438,537,3.807,550,4.497,566,4.181,567,3.721,730,3.587,959,3.808,1017,2.811,1238,1.988,1271,3.293,1465,2.979,1598,2.516,1643,3.414,1711,3.977,1853,7.61,2057,5.396,2070,6.402,2071,7.799,2072,5.396,2073,5.396,2074,5.396,2075,5.396,2076,7.113,2077,4.931,2078,6.439,2079,6.806,2080,5.221,2260,3.414,3753,6.783,3913,4.98,3915,6.783,3916,5.84,3917,8.276,3918,4.98,3919,4.98]],["title/tutorial/core-python/#range-query-window",[349,1.441,370,2.225,1711,2.747]],["text/tutorial/core-python/#range-query-window",[2,1.774,20,2.461,36,2.641,93,5.347,108,4.562,110,1.695,119,3.151,126,2.632,171,3.77,200,2.923,349,2.911,370,4.496,530,2.292,583,5.17,594,2.923,1401,5.901,1711,5.551,1784,5.987,2081,6.652]],["title/tutorial/core-python/#use-spatial-indexes",[17,1.182,101,1.005,243,1.917]],["text/tutorial/core-python/#use-spatial-indexes",[2,1.698,17,2.167,23,0.644,42,2.835,57,1.918,65,2.463,101,1.193,106,1.35,108,4.366,243,3.771,281,2.396,349,2.324,370,2.639,373,2.979,457,2.44,488,3.016,530,1.613,537,3.119,550,3.684,558,1.946,594,2.798,831,2.173,882,2.818,905,4.095,938,2.771,955,2.56,959,3.59,961,3.647,981,3.035,1498,3.163,1560,5.638,1561,3.892,1620,2.19,1711,3.259,2057,6.013,2070,6.121,2071,6.84,2072,4.421,2073,4.421,2074,4.421,2075,4.421,2076,6.239,2077,4.04,2078,5.648,2079,4.784,2080,4.278,2082,4.152,2083,5.73,2084,6.664,2085,4.213,3912,4.9,3915,5.558,3916,4.784]],["title/tutorial/core-python/#output-format",[111,1.038,252,1.985]],["text/tutorial/core-python/#output-format",[15,2.381,17,1.425,23,0.651,26,0.854,48,4.27,101,1.859,110,1.212,111,1.05,114,0.94,136,4.385,201,5.917,252,2.007,349,1.737,352,2.31,370,2.682,464,3.084,532,2.696,641,3.167,653,5.473,676,4.053,701,4.347,959,2.361,1238,3.62,1522,3.064,1697,4.161,1997,4.418,2067,6.738,2079,6.579,2080,4.347,2086,4.757,2087,5.261,2088,5.648,2089,5.648,2090,5.648,2091,5.648,2092,7.643,2093,5.648,2094,5.648,2095,5.648,2096,5.883,2097,6.738,2098,6.437,2099,5.648]],["title/tutorial/core-python/#write-a-spatial-knn-query",[17,1.018,349,1.24,941,2.203,1617,2.28]],["text/tutorial/core-python/#write-a-spatial-knn-query",[17,2.071,23,0.635,32,3.457,57,2.17,61,2.639,89,2.911,101,1.349,110,1.349,121,2.827,200,3.814,222,3.48,349,2.978,352,2.572,488,2.509,530,1.825,558,2.874,582,3.687,594,2.327,836,3.632,959,3.43,1238,2.628,1598,3.325,1617,3.553,1724,7.216,2066,4.698,2078,6.132,2100,5.543,2101,5.89,2102,5.543,2103,6.646,2104,4.512,2105,4.918,2106,4.918,2107,4.512,2108,4.918,3916,5.413]],["title/tutorial/core-python/#query-center-geometry",[110,1.005,349,1.441,762,3.452]],["text/tutorial/core-python/#query-center-geometry",[2,1.815,20,2.518,36,2.703,93,5.472,119,3.829,126,2.694,171,4.582,200,2.991,349,2.485,530,2.346,583,4.414,594,2.991,641,3.349,762,5.955,1401,6.038,1617,4.567,1784,6.127]],["title/tutorial/core-python/#use-spatial-indexes_1",[17,1.182,101,1.005,243,1.917]],["text/tutorial/core-python/#use-spatial-indexes_1",[8,2.306,17,2.26,23,0.646,42,3.082,57,2.085,101,1.296,186,3.082,200,3.53,243,3.27,349,2.755,352,2.471,373,3.151,457,2.653,488,2.41,530,1.753,591,3.175,831,2.362,959,3.745,961,3.965,975,4.892,1560,3.965,1617,4.518,1620,2.381,1724,6.275,2057,6.359,2078,5.973,2083,6.061,2084,7.048,2085,4.58,2101,4.336,2103,6.474,2104,4.336,2105,4.725,2106,4.725,2107,4.336,2108,4.725,3912,5.326,3916,5.201]],["title/tutorial/core-python/#output-format_1",[111,1.038,252,1.985]],["text/tutorial/core-python/#output-format_1",[17,1.959,23,0.628,111,1.443,114,1.293,252,2.759,349,2.388,352,3.177,641,3.883,675,4.78,1617,4.389,1724,5.438,1997,8.6]],["title/tutorial/core-python/#write-a-spatial-join-query",[17,1.018,349,1.24,831,1.577,941,2.203]],["text/tutorial/core-python/#write-a-spatial-join-query",[17,2.215,23,0.64,32,2.728,57,1.713,61,2.083,65,3.097,89,2.297,101,1.065,102,2.11,106,1.205,110,1.986,121,2.23,236,3.924,281,3.013,349,2.487,352,3.309,384,2.909,488,2.788,530,1.44,537,2.784,550,4.633,558,1.737,582,2.909,594,2.994,653,3.135,675,2.531,676,3.561,831,2.732,836,2.866,959,2.921,978,3.434,1238,2.921,1598,2.624,1703,5.015,1711,2.909,1721,3.517,1785,3.323,1981,4.837,1997,8.643,2066,6.561,2076,5.767,2078,5.221,2109,4.018,2110,5.08,2111,3.607,2112,4.633,2113,5.886,2114,3.517,2115,6.161,3912,4.374,3916,4.271]],["title/tutorial/core-python/#use-spatial-partitioning",[17,1.182,101,1.005,882,2.376]],["text/tutorial/core-python/#use-spatial-partitioning",[2,1.432,17,2.089,23,0.641,36,2.132,42,3.251,44,3.31,101,1.368,102,2.711,236,3.092,281,2.748,349,1.96,558,2.9,619,3.89,696,3.233,745,3.29,831,2.492,882,5.118,978,5.732,1013,4.363,1522,4.493,1560,6.036,1561,4.464,1593,4.464,1615,5.162,1638,4.907,2066,6.872,2110,6.02,2112,6.455,2113,7.747,2114,5.869,2116,5.62]],["title/tutorial/core-python/#use-spatial-indexes_2",[17,1.182,101,1.005,243,1.917]],["text/tutorial/core-python/#use-spatial-indexes_2",[17,2.005,23,0.648,57,2.067,61,2.514,101,1.285,243,3.252,281,2.582,349,2.444,352,2.45,373,3.745,452,2.801,457,2.63,530,1.738,558,2.783,831,3.107,905,4.413,959,3.729,961,3.931,978,4.146,981,3.271,999,4.475,1620,2.36,1703,5.705,1876,5.044,2066,6.666,2078,5.939,2083,6.026,2084,7.008,2085,4.54,2110,5.779,2112,5.27,2113,7.514,2114,4.245,2117,5.156,3912,7.008,3916,5.156]],["title/tutorial/core-python/#output-format_2",[111,1.038,252,1.985]],["text/tutorial/core-python/#output-format_2",[17,1.694,23,0.599,65,3.795,111,1.248,114,1.118,252,2.385,281,2.894,349,2.064,352,2.746,452,4.004,641,4.114,653,4.242,831,2.625,838,4.818,888,5.927,891,5.927,1997,8.795,2066,5.016,2109,5.437,2113,5.655,2118,6.933,2119,8.311,2120,5.919,2121,5.919,2122,5.919]],["title/tutorial/core-python/#write-a-distance-join-query",[234,1.906,349,1.24,831,1.577,941,2.203]],["text/tutorial/core-python/#write-a-distance-join-query",[7,2.62,10,1.274,15,2.228,17,1.333,20,1.646,22,1.26,23,0.652,26,0.514,50,0.598,57,1.175,65,2.342,89,1.576,101,1.697,102,2.248,106,1.283,110,1.697,114,0.567,119,1.358,126,1.761,179,1.584,200,1.956,234,3.953,235,1.966,242,2.912,281,2.278,349,2.246,352,2.987,403,1.789,488,2.914,529,1.966,530,0.988,537,2.966,545,2.043,550,3.504,566,2.795,567,2.662,582,1.996,591,1.789,594,2.398,641,1.41,730,1.8,823,2.011,831,2.533,834,2.043,836,1.966,959,3.497,978,3.658,1062,3.001,1238,2.209,1392,1.847,1465,2.132,1522,1.847,1598,1.8,1643,2.443,1703,3.793,1711,3.099,1721,5.176,1751,4.204,1785,2.28,1853,3.277,1955,2.756,1994,6.656,2057,6.946,2066,6.252,2076,6.027,2077,3.842,2078,5.456,2110,5.309,2111,3.842,2112,4.842,2114,3.746,2117,2.93,2123,3.404,2124,9.12,2125,5.577,2260,2.443,3910,5.088,3912,4.659,3916,4.55,3920,3.404,3921,6.782,3922,3.777,3923,3.777,3924,3.563,3925,3.563,3926,3.563,3927,3.563]],["title/tutorial/core-python/#output-format_3",[111,1.038,252,1.985]],["text/tutorial/core-python/#output-format_3",[23,0.643,47,2.512,48,3.232,114,1.091,119,2.615,136,3.097,201,5.145,220,2.133,281,2.826,349,2.016,352,4.025,529,3.786,545,3.935,639,7.433,641,2.716,653,5.328,675,4.301,973,4.591,1238,3.524,1911,5.779,1997,7.963,2000,6.106,2034,5.521,2067,5.779,2126,9.841,2127,6.555,2128,6.555,2129,6.555,2130,6.555]],["title/tutorial/core-python/#save-to-permanent-storage",[1055,2.362,1719,2.812,2131,3.016]],["text/tutorial/core-python/#save-to-permanent-storage",[17,1.937,22,2.842,139,4.34,159,3.94,558,3.259,576,2.955,595,4.538,641,3.182,837,4.564,1027,4.139,1051,3.388,1055,4.693,1066,4.31,1319,5.583,1320,5.583,1437,5.511,1633,4.991,1719,5.588,1738,5.511,1741,4.648,1756,6.219,1862,5.378,2131,5.991]],["title/tutorial/core-python/#save-an-spatialrdd-not-indexed",[243,1.917,558,1.641,1055,2.362]],["text/tutorial/core-python/#save-an-spatialrdd-not-indexed",[61,3.648,558,3.506,594,3.216,1055,4.381,1719,5.216,2131,5.593]],["title/tutorial/core-python/#save-an-spatialrdd-indexed",[243,1.917,558,1.641,1055,2.362]],["text/tutorial/core-python/#save-an-spatialrdd-indexed",[61,3.494,243,3.995,558,3.63,576,3.203,594,3.081,641,3.449,1055,4.197,1066,4.671,1719,4.997,1741,5.038,2131,5.358]],["title/tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed",[243,1.449,558,1.24,1055,1.786,2112,2.348,2140,3.122]],["text/tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed",[17,1.993,26,1.194,102,3.36,264,4.903,349,2.428,352,3.231,411,4.076,831,3.088,881,6.177,882,4.801,1055,3.982,1238,4.237,1391,4.005,1549,5.742,1719,4.741,1870,5.184,1910,5.819,1927,6.177,2131,5.084,2141,5.987]],["title/tutorial/core-python/#reload-a-saved-spatialrdd",[558,1.641,1055,2.362,2142,3.727]],["text/tutorial/core-python/#reload-a-saved-spatialrdd",[23,0.493,558,3.024,576,3.322,641,3.578,1055,4.354,1066,4.846,2142,6.869,2143,6.278]],["title/tutorial/core-python/#read-from-other-geometry-files",[94,1.721,110,1.005,576,1.803]],["text/tutorial/core-python/#read-from-other-geometry-files",[17,2.481,51,3.015,101,1.808,106,2.046,558,2.95,641,3.491,669,6.59,831,3.294,837,4.131,1070,5.972,1522,4.571]],["title/tutorial/core-python/#read-from-wkt-file",[94,1.721,159,2.404,576,1.803]],["text/tutorial/core-python/#read-from-wkt-file",[23,0.633,220,2.63,373,3.185,488,3.224,561,6.127,959,3.378,1478,8.084,2048,5.252,2153,8.082,2155,8.082,3929,8.082,3930,7.78]],["title/tutorial/core-python/#read-from-wkb-file",[94,1.721,166,3.016,576,1.803]],["text/tutorial/core-python/#read-from-wkb-file",[23,0.633,220,2.63,373,3.185,488,3.224,561,6.127,959,3.378,1479,8.462,2048,5.252,2156,8.082,2157,8.082,3929,8.082,3930,7.78]],["title/tutorial/core-python/#read-from-geojson-file",[94,1.721,139,2.648,576,1.803]],["text/tutorial/core-python/#read-from-geojson-file",[23,0.612,561,6.349,959,3.5,2048,5.443,2158,9.13,2159,8.375,2160,8.375,3929,8.375,3930,8.062]],["title/tutorial/core-python/#read-from-shapefile",[94,2.052,555,3.251]],["text/tutorial/core-python/#read-from-shapefile",[23,0.612,560,7.544,561,6.349,959,3.5,2048,5.443,2162,8.375,2163,8.375,3930,8.062,3931,9.292]],["title/tutorial/core-python/#tips",[2626,6.101]],["text/tutorial/core-python/#tips",[2,0.915,10,2.268,17,1.028,23,0.657,26,0.916,51,1.458,65,1.805,101,1.552,102,1.733,106,1.471,108,3.499,114,0.678,126,1.358,234,1.924,242,1.831,349,1.252,352,2.478,488,3.195,537,3.399,550,4.016,566,4.236,567,4.738,730,3.204,834,2.445,837,1.997,959,3.75,978,2.82,1465,2.551,1711,3.552,1721,4.294,1751,3.24,1955,3.298,1994,5.753,2057,5.753,2066,4.526,2071,5.482,2072,3.24,2073,3.24,2074,3.24,2075,3.24,2076,6.61,2077,4.404,2078,5.984,2079,5.215,2080,3.135,2110,4.404,2111,2.961,2112,4.016,2114,2.887,2124,8.241,2125,3.507,2260,4.347,3792,4.073,3910,3.921,3912,3.591,3913,4.264,3915,4.073,3916,5.215,3917,8.384,3918,4.264,3919,4.264,3921,8.384,3924,4.264,3925,4.264,3926,4.264,3927,4.264,3932,4.519,3933,4.519,3934,4.519]],["title/tutorial/demo/",[92,4.635]],["text/tutorial/demo/",[2,1.516,10,1.361,12,3.202,13,4.246,17,0.917,20,1.732,22,1.346,23,0.527,26,1.299,36,1.86,47,1.393,50,1.328,52,1.899,54,2.2,57,1.255,63,4.409,65,1.611,66,1.899,75,2.608,97,4.19,99,3.725,101,1.844,102,1.546,114,0.926,178,1.575,257,2.055,273,1.65,284,2.2,402,2.237,411,1.876,457,1.596,476,2.082,530,1.614,538,1.833,545,2.183,574,3.663,576,1.399,585,3.894,592,2.741,593,3.057,619,2.219,676,2.609,745,1.876,847,4.131,878,2.613,919,2.435,938,1.812,944,1.513,946,2.237,955,3.753,959,1.52,967,2.363,1020,2.318,1049,2.363,1100,2.892,1238,3.16,1243,3.275,1315,3.999,1363,2.668,1366,2.512,1391,2.82,1483,2.844,1540,3.062,1598,1.923,1600,2.489,1620,3.524,1687,4.974,1689,2.609,1690,3.485,1691,3.001,1717,4.215,1749,4.683,1779,1.666,1782,2.892,1811,2.489,1820,3.725,1821,3.078,1825,2.679,1831,6.254,1843,4.273,1844,6.123,1845,4.431,1846,2.944,1850,2.386,1851,5.18,1852,5.032,1855,3.387,1860,4.683,1861,3.636,1866,3.387,1870,2.386,1926,2.944,1943,2.798,1971,4.503,2063,2.577,2283,3.062,2604,2.643,2647,3.205,2743,3.062,2804,2.798,3031,3.062,3180,2.798,3233,2.609,3445,3.205,3935,4.034,3936,4.034,3937,4.034,3938,4.034,3939,4.034]],["title/tutorial/demo/#scala-and-java-examples",[13,1.975,97,2.285,114,0.78]],["text/tutorial/demo/#scala-and-java-examples",[12,3.326,13,3.978,22,2.907,50,1.38,97,4.601,101,1.685,102,3.34,114,1.308,257,4.438,538,3.96,847,4.42,967,5.104,1049,5.104,1100,6.247,1238,3.282,1243,3.809,1831,6.449,1971,6.36]],["title/tutorial/demo/#folder-structure",[585,3.913,1315,2.955]],["text/tutorial/demo/#folder-structure",[2,2.207,10,2.753,12,4.162,13,4.143,17,1.855,47,2.818,50,1.726,54,4.451,101,2.109,530,2.134,574,5.332,585,5.15,1238,4.107,1243,4.397,1315,3.889,1749,7.635,1831,6.266,3935,8.159]],["title/tutorial/demo/#compile-and-package",[1690,2.884,1843,3.158]],["text/tutorial/demo/#compile-and-package",[]],["title/tutorial/demo/#prerequisites",[3936,7.678]],["text/tutorial/demo/#prerequisites",[13,4.061,20,2.533,36,2.719,97,3.964,178,3.521,530,2.359,592,4.008,593,4.469,955,3.745,1363,3.901,1689,5.834,1691,6.709,1779,3.726,1820,5.445,1844,6.583,2804,6.257,3233,5.834]],["title/tutorial/demo/#compile",[1690,3.572]],["text/tutorial/demo/#compile",[65,3.803,545,5.152,1315,4.539,1540,7.228,1620,3.382,1811,5.874,1821,4.75,1831,5.472,1844,6.949]],["title/tutorial/demo/#submit-your-fat-jar-to-spark",[26,0.61,63,2.07,1687,2.972,1845,2.647]],["text/tutorial/demo/#submit-your-fat-jar-to-spark",[20,1.959,26,1.464,36,2.103,57,2.17,63,5.155,66,3.285,75,3.529,99,5.498,101,1.349,273,2.854,284,3.805,402,3.87,476,2.354,592,3.1,593,3.457,619,3.837,676,4.512,847,2.748,878,3.858,919,4.212,938,3.135,944,2.617,946,3.87,955,3.781,1020,4.009,1315,3.325,1363,3.017,1366,3.707,1483,4.918,1598,3.325,1600,4.304,1620,3.601,1687,6.047,1690,3.245,1782,5.002,1821,3.48,1825,4.633,1831,4.009,1843,5.164,1844,5.092,1845,5.386,1846,5.092,1866,5.857,1870,4.127,2283,5.296,2604,4.571,2647,5.543,3937,6.976,3938,6.976]],["title/tutorial/demo/#run-template-projects-locally",[847,1.763,955,1.858,1620,1.59,1831,2.572]],["text/tutorial/demo/#run-template-projects-locally",[13,4.124,26,1.1,52,3.801,97,4.392,101,1.561,411,3.756,457,3.195,476,2.724,745,3.756,847,3.18,955,3.352,1391,4.567,1620,2.868,1717,6.827,1820,4.874,1831,4.64,1850,4.776,1851,8.39,1852,8.15,1855,6.779,1860,7.586,1861,7.277,1926,5.893,1943,5.601,1971,5.893,2063,5.158,3031,6.129,3180,5.601,3445,6.415,3939,8.074]],["title/tutorial/demo/#scala",[13,2.918]],["text/tutorial/demo/#scala",[13,3.596,576,3.282,847,4.576,959,3.565,1620,3.361,1831,5.439,1844,6.907,2743,7.184]],["title/tutorial/jupyter-notebook/",[15,2.918]],["text/tutorial/jupyter-notebook/",[2,2.33,8,1.887,15,4.422,20,1.54,23,0.501,26,0.747,32,2.718,36,1.653,52,2.583,53,4.219,56,3.381,57,1.707,63,2.537,75,1.91,94,2.966,100,2.181,101,1.061,114,1.161,115,0.868,129,2.223,178,2.141,325,4.825,365,3.182,397,2.718,404,3.805,530,1.435,566,2.615,604,2.774,878,2.324,938,2.465,1051,2.181,1286,3.245,1366,2.233,1395,3.347,1556,2.877,1620,1.948,1779,4.691,1803,3.594,1817,3.933,1820,3.312,1841,5.654,2020,3.805,2023,8.874,2165,4.08,2786,6.651,3080,3.748,3180,3.805,3212,4.08,3232,3.462,3248,5.645,3275,7.364,3456,6.001,3515,4.358,3516,4.605,3527,4.474,3588,4.944,3589,4.474,3911,6.494,3940,9.728,3941,7.734,3942,5.485,3943,5.485]],["title/tutorial/jupyter-notebook/#python-jupyter-notebook-examples",[15,1.701,114,0.672,2786,2.621,3275,3.014]],["text/tutorial/jupyter-notebook/#python-jupyter-notebook-examples",[2,2.338,8,1.921,15,4.39,20,1.568,23,0.466,26,0.761,32,2.767,36,1.683,52,2.629,53,4.272,56,3.424,57,1.737,63,2.583,75,1.944,94,2.995,100,2.22,101,1.08,114,0.838,115,0.884,129,2.263,178,2.18,325,4.887,365,3.24,397,2.767,404,3.874,530,1.461,566,2.662,604,2.825,878,2.366,938,2.509,1051,2.22,1286,3.303,1366,2.274,1395,3.408,1556,2.929,1620,1.984,1779,4.71,1803,3.659,1817,4.004,1820,3.372,1841,5.71,2020,3.874,2023,8.914,2165,4.154,2786,6.571,3080,3.816,3180,3.874,3212,4.154,3232,3.525,3248,5.716,3275,7.208,3456,6.077,3515,4.438,3516,4.689,3527,4.555,3588,5.034,3589,4.555,3911,6.576,3940,9.805,3941,7.832,3942,5.585,3943,5.585]],["title/tutorial/python-vector-osm/",[2,0.429,23,0.188,26,0.289,47,0.732,114,0.318,1633,1.241,1763,1.608,2018,1.608,3944,1.999,3945,1.999,3946,1.91]],["text/tutorial/python-vector-osm/",[2,1.276,12,1.911,15,1.176,23,0.628,26,0.987,47,2.502,52,1.457,114,0.464,115,0.49,128,1.146,136,3.085,189,2.598,225,1.716,245,1.674,283,2.606,327,2.687,335,1.743,369,2.932,373,2.826,440,2.598,492,2.114,562,2.165,566,1.475,576,1.073,706,2.348,894,4.203,948,2.054,949,1.731,950,1.716,958,1.731,959,4.25,967,1.812,1051,1.23,1055,2.275,1117,2.598,1292,2.598,1306,2.258,1344,2.851,1391,3.311,1433,4.203,1499,3.724,1554,3.589,1555,2.598,1633,4.244,1664,2.181,1763,2.348,1864,2.788,1908,2.598,2002,2.001,2012,2.348,2017,2.523,2018,4.786,2048,1.812,2175,1.716,2181,2.523,2191,2.598,2286,2.598,2287,2.4,2289,2.4,2595,3.884,2855,2.218,2933,2.684,3061,2.598,3509,2.598,3552,2.218,3560,2.523,3595,3.654,3646,2.684,3855,4.512,3944,2.919,3945,2.919,3946,4.512,3947,3.094,3948,3.094,3949,3.094,3950,3.094,3951,2.684,3952,3.094,3953,7.777,3954,3.094,3955,2.684,3956,5.006,3957,5.006,3958,4.512,3959,2.788,3960,3.094,3961,3.094,3962,3.094,3963,3.094,3964,3.094,3965,5.006,3966,3.094,3967,3.094,3968,3.094,3969,3.094,3970,3.094,3971,3.094,3972,3.094,3973,3.094,3974,3.094,3975,3.094,3976,3.094,3977,3.094,3978,3.094,3979,3.094,3980,3.094,3981,3.094,3982,3.094,3983,2.788,3984,3.094,3985,3.094,3986,3.094,3987,3.094,3988,2.788,3989,3.094,3990,3.094,3991,3.094,3992,3.094,3993,3.094,3994,5.006,3995,3.094,3996,3.094,3997,3.094,3998,3.094,3999,3.094,4000,3.094,4001,3.094,4002,3.094,4003,3.094,4004,3.094,4005,3.094,4006,3.094,4007,3.094,4008,3.094,4009,3.094,4010,3.094,4011,3.094,4012,3.094,4013,3.094,4014,3.094,4015,3.094,4016,3.094,4017,6.305,4018,7.245,4019,3.094,4020,7.245,4021,3.094,4022,3.094,4023,3.094,4024,3.094,4025,3.094,4026,3.094,4027,3.094,4028,3.094,4029,3.094,4030,8.514,4031,3.094,4032,3.094,4033,6.305,4034,7.245,4035,3.094,4036,3.094,4037,3.094,4038,3.094,4039,5.006,4040,3.094,4041,3.094,4042,3.094,4043,3.094,4044,3.094,4045,3.094,4046,3.094,4047,3.094,4048,3.094,4049,3.094,4050,3.094,4051,3.094,4052,3.094,4053,3.094,4054,8.514,4055,3.094,4056,3.094,4057,3.094,4058,3.094,4059,3.094,4060,3.094,4061,3.094,4062,5.006,4063,3.094,4064,3.094,4065,5.006,4066,5.006,4067,3.094,4068,3.094,4069,3.094,4070,3.094,4071,3.094,4072,3.094,4073,3.094,4074,3.094,4075,3.094,4076,3.094,4077,3.094,4078,3.094,4079,3.094,4080,3.094,4081,3.094]],["title/tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults",[2,0.429,23,0.188,26,0.289,47,0.732,114,0.318,1633,1.241,1763,1.608,2018,1.608,3944,1.999,3945,1.999,3946,1.91]],["text/tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults",[562,3.059,894,7.714,959,4.702,1117,5.938,1344,5.232,1433,7.714,1554,6.587,1664,4.986,1908,5.938,2002,4.575,2012,5.369,2191,5.938,2286,5.938,2287,5.488,2289,5.488,2595,5.488,3509,5.938,3560,5.768,3595,6.706,3947,7.072,3948,7.072,3949,7.072,3950,7.072,3951,6.136,3952,7.072,3953,9.957,3954,7.072,3955,6.136,3956,9.187,3957,9.187,3958,8.281,3959,6.375,3960,7.072,3961,7.072,3962,7.072,3963,7.072]],["title/tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator",[2,0.534,26,0.36,245,1.428,948,1.753,967,1.546,1555,2.217,2017,2.153,2018,2.004,2175,1.464]],["text/tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator",[12,2.928,15,2.915,23,0.546,26,1.045,373,3.955,562,3.318,566,3.657,706,5.824,949,4.292,950,4.255,958,4.292,1864,6.915,2048,4.493,2181,6.257,3552,5.5,3646,6.656,3964,7.671,3965,9.678,3966,7.671,3967,7.671,3968,7.671,3969,7.671,3970,7.671,3971,7.671,3972,7.671,3973,7.671,3974,7.671,3975,7.671,3976,7.671,3977,7.671,3978,7.671,3979,7.671,3980,7.671,3981,7.671,3982,7.671,3983,6.915,3984,7.671,3985,7.671,3986,7.671,3987,7.671,3988,6.915,3989,7.671]],["title/tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs",[12,1.098,47,0.993,52,1.354,492,1.965,1055,1.307,1499,2.139,1633,1.685,3990,2.876]],["text/tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs",[23,0.633,47,2.731,136,3.367,369,5.778,959,3.716,1633,4.632,2595,6.136,2855,5.669,2933,6.861,3991,7.908,3992,7.908,3993,7.908,3994,9.864,3995,7.908,3996,7.908,3997,7.908,3998,7.908,3999,7.908,4000,7.908,4001,7.908,4002,7.908,4003,7.908,4004,7.908,4005,7.908,4006,7.908,4007,7.908,4008,7.908,4009,7.908,4010,7.908,4011,7.908]],["title/tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file",[2,0.709,26,0.477,576,1.214,1055,1.591,1499,2.605,1633,2.051]],["text/tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file",[23,0.6,189,7.994,225,5.281,327,5.111,373,3.382,4012,9.521,4013,9.521]],["title/tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis",[47,1.546,3061,3.758,3946,4.034,4014,4.475]],["text/tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis",[23,0.629,115,0.841,128,1.968,136,3.749,283,3.937,327,2.853,335,2.633,440,4.462,959,2.002,1051,2.113,1292,4.462,1306,3.879,1391,4.384,2018,4.035,3855,6.817,3953,4.611,4015,5.315,4016,5.315,4017,8.804,4018,9.592,4019,5.315,4020,9.592,4021,5.315,4022,5.315,4023,5.315,4024,5.315,4025,5.315,4026,5.315,4027,5.315,4028,5.315,4029,5.315,4030,10.533,4031,5.315,4032,5.315,4033,8.804,4034,9.592,4035,5.315,4036,5.315,4037,5.315,4038,5.315,4039,7.563,4040,5.315,4041,5.315,4042,5.315,4043,5.315,4044,5.315,4045,5.315,4046,5.315,4047,5.315,4048,5.315,4049,5.315,4050,5.315,4051,5.315,4052,5.315,4053,5.315,4054,10.533,4055,5.315,4056,5.315,4057,5.315,4058,5.315,4059,5.315,4060,5.315,4061,5.315,4062,7.563,4063,5.315,4064,5.315,4065,7.563,4066,7.563,4067,5.315,4068,5.315,4069,5.315,4070,5.315,4071,5.315,4072,5.315,4073,5.315,4074,5.315,4075,5.315,4076,5.315,4077,5.315,4078,5.315,4079,5.315,4080,5.315,4081,5.315]],["title/tutorial/raster/",[46,3.014,47,1.546,48,1.989,49,3.397]],["text/tutorial/raster/",[2,1.941,8,3.299,10,3.554,12,2.885,13,2.872,15,3.643,23,0.589,26,1.03,42,3.475,44,3.537,46,7.458,47,3.312,48,3.359,49,5.738,50,1.518,56,3.304,93,4.612,97,3.322,263,3.475,374,3.495,457,2.991,522,3.964,529,3.935,733,4.025,745,3.516,948,5.019,1366,3.077,1405,4.057,1583,4.884,1854,5.419,2175,4.192,2786,4.427,2964,6.165,3275,5.09,3456,5.865,4082,7.558]],["title/tutorial/raster/#initial-setup",[1583,3.158,3456,4.81]],["text/tutorial/raster/#initial-setup",[26,1.305,457,3.792,522,5.025,745,4.457,948,6.362,1366,3.901,1583,4.88,2175,5.314]],["title/tutorial/raster/#api-docs",[12,2.366,93,3.783]],["text/tutorial/raster/#api-docs",[10,3.749,46,6.492,47,3.33,48,4.284,49,7.319,4082,9.641]],["title/tutorial/raster/#tutorials",[1405,4.121]],["text/tutorial/raster/#tutorials",[15,3.758,2786,5.792,3275,6.659]],["title/tutorial/rdd-r/",[42,3.53]],["text/tutorial/rdd-r/",[2,1.111,8,1.888,10,1.171,13,2.085,17,2.134,22,1.158,23,0.643,26,1.054,33,2.095,36,1.046,42,2.523,47,2.672,50,1.334,57,1.08,62,2.013,65,2.192,66,1.634,94,1.817,101,0.671,111,1.14,114,1.161,115,0.549,126,1.648,136,2.898,139,1.768,159,1.605,166,2.013,172,1.768,173,1.994,177,1.803,178,1.355,200,1.831,219,1.413,220,1.018,231,2.757,241,2.095,243,2.023,246,1.82,257,3.467,258,4.247,273,2.245,335,1.208,349,2.335,355,2.649,370,1.485,373,1.233,374,1.605,402,3.044,452,2.869,456,2.141,471,2.19,476,1.171,489,1.517,529,1.806,530,1.435,532,3.626,538,1.577,558,2.962,576,2.36,585,2.19,592,1.542,594,1.831,595,1.848,613,1.82,641,1.296,671,6.003,676,2.245,702,1.806,766,3.128,781,2.304,823,1.848,837,1.534,882,1.586,919,4.109,930,3.644,943,1.941,955,1.441,959,1.307,964,2.304,981,1.708,1027,1.686,1049,2.033,1051,1.38,1063,5.715,1066,1.755,1238,2.067,1247,2.533,1254,2.074,1300,1.925,1307,3.128,1405,1.863,1406,2.217,1497,2.033,1498,1.78,1552,2.371,1617,1.768,1620,1.233,1741,1.893,1836,3.775,1854,2.488,1907,2.304,2003,2.141,2032,2.533,2048,3.987,2057,3.934,2821,3.128,2865,2.693,3393,2.693,3396,3.011,3599,6.003,3602,4.166,3607,4.476,3614,3.128,3633,2.757,4083,5.906,4084,3.47,4085,5.178,4086,6.806,4087,6.806,4088,3.128,4089,3.128,4090,5.488,4091,3.47,4092,6.806,4093,3.47,4094,3.47,4095,3.47,4096,3.47,4097,3.47,4098,3.47,4099,3.47,4100,3.47,4101,3.47,4102,3.47,4103,5.488,4104,5.488,4105,3.128,4106,3.47,4107,3.47,4108,3.47,4109,3.47,4110,3.47,4111,3.47,4112,3.47,4113,3.47]],["title/tutorial/rdd-r/#spatial-rdd-applications-in-r-language",[17,0.893,42,1.806,943,2.198,1238,1.48,1854,2.817]],["text/tutorial/rdd-r/#spatial-rdd-applications-in-r-language",[]],["title/tutorial/rdd-r/#what-are-spatialrdds",[558,2.423]],["text/tutorial/rdd-r/#what-are-spatialrdds",[2,1.584,10,2.641,17,2.229,23,0.403,26,1.335,36,2.359,47,3.386,50,1.239,101,1.514,243,2.886,257,3.987,258,4.884,349,2.716,370,3.35,452,3.299,529,4.075,558,3.093,585,4.941,592,3.478,671,6.073,766,7.055,882,3.578,930,6.509,981,3.853,1066,3.959,1247,5.713,1300,4.342,1617,3.987,1907,5.198,2865,6.073,3393,6.073,3396,6.792,3602,5.942,3607,6.384,3614,7.055,4083,6.792,4084,7.827,4085,7.385]],["title/tutorial/rdd-r/#creating-a-spatialrdd",[126,1.862,558,1.956]],["text/tutorial/rdd-r/#creating-a-spatialrdd",[2,0.804,8,2.097,13,2.316,17,1.892,22,1.325,23,0.646,26,0.83,33,2.398,42,1.826,47,2.106,50,1.318,57,1.236,62,2.304,65,2.435,66,1.87,94,2.018,111,1.243,114,1.249,115,0.629,126,1.193,136,3.159,139,2.023,159,1.837,166,2.304,172,2.023,173,2.282,177,2.003,178,1.55,200,2.034,219,1.57,220,1.165,231,3.156,241,2.398,243,1.464,246,2.083,257,3.105,258,3.803,273,2.494,335,1.383,349,2.056,355,2.943,373,1.411,374,1.837,402,3.381,452,2.569,456,2.45,471,2.507,476,1.34,489,1.736,530,1.595,532,3.862,538,1.805,558,2.341,576,2.573,594,2.034,595,2.115,613,2.083,641,1.483,671,5.756,676,2.569,702,2.067,781,2.637,823,2.115,837,1.755,919,4.479,955,1.649,959,1.496,964,2.637,1027,1.929,1049,2.326,1051,1.579,1063,6.229,1238,1.496,1254,2.373,1307,3.58,1405,2.132,1406,2.537,1497,2.326,1498,2.037,1552,2.714,1620,1.411,1741,2.166,1836,4.115,2003,2.45,2032,2.899,2048,4.345,2057,4.37,2821,3.58,3599,6.457,3602,3.015,3607,3.239,3633,3.156,4083,3.446,4085,3.747,4086,7.419,4087,7.419,4088,3.58,4089,3.58,4090,6.096,4091,3.971,4092,7.419,4093,3.971,4094,3.971,4095,3.971,4096,3.971,4097,3.971,4098,3.971,4099,3.971,4100,3.971,4101,3.971,4102,3.971,4103,6.096,4104,6.096,4105,3.58,4106,3.971,4107,3.971,4108,3.971,4109,3.971,4110,3.971,4111,3.971,4112,3.971,4113,3.971]],["title/tutorial/rdd/",[92,4.635]],["text/tutorial/rdd/",[2,1.141,6,0.466,8,0.302,10,0.43,12,0.173,13,0.173,17,1.928,20,0.462,22,0.976,23,0.653,26,0.224,32,0.816,36,0.384,42,0.586,44,0.213,47,1.011,48,0.202,50,0.417,51,0.147,57,1.929,58,0.555,61,1.659,65,1.667,85,0.277,86,0.877,89,0.687,90,0.424,94,0.77,96,0.393,97,0.2,99,0.274,100,0.181,101,1.524,102,1.423,106,0.576,108,0.664,109,0.232,110,1.617,111,0.735,114,0.299,115,0.417,119,1.577,121,0.942,126,1.646,128,1.283,129,0.809,135,2.173,136,0.701,137,0.315,139,1.764,159,1.717,161,0.24,165,0.298,166,1.348,171,0.709,172,1.184,177,0.764,178,0.643,179,1.343,186,1.068,192,0.294,200,1.531,218,0.24,219,0.514,220,1.78,222,0.438,225,0.913,226,0.548,232,0.287,234,1.868,235,0.237,236,1.151,242,0.356,243,2.133,246,0.238,252,0.843,257,0.232,263,0.404,264,0.254,266,0.242,273,0.359,281,1.346,284,0.248,293,0.394,299,1.117,311,0.877,319,0.5,324,0.6,327,0.472,334,0.246,335,2.795,349,2.507,352,0.971,355,0.795,366,0.815,370,1.589,373,1.482,374,0.59,384,0.674,397,0.225,403,0.945,411,0.409,412,2.525,424,0.224,433,0.576,445,0.698,446,0.468,452,0.694,455,0.438,457,1.469,459,0.74,464,0.432,476,0.153,486,0.505,487,0.542,488,1.5,489,0.557,491,0.264,492,0.311,493,0.311,500,0.298,522,1.047,530,1.934,532,2.215,534,0.72,537,0.833,538,0.748,543,0.252,545,0.891,550,1.193,555,0.669,556,0.649,557,2.125,558,2.811,559,1.016,560,0.315,561,0.871,562,0.863,563,1.275,564,0.738,566,0.419,568,0.264,569,0.555,573,0.274,576,2.563,577,0.315,578,0.345,579,0.332,580,0.32,581,0.382,582,1.055,583,0.224,584,1.071,585,0.287,586,0.382,587,0.382,588,0.382,589,0.382,590,0.382,591,1.101,592,0.202,593,0.225,594,2.338,595,0.679,596,0.382,597,0.345,598,0.382,599,0.382,600,0.32,601,0.294,602,0.829,603,1.344,604,0.23,605,0.382,606,0.382,607,0.382,613,1.535,615,0.277,616,0.963,619,0.701,620,0.416,641,1.638,643,1.016,666,0.29,675,0.404,696,0.583,701,0.61,702,0.457,713,0.302,730,0.419,745,0.409,753,0.29,762,0.583,784,0.382,823,0.877,831,2.039,833,0.898,836,1.039,837,0.563,838,0.568,840,0.345,847,0.179,849,0.338,872,0.28,873,0.287,875,0.946,876,0.542,877,0.568,878,0.193,881,0.32,882,1.583,886,0.32,888,0.548,891,0.796,903,0.738,905,0.583,919,0.274,938,0.395,941,0.811,944,0.872,945,0.242,946,0.252,951,0.464,952,0.576,953,0.457,954,0.338,955,0.365,961,0.754,965,0.332,968,4.28,970,1.847,975,0.332,978,1.027,981,0.628,989,0.738,994,0.738,996,0.738,999,0.306,1003,0.311,1013,1.016,1014,0.214,1017,0.242,1024,1.005,1027,0.8,1049,0.515,1050,0.619,1051,1.476,1055,2.561,1066,2.218,1069,0.914,1138,0.274,1140,0.311,1238,1.398,1243,0.199,1244,0.332,1272,0.361,1318,0.835,1319,0.576,1320,0.576,1330,0.41,1343,1.065,1344,0.5,1345,0.955,1363,0.197,1364,0.246,1366,0.946,1391,0.753,1392,0.222,1408,0.302,1420,0.361,1422,0.361,1437,0.294,1478,0.345,1487,0.272,1498,0.451,1522,0.43,1549,0.576,1556,0.461,1558,0.32,1560,1.558,1561,0.555,1563,0.682,1567,0.29,1569,0.451,1572,0.542,1583,0.232,1593,0.287,1594,0.246,1598,0.951,1600,0.28,1615,0.332,1617,1.341,1620,0.709,1621,0.215,1633,0.266,1638,0.315,1646,0.619,1648,0.306,1683,0.332,1697,0.583,1703,0.825,1711,2.978,1719,1.257,1721,0.561,1724,2.187,1733,0.28,1737,0.825,1738,0.294,1741,0.898,1751,0.326,1756,0.332,1784,0.6,1785,0.53,1806,0.28,1815,0.345,1818,0.345,1825,0.583,1837,0.394,1841,0.287,1850,0.52,1857,0.266,1858,0.287,1862,0.555,1869,0.311,1870,0.754,1876,0.345,1890,1.005,1905,0.674,1910,0.302,1927,0.32,1928,1.943,1929,1.364,1932,1.25,1933,0.968,1934,1.666,1949,0.361,1953,0.311,1962,0.353,1978,0.345,1981,0.284,1991,0.332,1993,0.345,1994,1.666,2001,0.332,2029,0.32,2030,0.284,2031,0.32,2032,1.922,2037,0.738,2038,0.382,2040,0.931,2041,1.071,2042,1.071,2048,1.876,2058,0.371,2062,0.41,2063,0.29,2064,1.588,2070,0.641,2072,0.63,2073,0.63,2074,0.63,2075,0.63,2077,1.079,2080,0.61,2081,0.345,2082,0.306,2083,0.871,2085,0.871,2086,0.345,2100,0.361,2101,1.065,2102,0.361,2103,0.641,2105,0.899,2106,0.899,2107,0.825,2108,0.619,2109,0.641,2110,1.079,2111,2.432,2112,2.218,2114,1.275,2115,0.361,2116,0.361,2117,0.353,2118,0.641,2119,1.013,2120,0.361,2121,0.361,2122,0.361,2125,0.353,2131,1.348,2132,0.41,2133,3.122,2134,0.41,2136,0.41,2137,0.717,2138,0.41,2139,0.41,2140,0.361,2141,0.311,2142,1.431,2143,0.298,2144,0.41,2158,0.382,2187,0.382,2319,0.371,2320,0.41,2322,0.41,2323,1.647,2324,1.647,2325,0.879,2326,0.879,2327,0.879,2328,0.879,2329,0.879,2330,1.149,2331,1.149,2332,1.484,2333,4.118,2334,0.455,2335,0.455,2336,0.879,2337,1.647,2338,1.647,2339,1.647,2340,1.647,2341,0.455,2342,0.879,2343,0.879,2344,0.879,2345,1.275,2347,0.41,2348,0.879,2349,0.455,2350,0.41,2351,0.455,2352,0.879,2353,0.455,2354,0.455,2355,0.455,2356,0.455,2357,0.455,2358,0.455,2359,0.382,2360,0.382,2361,0.455,2362,2.211,2363,0.455,2364,0.879,2365,1.647,2366,1.647,2367,0.455,2368,0.455,2369,0.879,2370,1.647,2371,1.484,2372,1.647,2373,0.455,2374,1.647,2375,0.455,2376,1.647,2377,1.647,2378,0.455,2379,1.647,2380,0.455,2381,1.647,2382,1.647,2383,1.647,2384,0.455,2385,1.647,2386,0.455,2387,0.792,2388,0.792,2389,0.41,2390,0.41,2391,0.41,2392,0.41,2393,0.455,2394,0.455,2395,0.455,2396,0.455,2397,0.455,2398,0.455,2399,0.455,2400,0.455,2401,0.455,2402,0.455,2403,0.455,2404,0.455,2405,0.455,2406,0.455,2407,0.455,2408,0.455,2409,0.455,2410,0.455,2411,0.455,2412,0.455,2413,0.455,2414,0.455,2415,0.455,2416,0.455,2417,0.455,2418,0.455,2419,0.455,2420,0.455,2421,0.455,2422,0.455,2423,0.455,2424,0.455,2425,0.455,2426,0.455,2427,0.455,2428,0.455,2429,0.455,2430,0.455,2431,0.455,2432,0.455,2433,0.455,2434,0.455,2435,0.455,2436,0.455,2437,0.455,2438,0.455,2439,0.455,2440,0.455,2441,0.455,2442,0.455,2443,0.455,2444,0.455,2445,0.455,2446,0.455,2447,0.455,2448,0.792,2449,0.792,2450,0.41,2451,0.41,2452,0.41,2453,0.41,2454,0.455,2455,0.455,2456,0.455,2457,0.455,2458,0.455,2459,0.455,2460,0.455,2461,0.455,2462,0.455,2463,0.455,2464,0.455,2465,0.455,2466,0.455,2467,0.455,2468,0.455,2469,0.455,2470,0.455,2471,0.455,2472,0.455,2473,0.455,2474,0.455,2475,0.455,2476,0.455,2477,0.455,2478,0.455,2479,0.455,2480,0.455,2481,0.455,2482,0.455,2483,0.455,2484,0.455,2485,0.455,2486,0.455,2487,0.455,2488,0.455,2489,0.455,2490,0.455,2491,0.455,2492,0.455,2493,0.455,2494,0.455,2495,0.455,2496,0.455,2497,0.455,2498,0.455,2499,0.455,2500,0.455,2501,0.455,2502,0.455,2503,0.455,2504,0.455,2505,0.455,2506,0.455,2507,0.455,2508,0.455,2509,0.455,2510,0.455,2511,0.455,2512,0.455,2513,0.455,2514,0.455,2515,0.455,2516,0.455,2517,0.455,2518,0.455,2519,0.455,2520,0.455,2521,0.455,2522,0.455,2523,0.455,2524,0.455,2525,0.455,2526,0.455,2527,0.455,2528,0.455,2529,0.455,2530,0.455,2531,0.455,2532,0.455,2533,0.455,2534,0.455,2535,0.455,2536,0.792,2537,0.792,2538,0.41,2539,0.41,2540,0.41,2541,0.41,2542,0.455,2543,0.455,2544,0.455,2545,0.455,2546,0.455,2547,0.455,2548,0.455,2549,0.455,2550,0.455,2551,0.455,2552,0.455,2553,0.455,2554,0.455,2555,0.455,2556,0.455,2557,0.455,2558,0.455,2559,0.455,2560,0.455,2561,0.455,2562,0.455,2563,0.455,2564,0.455,2565,0.455,2566,0.455,2567,0.455,2568,0.455,2569,0.455,2570,0.455,2571,0.879,2572,0.879,2573,0.455,2574,0.455,2575,0.455,2576,0.455,2577,0.455,2578,0.455,2579,0.455,2580,0.455,2581,0.455,2582,0.455,2583,0.455,2584,0.455,2585,0.455,2586,0.455,2587,0.455,2588,0.455,2589,0.455,2590,0.455,2591,0.455,2592,0.455,2593,0.455,2594,0.455,2595,0.353,2596,0.455,2597,0.455,2598,0.879,2599,0.455,2600,0.455,2602,0.306,2603,0.792,2604,0.835,2605,1.149,2606,0.345,2607,0.41,2608,0.345,2609,0.41,2610,0.667,2611,0.41,2612,1.383,2613,2.997,2614,0.738,2615,0.41,2616,0.41,2617,3.484,2618,1.586,2619,1.013,2620,0.361,2621,0.41,2622,0.382,2623,0.41,2624,0.41,2625,1.847,2626,0.361,2627,0.41,2628,0.41,2629,1.484,2630,0.41,2631,0.41,2632,0.345,2633,1.951,2634,1.951,2635,0.717,2636,0.738,2637,0.41,2638,0.792,2639,0.792,2640,0.361,2641,0.41,2642,0.455,2643,2.634,2644,1.996,3595,0.332,3759,0.371,3886,0.41,3887,0.41,3920,0.41,4114,0.455,4115,0.382,4116,0.455,4117,0.455,4118,0.455,4119,3.683,4120,2.017,4121,0.455,4122,0.455,4123,0.879,4124,0.455]],["title/tutorial/rdd/#set-up-dependencies",[457,2.057,745,2.418,1366,2.116]],["text/tutorial/rdd/#set-up-dependencies",[2,2.373,6,3.539,20,2.154,22,2.559,23,0.573,26,1.444,36,3.196,50,1.215,51,2.475,94,2.54,114,1.151,115,1.215,232,4.842,263,3.527,273,3.138,335,2.671,556,3.908,847,3.022,944,4.176,945,4.085,946,4.255,1238,2.89,1243,3.354,1363,3.318,1364,4.151,1366,4.317,1733,4.733,1850,4.538,1890,5.906]],["title/tutorial/rdd/#initiate-sparkcontext",[563,3.96,1583,3.158]],["text/tutorial/rdd/#initiate-sparkcontext",[2,1.969,6,2.005,20,1.54,23,0.653,101,1.061,110,1.061,179,2.3,243,2.022,257,2.794,281,2.131,334,2.968,403,4.608,412,2.828,457,3.85,530,1.435,563,3.504,591,2.598,823,2.921,878,2.324,919,3.312,951,4.087,952,5.067,953,4.026,954,4.08,955,2.277,965,4.003,968,3.641,970,7.049,1049,3.213,1051,2.181,1244,4.003,1343,6.292,1344,4.404,1345,5.644,1366,2.233,1567,3.504,1572,4.771,1594,2.968,1600,3.384,1620,1.948,1621,2.598,1850,3.245,1858,3.462,1869,3.748,1870,3.245,1890,3.347,1905,4.734,2029,3.867,2030,3.422,2031,3.867,2048,3.213,2320,4.944,2322,4.944,3595,4.003,4114,5.485,4115,4.605]],["title/tutorial/rdd/#create-a-spatialrdd",[126,1.862,558,1.956]],["text/tutorial/rdd/#create-a-spatialrdd",[]],["title/tutorial/rdd/#create-a-typed-spatialrdd",[126,1.561,558,1.641,594,1.734]],["text/tutorial/rdd/#create-a-typed-spatialrdd",[2,1.815,23,0.462,111,1.502,139,4.567,159,4.147,166,5.202,555,4.703,558,2.83,613,4.703,616,4.329,938,4.029,944,3.363,1013,5.532,1683,6.545,1737,5.8,1928,5.955,1929,6.127,1993,6.807,2032,6.545]],["title/tutorial/rdd/#create-a-generic-spatialrdd",[61,1.967,126,1.561,558,1.641]],["text/tutorial/rdd/#create-a-generic-spatialrdd",[23,0.53,47,2.927,61,3.206,110,1.991,119,3.047,121,3.433,159,3.918,171,3.646,192,5.481,538,4.678,558,2.674,576,3.569,594,3.847,840,6.433,1013,5.227,1014,3.99,1392,4.144,1815,6.433,1818,6.433,1857,4.963,1981,5.287,2347,7.638]],["title/tutorial/rdd/#transform-the-coordinate-reference-system",[90,2.16,335,1.558,459,2.011,464,2.203]],["text/tutorial/rdd/#transform-the-coordinate-reference-system",[2,1.614,23,0.636,57,1.783,65,2.289,85,3.497,90,2.766,99,3.46,101,1.774,102,2.197,110,1.542,126,1.721,234,2.44,284,3.126,335,2.776,349,1.588,352,2.113,355,4.787,373,2.035,412,2.095,459,2.575,464,2.82,486,4.583,487,4.919,488,3.566,489,2.505,491,3.324,493,3.915,530,1.499,557,2.919,558,3.13,591,2.714,730,2.731,823,3.052,872,3.535,873,3.617,875,5.271,876,4.919,877,5.158,891,3.575,968,3.754,1003,3.915,1017,3.052,1024,6.051,1549,3.755,1563,6.187,1870,3.39,1928,3.805,2048,3.356,2064,3.915,2330,5.165,2331,5.165,2332,5.165,2333,6.09,2602,3.859,2603,7.187,2604,5.225,2605,8.267,2606,4.35,2607,5.165,2608,4.35,3886,5.165,3887,5.165,4116,5.73,4117,5.73,4118,5.73]],["title/tutorial/rdd/#read-other-attributes-in-an-spatialrdd",[94,1.721,558,1.641,1027,2.525]],["text/tutorial/rdd/#read-other-attributes-in-an-spatialrdd",[17,1.694,23,0.635,48,3.31,57,2.317,65,3.795,100,2.962,101,1.441,110,1.441,128,3.873,373,2.646,457,2.948,530,1.949,558,2.351,559,4.595,595,3.967,713,4.946,837,3.292,886,5.251,968,3.507,1027,4.615,1050,6.697,1051,2.962,1140,5.089,1238,2.806,1318,4.881,1319,4.881,1320,4.881,1697,6.308,1741,4.063,2001,5.437,2063,4.759,2064,5.089,2333,4.946,2609,6.714,2610,7.211,2611,6.714]],["title/tutorial/rdd/#write-a-spatial-range-query",[17,1.018,349,1.24,370,1.915,941,2.203]],["text/tutorial/rdd/#write-a-spatial-range-query",[8,1.588,17,2.474,22,1.539,23,0.637,32,2.286,50,0.731,57,1.436,61,1.746,89,1.925,101,0.892,106,1.778,108,2.402,109,2.35,110,2.198,114,0.692,115,1.081,121,1.87,200,2.995,235,2.402,299,3.819,349,3.295,370,3.842,384,3.607,412,1.687,452,1.945,457,1.826,488,1.659,492,3.153,530,1.785,534,3.852,537,2.334,538,2.097,543,2.559,545,3.693,550,4.078,557,2.35,558,2.564,582,2.438,594,1.539,702,2.402,784,3.874,968,3.825,989,5.731,994,5.731,996,5.731,1498,2.367,1598,2.199,1646,4.812,1711,6.122,1962,3.58,2070,3.368,2072,3.308,2073,3.308,2074,3.308,2075,3.308,2077,3.023,2080,3.201,2187,3.874,2362,5.731,2604,3.023,2612,5.731,2613,4.664,2614,3.874,2615,4.159,3759,3.763,4119,7.537,4120,5.922,4121,4.614,4122,4.614,4123,6.825,4124,4.614]],["title/tutorial/rdd/#range-query-window",[349,1.441,370,2.225,1711,2.747]],["text/tutorial/rdd/#range-query-window",[2,0.85,23,0.658,57,2.389,102,1.61,108,2.186,119,1.51,126,2.306,128,1.555,135,5.519,177,2.09,178,2.483,179,1.761,186,1.93,200,1.401,219,1.638,220,3.222,226,2.62,324,2.869,335,4.231,349,1.763,370,2.722,412,4.162,433,2.751,445,5.054,446,2.236,530,2.008,594,1.401,643,3.924,696,1.919,968,4.878,1711,3.361,1784,2.869,2081,3.187,2105,2.96,2106,2.96,2616,3.785,2617,8.052,2618,3.336,2619,3.336,2620,3.336,2621,3.785,2622,3.525,2623,3.785,2624,3.785]],["title/tutorial/rdd/#use-spatial-indexes",[17,1.182,101,1.005,243,1.917]],["text/tutorial/rdd/#use-spatial-indexes",[2,1.618,17,2.258,23,0.641,42,2.644,47,1.987,57,1.789,65,2.298,101,1.777,106,1.259,108,2.994,119,2.068,128,2.13,179,2.412,243,4.086,281,2.235,349,2.216,370,2.462,373,2.84,412,2.103,457,2.276,488,2.068,530,1.505,537,2.909,550,3.437,557,2.93,558,2.9,594,2.667,831,2.027,882,2.629,905,3.819,938,2.584,955,2.388,961,3.402,968,4.676,981,3.935,1498,2.951,1558,4.055,1560,5.436,1561,3.63,1569,4.101,1598,2.742,1620,2.043,1648,3.873,1711,3.039,1978,4.366,2070,4.198,2072,4.124,2073,4.124,2074,4.124,2075,4.124,2077,3.769,2080,3.99,2082,3.873,2083,3.93,2085,3.93,2612,6.713,2613,5.463,2614,4.829,2625,6.353,2626,4.57,2627,5.184,4119,7.716,4120,4.99]],["title/tutorial/rdd/#output-format",[111,1.038,252,1.985]],["text/tutorial/rdd/#output-format",[17,2.192,111,1.615,252,3.087,349,2.672,370,4.126,558,3.043,2086,7.319]],["title/tutorial/rdd/#write-a-spatial-knn-query",[17,1.018,349,1.24,941,2.203,1617,2.28]],["text/tutorial/rdd/#write-a-spatial-knn-query",[17,2.258,22,1.919,23,0.643,32,2.85,50,0.911,57,1.789,61,2.176,89,2.4,101,1.112,106,1.259,110,1.112,115,0.911,121,2.33,186,3.675,200,2.667,222,2.869,234,3.404,299,3.218,319,3.275,335,2.002,349,2.893,352,2.121,412,2.923,446,3.063,488,2.068,530,2.091,558,2.523,582,3.039,594,1.919,702,2.994,836,2.994,968,4.914,1051,2.287,1238,2.167,1598,2.742,1617,4.072,1724,6.82,1806,3.548,2100,4.57,2101,5.944,2102,4.57,2103,4.198,2105,4.055,2106,4.055,2107,5.171,2108,4.055,2333,3.819,2362,4.829,2613,5.463,2617,6.976,2618,6.353,2619,4.57,2628,5.184,2629,8.952,2630,5.184,2631,5.184,2632,4.366]],["title/tutorial/rdd/#query-center-geometry",[110,1.005,349,1.441,762,3.452]],["text/tutorial/rdd/#query-center-geometry",[2,1.815,23,0.462,119,3.829,126,2.694,171,4.582,200,2.991,273,3.668,349,2.951,370,3.838,594,2.991,641,3.349,762,5.955,1617,4.567,1711,4.739,1784,6.127,1841,5.66]],["title/tutorial/rdd/#use-spatial-indexes_1",[17,1.182,101,1.005,243,1.917]],["text/tutorial/rdd/#use-spatial-indexes_1",[8,2.238,17,2.227,23,0.649,42,2.99,57,2.024,101,1.258,222,3.245,243,3.206,335,2.265,349,2.714,352,2.398,373,3.088,412,3.179,457,2.574,488,2.339,530,1.702,591,3.081,831,2.292,961,3.848,968,5.278,975,4.748,1560,3.848,1617,4.429,1620,2.311,1724,6.182,2083,4.444,2085,4.444,2101,4.207,2103,4.748,2105,4.586,2106,4.586,2107,4.207,2108,4.586,2333,5.774,2613,5.941,2617,7.435,2618,6.909,2619,5.169,2625,6.909]],["title/tutorial/rdd/#output-format_1",[111,1.038,252,1.985]],["text/tutorial/rdd/#output-format_1",[17,2.139,110,2.118,111,1.575,252,3.012,349,2.606,641,3.512,675,5.035,1617,4.791,1724,5.937]],["title/tutorial/rdd/#write-a-spatial-join-query",[17,1.018,349,1.24,831,1.577,941,2.203]],["text/tutorial/rdd/#write-a-spatial-join-query",[17,2.357,22,1.884,23,0.645,32,2.798,50,0.894,57,1.757,61,2.136,65,3.635,89,2.356,101,1.092,102,2.165,106,1.236,110,1.905,115,0.894,121,2.288,136,3.361,218,2.984,236,3.978,281,3.067,299,3.159,349,2.873,352,2.082,488,2.03,530,2.065,537,2.856,550,3.374,558,1.782,582,2.984,594,3.036,831,3.206,836,4.108,968,4.284,978,3.523,1051,2.245,1238,2.127,1598,2.691,1703,3.652,1711,2.984,1721,3.607,1785,3.409,2077,3.699,2109,4.121,2110,3.699,2111,5.962,2112,4.716,2114,3.607,2115,4.486,2333,6.543,2613,5.393,2633,7.64,2634,7.64,2635,4.605,2636,4.741,4119,7.64,4120,4.899]],["title/tutorial/rdd/#use-spatial-partitioning",[17,1.182,101,1.005,882,2.376]],["text/tutorial/rdd/#use-spatial-partitioning",[2,1.438,17,2.095,23,0.641,42,3.266,44,3.325,101,1.374,102,2.724,236,3.106,281,2.761,349,1.969,558,2.908,619,3.908,696,3.247,745,3.305,831,2.503,882,5.125,978,5.749,1013,4.383,1522,4.506,1560,6.05,1561,4.485,1593,4.485,1615,5.186,1638,4.929,2110,6.038,2111,6.701,2112,6.466,2114,5.887,2116,5.646,2333,6.792]],["title/tutorial/rdd/#use-spatial-indexes_2",[17,1.182,101,1.005,243,1.917]],["text/tutorial/rdd/#use-spatial-indexes_2",[17,2.052,23,0.648,57,2.141,61,2.604,101,1.331,243,3.328,281,2.674,349,2.501,352,2.538,373,3.577,452,2.901,457,2.724,530,1.8,558,2.849,831,3.18,905,4.571,961,4.071,968,4.742,981,3.388,999,4.635,1620,2.445,1703,4.452,1876,5.225,2083,4.703,2085,4.703,2111,6.599,2112,5.393,2114,4.397,2117,5.34,2333,6.688,2613,6.167,2625,7.172,2637,6.204,4119,5.779]],["title/tutorial/rdd/#output-format_2",[111,1.038,252,1.985]],["text/tutorial/rdd/#output-format_2",[17,1.885,23,0.427,65,4.057,110,2.124,111,1.389,252,2.655,281,3.222,349,2.298,452,4.281,641,4.101,831,2.921,838,5.363,888,6.337,891,6.337,2109,6.051,2111,5.433,2118,7.413,2119,8.725,2120,6.588,2121,6.588,2122,6.588,2333,5.506]],["title/tutorial/rdd/#write-a-distance-join-query",[234,1.906,349,1.24,831,1.577,941,2.203]],["text/tutorial/rdd/#write-a-distance-join-query",[17,2.32,20,1.229,22,1.461,23,0.642,32,2.169,50,1.039,57,1.362,61,1.656,65,3.145,86,4.658,89,1.827,101,1.692,102,2.516,106,0.958,110,1.812,111,0.733,115,0.693,121,1.774,126,1.315,136,2.795,200,1.461,234,4.653,236,3.442,242,2.659,243,1.614,252,1.402,281,2.55,299,2.449,311,3.495,319,2.493,349,3.029,352,1.614,384,2.314,412,1.601,488,1.574,489,2.869,530,1.717,534,2.471,537,2.214,545,3.551,550,2.616,558,1.382,582,2.314,591,2.074,594,2.918,666,2.797,831,3.851,836,3.417,875,2.516,882,2.001,968,4.118,978,2.731,1051,1.741,1238,2.472,1408,2.907,1487,2.616,1598,2.087,1703,2.832,1711,2.314,1721,2.797,1751,3.139,1785,2.643,1994,7.053,2077,2.869,2110,2.869,2111,2.869,2112,3.922,2114,2.797,2125,3.397,2613,4.485,2633,6.611,2634,6.611,2635,3.571,2636,3.676,2638,5.916,2639,5.916,2640,3.479,2641,3.946,3920,3.946,4119,6.611,4120,5.695]],["title/tutorial/rdd/#save-to-permanent-storage",[1055,2.362,1719,2.812,2131,3.016]],["text/tutorial/rdd/#save-to-permanent-storage",[17,1.937,22,2.842,139,4.34,159,3.94,558,3.259,576,2.955,595,4.538,641,3.182,837,4.564,1027,4.139,1051,3.388,1055,4.693,1066,4.31,1319,5.583,1320,5.583,1437,5.511,1633,4.991,1719,5.588,1738,5.511,1741,4.648,1756,6.219,1862,5.378,2131,5.991]],["title/tutorial/rdd/#save-an-spatialrdd-not-indexed",[243,1.917,558,1.641,1055,2.362]],["text/tutorial/rdd/#save-an-spatialrdd-not-indexed",[61,3.648,558,3.506,594,3.216,1055,4.381,1719,5.216,2131,5.593]],["title/tutorial/rdd/#save-an-spatialrdd-indexed",[243,1.917,558,1.641,1055,2.362]],["text/tutorial/rdd/#save-an-spatialrdd-indexed",[61,3.494,243,3.995,558,3.63,576,3.203,594,3.081,641,3.449,1055,4.197,1066,4.671,1719,4.997,1741,5.038,2131,5.358]],["title/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed",[243,1.449,558,1.24,1055,1.786,2112,2.348,2140,3.122]],["text/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed",[17,1.993,26,1.194,102,3.36,264,4.903,349,2.428,352,3.231,411,4.076,831,3.088,881,6.177,882,4.801,1055,3.982,1238,4.237,1391,4.005,1549,5.742,1719,4.741,1870,5.184,1910,5.819,1927,6.177,2131,5.084,2141,5.987]],["title/tutorial/rdd/#reload-a-saved-spatialrdd",[558,1.641,1055,2.362,2142,3.727]],["text/tutorial/rdd/#reload-a-saved-spatialrdd",[23,0.493,558,3.024,576,3.322,641,3.578,1055,4.354,1066,4.846,2142,6.869,2143,6.278]],["title/tutorial/sql-pure-sql/",[50,0.981,3561,4.926]],["text/tutorial/sql-pure-sql/",[2,1.095,4,1.656,8,1.173,10,1.15,12,2.065,15,1.295,17,0.775,23,0.653,26,0.916,44,1.595,47,3.34,50,1.323,51,1.1,57,1.683,75,1.884,86,1.815,100,1.355,101,1.616,114,0.812,115,1.065,119,1.946,123,3.94,126,2.509,128,3.292,129,2.192,143,4.577,186,1.567,199,1.844,200,1.137,205,3.415,209,2.859,218,2.859,219,0.878,220,2.246,281,1.325,313,5.158,374,2.502,377,1.678,411,1.586,455,3.356,464,2.663,476,1.826,488,1.946,489,1.49,522,4.017,523,2.329,524,2.329,525,2.295,530,1.415,531,1.941,566,1.625,571,5.019,572,3.879,576,1.182,594,1.137,613,3.528,615,3.301,616,3.247,628,6.168,629,6.075,630,6.268,702,2.816,703,2.365,826,3.054,827,3.266,831,1.201,832,2.037,922,2.862,923,2.862,924,2.862,948,2.264,951,1.801,952,2.233,953,1.774,970,4.246,984,3.266,1019,2.152,1049,1.997,1206,3.072,1243,1.49,1244,2.488,1286,2.016,1583,1.736,1806,2.103,1821,1.701,1843,1.736,2175,1.891,2655,2.862,2658,4.025,2691,2.403,2749,2.862,2753,3.338,3536,2.862,3552,2.444,3561,2.709,3582,3.072,3583,3.072,3648,2.264,3686,2.862,4125,3.409,4126,3.409,4127,3.409,4128,3.409,4129,7.227,4130,5.41,4131,3.409,4132,8.389,4133,3.409,4134,6.347,4135,7.227]],["title/tutorial/sql-pure-sql/#initiate-session",[948,4.117,1583,3.158]],["text/tutorial/sql-pure-sql/#initiate-session",[4,3.784,15,2.959,23,0.615,26,1.331,50,1.547,51,2.512,75,3.402,100,3.096,374,3.601,455,3.885,522,4.084,530,2.037,566,3.712,832,4.653,951,4.116,952,5.103,953,4.054,970,6.739,1019,4.916,1243,3.404,1244,5.684,1843,3.967,2175,4.32,2691,5.49,2749,6.539,3536,6.539,3552,5.583,3582,7.019,3583,7.019,3648,5.172,3686,6.539,4125,7.788,4126,7.788,4127,7.788]],["title/tutorial/sql-pure-sql/#load-data",[47,2.141,616,2.992]],["text/tutorial/sql-pure-sql/#load-data",[10,2.312,23,0.641,47,3.471,57,2.132,101,2.064,126,3.019,128,4.212,129,3.646,143,5.377,281,2.663,476,2.312,488,3.236,530,1.792,531,3.902,571,5.897,572,4.913,576,2.376,613,5.271,615,5.492,616,4.344,702,4.685,827,5.433,984,5.433,1821,3.418,2655,5.753,2658,5.097,4128,6.852,4129,6.465,4130,9,4131,6.852,4132,6.465,4133,6.852]],["title/tutorial/sql-pure-sql/#transform-the-data",[47,2.141,464,3.051]],["text/tutorial/sql-pure-sql/#transform-the-data",[23,0.654,47,2.147,115,1.335,119,2.235,123,3.641,126,2.533,143,5.039,199,3.363,200,2.074,205,3.924,209,3.285,313,6.418,455,4.207,464,3.06,476,2.098,571,5.525,572,4.456,594,2.074,628,7.675,629,7.559,630,7.799,826,4.759,1206,5.603,2658,4.624,2753,5.202,4129,9.03,4132,10.123,4134,5.865,4135,5.865]],["title/tutorial/sql-pure-sql/#work-with-data",[47,2.141,411,2.884]],["text/tutorial/sql-pure-sql/#work-with-data",[23,0.652,47,2.663,114,1.157,115,1.221,119,2.772,123,5.687,186,3.544,205,4.867,209,4.074,218,5.131,219,1.985,220,3.271,377,3.795,831,2.717,922,6.473,923,6.473,924,6.473,1806,4.756,4134,9.161,4135,10.027]],["title/tutorial/sql-python/",[15,2.918]],["text/tutorial/sql-python/",[2,1.069,7,1.082,8,0.959,10,2.149,11,1.05,12,0.843,15,1.436,17,0.634,20,1.061,21,0.778,22,0.277,23,0.66,26,1.22,36,0.25,44,1.033,47,2.278,50,0.836,51,2.319,57,0.867,61,0.835,64,1.118,66,0.39,71,0.55,75,0.289,85,0.506,90,0.753,94,0.923,96,0.986,101,1.134,105,0.154,106,0.341,110,1.355,111,0.139,114,0.69,115,0.666,119,2.008,126,0.994,128,0.577,129,1.129,136,1.957,160,1.16,171,1.423,173,0.896,177,1.736,178,0.324,179,0.654,182,2.26,186,1.015,187,0.481,192,2.139,199,0.844,200,2.457,219,2.525,220,2.414,248,0.865,251,0.629,253,0.584,263,0.381,273,0.339,296,0.558,311,3.263,313,3.064,325,0.517,327,2.258,355,2.03,365,0.481,366,0.53,373,0.99,374,0.383,389,2.227,391,4.008,392,3.023,397,0.411,402,0.46,403,0.393,411,0.386,430,1.922,431,0.922,476,0.526,488,2.109,489,0.362,516,1.184,522,2.206,523,0.566,524,0.566,525,0.558,528,0.747,529,0.812,530,0.988,532,1.978,533,0.49,545,0.448,555,0.435,562,1.431,568,1.617,574,2.583,575,0.543,576,0.287,577,0.575,582,0.438,583,2.887,592,0.368,593,0.411,594,1.403,603,0.558,604,0.419,613,1.462,615,0.951,616,0.753,620,0.393,641,2.288,653,0.888,675,1.015,697,2.26,702,0.431,730,1.328,750,0.536,775,0.55,827,0.5,831,0.292,842,0.594,843,0.594,844,0.584,847,0.614,854,0.594,868,0.543,919,0.5,926,0.558,927,1.022,928,0.55,929,0.536,930,1.466,932,0.643,941,0.767,943,0.872,949,1.235,950,0.865,951,0.438,953,0.431,955,0.344,956,0.5,958,1.235,959,2.708,963,1.333,964,0.55,970,0.523,973,0.984,984,0.5,1007,1.065,1019,0.523,1020,0.476,1041,0.629,1048,2.874,1051,0.62,1138,0.5,1139,1.05,1228,0.456,1268,0.506,1339,0.558,1344,0.472,1345,0.905,1366,0.337,1391,2.264,1392,0.762,1405,0.445,1406,0.53,1408,0.55,1465,1.246,1487,1.319,1492,1.997,1498,0.425,1522,1.617,1536,0.629,1582,0.506,1594,0.448,1597,0.643,1598,1.052,1733,0.511,1779,0.644,1795,0.643,1803,0.543,1805,0.605,1826,0.594,1843,1.124,1845,0.49,1862,0.984,1895,0.566,1981,0.973,1991,0.605,1999,0.659,2002,1.008,2003,0.962,2012,1.676,2034,0.629,2040,1.611,2051,3.568,2096,3.189,2097,1.754,2098,2.868,2104,2.444,2169,0.719,2172,0.719,2175,0.865,2178,2.162,2179,0.696,2180,1.272,2181,0.676,2184,0.747,2186,0.696,2187,1.309,2189,0.747,2190,1.309,2191,0.696,2192,0.747,2193,0.747,2194,0.696,2195,1.309,2196,2.777,2197,1.99,2198,1.309,2199,0.747,2200,0.747,2201,0.747,2202,0.747,2203,0.747,2204,0.747,2205,0.747,2206,0.747,2207,0.747,2208,0.747,2209,1.853,2210,1.309,2211,1.99,2212,3.052,2213,2.777,2214,0.747,2215,1.309,2216,0.747,2217,1.309,2218,1.309,2219,0.747,2220,1.309,2221,1.309,2222,0.747,2223,2.34,2224,1.309,2225,0.747,2226,1.309,2227,0.747,2228,1.99,2229,1.99,2230,0.747,2231,0.747,2232,0.696,2233,0.747,2234,0.747,2235,1.405,2236,0.747,2237,0.747,2238,1.405,2239,0.747,2240,0.747,2241,0.747,2242,0.747,2243,0.747,2245,0.747,2246,0.747,2247,0.747,2248,0.747,2249,1.405,2250,0.747,2251,0.747,2252,1.405,2253,0.747,2254,0.696,2255,0.747,2256,0.747,2257,0.747,2258,0.747,2259,0.747,2260,4.402,2261,0.747,2262,0.747,2263,0.747,2264,0.605,2265,0.747,2266,0.747,2267,0.747,2268,0.747,2269,0.747,2270,2.512,2271,0.747,2272,0.747,2273,0.747,2274,0.747,2275,0.747,2276,0.747,2277,0.747,2278,0.747,2279,0.747,2280,0.747,2281,0.747,2282,0.747,2283,0.629,2285,0.747,2286,0.696,2287,1.21,2288,1.8,2289,1.21,2290,0.747,2291,0.747,2292,0.747,2293,0.747,2294,0.747,2295,0.747,2296,1.99,2297,0.747,2298,0.747,2299,0.696,2300,1.405,2301,1.405,2302,1.405,2303,1.405,2304,1.405,2305,1.405,2306,2.512,2307,2.512,2308,1.405,2309,1.405,2310,1.405,2311,1.405,2312,0.747,2313,1.405,2314,0.747,2315,1.405,2316,1.405,2317,3.749,2318,1.405,2610,1.676,2691,0.584,2723,0.747,2786,1.293,3080,0.566,3232,0.523,3275,1.05,3560,3.082,3589,0.676,3595,0.605,3703,0.676,3911,0.696,3953,0.719,3955,1.915,3983,0.747,3988,0.747,4136,0.747,4137,0.829,4138,0.829,4139,0.829,4140,0.829,4141,0.829,4142,0.829,4143,0.829,4144,0.829,4145,0.829,4146,0.829,4147,0.747,4148,0.747,4149,0.829,4150,0.829,4151,2.207,4152,0.747,4153,1.405,4154,0.747,4155,1.405,4156,0.747,4157,0.829,4158,1.405,4159,0.747,4160,1.559,4161,0.829,4162,1.405,4163,0.829,4164,0.829,4165,1.559]],["title/tutorial/sql-python/#spatial-sql-application-in-python",[15,1.701,17,1.018,50,0.709,943,2.504]],["text/tutorial/sql-python/#spatial-sql-application-in-python",[]],["title/tutorial/sql-python/#introduction",[105,1.423]],["text/tutorial/sql-python/#introduction",[2,1.905,8,2.526,10,2.478,15,2.79,17,2.14,22,2.449,23,0.564,26,1.282,36,2.213,50,1.794,51,2.368,96,3.281,101,1.42,114,1.102,115,1.162,263,3.375,355,3.544,522,3.851,523,5.017,524,5.017,525,4.944,529,4.9,530,1.921,577,5.094,927,4.811,928,4.876,929,4.749,930,4.876,932,5.697,1392,3.59,1405,3.941,1733,4.53,1803,4.811,1805,5.359,1826,5.264,1843,4.794,2786,6.085,3080,5.017,3275,6.338,3589,5.988,3703,5.988,3911,6.165]],["title/tutorial/sql-python/#installation",[1779,3.172]],["text/tutorial/sql-python/#installation",[2,1.952,15,3.664,20,2.707,94,3.192,374,4.458,926,6.492,1779,3.983]],["title/tutorial/sql-python/#register-package",[1843,3.158,2175,3.438]],["text/tutorial/sql-python/#register-package",[2,1.734,20,2.406,23,0.596,26,1.517,51,2.764,57,3.224,101,1.657,325,5.346,530,2.241,604,4.334,941,4.217,959,3.227,963,5.173,970,5.408,1492,5.173,1845,5.068,2175,4.752,3560,8.451,3955,7.434,4136,7.723]],["title/tutorial/sql-python/#writing-application",[941,3.051,943,3.468]],["text/tutorial/sql-python/#writing-application",[2,1.196,10,3.39,20,1.658,23,0.645,26,1.269,44,2.764,51,2.627,57,1.837,66,2.781,101,2.038,106,1.293,110,1.142,114,0.886,126,1.774,273,2.416,355,2.851,522,4.271,528,5.323,562,2.554,583,4.587,603,3.977,641,3.48,653,3.363,775,3.922,949,3.304,950,4.517,951,3.121,953,3.074,955,2.452,956,3.566,958,3.304,984,3.566,1048,3.426,1344,3.363,1345,4.724,1406,3.773,1498,3.03,1522,4.557,1582,3.604,1594,3.195,1981,5.08,2002,3.82,2003,3.643,2034,4.483,2096,4.097,2172,5.124,2178,4.583,2180,4.817,2181,4.817,2184,5.323,2186,4.959,2187,6.837,2189,5.323,2190,4.959,2191,4.959,2192,5.323,2193,5.323,2194,4.959,3595,4.311,3983,5.323,3988,5.323,4137,5.906]],["title/tutorial/sql-python/#examples",[114,1.152]],["text/tutorial/sql-python/#examples",[]],["title/tutorial/sql-python/#sedonasql",[522,4.027]],["text/tutorial/sql-python/#sedonasql",[12,1.307,15,1.301,17,0.779,20,0.961,23,0.659,26,1.046,44,1.602,50,0.86,51,1.104,64,2.455,75,1.192,90,1.653,94,1.134,101,0.662,110,1.723,111,0.573,114,0.514,115,0.86,129,2.2,173,1.968,177,1.125,186,3.102,187,1.986,200,2.972,219,0.882,313,1.986,366,2.187,373,1.929,397,1.697,431,3.212,488,2.426,489,1.497,522,3.538,533,2.025,545,1.852,568,3.914,574,3.299,613,3.538,615,2.089,675,1.574,702,1.782,831,1.206,842,2.455,843,2.455,844,2.414,847,2.139,854,2.455,959,1.29,1138,2.067,1366,1.394,1408,2.274,1536,2.599,2040,2.499,2051,5.964,2096,2.375,2098,4.122,2195,2.875,2196,5.665,2197,6.081,2198,2.875,2199,3.086,2200,3.086,2201,3.086,2202,3.086,2203,3.086,2204,3.086,2205,3.086,2206,3.086,2207,3.086,2208,3.086,2209,2.875,2210,2.875,2211,6.081,2212,2.274,2213,6.447,2214,3.086,2215,2.875,2216,3.086,2217,2.875,2218,2.875,2219,3.086,2220,2.875,2221,2.875,2222,3.086,2223,5.665,2224,2.875,2225,3.086,2226,2.875,2227,3.086,2228,6.081,2229,6.081,2230,3.086,2231,3.086,2232,2.875,2233,3.086,2234,3.086,2235,4.894,2236,3.086,2237,3.086,2238,4.894,2239,3.086,2240,3.086,2241,3.086,2242,3.086,2243,3.086,2245,3.086,2246,3.086,2247,3.086,2248,3.086,2249,4.894,2250,3.086,2251,3.086,2252,4.894,2253,3.086,2254,2.875,2255,3.086,2256,3.086,2257,3.086,2258,3.086,2259,3.086,4138,3.424,4139,3.424]],["title/tutorial/sql-python/#integration-with-geopandas-and-shapely",[71,3.452,583,2.559,2096,3.606]],["text/tutorial/sql-python/#integration-with-geopandas-and-shapely",[2,1.174,10,1.956,23,0.659,26,1.426,47,2.46,50,0.589,94,1.92,101,0.72,110,1.685,114,0.558,115,0.589,126,1.741,129,2.349,173,2.139,311,1.982,327,3.112,355,3.438,365,2.159,373,2.059,403,1.763,430,1.701,532,1.601,555,1.952,562,3.477,568,2.159,574,1.82,576,1.291,583,1.832,613,1.952,615,2.271,616,2.799,641,2.659,730,2.763,750,2.407,949,3.243,958,3.243,959,3.476,963,3.5,973,3.659,1051,1.48,1268,2.271,1392,1.82,1522,1.82,1795,2.888,2003,2.296,2012,4.401,2040,4.231,2051,5.136,2096,6.045,2097,5.659,2098,6.103,2169,3.229,2179,3.125,2180,3.036,2190,3.125,2195,3.125,2196,4.868,2198,3.125,2209,4.868,2210,3.125,2212,2.472,2213,3.125,2215,3.125,2217,3.125,2218,3.125,2220,3.125,2221,3.125,2223,3.125,2224,3.125,2226,3.125,2260,5.2,2261,3.355,2262,3.355,2263,3.355,2264,2.716,2265,3.355,2266,3.355,2267,3.355,2268,3.355,2269,3.355,2270,7.246,2271,3.355,2272,3.355,2273,3.355,2274,3.355,2275,3.355,2276,3.355,2277,3.355,2278,3.355,2279,3.355,2280,3.355,2281,3.355,2282,3.355,3560,6.557,3955,5.03]],["title/tutorial/sql-python/#dataframe-style-api",[10,1.754,11,3.5,12,1.984]],["text/tutorial/sql-python/#dataframe-style-api",[2,1.499,7,4.221,8,2.093,10,2.499,11,2.667,12,1.512,15,2.312,20,1.112,21,3.035,23,0.647,26,0.54,50,0.627,51,3.59,57,1.232,61,2.802,64,2.84,85,2.417,90,1.912,96,2.718,101,1.177,106,0.867,110,0.766,114,0.913,115,1.173,128,2.253,160,4.525,177,1.302,178,1.546,199,3.292,200,3.288,219,2.309,220,1.162,296,2.667,327,4.813,402,2.197,430,4.326,476,2.053,516,4.618,530,1.938,532,4.241,582,2.093,583,1.95,592,1.76,593,1.963,594,2.772,620,1.877,641,1.479,697,6.127,868,2.595,919,2.392,927,2.595,930,4.04,959,2.292,1051,1.575,1139,4.097,1339,2.667,1465,3.434,1487,4.426,1492,5.017,1597,3.074,1598,3.531,1862,3.84,1895,2.707,1991,2.891,1999,3.148,2002,2.562,2012,3.007,2610,5.623,2691,2.792,2723,3.57,3232,2.5,3953,3.437,4140,3.961,4141,3.961,4142,3.961,4143,3.961,4144,3.961,4145,3.961,4146,3.961,4147,3.57,4148,3.57,4149,3.961,4150,3.961,4151,7.407,4152,3.57,4153,5.484,4154,3.57,4155,5.484,4156,3.57,4157,3.961,4158,5.484,4159,3.57,4160,6.084,4161,3.961,4162,5.484,4163,3.961,4164,3.961]],["title/tutorial/sql-python/#creating-spark-dataframe-based-on-shapely-objects",[10,1.182,26,0.477,126,1.052,355,1.69,583,1.724,641,1.308]],["text/tutorial/sql-python/#creating-spark-dataframe-based-on-shapely-objects",[]],["title/tutorial/sql-python/#supported-shapely-objects",[8,1.788,583,2.559,641,1.941]],["text/tutorial/sql-python/#supported-shapely-objects",[10,2.976,20,1.866,23,0.634,26,1.201,44,3.11,101,1.285,110,1.914,119,2.389,126,1.996,136,2.83,171,2.859,182,4.54,192,4.298,200,2.217,248,3.686,355,3.208,389,4.475,411,3.091,488,3.171,530,1.738,583,4.872,594,3.302,641,3.697,653,3.784,675,4.054,730,4.204,827,4.012,959,3.322,1019,4.194,1020,3.819,1048,5.116,1391,4.031,1465,3.75,1522,3.249,2178,7.681,2283,5.044,2285,5.99,2286,5.579,2287,6.843,2288,8.073,2289,6.843,4165,8.819]],["title/tutorial/sql-python/#example-usage-for-shapely-objects",[114,0.672,583,2.203,641,1.671,964,2.972]],["text/tutorial/sql-python/#example-usage-for-shapely-objects",[]],["title/tutorial/sql-python/#point",[200,2.561]],["text/tutorial/sql-python/#point",[23,0.659,26,0.868,47,2.961,110,1.232,136,3.651,200,3.458,219,2.496,248,3.533,251,4.836,253,4.491,488,3.083,574,3.115,575,4.174,959,2.4,1007,5.858,1041,4.836,1048,3.696,1228,3.504,1391,3.919,2104,4.12,2212,4.23,2260,6.268,2290,5.742,2291,5.742,2292,5.742,2293,5.742,2294,5.742,2295,5.742,2296,8.735,2297,5.742,2298,5.742,2299,5.349]],["title/tutorial/sql-python/#multipoint",[389,5.17]],["text/tutorial/sql-python/#multipoint",[23,0.658,26,1.005,47,3.261,136,3.141,219,2.681,389,7.011,488,2.653,574,3.607,959,2.779,1048,4.28,1391,3.372,2104,4.772,2212,4.899,2260,4.772,2300,8.51,2301,8.51,2302,8.51,2303,8.51]],["title/tutorial/sql-python/#linestring",[171,3.303]],["text/tutorial/sql-python/#linestring",[23,0.659,26,0.925,47,3.091,136,2.892,171,4.305,179,3.752,219,2.577,311,5.664,313,5.805,391,7.267,392,6.106,488,2.442,574,3.321,959,2.558,1048,3.94,1391,3.104,2104,4.393,2212,4.51,2260,5.787]],["title/tutorial/sql-python/#multilinestring",[182,5.246]],["text/tutorial/sql-python/#multilinestring",[23,0.66,26,0.827,47,2.866,136,2.584,182,6.459,219,2.434,311,6.097,313,6.372,391,7.822,392,6.703,488,2.182,574,2.968,959,2.286,1048,3.521,1391,2.774,2104,3.926,2212,4.03,2260,5.366,2304,7.478,2305,7.478]],["title/tutorial/sql-python/#polygon",[119,2.761]],["text/tutorial/sql-python/#polygon",[23,0.66,26,0.879,47,2.986,119,3.907,136,2.747,219,2.511,488,2.319,574,3.154,959,2.43,1048,3.742,1391,2.948,2104,4.172,2212,4.283,2260,5.592,2306,9.391,2307,9.391,2308,7.793,2309,7.793,2310,7.793,2311,7.793,2312,5.814,2313,7.793,2314,5.814]],["title/tutorial/sql-python/#multipolygon",[192,4.966]],["text/tutorial/sql-python/#multipolygon",[23,0.661,26,0.646,47,2.406,119,3.271,136,2.019,177,3.529,192,5.339,219,3.135,220,3.581,488,1.705,574,2.319,959,1.786,1048,2.751,1391,2.167,2104,3.067,2212,3.149,2260,4.505,2315,6.277,2316,6.277,2317,8.759,2318,6.277]],["title/tutorial/sql-r/",[42,3.53]],["text/tutorial/sql-r/",[2,0.748,8,1.983,10,2.702,17,1.821,23,0.652,26,1.253,33,3.481,42,2.65,47,1.276,50,0.913,51,1.86,56,2.52,57,1.15,61,1.398,66,1.74,71,2.454,98,2.805,99,2.231,100,1.469,101,1.115,110,1.371,114,0.865,119,3.122,177,1.214,178,2.25,201,3.171,219,2.062,235,1.923,241,2.231,252,1.183,254,2.749,255,2.936,257,1.882,266,3.07,352,1.362,363,2.697,365,2.144,411,1.719,452,2.43,456,2.28,529,1.923,558,1.166,594,1.233,595,1.968,620,1.75,641,3.243,675,1.699,702,1.923,730,1.761,741,3.33,745,1.719,822,2.488,833,3.145,836,1.923,837,1.633,919,2.231,943,2.067,955,1.534,959,1.392,973,2.332,981,1.819,1014,1.74,1027,1.795,1063,3.102,1069,2.649,1070,2.361,1240,2.857,1254,3.445,1300,2.05,1437,2.39,1554,2.649,1610,3.102,1759,2.936,1836,3.198,1854,2.649,1857,2.164,1939,2.697,2048,3.377,2082,2.488,2143,2.421,2148,4.84,2387,3.33,2388,3.33,2389,3.33,2390,3.33,2391,3.33,2392,3.33,2448,3.33,2449,3.33,2450,3.33,2451,3.33,2452,3.33,2453,3.33,2536,3.33,2537,3.33,2538,3.33,2539,3.33,2540,3.33,2541,3.33,2729,3.102,2798,2.936,3445,2.936,3599,5.5,3602,6.079,3607,5.781,3611,3.014,3618,6.389,3620,3.33,3621,3.33,3633,2.936,4083,3.206,4166,5.765,4167,5.196,4168,3.695,4169,3.695,4170,8.683,4171,3.695,4172,3.695,4173,3.695,4174,3.695,4175,3.695,4176,3.206,4177,3.695,4178,5.765,4179,5.765,4180,3.695,4181,3.695,4182,3.695,4183,3.695,4184,3.695,4185,3.695,4186,3.695,4187,3.695,4188,3.695]],["title/tutorial/sql-r/#spatial-sql-applications-in-r-language",[17,0.893,42,1.806,50,0.622,943,2.198,1854,2.817]],["text/tutorial/sql-r/#spatial-sql-applications-in-r-language",[2,0.759,8,2.006,10,2.724,17,1.627,23,0.652,26,1.261,33,3.52,42,1.724,47,1.295,50,0.594,51,1.881,56,2.549,57,1.166,61,1.418,66,1.765,71,2.49,98,2.846,99,2.263,100,1.491,101,1.128,110,1.384,114,0.875,119,3.144,177,1.232,178,2.276,201,3.207,219,2.078,235,1.952,241,2.263,252,1.201,254,2.789,255,2.979,257,1.91,266,3.105,352,1.382,363,2.736,365,2.175,411,1.744,452,2.457,456,2.313,529,1.952,558,1.183,594,1.251,595,1.997,620,1.776,641,3.265,675,1.724,702,1.952,730,1.787,741,3.379,745,1.744,822,2.525,833,3.18,836,1.952,837,1.657,919,2.263,955,1.556,959,1.412,973,2.366,981,1.845,1014,1.765,1027,1.821,1063,3.148,1069,2.688,1070,2.395,1240,2.889,1254,3.484,1300,2.079,1437,2.425,1554,2.688,1610,3.148,1759,2.979,1836,3.234,1857,2.196,1939,2.736,2048,3.415,2082,2.525,2143,2.456,2148,4.895,2387,3.379,2388,3.379,2389,3.379,2390,3.379,2391,3.379,2392,3.379,2448,3.379,2449,3.379,2450,3.379,2451,3.379,2452,3.379,2453,3.379,2536,3.379,2537,3.379,2538,3.379,2539,3.379,2540,3.379,2541,3.379,2729,3.148,2798,2.979,3445,2.979,3599,5.551,3602,6.127,3607,5.835,3611,3.058,3618,6.449,3620,3.379,3621,3.379,3633,2.979,4083,3.253,4166,5.83,4167,5.255,4168,3.749,4169,3.749,4170,8.743,4171,3.749,4172,3.749,4173,3.749,4174,3.749,4175,3.749,4176,3.253,4177,3.749,4178,5.83,4179,5.83,4180,3.749,4181,3.749,4182,3.749,4183,3.749,4184,3.749,4185,3.749,4186,3.749,4187,3.749,4188,3.749]],["title/tutorial/sql/",[92,4.635]],["text/tutorial/sql/",[2,1.426,3,0.895,6,0.983,7,1.04,8,1.1,9,3.656,10,2.81,11,1.009,12,1.557,13,1.022,17,0.832,18,0.433,20,1.145,21,1.061,22,1.221,23,0.652,26,0.656,36,0.811,44,0.995,47,1.664,50,0.906,51,2.481,56,0.929,57,1.693,60,0.427,61,0.301,64,0.57,65,0.317,66,0.374,70,0.502,85,0.485,86,0.798,90,0.723,94,1.894,96,0.355,97,0.349,100,1.069,101,1.459,102,0.574,106,0.328,110,1.588,111,0.45,114,0.404,115,0.762,119,2.596,121,0.607,122,0.312,124,0.774,126,1.225,128,2.9,129,0.861,139,0.763,159,0.693,173,0.457,179,0.628,186,0.689,199,0.43,200,0.265,218,0.792,219,0.548,225,0.441,232,0.502,234,1.558,235,0.414,239,0.915,242,0.607,243,0.293,252,1.172,257,0.763,263,0.689,266,0.798,273,0.87,275,0.56,281,0.309,301,1.27,304,1.931,319,0.453,325,0.496,327,1.444,334,0.43,335,1.113,349,1.787,352,0.992,355,1.298,370,0.641,373,3.035,403,1.274,411,0.37,424,0.391,430,0.972,446,0.423,452,0.632,457,0.314,459,0.673,463,1.233,464,0.738,467,0.423,471,0.502,475,0.811,476,0.717,486,1.222,487,1.312,488,0.539,489,0.929,490,1.024,491,0.461,493,0.543,516,0.603,522,3.381,523,0.543,524,0.543,525,0.535,529,1.107,530,1.742,532,3.583,533,0.47,538,0.361,543,0.441,544,0.508,545,0.43,555,0.786,556,0.763,557,2.619,558,1.805,562,3.194,566,2.966,567,2.254,568,1.855,569,4.943,571,1.393,572,1.524,573,1.931,574,1.564,575,0.982,576,1.109,582,1.124,591,0.71,594,2.288,595,0.423,604,0.758,613,0.417,614,0.58,615,0.485,616,2.627,620,1.007,641,0.56,643,0.924,653,0.453,696,0.363,697,2.787,698,0.528,730,2.127,745,0.37,754,0.631,823,0.423,827,0.48,831,1.289,832,0.475,836,0.414,837,1.413,847,0.313,868,0.521,872,0.49,873,0.502,875,1.222,876,0.924,877,0.969,878,0.901,886,0.56,888,0.496,891,0.496,919,0.48,927,0.521,928,0.995,929,0.969,930,0.528,931,0.667,932,0.617,937,0.47,938,1.208,939,2.137,941,0.738,944,1.009,945,0.423,946,0.441,947,0.528,949,0.445,950,1.492,951,0.792,952,0.982,953,0.78,954,0.591,955,0.33,956,0.48,958,0.445,959,0.299,962,0.603,963,0.48,968,2.268,970,0.502,1003,0.543,1007,5.906,1014,0.374,1017,0.423,1019,0.946,1020,0.457,1024,2.233,1027,1.982,1048,2.794,1049,0.878,1051,2.474,1055,1.663,1068,1.432,1077,0.716,1100,1.074,1138,0.48,1139,1.009,1228,1.169,1238,1.205,1243,0.347,1244,0.58,1254,0.475,1319,1.762,1320,1.762,1343,1.74,1344,0.853,1345,1.56,1363,0.344,1364,0.43,1366,1.302,1392,0.733,1492,1.284,1498,1.38,1522,0.389,1556,0.417,1567,0.508,1572,0.924,1583,0.763,1594,0.43,1597,0.617,1598,1.282,1600,0.49,1617,0.405,1620,0.955,1621,0.376,1628,0.895,1633,0.465,1680,0.58,1711,0.42,1719,0.811,1733,0.49,1738,0.969,1797,0.543,1806,0.49,1818,1.137,1819,0.453,1825,0.528,1841,0.502,1845,0.47,1850,0.886,1858,0.502,1869,0.543,1870,0.47,1890,1.297,1905,1.124,1953,0.543,1981,0.496,1982,0.667,1990,0.591,1991,0.58,2003,0.49,2029,0.56,2030,0.496,2031,0.56,2051,4.5,2053,0.667,2054,1.191,2058,0.648,2063,1.718,2064,1.024,2101,0.514,2107,0.514,2118,0.58,2131,0.869,2175,1.179,2264,2.977,2287,1.163,2288,4.193,2289,1.163,2319,0.648,2602,0.535,2604,0.982,2608,0.603,2620,0.631,2632,0.603,2645,0.57,2646,0.667,2647,0.631,2648,0.667,2649,1.916,2650,1.351,2651,3.241,2652,3.241,2653,3.241,2654,3.241,2655,0.667,2656,2.685,2657,0.716,2658,2.379,2659,2.541,2660,2.541,2661,1.258,2662,1.258,2663,1.258,2664,1.258,2665,1.258,2666,1.258,2667,1.258,2668,1.258,2669,1.689,2670,4.546,2671,3.072,2672,3.072,2673,1.258,2674,1.258,2675,1.258,2676,1.689,2677,1.258,2678,1.258,2679,1.258,2680,1.689,2681,1.258,2682,1.258,2683,1.258,2684,1.689,2685,1.258,2686,1.258,2687,1.258,2688,1.258,2689,0.716,2690,0.716,2691,0.56,2692,1.258,2693,0.667,2694,1.582,2695,0.716,2696,0.716,2697,0.716,2698,0.716,2699,0.716,2700,0.716,2701,0.667,2702,0.667,2703,0.667,2704,0.667,2705,1.222,2706,0.716,2707,1.351,2708,0.716,2711,0.716,2716,1.351,2717,1.222,2719,0.716,2720,1.916,2721,1.916,2826,0.56,2832,0.521,3031,0.603,3067,0.667,3147,0.631,3329,1.222,3430,1.3,3595,0.58,3839,1.785,3951,1.3,3958,0.716,4115,0.667,4136,0.716,4147,0.716,4148,0.716,4152,0.716,4153,1.351,4154,1.351,4155,1.351,4156,1.351,4158,1.916,4162,1.351,4167,0.716,4189,1.498,4190,1.498,4191,1.498,4192,1.498,4193,1.498,4194,1.498,4195,0.795,4196,0.795,4197,0.795,4198,1.414,4199,2.006,4200,1.498,4201,0.795,4202,0.795,4203,0.795,4204,0.795,4205,0.795,4206,0.795,4207,0.795,4208,1.498,4209,0.795,4210,0.795,4211,0.795,4212,0.795,4213,0.795,4214,0.795,4215,0.795,4216,0.795,4217,0.795,4218,0.795,4219,0.795,4220,0.795,4221,0.795,4222,1.498,4223,0.795]],["title/tutorial/sql/#set-up-dependencies",[457,2.057,745,2.418,1366,2.116]],["text/tutorial/sql/#set-up-dependencies",[2,2.396,6,3.484,20,2.102,22,2.497,23,0.6,26,1.298,36,3.326,50,1.66,51,2.414,94,2.478,114,1.123,115,1.185,232,4.725,263,3.441,273,3.062,335,2.606,556,4.854,847,2.949,944,4.139,945,3.986,946,4.152,1243,3.272,1363,3.237,1364,4.05,1366,4.268,1733,4.618,1850,4.428,1890,5.814]],["title/tutorial/sql/#initiate-sparksession",[562,2.681,1583,3.158]],["text/tutorial/sql/#initiate-sparksession",[2,1.982,6,2.034,20,1.562,23,0.654,57,1.731,66,2.62,101,1.511,110,1.076,179,2.333,243,2.052,257,2.834,281,2.162,334,3.011,403,4.638,530,2.044,557,2.834,562,3.905,591,2.636,823,2.963,878,2.357,919,3.36,949,3.113,950,5.43,951,4.128,952,5.119,953,4.067,954,4.139,955,2.31,956,3.36,958,3.113,1049,3.259,1051,2.212,1244,4.061,1343,6.332,1344,4.449,1345,5.68,1366,2.265,1567,3.555,1572,4.82,1583,2.834,1594,3.011,1600,3.433,1620,1.977,1621,2.636,1850,3.292,1858,3.512,1869,3.802,1870,3.292,1890,3.395,1905,4.771,2029,3.923,2030,3.472,2031,3.923,2645,3.989,2646,4.672,3595,4.061,4115,4.672]],["title/tutorial/sql/#register-sedonasql",[522,3.251,2175,3.438]],["text/tutorial/sql/#register-sedonasql",[2,1.669,6,3.015,23,0.588,26,1.379,51,3.266,100,4.025,179,3.458,325,5.145,349,2.285,530,2.157,562,4.379,594,2.751,831,2.906,832,4.928,947,5.476,962,6.26,963,4.979,970,5.205,1019,6.39,1492,4.979,1845,4.878,2175,5.615,2647,6.553,3031,6.26,4136,7.433]],["title/tutorial/sql/#load-data-from-files",[47,1.795,576,1.803,616,2.509]],["text/tutorial/sql/#load-data-from-files",[10,1.646,23,0.653,47,1.685,57,1.517,94,1.615,101,0.943,111,0.817,119,3.892,126,1.465,129,2.88,159,2.255,173,2.803,225,2.705,252,1.562,266,2.597,488,1.754,530,1.86,532,2.098,557,2.484,562,2.109,568,2.829,574,2.385,576,2.465,582,2.577,613,2.558,614,3.56,615,2.976,616,3.432,1051,1.939,2051,6.915,2264,6.123,2648,4.095,2649,7.561,2650,6.408,2651,6.666,2652,6.666,2653,6.666,2654,6.666,2655,4.095,2656,7.74,2657,4.396,2658,3.628,2659,3.875,2660,3.875,2661,4.095,2662,4.095,2663,4.095,2664,4.095,2665,4.095,2666,4.095,2667,4.095,2668,4.095,2669,3.875,2670,7.325,2671,7.043,2672,7.043,2673,4.095,2674,4.095,2675,4.095,2676,3.875,2677,4.095,2678,4.095,2679,4.095,2680,3.875,2681,4.095,2682,4.095,2683,4.095,2684,3.875,2685,4.095,2686,4.095,2687,4.095,2688,4.095]],["title/tutorial/sql/#create-a-geometry-type-column",[110,0.866,126,1.344,532,1.925,594,1.493]],["text/tutorial/sql/#create-a-geometry-type-column",[10,2.124,12,1.581,20,1.163,22,1.382,23,0.65,50,0.656,51,1.336,57,1.289,70,2.615,94,1.372,101,0.801,102,1.588,110,1.769,115,0.997,119,3.058,121,1.678,124,2.141,126,1.891,128,3.707,239,3.276,252,2.016,266,2.206,349,1.148,373,3.556,476,1.398,488,1.49,522,3.993,529,2.156,530,1.084,532,3.276,557,2.11,562,1.792,568,2.403,569,5.774,571,4.125,572,4.513,573,2.501,574,2.026,575,2.714,594,2.837,604,2.095,641,1.547,878,1.755,928,2.751,938,1.861,1007,7.049,1027,2.012,1048,2.403,1100,2.97,1228,2.278,1254,2.475,1680,3.023,1953,2.83,2003,2.555,2051,5.434,2053,3.478,2054,3.291,2264,4.595,2608,3.145,2620,3.291,2651,5.002,2652,5.002,2653,5.002,2654,5.002,2656,3.478,2658,4.683,2659,5.002,2660,5.002,2661,3.478,2662,3.478,2663,3.478,2664,3.478,2665,3.478,2666,3.478,2667,3.478,2668,3.478,2669,3.291,2670,6.758,2671,6.393,2672,6.393,2673,3.478,2674,3.478,2675,3.478,2676,3.291,2677,3.478,2678,3.478,2679,3.478,2680,3.291,2681,3.478,2682,3.478,2683,3.478,2684,3.291,2685,3.478,2686,3.478,2687,3.478,2688,3.478,2689,3.734,2690,3.734,2691,2.92,2692,3.478,2705,3.379]],["title/tutorial/sql/#load-shapefile-and-geojson",[139,2.648,555,2.726,616,2.509]],["text/tutorial/sql/#load-shapefile-and-geojson",[10,3.619,20,2.548,23,0.588,94,3.004,101,1.755,139,4.621,555,4.758,558,3.384,566,4.325,616,5.176,730,4.325,1238,3.418]],["title/tutorial/sql/#load-geoparquet",[9,4.706,616,2.992]],["text/tutorial/sql/#load-geoparquet",[2,1.072,3,3.165,7,3.674,8,1.822,9,7.27,10,1.787,23,0.653,94,2.498,101,1.024,110,1.958,111,1.264,128,3.896,129,2.146,252,2.416,301,4.508,327,4.717,373,4.146,467,2.821,530,1.974,532,2.279,557,2.698,562,3.263,575,3.47,576,1.837,616,4.623,620,2.509,968,2.494,1007,7.976,1051,3.808,1077,4.774,1228,4.149,2063,4.82,3329,4.32,4189,7.544,4190,7.544,4191,7.544,4192,7.544,4193,7.544,4194,7.544]],["title/tutorial/sql/#transform-the-coordinate-reference-system",[90,2.16,335,1.558,459,2.011,464,2.203]],["text/tutorial/sql/#transform-the-coordinate-reference-system",[2,0.984,23,0.644,50,0.77,56,2.125,57,2.605,85,2.967,90,2.347,101,0.94,102,1.864,110,2.041,115,0.77,119,3.519,126,1.46,234,2.07,252,1.557,335,2.915,355,4.443,459,2.184,463,4.858,464,2.393,486,4.812,487,5.166,489,2.125,490,4.846,491,2.82,493,3.322,522,2.55,530,1.272,532,3.603,562,2.103,568,2.82,569,6.178,571,3.186,572,3.486,573,2.935,574,2.377,604,2.459,696,2.222,698,3.228,730,2.317,754,3.863,872,2.999,873,3.069,875,4.812,876,4.376,877,4.588,878,2.06,1003,3.322,1020,2.794,1024,6.236,2051,5.88,2054,3.863,2264,5.177,2602,3.274,2604,4.647,2651,5.636,2652,5.636,2653,5.636,2654,5.636,2658,5.276,2659,5.636,2660,5.636,2669,3.863,2670,7.314,2676,3.863,2680,3.863,2684,3.863,2692,4.082,2693,4.082,2694,3.616,2695,4.382,2696,4.382,2697,4.382,2698,4.382,2699,4.382,2700,4.382]],["title/tutorial/sql/#run-spatial-queries",[17,1.182,349,1.441,1620,1.846]],["text/tutorial/sql/#run-spatial-queries",[17,2.192,110,1.864,126,2.896,349,2.672,532,4.148,594,3.216,1620,3.424]],["title/tutorial/sql/#range-query",[349,1.718,370,2.653]],["text/tutorial/sql/#range-query",[12,2.802,22,2.449,23,0.641,50,1.162,94,2.431,101,1.42,110,1.42,114,1.102,115,1.162,119,2.64,124,3.794,126,2.206,218,4.974,242,2.975,349,2.608,370,3.143,424,3.614,522,3.851,530,1.921,532,3.159,543,4.072,544,4.69,545,3.973,562,3.176,568,4.26,569,7.151,573,4.433,574,3.59,594,2.449,836,3.822,1620,2.608,1711,3.88,1797,5.017,1841,4.634,2051,4.69,2694,5.462,2701,6.165]],["title/tutorial/sql/#knn-query",[349,1.718,1617,3.158]],["text/tutorial/sql/#knn-query",[23,0.638,50,1.227,57,2.411,101,1.499,106,1.696,115,1.227,119,2.786,186,4.478,234,4.758,242,3.14,319,4.413,446,4.127,530,2.027,533,4.584,562,3.351,568,4.495,569,7.268,573,4.678,574,3.789,1806,4.78,2101,5.012,2107,5.012,2632,5.882,2694,5.764,2702,6.506,2703,6.506,2704,6.506]],["title/tutorial/sql/#join-query",[349,1.718,831,2.184]],["text/tutorial/sql/#join-query",[23,0.493,44,4.484,86,5.102,349,3.068,489,4.188,831,3.901]],["title/tutorial/sql/#other-queries",[349,2.128]],["text/tutorial/sql/#other-queries",[18,5.099,20,2.625,23,0.481,51,3.728,94,3.095,349,2.591,522,5.723,886,6.59,2705,7.624]],["title/tutorial/sql/#save-to-permanent-storage",[1055,2.362,1719,2.812,2131,3.016]],["text/tutorial/sql/#save-to-permanent-storage",[10,3.506,17,1.67,22,2.449,23,0.607,44,3.436,50,1.162,51,2.368,57,2.284,65,2.933,101,1.42,110,2.009,115,1.162,122,2.879,128,3.485,159,3.395,275,5.176,530,1.921,532,4.47,557,3.74,562,3.176,573,4.433,594,2.449,730,4.486,827,4.433,837,3.245,1014,3.457,1017,3.91,1055,4.277,1633,4.301,1719,3.973,1738,6.088,1825,4.876,2131,4.26,2706,6.618,2707,8.484,2708,6.618,2711,6.618,2826,5.176,2832,4.811,4195,7.342]],["title/tutorial/sql/#save-geoparquet",[9,4.706,1055,2.817]],["text/tutorial/sql/#save-geoparquet",[2,1.744,3,5.148,7,5.977,8,2.964,9,8.477,23,0.634,111,1.443,327,4.624,530,2.254,576,2.988,941,5.118,1055,4.725,3329,7.027,4196,8.616,4197,8.616]],["title/tutorial/sql/#convert-between-dataframe-and-spatialrdd",[10,1.51,235,2.33,558,1.412,730,2.133]],["text/tutorial/sql/#convert-between-dataframe-and-spatialrdd",[]],["title/tutorial/sql/#dataframe-to-spatialrdd",[10,2.092,558,1.956]],["text/tutorial/sql/#dataframe-to-spatialrdd",[10,3.688,20,2.303,23,0.603,64,5.881,94,2.716,101,1.586,110,1.952,452,3.457,522,4.302,532,4.341,557,4.178,558,3.185,566,5.21,569,5.178,591,3.886,594,2.736,730,3.91,939,6.518,1051,3.261,1238,3.09,1392,4.011,2058,6.69,2716,9.095]],["title/tutorial/sql/#spatialrdd-to-dataframe",[10,2.092,558,1.956]],["text/tutorial/sql/#spatialrdd-to-dataframe",[8,1.874,10,3.272,20,1.529,21,2.717,22,1.817,23,0.65,47,3.082,56,2.381,57,1.694,94,2.548,100,2.165,101,1.488,128,2.017,273,2.228,352,2.008,373,3.445,452,2.295,475,2.947,522,2.856,532,3.311,557,2.774,558,3.061,562,3.328,566,4.876,567,5.425,569,4.857,594,2.567,620,2.58,643,3.36,730,2.596,837,2.407,938,2.447,939,6.115,968,3.623,1007,6.626,1027,3.739,1048,5.626,1051,3.06,1068,4.098,1238,2.052,1319,5.042,1320,5.042,1498,3.948,1628,3.254,2051,3.479,2063,3.479,2064,3.721,2287,4.226,2288,7.909,2289,4.226,2717,4.442,3430,4.726,3839,4.573,3951,4.726,4198,5.139,4199,5.139]],["title/tutorial/sql/#spatialpairrdd-to-dataframe",[10,2.092,2719,5.587]],["text/tutorial/sql/#spatialpairrdd-to-dataframe",[8,1.489,10,2.935,13,1.645,17,0.984,21,2.159,22,1.444,23,0.654,47,2.701,56,1.892,57,1.347,94,1.433,100,1.721,101,1.259,121,1.754,128,1.603,234,1.843,273,1.771,349,1.804,352,2.883,373,3.48,475,2.342,476,1.461,522,2.27,532,2.8,557,3.315,558,1.366,562,3.383,566,4.445,567,5.513,594,2.171,620,2.051,643,2.67,653,2.465,730,2.063,831,2.293,837,1.913,888,2.701,891,2.701,929,2.8,938,2.924,939,3.44,959,1.631,968,3.064,1007,6.693,1027,4.226,1048,5.046,1051,3.458,1068,3.466,1238,2.452,1319,4.264,1320,4.264,1498,3.339,1628,2.586,2063,2.765,2064,2.958,2118,3.159,2287,3.359,2288,7.99,2289,3.359,2717,3.53,2720,7.049,2721,7.049,3430,3.756,3839,5.464,3951,3.756,4198,4.084,4199,6.141,4200,6.508,4201,4.329,4202,4.329,4203,4.329,4204,4.329,4205,4.329,4206,4.329,4207,4.329,4208,6.508,4209,4.329,4210,4.329,4211,4.329,4212,4.329]],["title/tutorial/sql/#dataframe-style-api",[10,1.754,11,3.5,12,1.984]],["text/tutorial/sql/#dataframe-style-api",[2,1.668,10,2.345,11,3.183,12,2.652,13,2.641,21,2.358,23,0.629,26,1.318,50,0.748,51,3.753,60,2.537,61,1.789,101,1.871,106,1.035,114,0.709,115,1.1,128,3.746,199,2.558,200,1.577,219,2.122,257,2.408,301,2.825,304,5.842,430,3.766,471,2.984,476,1.595,516,3.589,530,1.818,532,4.5,538,2.148,582,3.672,594,2.749,595,2.518,641,1.765,697,7.146,837,3.071,868,3.097,937,2.796,968,4.276,1051,1.88,1100,3.389,1139,4.679,1392,2.312,1492,4.195,1522,2.312,1597,3.668,1598,4.329,1818,5.275,1981,2.949,1982,3.969,1990,3.516,1991,3.45,3067,3.969,3147,3.756,3958,4.261,4147,4.261,4148,4.261,4152,4.261,4153,6.263,4154,6.263,4155,6.263,4156,6.263,4158,7.426,4162,6.263,4167,4.261,4213,4.727,4214,4.727,4215,4.727,4216,4.727,4217,4.727,4218,4.727,4219,4.727,4220,4.727,4221,4.727,4222,6.949,4223,4.727]],["title/tutorial/viz-gallery/",[4224,8.336]],["text/tutorial/viz-gallery/",[48,4.311,75,3.378,1291,6.357,1706,7.913,2030,6.053,4225,10.533]],["title/tutorial/viz-r/",[42,3.53]],["text/tutorial/viz-r/",[2,0.845,13,1.587,23,0.657,42,3.926,47,1.442,48,3.795,66,1.966,109,4.676,114,0.95,119,1.502,126,1.254,200,2.113,220,1.858,222,2.083,273,1.708,352,1.54,384,2.207,402,2.316,488,1.502,489,1.826,530,1.092,574,2.042,594,2.113,653,2.378,666,2.668,702,3.297,750,2.701,943,2.336,955,1.734,959,1.573,1014,1.966,1070,2.668,1205,2.127,1219,5.709,1240,3.792,1250,2.576,1262,3.24,1267,4.465,1268,3.865,1536,5.809,1836,3.513,1854,2.994,1907,4.206,2048,4.482,2148,6.425,2602,2.812,2780,7.171,2797,3.506,2940,3.623,2991,3.318,3060,5.318,3599,5.938,3602,3.17,3611,3.406,3633,3.318,3759,3.406,4088,5.709,4089,5.709,4226,4.176,4227,7.652,4228,7.652,4229,4.176,4230,4.176,4231,4.176,4232,4.176,4233,4.176,4234,4.176,4235,4.176,4236,6.334,4237,4.176,4238,4.176,4239,4.176,4240,6.334,4241,4.176,4242,6.334,4243,4.176,4244,4.176,4245,4.176,4246,4.176,4247,4.176,4248,4.176,4249,4.176,4250,7.652,4251,4.176,4252,4.176,4253,4.176,4254,4.176,4255,6.334,4256,4.176,4257,4.176,4258,4.176,4259,4.176]],["title/tutorial/viz-r/#map-visualization-applications-in-r-language",[42,1.806,48,1.746,943,2.198,1240,1.947,1854,2.817]],["text/tutorial/viz-r/#map-visualization-applications-in-r-language",[2,0.859,13,1.613,23,0.657,42,3.553,47,1.466,48,3.434,66,1.999,109,4.71,114,0.962,119,1.526,126,1.275,200,2.139,220,1.881,222,2.118,273,1.737,352,1.565,384,2.243,402,2.355,488,1.526,489,1.856,530,1.11,574,2.076,594,2.139,653,2.418,666,2.712,702,3.338,750,2.746,955,1.762,959,1.599,1014,1.999,1070,2.712,1205,2.162,1219,5.78,1240,3.178,1250,2.619,1262,3.294,1267,4.521,1268,3.913,1536,5.867,1836,3.557,1907,4.259,2048,4.527,2148,6.489,2602,2.859,2780,7.231,2797,3.564,2940,3.683,2991,3.373,3060,5.385,3599,5.997,3602,3.223,3611,3.462,3633,3.373,3759,3.462,4088,5.78,4089,5.78,4226,4.245,4227,7.729,4228,7.729,4229,4.245,4230,4.245,4231,4.245,4232,4.245,4233,4.245,4234,4.245,4235,4.245,4236,6.413,4237,4.245,4238,4.245,4239,4.245,4240,6.413,4241,4.245,4242,6.413,4243,4.245,4244,4.245,4245,4.245,4246,4.245,4247,4.245,4248,4.245,4249,4.245,4250,7.729,4251,4.245,4252,4.245,4253,4.245,4254,4.245,4255,6.413,4256,4.245,4257,4.245,4258,4.245,4259,4.245]],["title/tutorial/viz/",[92,4.635]],["text/tutorial/viz/",[2,1.552,6,0.978,7,1.033,8,0.512,10,1.728,11,1.003,12,1.954,13,0.566,17,2.004,18,3.382,20,1.438,22,0.892,23,0.642,26,0.496,32,1.326,33,1.615,35,1.689,36,0.806,44,0.697,47,2.141,48,4.247,50,0.424,51,0.863,57,0.832,61,2.657,65,0.595,66,0.701,85,0.909,94,1.206,97,0.655,100,1.767,101,1.424,102,1.703,104,0.929,106,0.326,109,1.363,110,0.288,111,0.249,114,0.667,115,1.297,126,2.461,143,1.598,178,1.734,179,0.625,199,0.806,206,3.913,246,0.781,261,1.801,263,0.685,266,1.425,268,1.087,273,1.49,278,0.929,284,0.813,313,1.552,325,0.929,334,0.806,335,0.931,349,0.413,355,1.291,369,0.872,399,1.108,403,1.267,411,0.693,412,0.545,424,2.805,431,0.881,438,1.05,452,1.535,455,3.503,456,1.65,457,1.059,459,0.669,463,2.97,475,0.806,476,2.092,486,2.554,487,3.159,489,1.169,522,1.403,529,0.775,530,1.339,532,1.567,538,0.677,556,0.759,557,1.855,558,0.47,562,2.681,571,1.753,583,2.805,591,0.706,594,0.892,604,0.753,616,0.719,619,0.819,620,1.267,628,1.856,629,1.828,630,1.886,641,1.36,643,1.65,696,2.031,702,0.775,703,1.856,730,1.275,745,0.693,749,1.156,753,0.952,825,2.246,826,4.329,832,0.89,837,1.964,847,1.054,876,0.919,878,0.631,929,0.963,938,1.202,941,0.733,942,2.031,943,0.833,944,1.003,947,0.989,949,0.833,950,1.484,951,0.787,952,0.976,953,0.775,955,0.618,956,0.899,958,0.833,962,1.131,963,1.615,970,0.94,982,0.976,1000,4.502,1002,3.531,1014,0.701,1017,0.793,1019,0.94,1049,0.872,1051,1.448,1068,0.793,1138,0.899,1139,1.003,1162,1.886,1205,5.4,1238,1.372,1240,3.649,1243,2.238,1244,1.087,1246,1.343,1248,1.886,1249,4.16,1250,4.094,1251,1.952,1252,1.184,1253,1.184,1260,1.184,1261,1.184,1263,1.184,1267,1.05,1268,1.632,1269,1.018,1271,0.929,1282,1.131,1290,3.838,1291,2.911,1292,3.057,1296,3.531,1297,1.05,1298,4.747,1299,3.132,1300,2.84,1305,2.911,1306,2.657,1308,3.498,1339,1.003,1343,1.73,1344,0.848,1345,1.552,1363,0.644,1364,0.806,1366,0.606,1392,0.728,1405,1.436,1408,2.418,1492,0.899,1497,1.567,1498,0.764,1522,0.728,1539,2.488,1540,1.131,1556,1.403,1558,1.05,1567,1.709,1569,0.764,1572,1.65,1583,1.363,1598,0.71,1600,0.919,1620,1.819,1621,0.706,1634,2.031,1667,1.033,1668,1.018,1678,1.184,1721,0.952,1732,1.689,1741,2.424,1757,3.531,1760,2.657,1796,1.184,1806,0.919,1815,1.131,1821,2.554,1845,0.881,1850,0.881,1858,0.94,1871,0.989,1889,1.018,1895,1.018,1905,0.787,1926,1.087,2003,0.919,2030,2.272,2141,1.018,2175,2.465,2319,1.215,2359,1.251,2360,1.251,2635,1.215,2645,1.068,2722,1.251,2723,1.343,2724,2.411,2725,1.49,2726,1.49,2729,1.251,2730,1.343,2731,1.215,2732,1.251,2733,1.343,2734,1.343,2735,1.343,2736,2.657,2737,1.184,2738,1.251,2739,1.343,2740,1.343,2741,1.343,2742,1.343,2743,1.131,2744,1.343,2745,1.343,2746,1.343,2747,1.343,2749,1.251,2750,1.343,2751,1.343,2752,1.343,2753,4.332,2754,3.373,2756,1.343,2757,1.343,2758,1.343,2759,1.343,2760,1.343,2761,4.844,2762,1.343,2763,2.246,2764,1.343,2765,1.343,2766,1.343,2767,1.343,2768,1.343,2769,1.343,2770,1.343,2771,1.343,2772,1.343,2773,2.246,3031,1.131,3648,5.093,3959,2.411,4115,1.251,4260,1.617,4261,1.617,4262,2.675,4263,1.49,4264,1.49,4265,1.49,4266,1.49]],["title/tutorial/viz/#why-scalable-map-visualization",[48,2.31,1240,2.576,1889,3.552]],["text/tutorial/viz/#why-scalable-map-visualization",[11,4.573,17,1.544,18,3.705,33,5.402,35,4.287,47,3.673,48,4.911,61,2.57,100,3.557,268,4.957,438,4.788,456,5.52,457,2.688,475,3.675,489,2.969,529,3.535,753,4.339,837,3.001,1205,3.459,1240,5.27,1291,4.45,1299,4.788,1300,3.767,1308,4.64,1339,4.573,1392,3.321,1497,3.978,1540,5.156,1556,3.562,1567,4.339,1569,3.484,1598,3.237,1620,2.412,1678,5.397,1721,4.339,1732,4.287,1760,4.957,1796,5.397,1806,4.19,1815,5.156,1871,4.51,2030,4.237,2141,4.64,2729,5.702,2730,6.122,2731,5.539,2732,5.702,2733,6.122,2734,6.122,2735,6.122,2736,4.957,2737,5.397,2738,5.702,2739,6.122,2740,6.122,2741,6.122,2742,6.122,2743,5.156,2744,6.122,2745,6.122,3648,4.51]],["title/tutorial/viz/#visualize-spatialrdd",[558,1.956,1240,3.072]],["text/tutorial/viz/#visualize-spatialrdd",[12,3.504,20,2.578,85,5.602,114,1.378,273,3.756,847,3.617,942,6.969,1238,3.458,1243,4.013,1405,4.928,1408,6.097,2746,8.275,2747,8.275,3648,6.097,4262,9.181]],["title/tutorial/viz/#set-up-dependencies",[457,2.057,745,2.418,1366,2.116]],["text/tutorial/viz/#set-up-dependencies",[2,2.379,6,3.278,23,0.548,26,1.221,36,3.21,50,1.42,94,2.969,335,3.122,556,4.567,944,3.994,1243,3.92,1363,3.878,1364,4.852]],["title/tutorial/viz/#initiate-sparksession",[562,2.681,1583,3.158]],["text/tutorial/viz/#initiate-sparksession",[2,1.822,23,0.654,57,2.132,66,3.226,101,1.325,334,3.707,403,4.263,530,1.792,557,3.49,562,4.347,878,2.903,949,3.833,950,4.992,951,3.621,952,4.49,953,3.567,955,2.845,956,4.137,958,3.833,1051,2.724,1243,2.995,1244,5.001,1343,5.821,1344,3.902,1345,5.221,1567,4.377,1572,5.552,1583,3.49,1600,4.227,1620,2.434,1621,3.246,1858,4.325,1905,3.621,2175,3.801,2645,4.913,3648,4.55,4115,5.753]],["title/tutorial/viz/#register-sedonasql-and-sedonaviz",[522,2.726,2175,2.883,3648,3.452]],["text/tutorial/viz/#register-sedonasql-and-sedonaviz",[6,2.999,23,0.622,26,1.375,51,2.646,100,3.261,179,3.44,325,5.118,522,4.302,530,2.146,562,4.727,832,4.901,947,5.447,962,6.227,963,6.092,970,5.178,1019,5.178,1246,7.393,1492,4.952,1845,4.852,2175,5.597,2749,6.887,3031,6.227,3648,5.447,4263,8.203]],["title/tutorial/viz/#create-spatial-dataframe",[10,1.754,17,1.182,126,1.561]],["text/tutorial/viz/#create-spatial-dataframe",[2,1.363,10,3.002,17,2.023,20,1.89,23,0.648,47,2.325,94,2.229,110,1.302,111,1.128,115,1.066,126,2.672,143,5.315,199,3.642,206,6.69,266,3.585,313,5.161,455,3.359,476,2.272,530,1.761,532,2.897,571,5.829,583,3.314,594,2.246,616,3.25,620,3.189,628,6.171,629,6.078,630,6.271,696,3.077,826,3.8,938,3.025,941,3.314,943,3.766,1260,5.349,1522,3.292,1667,4.671,2359,5.653,2360,5.653,2750,6.068,2751,6.068,2752,6.068,2753,4.153]],["title/tutorial/viz/#generate-a-single-image",[61,1.967,424,2.559,1000,2.418]],["text/tutorial/viz/#generate-a-single-image",[17,2.179,273,3.92,369,5.612,424,4.716,1000,4.457,1017,5.102,1068,5.102,1668,6.546]],["title/tutorial/viz/#pixelize-spatial-objects",[17,1.182,641,1.941,1205,2.648]],["text/tutorial/viz/#pixelize-spatial-objects",[2,1.452,17,1.632,23,0.641,48,3.188,51,1.593,61,1.869,101,1.634,104,3.082,106,1.081,109,2.516,114,1.077,115,1.559,126,2.538,206,5.334,246,2.591,261,3.326,284,2.694,335,1.72,455,4.215,463,5.714,476,2.421,486,5.33,487,6.077,532,2.125,583,4.848,591,2.34,604,2.498,641,1.845,643,4.427,696,3.28,703,4.978,730,3.42,825,4.427,826,5.559,837,2.183,929,3.195,1000,3.338,1002,6.714,1139,3.326,1205,5.64,1240,2.448,1269,3.375,1271,3.082,1290,6.633,1291,3.237,1292,7.095,1296,7.369,1305,3.237,1405,2.651,1620,1.755,1634,3.75,1850,2.922,1926,3.605,2003,3.047,2736,3.605,2753,5.213,2754,6.415,2756,4.452,2757,4.452,2758,4.452,2759,4.452,2760,4.452,3959,6.467]],["title/tutorial/viz/#aggregate-pixels",[18,3.381,1205,3.158]],["text/tutorial/viz/#aggregate-pixels",[17,2.55,18,5.837,23,0.578,32,3.879,102,3.001,115,1.239,126,2.351,266,4.168,355,3.778,431,4.63,455,3.905,476,2.641,641,2.923,702,4.075,825,4.829,826,4.418,837,3.459,876,4.829,982,5.129,1205,6.002,1249,7.154,1250,4.829,1251,7.154,1252,6.22,1253,6.22,1306,5.713,2753,4.829,2761,5.713,2762,7.055]],["title/tutorial/viz/#colorize-pixels",[1205,3.158,1250,3.824]],["text/tutorial/viz/#colorize-pixels",[12,3.114,20,2.291,23,0.621,94,2.701,115,1.592,126,2.451,355,3.939,455,4.07,489,3.567,530,2.134,826,4.605,1205,5.123,1248,7.09,1249,7.958,1250,6.205,1263,6.483,1620,2.898,1821,4.07,1895,5.575,2753,5.034,2761,7.958,2763,6.851]],["title/tutorial/viz/#render-the-image",[1000,2.884,1308,4.236]],["text/tutorial/viz/#render-the-image",[10,2.739,23,0.627,101,1.57,109,4.134,115,1.587,126,2.438,278,5.064,424,3.995,452,3.421,455,4.049,532,3.492,538,3.688,594,2.708,826,4.581,1000,5.43,1002,6.449,1205,5.106,1250,5.007,1268,4.953,1305,6.569,2753,5.007,2754,6.161,2761,5.924]],["title/tutorial/viz/#store-the-image-on-disk",[1000,2.418,1539,3.552,1741,2.835]],["text/tutorial/viz/#store-the-image-on-disk",[2,1.626,10,2.71,23,0.641,101,1.553,412,2.936,459,3.609,557,5.073,749,6.232,1000,5.265,1162,5.662,1243,3.511,1282,6.097,1539,5.488,1741,4.381,1757,8.994,2764,7.239,2765,7.239,2766,7.239,2767,7.239,2768,7.239,2769,7.239]],["title/tutorial/viz/#generate-map-tiles",[48,2.31,61,1.967,1298,3.106]],["text/tutorial/viz/#generate-map-tiles",[48,5.11,61,3.494,126,2.774,476,3.117,620,4.375,1298,6.475,1299,6.511,1300,5.123,2770,8.325,2771,8.325,2772,8.325]],["title/tutorial/viz/#pixelization-and-pixel-aggregation",[18,2.835,1205,3.792]],["text/tutorial/viz/#pixelization-and-pixel-aggregation",[18,4.726,20,2.433,22,2.89,61,3.278,65,3.461,101,1.676,102,3.322,399,6.445,424,4.265,476,2.924,696,3.96,837,3.829,1000,4.031,1205,5.314,1290,5.834,1291,5.677,1300,4.806,1498,4.445,1558,6.108,1821,4.322,2030,5.406,4264,8.664,4265,8.664,4266,8.664]],["title/tutorial/viz/#create-tile-name",[126,1.561,1051,2.067,1298,3.106]],["text/tutorial/viz/#create-tile-name",[23,0.608,48,3.745,115,1.334,126,2.531,178,4.004,455,4.204,530,2.204,826,4.756,1051,3.351,1205,5.634,1249,6.151,1297,5.941,1298,6.13,1299,5.941,1300,4.674,1620,2.993,1821,4.204,2736,6.151,2753,5.199,2761,7.487,2773,7.076]],["title/tutorial/viz/#colorize-pixels_1",[1205,3.158,1250,3.824]],["text/tutorial/viz/#colorize-pixels_1",[61,3.602,101,1.841,102,3.65,424,4.687,1000,4.429,1250,5.874,1408,6.323,1821,4.75,2763,7.994]],["title/tutorial/viz/#render-map-tiles",[48,2.31,1298,3.106,1308,3.552]],["text/tutorial/viz/#render-map-tiles",[23,0.589,32,4.108,48,4.513,115,1.313,126,2.491,178,3.965,455,4.136,476,2.798,826,4.679,1000,5.108,1205,5.174,1250,5.115,1298,6.561,1299,5.845,1300,4.599,1305,5.433,1306,7.413,1308,5.665,1760,6.051,2753,5.115,2761,6.051,2773,6.961]],["title/tutorial/viz/#store-map-tiles-on-disk",[48,1.989,1298,2.674,1539,3.058,1741,2.441]],["text/tutorial/viz/#store-map-tiles-on-disk",[48,4.154,61,3.537,101,1.808,102,3.584,424,4.601,452,4.6,1000,4.349,1162,6.59,1298,5.586,1741,5.099,1821,4.663]],["title/tutorial/zeppelin/",[36,1.567,101,1.005,1288,2.509]],["text/tutorial/zeppelin/",[2,1.881,10,1.982,13,2.232,17,2.113,20,2.278,23,0.594,26,1.196,33,3.547,36,1.771,47,3.349,48,3.902,50,1.39,51,1.221,52,1.783,61,1.432,94,2.384,101,1.797,109,2.992,110,1.136,115,1.535,121,1.534,126,2.437,128,1.402,136,1.612,159,1.751,200,1.263,206,2.39,219,0.975,222,1.889,225,2.1,235,1.971,246,1.986,281,1.471,377,1.863,397,1.876,452,1.596,455,2.931,459,1.701,476,1.982,530,0.99,532,3.097,573,3.547,576,1.313,582,2.001,600,2.669,619,2.082,641,2.688,696,2.685,698,2.514,730,1.805,762,2.514,826,3.316,837,1.673,938,2.64,959,1.426,1000,4.662,1014,1.783,1056,2.816,1062,5.72,1066,1.915,1104,2.449,1162,4.142,1240,4.805,1268,3.585,1271,2.362,1288,5.527,1366,1.541,1392,1.851,1471,2.549,1497,3.441,1528,4.014,1621,1.793,1708,2.714,1732,5.121,1779,2.427,1821,1.889,1831,2.176,1841,2.39,1865,2.938,1871,2.514,1889,2.587,1890,2.31,1894,2.763,1984,2.763,2141,2.587,2143,2.481,2595,2.938,2753,3.624,2754,2.874,2774,4.668,2775,3.786,2776,3.786,2777,3.786,2778,3.786,2779,3.786,2780,4.933,2781,3.412,2782,3.412,2783,2.874,2784,3.412,2785,2.874,2786,5.68,2787,6.812,2788,5.295,2789,3.412,2790,3.412,2791,3.412,2792,3.412,2793,3.412,2794,3.412,2795,2.816,2796,3.412,2797,3.179,2798,3.008,3648,6.656]],["title/tutorial/zeppelin/#small-scale-without-sedonaviz",[1271,2.792,1528,3.058,1732,2.825,3648,2.972]],["text/tutorial/zeppelin/#small-scale-without-sedonaviz",[10,2.223,13,2.504,17,1.994,20,1.85,23,0.601,26,1.194,33,3.978,36,1.986,47,3.029,50,1.561,94,2.181,101,1.696,110,1.696,115,1.561,126,2.634,128,2.439,136,2.805,159,3.047,200,2.198,206,4.159,222,3.287,246,3.455,397,3.265,455,3.287,476,2.223,530,1.723,532,4.241,573,3.978,582,3.482,641,2.46,730,3.14,826,3.718,837,2.911,1056,4.901,1062,5.235,1162,4.644,1240,4.345,1268,4.02,1288,4.758,1471,4.436,1497,3.859,1528,4.502,1732,4.159,1821,3.287,1889,4.502,2141,4.502,2753,4.064,2781,5.938,2782,5.938,2783,5.001,2784,5.938,2785,5.001,2786,3.859,2787,7.363,2788,7.904,2789,5.938,3648,4.375]],["title/tutorial/zeppelin/#large-scale-with-sedonaviz",[1497,3.045,1732,3.281,3648,3.452]],["text/tutorial/zeppelin/#large-scale-with-sedonaviz",[2,1.345,10,2.242,13,2.525,17,2.005,20,1.866,23,0.565,26,0.905,33,4.012,47,3.046,48,3.919,50,1.396,94,2.2,101,1.706,109,4.492,115,1.669,126,2.649,219,1.711,455,3.315,459,2.986,573,4.012,600,4.684,619,3.655,641,2.482,696,3.037,762,4.413,826,3.75,1000,5.354,1014,3.129,1066,3.361,1104,4.298,1162,4.684,1240,4.905,1288,4.778,1366,2.705,1392,3.249,1621,3.148,1732,4.194,1871,4.413,1984,4.85,2143,4.354,2753,4.099,2754,5.044,2780,5.579,2786,3.892,2787,7.405,2790,5.99,2791,5.99,2792,5.99,2793,5.99,2794,5.99,3648,7.002]],["title/tutorial/zeppelin/#zeppelin-spark-notebook-demo",[26,0.61,1288,2.16,1865,3.472,2786,2.621]],["text/tutorial/zeppelin/#zeppelin-spark-notebook-demo",[2,1.706,20,2.366,23,0.434,26,1.148,47,3.544,51,2.718,52,3.968,101,1.63,121,3.415,225,4.674,377,4.148,476,2.844,576,2.922,938,3.786,959,3.174,1288,5.339,1831,4.843,1890,5.142,2595,6.539,2786,6.742,2795,6.269,2796,7.596,2797,7.076,2798,6.696]],["title/tutorial/flink/sql/",[92,4.635]],["text/tutorial/flink/sql/",[2,0.769,6,0.812,8,0.287,10,0.53,12,1.27,13,0.317,17,1.399,19,1.277,20,0.234,22,0.935,23,0.658,34,0.701,44,0.391,47,0.288,48,2.941,50,0.352,51,1.073,56,0.365,57,1.437,65,0.333,70,0.527,72,2.501,85,0.509,86,0.445,90,0.758,94,0.928,96,0.373,97,0.367,100,0.624,101,1.139,102,0.602,106,1.011,110,1.968,114,0.421,115,0.444,119,3.261,121,0.338,124,0.431,126,1.769,128,2.451,135,1.648,136,1.416,143,0.499,159,1.027,172,1.428,173,0.48,177,0.516,178,0.867,179,0.35,186,1.529,187,0.484,188,0.547,200,3.239,210,1.765,211,1.765,212,1.765,213,1.765,218,0.829,219,0.572,220,1.114,234,1.416,242,0.636,243,0.308,252,0.898,257,0.799,263,0.384,281,0.324,301,0.499,311,1.183,319,0.475,335,2.573,349,1.28,355,1.353,365,0.484,366,0.533,369,0.489,370,0.672,382,0.588,391,0.57,403,0.743,411,0.388,412,2.497,424,0.411,430,3.122,442,5.884,446,0.445,448,7.457,457,1.316,459,0.705,463,1.626,464,1.38,470,2.735,471,2.668,476,0.282,486,0.902,487,0.968,488,0.799,489,0.686,490,1.915,491,0.484,493,0.57,500,0.547,501,1.089,522,2.942,523,0.57,524,0.57,525,0.562,529,1.156,530,1.208,531,1.596,532,2.413,533,0.494,534,1.254,543,0.463,545,0.452,569,0.527,575,0.547,582,0.441,591,0.395,594,1.77,595,0.836,604,1.123,619,0.459,620,0.743,641,1.047,696,0.382,698,0.554,730,1.059,745,0.388,754,0.663,796,0.681,797,0.701,822,4.457,825,0.515,827,3.203,836,0.435,872,0.515,873,0.527,875,1.277,876,0.968,877,1.015,878,0.354,927,1.028,928,1.042,929,0.54,930,0.554,932,0.648,938,0.375,941,0.411,945,0.836,946,0.871,947,0.554,959,2.317,981,0.411,1003,0.57,1019,0.991,1020,0.48,1024,2.318,1027,1.079,1041,0.634,1048,0.484,1049,0.919,1050,1.566,1051,0.332,1061,3.448,1100,0.598,1138,0.504,1140,0.57,1254,3.17,1269,1.072,1286,0.494,1363,0.361,1364,0.452,1366,0.904,1372,0.598,1500,1.167,1556,0.438,1576,0.681,1583,0.799,1594,0.452,1617,0.425,1620,0.789,1680,0.609,1686,0.598,1697,1.475,1741,0.856,1797,0.57,1806,0.515,1819,0.475,1821,0.416,1841,0.991,1869,0.57,1870,0.494,1905,0.441,1934,1.125,1953,0.57,2001,0.609,2003,0.515,2029,0.588,2030,0.521,2031,0.588,2051,0.533,2081,0.634,2101,0.54,2107,0.54,2175,0.871,2178,0.648,2317,5.884,2319,0.681,2602,0.562,2604,1.028,2617,2.128,2622,0.701,2632,0.634,2645,0.598,2691,0.588,2693,0.701,2694,1.167,2701,0.701,2702,0.701,2703,0.701,2704,0.701,2705,0.681,3696,3.625,3720,0.752,3800,0.752,3816,0.724,3818,0.752,3821,0.724,3822,0.724,3824,0.724,3826,0.752,3852,0.752,3874,0.752,3876,0.752,3879,0.752,4105,1.415,4159,0.752,4176,1.927,4267,2.645,4268,4.117,4269,2.527,4270,2.645,4271,0.835,4272,1.569,4273,0.835,4274,0.835,4275,2.096,4276,1.569,4277,0.835,4278,0.835,4279,2.645,4280,3.584,4281,3.138,4282,2.096,4283,2.096,4284,2.096,4285,6.807,4286,2.096,4287,6.807,4288,2.096,4289,6.807,4290,2.096,4291,6.807,4292,2.096,4293,6.807,4294,2.096,4295,6.807,4296,2.096,4297,3.584,4298,2.096,4299,0.835,4300,2.221,4301,0.835,4302,0.835,4303,1.569,4304,0.835,4305,0.835,4306,0.835,4307,1.569,4308,0.835,4309,0.835,4310,0.835,4311,0.835,4312,0.835,4313,0.835,4314,0.835,4315,0.835,4316,0.835,4317,0.835,4318,0.835,4319,0.835,4320,0.835,4321,0.835,4322,0.835,4323,0.835,4324,0.835,4325,3.668,4326,1.481,4327,1.569,4328,3.189,4329,3.668,4330,3.668,4331,2.096,4332,0.835,4333,0.835,4334,0.835,4335,5.544,4336,2.645,4337,2.096,4338,3.326,4339,2.803,4340,0.835,4341,0.835,4342,1.569,4343,0.835,4344,1.569,4345,1.569]],["title/tutorial/flink/sql/#set-up-dependencies",[457,2.057,745,2.418,1366,2.116]],["text/tutorial/flink/sql/#set-up-dependencies",[2,2.186,6,3.948,19,5.277,94,3.04,335,3.196,945,5.751,946,5.989,1363,3.971,1364,4.967,1366,4.396]],["title/tutorial/flink/sql/#initiate-stream-environment",[34,4.364,1286,3.075,1583,2.648]],["text/tutorial/flink/sql/#initiate-stream-environment",[23,0.645,57,2.552,101,1.586,126,2.464,457,3.993,530,2.146,981,4.038,1583,4.178,2645,5.881,4176,8.755,4268,6.365,4270,10.312,4271,8.203,4272,10.091,4273,8.203,4274,8.203,4275,9.521]],["title/tutorial/flink/sql/#register-sedonasql",[522,3.251,2175,3.438]],["text/tutorial/flink/sql/#register-sedonasql",[2,1.997,6,2.891,23,0.608,51,3.182,100,3.922,110,1.529,179,3.316,243,2.916,257,4.028,403,4.673,530,2.069,591,3.746,594,2.638,947,5.251,1019,6.226,1049,4.632,1594,4.279,1869,5.403,1870,4.678,1905,4.179,2029,5.575,2030,4.934,2031,5.575,2175,4.386,4176,6.861,4268,6.136,4270,7.461,4275,7.461,4276,9.864,4277,7.908,4278,7.908]],["title/tutorial/flink/sql/#create-a-geometry-type-column",[110,0.866,126,1.344,532,1.925,594,1.493]],["text/tutorial/flink/sql/#create-a-geometry-type-column",[10,1.692,12,1.183,19,1.782,20,0.87,22,1.034,23,0.659,50,0.491,51,1,57,0.964,70,1.957,94,1.026,101,0.6,102,1.188,110,1.54,115,0.491,119,4.058,121,1.256,124,1.602,126,1.896,128,1.148,220,1.47,252,1.606,311,2.67,349,0.859,442,7.617,448,8.962,457,1.984,476,1.046,522,3.311,529,1.614,530,1.312,531,1.765,532,3.121,575,2.031,582,1.638,594,2.657,604,1.568,641,1.158,822,3.376,827,3.812,878,1.313,928,2.059,938,1.393,1048,1.798,1100,2.222,1254,2.996,1680,2.263,1953,2.118,2003,1.912,2317,7.617,2691,2.185,2705,2.528,4105,4.519,4267,4.731,4268,3.89,4279,4.731,4280,7.515,4281,6.844,4282,4.731,4283,4.731,4284,4.731,4285,8.811,4286,4.731,4287,8.811,4288,4.731,4289,8.811,4290,4.731,4291,8.811,4292,4.731,4293,8.811,4294,4.731,4295,8.811,4296,4.731,4297,4.731,4298,4.731,4299,3.1,4300,6.313,4301,3.1,4302,3.1]],["title/tutorial/flink/sql/#transform-the-coordinate-reference-system",[90,2.16,335,1.558,459,2.011,464,2.203]],["text/tutorial/flink/sql/#transform-the-coordinate-reference-system",[2,0.657,12,1.238,17,0.738,22,1.082,23,0.661,56,1.418,57,2.025,85,1.979,90,1.566,94,1.074,101,0.627,102,1.244,110,1.767,114,0.487,115,0.514,126,0.974,135,2.577,143,1.938,178,1.266,200,4.064,234,1.381,335,2.266,349,0.899,355,3.594,391,2.216,459,1.457,463,4.32,464,3.204,486,2.989,487,3.208,489,1.418,490,5.088,491,1.882,493,2.216,522,2.727,530,0.848,531,1.847,532,2.801,534,1.831,604,2.63,620,1.537,696,1.483,698,2.154,730,1.546,754,2.577,797,2.723,827,3.14,872,2.001,873,2.047,875,3.741,876,3.208,877,3.364,1003,2.216,1020,1.864,1024,5.308,1041,2.462,1254,1.938,1576,2.645,1686,2.325,1841,2.047,2602,2.184,2604,3.407,2693,2.723,3800,2.924,3816,2.814,3818,2.924,3821,2.814,3822,2.814,3824,2.814,3826,2.924,3852,2.924,3876,2.924,4267,3.06,4268,2.517,4269,2.924,4279,4.907,4280,3.06,4281,3.06,4303,5.2,4304,3.244,4305,3.244,4306,3.244,4307,5.2,4308,3.244,4309,3.244,4310,3.244,4311,3.244,4312,3.244,4313,3.244,4314,3.244,4315,3.244,4316,3.244,4317,3.244,4318,3.244,4319,3.244,4320,3.244,4321,3.244,4322,3.244,4323,3.244,4324,3.244]],["title/tutorial/flink/sql/#run-spatial-queries",[17,1.182,349,1.441,1620,1.846]],["text/tutorial/flink/sql/#run-spatial-queries",[17,2.192,110,1.864,126,2.896,349,2.672,532,4.148,594,3.216,1620,3.424]],["title/tutorial/flink/sql/#range-query",[349,1.718,370,2.653]],["text/tutorial/flink/sql/#range-query",[12,2.928,17,1.744,22,2.559,23,0.634,94,2.54,101,1.484,114,1.151,115,1.215,119,2.759,218,5.115,242,3.108,349,2.682,370,3.283,424,3.776,522,4.023,530,2.007,531,4.369,532,3.301,534,5.462,543,4.255,545,4.151,569,4.842,620,3.634,836,3.993,1254,4.584,1620,2.725,1797,5.242,1841,4.842,2051,4.901,2694,5.706,2701,6.441,4268,5.952,4269,6.915,4325,8.398]],["title/tutorial/flink/sql/#knn-query",[349,1.718,1617,3.158]],["text/tutorial/flink/sql/#knn-query",[23,0.63,57,2.486,101,1.545,106,1.749,115,1.265,119,2.873,186,4.564,234,4.811,242,3.237,319,4.55,446,4.255,530,2.09,531,4.55,533,4.726,1254,4.774,1806,4.929,2101,5.168,2107,5.168,2632,6.065,2694,5.943,2702,6.708,2703,6.708,2704,6.708,4268,6.2,4269,7.202,4325,9.372]],["title/tutorial/flink/sql/#convert-spatial-table-to-spatial-datastream",[17,1.375,730,1.873,827,2.372,3696,2.685]],["text/tutorial/flink/sql/#convert-spatial-table-to-spatial-datastream",[]],["title/tutorial/flink/sql/#get-datastream",[3696,5.246]],["text/tutorial/flink/sql/#get-datastream",[23,0.629,51,2.944,101,1.765,822,6.146,3696,6.236,4268,7.081,4325,7.919,4326,8.611,4327,10.761,4328,7.663]],["title/tutorial/flink/sql/#retrieve-geometries",[110,1.199,1140,4.236]],["text/tutorial/flink/sql/#retrieve-geometries",[23,0.628,48,3.635,65,1.865,72,2.762,101,0.903,106,1.022,110,2.015,119,3.992,135,2.314,177,1.535,178,1.823,186,2.147,219,1.203,220,1.37,252,1.495,412,1.707,430,3.148,442,9.055,448,10.219,470,3.021,471,2.948,501,3.24,641,1.744,796,3.809,822,5.509,959,1.759,1061,3.809,1254,2.79,1500,3.474,2317,9.055,3696,3.191,3874,4.209,3879,4.209,4285,10.475,4287,10.475,4289,10.475,4291,10.475,4293,10.475,4295,10.475,4297,8.519,4328,3.921,4329,4.052,4330,4.052,4331,4.406]],["title/tutorial/flink/sql/#store-non-spatial-attributes-in-geometries",[17,0.893,110,0.76,595,2.092,1027,1.909,1741,2.143]],["text/tutorial/flink/sql/#store-non-spatial-attributes-in-geometries",[17,1.176,23,0.654,48,4.21,72,4.388,106,1.623,110,2.198,128,3.211,135,2.563,136,3.693,186,2.378,187,3,188,3.389,219,1.332,220,1.517,252,1.656,311,2.754,365,3,366,3.304,369,3.029,382,3.646,412,2.712,430,4.584,470,4.798,471,4.682,500,3.389,501,3.588,594,1.725,595,2.754,619,2.845,641,1.931,822,4.995,825,3.191,959,2.794,1027,2.513,1050,6.113,1061,6.049,1254,5.661,1500,3.847,1697,5.759,1741,2.821,1821,2.58,2001,3.775,3696,3.534,4282,4.88,4283,4.88,4284,4.88,4286,4.88,4288,4.88,4290,4.88,4292,4.88,4294,4.88,4296,4.88,4298,4.88,4328,4.342,4329,6.436,4330,6.436,4331,6.998,4332,5.172,4333,5.172,4334,5.172]],["title/tutorial/flink/sql/#convert-spatial-datastream-to-spatial-table",[17,1.375,730,1.873,827,2.372,3696,2.685]],["text/tutorial/flink/sql/#convert-spatial-datastream-to-spatial-table",[]],["title/tutorial/flink/sql/#create-geometries-using-sedona-formatutils",[2,0.795,101,0.76,110,0.76,126,1.18,4335,3.541]],["text/tutorial/flink/sql/#create-geometries-using-sedona-formatutils",[23,0.66,48,4.02,57,1.105,72,4.086,101,0.687,106,1.512,110,2.126,119,1.277,126,2.075,128,3.736,135,1.759,159,2.584,172,3.519,173,2.04,177,1.167,178,1.386,186,1.632,200,1.864,210,5.489,211,5.489,212,5.489,213,5.489,219,0.914,220,1.639,301,2.121,335,3.827,412,3.85,430,4.135,470,4.469,471,4.361,488,2.009,594,1.184,927,2.326,941,1.747,959,3.566,1061,5.634,1372,2.545,1934,2.545,2081,2.695,2178,2.755,2617,5.947,2622,2.981,3696,4.72,3720,3.2,4329,5.994,4330,5.994,4335,8.84,4336,6.518,4337,5.272,4338,8.52,4339,7.835,4340,3.55,4341,3.55]],["title/tutorial/flink/sql/#create-row-objects",[126,1.561,641,1.941,822,3.5]],["text/tutorial/flink/sql/#create-row-objects",[19,3.77,22,2.189,23,0.653,48,3.885,72,3.881,101,1.269,106,1.436,110,1.691,114,0.984,128,3.238,159,3.034,172,3.342,257,3.342,412,3.197,430,4.495,470,4.243,471,4.141,488,2.359,822,7.568,959,3.705,1027,3.187,1061,5.35,1269,5.974,1934,4.703,3696,4.482,4159,5.913,4328,7.342,4329,5.692,4330,5.692,4335,9.455,4336,6.19,4337,6.19,4342,8.744,4343,6.56]],["title/tutorial/flink/sql/#get-spatial-table",[17,1.41,827,3.743]],["text/tutorial/flink/sql/#get-spatial-table",[23,0.63,51,2.827,101,1.695,136,4.472,281,3.405,532,3.77,827,5.291,1051,3.484,4268,6.799,4325,7.603,4326,8.268,4328,7.357,4344,10.504,4345,10.504]]],"fields":["title","text"],"invertedIndex":[["",{"_index":23,"text":{"":{},"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Aggregator/#st_union_aggr":{},"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Constructor/#st_geomfromgml":{},"api/flink/Constructor/#st_geomfromkml":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/flink/Constructor/#st_point":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_area":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_distance":{},"api/flink/Function/#st_envelope":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_issimple":{},"api/flink/Function/#st_isvalid":{},"api/flink/Function/#st_length":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_transform":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_z":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_orderingequals":{},"api/flink/Predicate/#st_within":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromgml":{},"api/sql/Constructor/#st_geomfromkml":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_area":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_convexhull":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_length":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_npoints":{},"api/sql/Function/#st_numgeometries":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-loader/#rs_html":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalize":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_pixelize":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#buildsbt":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/cluster/#set-up-your-apache-spark-cluster":{},"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/benchmark/":{},"archive/tutorial/faq/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#read-from-geojson-file":{},"archive/tutorial/geospark-core-python/#read-from-shapefile":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#reload-a-saved-spatialrdd":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#join-query":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"archive/tutorial/sql/#other-queries":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#initiate-sparksession":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/viz/#set-up-dependencies":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"asf/asf/":{},"asf/asf/#copyright":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contact/":{},"community/contact/#discord-server":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#become-a-committer":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/develop/":{},"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#publication":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#10-release-sedona-r-to-cran":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#7-failed-vote":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#compile-r-html-docs":{},"community/publish/#fix-signature-issues":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#upload-releases":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"community/rule/#contributing-to-apache-sedona":{},"community/rule/#make-a-pull-request":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"download/":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/cluster/#set-up-your-apache-spark-cluster":{},"setup/compile/":{},"setup/compile/#compile-with-different-targets":{},"setup/compile/#mkdocs-website":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/install-scala/":{},"setup/flink/modules/":{},"setup/flink/modules/#api-availability":{},"setup/flink/platform/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-python/#setup-environment-variables":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#buildsbt":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/modules/":{},"setup/modules/#api-availability":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#core":{},"setup/release-notes/#core_1":{},"setup/release-notes/#flink":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global":{},"setup/release-notes/#global_1":{},"setup/release-notes/#global_2":{},"setup/release-notes/#global_3":{},"setup/release-notes/#highlights":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#python":{},"setup/release-notes/#python_1":{},"setup/release-notes/#r":{},"setup/release-notes/#rdd":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_1":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v101":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"setup/release-notes/#viz_1":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/benchmark/":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#read-from-geojson-file":{},"tutorial/core-python/#read-from-shapefile":{},"tutorial/core-python/#read-from-wkb-file":{},"tutorial/core-python/#read-from-wkt-file":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#reload-a-saved-spatialrdd":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/demo/":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#get-datastream":{},"tutorial/flink/sql/#get-spatial-table":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/raster/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#reload-a-saved-spatialrdd":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{},"tutorial/sql-python/#register-package":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#join-query":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/sql/#other-queries":{},"tutorial/sql/#range-query":{},"tutorial/sql/#register-sedonasql":{},"tutorial/sql/#save-geoparquet":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#initiate-sparksession":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#render-the-image":{},"tutorial/viz/#set-up-dependencies":{},"tutorial/viz/#store-the-image-on-disk":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"community/rule/#pick-annouce-a-task-using-jira":{},"setup/compile/#compile-scala-java-source-code":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}}}],["0",{"_index":220,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_z":{},"api/flink/Function/#st_zmax":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_orderingequals":{},"api/flink/Predicate/#st_within":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_normalize":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/snapshot/":{},"setup/release-notes/":{},"setup/release-notes/#v112":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#read-from-wkb-file":{},"tutorial/core-python/#read-from-wkt-file":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#multipolygon":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{"community/publish/#0-prepare-an-empty-script-file":{},"community/release-manager/#0-software-requirement":{},"community/snapshot/#0-prepare-an-empty-script-file":{}}}],["0)),((10",{"_index":317,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{}},"title":{}}],["0),(1",{"_index":343,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{}},"title":{}}],["0),(10",{"_index":312,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{}},"title":{}}],["0),(2",{"_index":634,"text":{"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{}},"title":{}}],["0,0",{"_index":315,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_force_2d":{}},"title":{}}],["0.0",{"_index":496,"text":{"api/flink/Function/":{},"api/flink/Function/#st_x":{},"api/sql/Function/":{},"api/sql/Function/#st_x":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-loader/#rs_base64":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{}},"title":{}}],["0.00217",{"_index":4181,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["0.1",{"_index":1751,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{}},"title":{}}],["0.1.0",{"_index":1771,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["0.1.0.jar",{"_index":1875,"text":{"archive/download/project/":{},"archive/download/project/#submit-the-compiled-jar":{}},"title":{}}],["0.1.1",{"_index":1769,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["0.14",{"_index":3786,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["0.14.3",{"_index":3877,"text":{"setup/release-notes/":{},"setup/release-notes/#global_2":{},"setup/release-notes/#global_3":{}},"title":{}}],["0.15",{"_index":3198,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{}},"title":{}}],["0.15.jar",{"_index":3203,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{}},"title":{}}],["0.16.1",{"_index":3679,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/release-notes/":{},"setup/release-notes/#global_2":{}},"title":{"setup/maven-coordinates/#jts2geojson-0161":{}}}],["0.2",{"_index":1750,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.2.0",{"_index":1761,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["0.2.1",{"_index":1383,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["0.2.2",{"_index":1752,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["0.3",{"_index":1744,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.3.1",{"_index":1742,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.3.2",{"_index":1739,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.4.0",{"_index":1734,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.5",{"_index":448,"text":{"api/flink/Function/":{},"api/flink/Function/#st_reverse":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#retrieve-geometries":{}},"title":{}}],["0.5.0",{"_index":1730,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.5.1",{"_index":1722,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.5.2",{"_index":1714,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.5.3",{"_index":1712,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.6.0",{"_index":1700,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.6.1",{"_index":1698,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.6.2",{"_index":1692,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.7.0",{"_index":1676,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["0.703125",{"_index":609,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{}},"title":{}}],["0.8",{"_index":1920,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["0.8.0",{"_index":1662,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["0.8.1",{"_index":1893,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#compatibility":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/zeppelin/":{},"setup/zeppelin/#compatibility":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["0.8.2",{"_index":1381,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1":{}},"title":{}}],["0.87890625",{"_index":610,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{}},"title":{}}],["001300",{"_index":2531,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["001700",{"_index":2567,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["01",{"_index":2371,"text":{"archive/tutorial/rdd/":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"tutorial/rdd/":{}},"title":{}}],["010450211024",{"_index":2446,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["010550013003",{"_index":2533,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["010770115015",{"_index":2380,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["010890017002",{"_index":2569,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["011501",{"_index":2375,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["021102",{"_index":2444,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["04/16/2022",{"_index":30,"text":{"":{}},"title":{"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink":{}}}],["045",{"_index":2443,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["055",{"_index":2530,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["06",{"_index":2670,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["077",{"_index":2373,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["08/30/2022",{"_index":24,"text":{"":{}},"title":{"#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112":{}}}],["0802",{"_index":2257,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["0803",{"_index":2255,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["0805",{"_index":2252,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["0862",{"_index":2259,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["089",{"_index":2566,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["096.6886584",{"_index":2688,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["096.7885168",{"_index":2674,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["0e7f",{"_index":3502,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["0x40a8cc",{"_index":1277,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{}},"title":{}}],["0x7efee2d28080",{"_index":2130,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_3":{}},"title":{}}],["0x7efee2d280b8",{"_index":2128,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_3":{}},"title":{}}],["0x7efee2d28128",{"_index":2127,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_3":{}},"title":{}}],["0x7efee2d28fd0",{"_index":2129,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_3":{}},"title":{}}],["0x7f1e5f29fe10",{"_index":2061,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{}},"title":{}}],["0x7f8fd2ee0710",{"_index":2163,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-shapefile":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-shapefile":{}},"title":{}}],["0x7f8fd2eecb90",{"_index":2160,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-geojson-file":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-geojson-file":{}},"title":{}}],["0x7f8fd2eece50",{"_index":2157,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-wkb-file":{}},"title":{}}],["0x7f8fd2fbf250",{"_index":2155,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-wkt-file":{}},"title":{}}],["1",{"_index":219,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_zmax":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_orderingequals":{},"api/flink/Predicate/#st_within":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_numgeometries":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_zmax":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#installation":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#close-a-vote":{},"community/contributor/#committer-done-template":{},"community/contributor/#nominate-a-committer-or-pmc-member":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#compile-r-html-docs":{},"community/publish/#make-a-sedona-release":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"community/rule/#review-a-pull-request":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/zeppelin/":{},"setup/zeppelin/#installation":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/snapshot/#1-upload-snapshot-versions":{}}}],["1,0",{"_index":633,"text":{"api/sql/Function/":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{}},"title":{}}],["1,1",{"_index":345,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{}},"title":{}}],["1,3",{"_index":344,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{}},"title":{}}],["1.0",{"_index":516,"text":{"api/flink/Function/":{},"api/flink/Function/#st_zmax":{},"api/sql/Function/":{},"api/sql/Function/#st_zmax":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["1.0.0",{"_index":3867,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-101":{},"setup/zeppelin/":{},"setup/zeppelin/#compatibility":{}},"title":{"setup/release-notes/#sedona-100":{}}}],["1.0.1",{"_index":3536,"text":{"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/release-notes/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{}},"title":{"setup/release-notes/#sedona-101":{}}}],["1.0.1.jar",{"_index":1886,"text":{"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{}},"title":{}}],["1.0.1.jar,geospark",{"_index":1885,"text":{"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{}},"title":{}}],["1.0546875",{"_index":611,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{}},"title":{}}],["1.1",{"_index":4338,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{}},"title":{}}],["1.1.0",{"_index":41,"text":{"":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#sedona-110":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"setup/release-notes/#sedona-110":{}}}],["1.1.1",{"_index":38,"text":{"":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/release-notes/":{}},"title":{"#11232021-sedona-111-incubating-is-released-it-now-supports-spark-32":{},"setup/release-notes/#sedona-111":{}}}],["1.1.3",{"_index":1379,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql_1":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier":{}}}],["1.1.x",{"_index":3842,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-111":{}},"title":{}}],["1.1096700000000084",{"_index":2091,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{}},"title":{}}],["1.11",{"_index":3465,"text":{"community/vote/":{},"community/vote/#install-necessary-software":{}},"title":{}}],["1.1110299999999995",{"_index":2090,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{}},"title":{}}],["1.12",{"_index":29,"text":{"":{},"setup/flink/platform/":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{"#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112":{}}}],["1.13",{"_index":3909,"text":{"setup/flink/platform/":{}},"title":{}}],["1.1386399999999952",{"_index":2093,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{}},"title":{}}],["1.1392780000000045",{"_index":2095,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{}},"title":{}}],["1.14",{"_index":3719,"text":{"setup/flink/platform/":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["1.1415619999999933",{"_index":2092,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{}},"title":{}}],["1.1418860000000137",{"_index":2094,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{}},"title":{}}],["1.18",{"_index":3882,"text":{"setup/release-notes/":{},"setup/release-notes/#global_3":{}},"title":{}}],["1.18.0",{"_index":3674,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{}},"title":{"setup/maven-coordinates/#locationtech-jts-core-1180":{}}}],["1.2",{"_index":746,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{}},"title":{}}],["1.2.0",{"_index":31,"text":{"":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#compatibility":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql_1":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/viz/":{},"archive/tutorial/zeppelin/":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#v120":{}},"title":{"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-120-and-later":{},"setup/release-notes/#sedona-120":{}}}],["1.2.1",{"_index":25,"text":{"":{},"download/":{},"setup/release-notes/":{}},"title":{"#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112":{},"download/#121-incubating":{},"setup/release-notes/#sedona-121":{}}}],["1.3.0",{"_index":3,"text":{"":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"download/":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#sedona-131":{},"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#save-geoparquet":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"download/#130-incubating":{},"setup/release-notes/#sedona-130":{}}}],["1.3.1",{"_index":184,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark":{},"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql_1":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{},"community/publish/":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#7-failed-vote":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#announce-email":{},"community/publish/#fix-signature-issues":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#upload-releases":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/release-notes/":{}},"title":{"setup/release-notes/#sedona-131":{}}}],["1.3.2",{"_index":1386,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{}},"title":{}}],["1.5",{"_index":2317,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multipolygon":{}},"title":{}}],["1.5900840000000045",{"_index":2088,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{}},"title":{}}],["1.5906639999999896",{"_index":2089,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{}},"title":{}}],["1.8",{"_index":1689,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/flink/platform/":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{}},"title":{}}],["1.x",{"_index":1380,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions":{}}}],["10",{"_index":311,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"community/publish/":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{}},"title":{"community/publish/#10-release-sedona-r-to-cran":{}}}],["10,10",{"_index":316,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{}},"title":{}}],["10.1",{"_index":4339,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{}},"title":{}}],["10.x",{"_index":3544,"text":{"setup/databricks/":{}},"title":{}}],["10/06/2021",{"_index":40,"text":{"":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{}}}],["100",{"_index":221,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_within":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#sql":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["1000",{"_index":222,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_within":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["1000*1000",{"_index":4264,"text":{"tutorial/viz/":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{}},"title":{}}],["101",{"_index":922,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#work-with-data":{}},"title":{}}],["1027",{"_index":3315,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["103",{"_index":1591,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["1039.0",{"_index":1043,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#rs_getband":{}},"title":{}}],["104",{"_index":1592,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["104.3686961",{"_index":2682,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["104.56",{"_index":2679,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["1040641",{"_index":2570,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["105",{"_index":3814,"text":{"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["1058.0",{"_index":1114,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{}},"title":{}}],["106",{"_index":3817,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["107",{"_index":3813,"text":{"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["107880",{"_index":2700,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["108",{"_index":3804,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["108001",{"_index":2697,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["109",{"_index":3826,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["10g",{"_index":1789,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["11",{"_index":500,"text":{"api/flink/Function/":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_z":{},"api/sql/Function/":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_z":{},"archive/tutorial/rdd/":{},"community/publish/":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/":{}},"title":{"community/publish/#11-publish-the-doc-website":{}}}],["11.0",{"_index":512,"text":{"api/flink/Function/":{},"api/flink/Function/#st_z":{},"api/sql/Function/":{},"api/sql/Function/#st_z":{}},"title":{}}],["11/23/2021",{"_index":37,"text":{"":{}},"title":{"#11232021-sedona-111-incubating-is-released-it-now-supports-spark-32":{}}}],["110",{"_index":1576,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#v110":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["1100",{"_index":223,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_within":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{}},"title":{}}],["111",{"_index":4314,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["111.70035626068274",{"_index":727,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{}},"title":{}}],["112",{"_index":3816,"text":{"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["113",{"_index":3824,"text":{"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["11360854",{"_index":2447,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["114",{"_index":4310,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["115",{"_index":3822,"text":{"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["116",{"_index":3821,"text":{"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["116403",{"_index":2699,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["117",{"_index":3818,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["118",{"_index":3800,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["119",{"_index":3743,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["11:48:31",{"_index":3482,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["11:48:42",{"_index":3504,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["12",{"_index":501,"text":{"api/flink/Function/":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/sql/Function/":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"setup/release-notes/":{},"setup/release-notes/#v131":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["12/01/2022",{"_index":1,"text":{"":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{}}}],["120",{"_index":815,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["121",{"_index":3758,"text":{"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["12133824.496466817",{"_index":4324,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["122",{"_index":3805,"text":{"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["12245143.987260092",{"_index":4323,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["123",{"_index":3801,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["123.4244583",{"_index":2678,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["123.43",{"_index":2675,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["12356463.478053367",{"_index":4322,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["124",{"_index":3825,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["12467782.96884664",{"_index":4321,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["125",{"_index":706,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#new-features":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["12579102.459639912",{"_index":4320,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["1258.0",{"_index":1115,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{}},"title":{}}],["126.790180",{"_index":4230,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["12690421.950433187",{"_index":4319,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["127",{"_index":3806,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["12801741.44122646",{"_index":4318,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["129",{"_index":3809,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["12913060.932019735",{"_index":4317,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["1298.0",{"_index":1046,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#rs_getband":{}},"title":{}}],["13",{"_index":1500,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["13024380.422813008",{"_index":4316,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["131",{"_index":1605,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["13135699.91360628",{"_index":4315,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["132",{"_index":3760,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["133",{"_index":3761,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["135",{"_index":3810,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["135g",{"_index":3971,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["136",{"_index":3744,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["137",{"_index":3746,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["137408",{"_index":2698,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["1378742",{"_index":2534,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["138",{"_index":3747,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["139",{"_index":1599,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["14",{"_index":3879,"text":{"setup/release-notes/":{},"setup/release-notes/#sql_3":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#retrieve-geometries":{}},"title":{}}],["14.8709625",{"_index":2218,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["140",{"_index":3762,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["140.21046313888758",{"_index":728,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{}},"title":{}}],["141",{"_index":1588,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["1410|polygon",{"_index":2201,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["1418|polygon",{"_index":2203,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["1425|polygon",{"_index":2205,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["1427|polygon",{"_index":2207,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["143",{"_index":3763,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["144",{"_index":3764,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["145",{"_index":3765,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["146",{"_index":3767,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["147",{"_index":3768,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["148",{"_index":3769,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["149",{"_index":3770,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["15",{"_index":796,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"community/develop/":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#retrieve-geometries":{}},"title":{}}],["15.0155749",{"_index":2274,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["15.0696777",{"_index":2226,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["15.0732014",{"_index":2224,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["15.0946636",{"_index":2221,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["15.3393145",{"_index":2215,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["150",{"_index":707,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#task":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["150,50",{"_index":681,"text":{"api/sql/Function/":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{}},"title":{}}],["1500000us010450211024",{"_index":2445,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["1500000us010550013003",{"_index":2532,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["1500000us010770115015",{"_index":2378,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["1500000us010890017002",{"_index":2568,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["151",{"_index":3771,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["152",{"_index":3772,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["153",{"_index":3748,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["154",{"_index":1577,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v110":{}},"title":{}}],["157",{"_index":3775,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["158",{"_index":3749,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["159",{"_index":3777,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["15g",{"_index":3969,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["16",{"_index":3874,"text":{"setup/release-notes/":{},"setup/release-notes/#global_2":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#retrieve-geometries":{}},"title":{}}],["160",{"_index":685,"text":{"api/sql/Function/":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["161",{"_index":3780,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["162",{"_index":3781,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["163",{"_index":3782,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["164",{"_index":3784,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["165",{"_index":3785,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["166",{"_index":3756,"text":{"setup/release-notes/":{},"setup/release-notes/#new-features":{}},"title":{}}],["168",{"_index":3757,"text":{"setup/release-notes/":{},"setup/release-notes/#new-features":{}},"title":{}}],["169",{"_index":3750,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["16a",{"_index":3117,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["170",{"_index":686,"text":{"api/sql/Function/":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v101":{}},"title":{}}],["171",{"_index":1580,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"setup/release-notes/":{},"setup/release-notes/#new-features":{},"setup/release-notes/#v101":{}},"title":{}}],["172",{"_index":3787,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["176",{"_index":3788,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["177",{"_index":1573,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v110":{}},"title":{}}],["178",{"_index":1579,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#v110":{}},"title":{}}],["18",{"_index":635,"text":{"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{},"setup/release-notes/":{},"setup/release-notes/#rdd":{}},"title":{}}],["18,2",{"_index":637,"text":{"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{}},"title":{}}],["181",{"_index":3794,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["1815|polygon",{"_index":2199,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["182",{"_index":3751,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["185",{"_index":1562,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#v110":{}},"title":{}}],["186",{"_index":3752,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["188",{"_index":1575,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#v110":{}},"title":{}}],["189",{"_index":1564,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v110":{}},"title":{}}],["19",{"_index":3881,"text":{"setup/release-notes/":{},"setup/release-notes/#python_1":{},"setup/release-notes/#sql_3":{}},"title":{}}],["19.446408",{"_index":2302,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multipoint":{}},"title":{}}],["19.5087",{"_index":2208,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["19.51056",{"_index":2308,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#polygon":{}},"title":{}}],["19.51121",{"_index":2306,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#polygon":{}},"title":{}}],["19.511463",{"_index":2300,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multipoint":{}},"title":{}}],["19.51216",{"_index":2310,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#polygon":{}},"title":{}}],["19.5128",{"_index":2314,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#polygon":{}},"title":{}}],["19.51280",{"_index":2312,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#polygon":{}},"title":{}}],["190",{"_index":708,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#v110":{}},"title":{}}],["192",{"_index":1566,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v110":{}},"title":{}}],["193",{"_index":1545,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#v112":{}},"title":{}}],["194",{"_index":1574,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#improvement":{},"setup/release-notes/#v110":{}},"title":{}}],["195",{"_index":3797,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["196",{"_index":3711,"text":{"setup/release-notes/":{},"setup/release-notes/#new-feature":{}},"title":{}}],["197",{"_index":3713,"text":{"setup/release-notes/":{},"setup/release-notes/#new-feature":{}},"title":{}}],["199",{"_index":3714,"text":{"setup/release-notes/":{},"setup/release-notes/#new-feature":{}},"title":{}}],["1mb",{"_index":1877,"text":{"archive/download/project/":{},"archive/download/project/#submit-the-compiled-jar":{}},"title":{}}],["1|point",{"_index":2296,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["2",{"_index":177,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_zmax":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_zmax":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/download/zeppelin/#installation":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#nominate-a-committer-or-pmc-member":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#make-a-sedona-release":{},"community/release-manager/":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"setup/zeppelin/#installation":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/release-manager/#2-prepare-secret-gpg-key":{}}}],["2),(1",{"_index":339,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{}},"title":{}}],["2),array(3",{"_index":1172,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{}}],["2,0",{"_index":337,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{}},"title":{}}],["2,1",{"_index":341,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{}},"title":{}}],["2,18",{"_index":636,"text":{"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{}},"title":{}}],["2,3",{"_index":340,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{}},"title":{}}],["2,5",{"_index":338,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{}},"title":{}}],["2.0",{"_index":868,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["2.1",{"_index":1374,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#compatibility":{},"setup/release-notes/":{},"setup/release-notes/#v101":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21_1":{}}}],["2.11",{"_index":1873,"text":{"archive/download/project/":{},"archive/download/project/#submit-the-compiled-jar":{},"setup/flink/platform/":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#highlights":{},"setup/release-notes/#task":{}},"title":{}}],["2.11/2.12",{"_index":3700,"text":{"setup/platform/":{}},"title":{}}],["2.12",{"_index":3233,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{},"setup/flink/platform/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#global_3":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{}},"title":{}}],["2.12/2.11",{"_index":3908,"text":{"setup/flink/platform/":{}},"title":{}}],["2.13",{"_index":14,"text":{"":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"setup/compile/":{},"setup/compile/#compile-with-different-targets":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#global":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{}}}],["2.2",{"_index":1372,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#apache-spark":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#apache-spark":{},"setup/release-notes/":{},"setup/release-notes/#v101":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22_1":{}}}],["2.3",{"_index":1370,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#apache-spark":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#apache-spark":{},"setup/release-notes/":{},"setup/release-notes/#v110":{},"setup/zeppelin/":{},"setup/zeppelin/#compatibility":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23_1":{}}}],["2.4",{"_index":27,"text":{"":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#apache-spark":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#apache-spark":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#task":{}},"title":{"#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112":{}}}],["2.5",{"_index":442,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointonsurface":{},"api/sql/Function/":{},"api/sql/Function/#st_pointonsurface":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#retrieve-geometries":{}},"title":{}}],["2.x",{"_index":1365,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#v01-v07":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions":{}}}],["20",{"_index":313,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_linefrommultipoint":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_subdivide":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["20,20",{"_index":318,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{}},"title":{}}],["20.9891",{"_index":2206,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["201",{"_index":3710,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{}},"title":{}}],["2015",{"_index":3150,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["2016",{"_index":3144,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["2018",{"_index":3122,"text":{"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["2019",{"_index":3138,"text":{"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["2020",{"_index":3109,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["2021",{"_index":3580,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["2022",{"_index":3483,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["203",{"_index":1531,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["204",{"_index":1548,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#v112":{}},"title":{}}],["2047",{"_index":3980,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["205",{"_index":1550,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["206",{"_index":3707,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{}},"title":{}}],["207",{"_index":1547,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["208",{"_index":3716,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement":{}},"title":{}}],["209",{"_index":1557,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["21",{"_index":253,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["21.0",{"_index":2290,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["21.1100",{"_index":2204,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["21.427834",{"_index":649,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collect":{}},"title":{}}],["21.6942",{"_index":2200,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["210",{"_index":3709,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{}},"title":{}}],["211",{"_index":1542,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#v112":{}},"title":{}}],["213",{"_index":1530,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["214",{"_index":1543,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["216",{"_index":1532,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["22",{"_index":3861,"text":{"setup/release-notes/":{},"setup/release-notes/#sql_2":{}},"title":{}}],["22.7238",{"_index":2202,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["222",{"_index":1520,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"setup/release-notes/":{},"setup/release-notes/#v113":{}},"title":{}}],["223",{"_index":1524,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"setup/release-notes/":{},"setup/release-notes/#v113":{}},"title":{}}],["224",{"_index":1468,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["225",{"_index":4255,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["228",{"_index":1469,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["23",{"_index":2297,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["23.0",{"_index":2292,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["23.5714285",{"_index":804,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["231",{"_index":1493,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["234",{"_index":1495,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["24",{"_index":630,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["24.0",{"_index":3686,"text":{"setup/maven-coordinates/":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{}},"title":{"setup/maven-coordinates/#geotools-240":{}}}],["24.1",{"_index":3846,"text":{"setup/release-notes/":{},"setup/release-notes/#global_1":{}},"title":{}}],["24.863836",{"_index":4232,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["244",{"_index":1481,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["245",{"_index":1484,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["247387",{"_index":2535,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["25",{"_index":287,"text":{"api/flink/Function/":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_z":{},"api/sql/Function/":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_z":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{}},"title":{}}],["25.0",{"_index":506,"text":{"api/flink/Function/":{},"api/flink/Function/#st_y":{},"api/sql/Function/":{},"api/sql/Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{}},"title":{}}],["25.2",{"_index":3987,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["255",{"_index":1219,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_normalize":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["256",{"_index":1296,"text":{"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_pixelize":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["256*256",{"_index":2756,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["26",{"_index":2299,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["26.0",{"_index":2294,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["26.4285714",{"_index":803,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["26860257|2422",{"_index":2262,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["26860294|2406",{"_index":2266,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["27",{"_index":3859,"text":{"setup/release-notes/":{},"setup/release-notes/#sql_2":{}},"title":{}}],["27.2",{"_index":3556,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["27.2.jar",{"_index":3567,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["27.2/geotool",{"_index":3570,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["270",{"_index":1475,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["284",{"_index":1488,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["288",{"_index":1485,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["29",{"_index":3875,"text":{"setup/release-notes/":{},"setup/release-notes/#global_2":{},"setup/release-notes/#viz_1":{}},"title":{}}],["298",{"_index":1476,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["29947493|2402",{"_index":2269,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["29947498|2602",{"_index":2271,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["29947499|2401",{"_index":2272,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["29947505|2401",{"_index":2273,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["2^zoom",{"_index":4266,"text":{"tutorial/viz/":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{}},"title":{}}],["2d",{"_index":719,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{}},"title":{}}],["2fa",{"_index":3054,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{}}],["2~5",{"_index":1799,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["3",{"_index":178,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_zmin":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_zmin":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/viz/sql/":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-tile-name":{},"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#committer-done-template":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#7-failed-vote":{},"community/publish/#make-a-sedona-release":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#v01-v07":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#render-map-tiles":{}},"title":{"community/publish/#3-update-mkdocsyml":{},"community/release-manager/#3-use-svn-to-update-keys":{}}}],["3,1",{"_index":346,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{}},"title":{}}],["3.0",{"_index":3232,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["3.0.1",{"_index":3518,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{}},"title":{}}],["3.0.2",{"_index":3871,"text":{"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#sql_3":{}},"title":{}}],["3.0_2.12",{"_index":3316,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["3.0_2.12/1.3.0",{"_index":3572,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["3.0_2.12:1.1.0",{"_index":3985,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["3.0_2.12:1.3.0",{"_index":3553,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{}},"title":{}}],["3.0_2.12:<version>,org.apache.sedona:sedona",{"_index":4125,"text":{"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{}},"title":{}}],["3.0_2.12:<version>,org.datasyslab:geotool",{"_index":4126,"text":{"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{}},"title":{}}],["3.0_2.13",{"_index":3317,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["3.1",{"_index":3226,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/platform/":{}},"title":{}}],["3.1.1",{"_index":3870,"text":{"setup/release-notes/":{},"setup/release-notes/#global_2":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#viz_1":{}},"title":{}}],["3.10",{"_index":16,"text":{"":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#improvement_1":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{}}}],["3.141592653589793",{"_index":288,"text":{"api/flink/Function/":{},"api/flink/Function/#st_azimuth":{},"api/sql/Function/":{},"api/sql/Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{}},"title":{}}],["3.2",{"_index":39,"text":{"":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sql_1":{}},"title":{"#11232021-sedona-111-incubating-is-released-it-now-supports-spark-32":{}}}],["3.3",{"_index":28,"text":{"":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sql-for-spark":{}},"title":{"#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112":{}}}],["3.3.1",{"_index":3466,"text":{"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{}},"title":{}}],["3.5",{"_index":4285,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#retrieve-geometries":{}},"title":{}}],["3.6",{"_index":2164,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#python":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#python":{}},"title":{}}],["3.7",{"_index":2165,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#python":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#python":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["3.8",{"_index":3526,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{}},"title":{}}],["3.9",{"_index":3527,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["3.x",{"_index":3367,"text":{"community/release-manager/":{},"community/release-manager/#0-software-requirement":{}},"title":{}}],["30",{"_index":392,"text":{"api/flink/Function/":{},"api/flink/Function/#st_linefrommultipoint":{},"api/sql/Function/":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_subdivide":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#sql_2":{},"tutorial/sql-python/":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{}},"title":{}}],["30.01",{"_index":2074,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["300",{"_index":1124,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_html":{}},"title":{}}],["300k/month",{"_index":3695,"text":{"setup/overview/":{},"setup/overview/#download-statistics":{}},"title":{}}],["3021",{"_index":461,"text":{"api/flink/Function/":{},"api/flink/Function/#st_setsrid":{},"api/sql/Function/":{},"api/sql/Function/#st_setsrid":{}},"title":{}}],["31",{"_index":3866,"text":{"setup/release-notes/":{},"setup/release-notes/#r":{}},"title":{}}],["31.275168",{"_index":2513,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.276814",{"_index":2515,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.276882",{"_index":2511,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.278848",{"_index":2517,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.279082",{"_index":2519,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.27935",{"_index":2509,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.28008",{"_index":2507,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.281049",{"_index":2505,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.281426",{"_index":2503,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.28285",{"_index":2501,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.283499",{"_index":2521,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.286376",{"_index":2499,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.288211",{"_index":2497,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.289718",{"_index":2523,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.290476",{"_index":2525,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.29314",{"_index":2495,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.295204",{"_index":2527,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.295638",{"_index":2493,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.29689",{"_index":2529,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.297677",{"_index":2491,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.297901",{"_index":2449,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["31.30022",{"_index":2489,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.30093",{"_index":2487,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.302076",{"_index":2485,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.302123",{"_index":2483,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.302764",{"_index":2481,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.305203",{"_index":2451,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["31.305299",{"_index":2479,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.305583",{"_index":2477,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.306178",{"_index":2475,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.306224",{"_index":2473,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.30666",{"_index":2471,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.307096",{"_index":2453,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["31.307552",{"_index":2455,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.307622",{"_index":2469,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.307951",{"_index":2457,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.309524",{"_index":2467,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.310988",{"_index":2465,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.311977",{"_index":2463,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.31218",{"_index":2459,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["31.312876",{"_index":2461,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["314",{"_index":1477,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["31|039|00835841|31039",{"_index":2669,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["31|109|00835876|31109",{"_index":2684,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["32",{"_index":1041,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"setup/release-notes/":{},"setup/release-notes/#viz_1":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["32.0",{"_index":2295,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["32.1428571",{"_index":805,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["32.324142",{"_index":2354,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["32.35078",{"_index":2360,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"tutorial/rdd/":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["32.357073",{"_index":2358,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["32.360763",{"_index":2356,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["320",{"_index":1473,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["321",{"_index":1486,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["32636",{"_index":2386,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["32|[1058.0",{"_index":1042,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["32|[1258.0",{"_index":1045,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["33",{"_index":3876,"text":{"setup/release-notes/":{},"setup/release-notes/#global_2":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["33.989548",{"_index":2561,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["33.994237",{"_index":2563,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["33.995153",{"_index":2559,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["33.99913",{"_index":2553,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["33.999131",{"_index":2555,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["33.999488",{"_index":2551,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["33.999714",{"_index":2557,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["331",{"_index":1489,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["333",{"_index":723,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{}},"title":{}}],["339|30700|null",{"_index":2686,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["34",{"_index":4308,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["34.000028",{"_index":2565,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.001502",{"_index":2549,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.002659",{"_index":2547,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.004552",{"_index":2545,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.00537",{"_index":2537,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["34.005426",{"_index":2543,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.009768",{"_index":2539,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["34.01",{"_index":2106,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["34.010398",{"_index":2541,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["34.0476190",{"_index":807,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["34.6825396",{"_index":810,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["34.717363",{"_index":2586,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.718322",{"_index":2584,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.718513",{"_index":2588,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.718565",{"_index":2590,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.718577",{"_index":2592,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.719143",{"_index":2582,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.719377",{"_index":2594,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.719766",{"_index":2580,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.723168",{"_index":2578,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.723865",{"_index":2576,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.727131",{"_index":2574,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.727375",{"_index":2572,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.831431",{"_index":2424,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.831526",{"_index":2426,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.831925",{"_index":2428,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.832699",{"_index":2422,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.833938",{"_index":2420,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.8352",{"_index":2430,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.836087",{"_index":2432,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.83763",{"_index":2418,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.837682",{"_index":2416,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.838423",{"_index":2414,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.841003",{"_index":2412,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.841884",{"_index":2410,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.84329",{"_index":2434,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.844307",{"_index":2408,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.844438",{"_index":2436,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.844829",{"_index":2406,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.846387",{"_index":2438,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.85053",{"_index":2440,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.851336",{"_index":2404,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.858537",{"_index":2402,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.865379",{"_index":2442,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.865687",{"_index":2400,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.867502",{"_index":2398,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.872316",{"_index":2396,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.873303",{"_index":2394,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["34.873337",{"_index":2392,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["34.873369",{"_index":2390,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["34.873444",{"_index":2388,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["344",{"_index":1409,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["345",{"_index":1428,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["346",{"_index":1429,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["35",{"_index":797,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"setup/release-notes/":{},"setup/release-notes/#core_1":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["359",{"_index":1423,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["35|011|00933054|35011",{"_index":2680,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["36",{"_index":4309,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["365",{"_index":1411,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["37",{"_index":4311,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["37.8571428",{"_index":808,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["37.857142857142854",{"_index":799,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["373",{"_index":1424,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["378",{"_index":1434,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["379",{"_index":1435,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["38",{"_index":4312,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["38(4",{"_index":3166,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{}},"title":{}}],["3857",{"_index":4305,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["39",{"_index":4313,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["395",{"_index":1431,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["396",{"_index":1432,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["398",{"_index":1425,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["399",{"_index":1418,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["3a79a47ac26ff4cd",{"_index":3474,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["3aa5c34371567bd2",{"_index":3392,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["3ca8",{"_index":3501,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["3d",{"_index":409,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{}}],["4",{"_index":135,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_zmin":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_zmin":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/publish/":{},"community/release-manager/":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#sql":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{}},"title":{"community/publish/#4-stage-and-upload-release-candidates":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{}}}],["4.0",{"_index":520,"text":{"api/flink/Function/":{},"api/flink/Function/#st_zmin":{},"api/sql/Function/":{},"api/sql/Function/#st_zmin":{}},"title":{}}],["4.5",{"_index":4287,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#retrieve-geometries":{}},"title":{}}],["40",{"_index":391,"text":{"api/flink/Function/":{},"api/flink/Function/#st_linefrommultipoint":{},"api/sql/Function/":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_subdivide":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql-python/":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{}},"title":{}}],["40.01",{"_index":2075,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["40.7128",{"_index":208,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_pointfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{}},"title":{}}],["401",{"_index":1419,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["402",{"_index":1421,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["406",{"_index":1426,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["4096",{"_index":3380,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["41",{"_index":3852,"text":{"setup/release-notes/":{},"setup/release-notes/#core":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["416",{"_index":1427,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["42",{"_index":2298,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["42.0",{"_index":2293,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["42.0872",{"_index":198,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mpolyfromtext":{}},"title":{}}],["42.0946",{"_index":196,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mpolyfromtext":{}},"title":{}}],["42.1002",{"_index":194,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mpolyfromtext":{}},"title":{}}],["42.28787",{"_index":4108,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["420",{"_index":1414,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["421",{"_index":1415,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["422",{"_index":1416,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["4269",{"_index":190,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{}},"title":{}}],["427",{"_index":3893,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{}}],["43",{"_index":3844,"text":{"setup/release-notes/":{},"setup/release-notes/#sql_1":{}},"title":{}}],["43.8095238",{"_index":812,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["4326",{"_index":4304,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["443",{"_index":3883,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-core":{}},"title":{}}],["448",{"_index":3900,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-python":{}},"title":{}}],["45",{"_index":795,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"setup/release-notes/":{},"setup/release-notes/#sql_1":{}},"title":{}}],["45.342524",{"_index":650,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collect":{}},"title":{}}],["451",{"_index":3885,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-core":{}},"title":{}}],["459",{"_index":3895,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{}}],["460",{"_index":3896,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{}}],["469",{"_index":3178,"text":{"community/publish/":{},"community/publish/#make-a-sedona-release":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{}}],["480",{"_index":3897,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{}}],["488",{"_index":3889,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-core":{}},"title":{}}],["499",{"_index":3894,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{}}],["4b18",{"_index":3498,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["4d",{"_index":405,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{}},"title":{}}],["5",{"_index":186,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_zmin":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_zmin":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"community/publish/":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{}},"title":{"community/publish/#5-vote-in-dev-sedonaapacheorg":{},"community/release-manager/#5-get-github-personal-access-token-classic":{}}}],["5,5",{"_index":342,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{}},"title":{}}],["5.4.2",{"_index":3659,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}}}],["5.5",{"_index":4289,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#retrieve-geometries":{}},"title":{}}],["50",{"_index":705,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"setup/release-notes/":{},"setup/release-notes/#python":{},"setup/release-notes/#sedona-130":{}},"title":{}}],["50.000",{"_index":4233,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["500",{"_index":3973,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["501",{"_index":923,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#work-with-data":{}},"title":{}}],["51.5974135047432",{"_index":709,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{}},"title":{}}],["51.76426",{"_index":2307,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#polygon":{}},"title":{}}],["51.76448",{"_index":2313,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#polygon":{}},"title":{}}],["51.765158",{"_index":2301,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multipoint":{}},"title":{}}],["51.76583",{"_index":2309,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#polygon":{}},"title":{}}],["51.76599",{"_index":2311,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#polygon":{}},"title":{}}],["51.779752",{"_index":2303,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multipoint":{}},"title":{}}],["512",{"_index":3258,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["52",{"_index":251,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["52.0",{"_index":2291,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{}},"title":{}}],["52.042576573",{"_index":351,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geohash":{},"api/sql/Function/":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_geohash":{}},"title":{}}],["52.3130396",{"_index":2222,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["52.3141083",{"_index":2225,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["52.3143013",{"_index":2227,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["52.3504247",{"_index":2216,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["52.691693",{"_index":2219,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["53",{"_index":3856,"text":{"setup/release-notes/":{},"setup/release-notes/#core":{}},"title":{}}],["53|069|01513275|53069",{"_index":2676,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["55",{"_index":1726,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["56",{"_index":3860,"text":{"setup/release-notes/":{},"setup/release-notes/#sql_2":{}},"title":{}}],["56.342354355",{"_index":648,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collect":{}},"title":{}}],["58",{"_index":1715,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["58.297",{"_index":1044,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["58.699",{"_index":1040,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["59",{"_index":3863,"text":{"setup/release-notes/":{},"setup/release-notes/#python":{}},"title":{}}],["5c69",{"_index":3496,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["5g",{"_index":1792,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["6",{"_index":187,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_zmin":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_zmin":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"community/publish/":{},"community/release-manager/":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{"community/publish/#6-vote-in-general-incubatorapacheorg":{},"community/release-manager/#6-set-up-credentials-for-maven":{}}}],["6.5",{"_index":4291,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#retrieve-geometries":{}},"title":{}}],["60",{"_index":682,"text":{"api/sql/Function/":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["600",{"_index":4229,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["601",{"_index":924,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#work-with-data":{}},"title":{}}],["62",{"_index":3851,"text":{"setup/release-notes/":{},"setup/release-notes/#global_1":{}},"title":{}}],["63",{"_index":3847,"text":{"setup/release-notes/":{},"setup/release-notes/#global_1":{}},"title":{}}],["64",{"_index":3849,"text":{"setup/release-notes/":{},"setup/release-notes/#global_1":{}},"title":{}}],["64.630926",{"_index":4231,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["64cea38dd3ca171ee4e2a7365dbce999773862f2a11599bd0f27e9551d740659a519a9b976b3e7b0826088010967093e6acc9462f7073e9737c24b007a2df846",{"_index":3506,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["65",{"_index":3831,"text":{"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{}}],["666",{"_index":724,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{}},"title":{}}],["67",{"_index":3843,"text":{"setup/release-notes/":{},"setup/release-notes/#sql_1":{}},"title":{}}],["68",{"_index":3832,"text":{"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{}}],["682138871|61658258|+46.2946377",{"_index":2677,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["6844991",{"_index":2384,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["69",{"_index":1713,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["69.28469348539744",{"_index":725,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{}},"title":{}}],["6c88",{"_index":3500,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["6c883ca80e7fd299",{"_index":3475,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["7",{"_index":188,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_zmin":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_zmin":{},"community/publish/":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{"community/publish/#7-failed-vote":{}}}],["7.3",{"_index":3557,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{}},"title":{"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}}}],["7.5",{"_index":4293,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#retrieve-geometries":{}},"title":{}}],["7.x",{"_index":3547,"text":{"setup/databricks/":{}},"title":{}}],["70",{"_index":683,"text":{"api/sql/Function/":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{}},"title":{}}],["70.916",{"_index":193,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mpolyfromtext":{}},"title":{}}],["70.9468",{"_index":195,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mpolyfromtext":{}},"title":{}}],["70.9765",{"_index":197,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mpolyfromtext":{}},"title":{}}],["71",{"_index":3845,"text":{"setup/release-notes/":{},"setup/release-notes/#sql_1":{}},"title":{}}],["71.064544",{"_index":4107,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["71.16028,42.258729",{"_index":149,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgml":{}},"title":{}}],["71.160837,42.259112",{"_index":150,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgml":{}},"title":{}}],["71.161143,42.25932</gml:coordinates></gml:linestr",{"_index":151,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgml":{}},"title":{}}],["71.1663,42.2614",{"_index":156,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromkml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromkml":{}},"title":{}}],["71.1667,42.2616</coordinates></linestr",{"_index":157,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromkml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromkml":{}},"title":{}}],["72",{"_index":2977,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["72fc",{"_index":3499,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["72hr",{"_index":3287,"text":{"community/publish/":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{}},"title":{}}],["73",{"_index":3827,"text":{"setup/release-notes/":{},"setup/release-notes/#global":{},"setup/release-notes/#rdd":{}},"title":{}}],["74.0060",{"_index":164,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/flink/Constructor/#st_pointfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{}},"title":{}}],["74.0421975,40.6921336",{"_index":228,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{}},"title":{}}],["74.0428197,40.6867969",{"_index":227,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{}},"title":{}}],["74.0508020,40.6912794",{"_index":229,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{}},"title":{}}],["75",{"_index":2254,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"setup/release-notes/":{},"setup/release-notes/#sql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["76.5974135047432",{"_index":710,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{}},"title":{}}],["77",{"_index":3828,"text":{"setup/release-notes/":{},"setup/release-notes/#rdd":{}},"title":{}}],["777",{"_index":3185,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["7x",{"_index":3118,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["8",{"_index":365,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_makepolygon":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"community/publish/":{},"community/publish/#compile-r-html-docs":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-sql":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{"community/publish/#8-release-source-code-and-maven-package":{}}}],["8.5",{"_index":4295,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#retrieve-geometries":{}},"title":{}}],["80",{"_index":684,"text":{"api/sql/Function/":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["80.01",{"_index":2073,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["80k/month",{"_index":3694,"text":{"setup/overview/":{},"setup/overview/#download-statistics":{}},"title":{}}],["82",{"_index":3833,"text":{"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{}}],["84",{"_index":3732,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["84\",6378137,298.257223563",{"_index":3735,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["84.01",{"_index":2105,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["85",{"_index":814,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"setup/release-notes/":{},"setup/release-notes/#flink_1":{}},"title":{}}],["85.66566",{"_index":2486,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.665687",{"_index":2488,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.668276",{"_index":2484,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.668703",{"_index":2492,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.669183",{"_index":2490,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.669796",{"_index":2472,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.669876",{"_index":2470,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.670356",{"_index":2474,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.670622",{"_index":2466,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.670729",{"_index":2468,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.671344",{"_index":2482,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.67145",{"_index":2464,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.671664",{"_index":2476,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.67177",{"_index":2478,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.671878",{"_index":2480,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.671985",{"_index":2494,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.672275",{"_index":2462,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.672733",{"_index":2460,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.674377",{"_index":2508,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.674661",{"_index":2506,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.675603",{"_index":2458,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.675714",{"_index":2510,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.676865",{"_index":2504,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.677177",{"_index":2496,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.677938",{"_index":2512,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.678452",{"_index":2498,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.679195",{"_index":2502,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.679236",{"_index":2500,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.680348",{"_index":2514,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.684032",{"_index":2516,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.684387",{"_index":2518,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.692398",{"_index":2520,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.697419",{"_index":2456,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.69999",{"_index":2454,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.705032",{"_index":2522,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.706755",{"_index":2524,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.714271",{"_index":2452,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["85.715626",{"_index":2450,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["85.718102",{"_index":2526,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.719017",{"_index":2448,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["85.719132",{"_index":2528,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.985",{"_index":2546,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.986656",{"_index":2544,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.987567",{"_index":2550,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.987865",{"_index":2542,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.98851",{"_index":2548,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.988666",{"_index":2552,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.992568",{"_index":2554,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.993144",{"_index":2556,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.994876",{"_index":2558,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.998012",{"_index":2540,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["85.998823",{"_index":2560,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["85.998837",{"_index":2538,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["85.999925",{"_index":2562,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86",{"_index":3836,"text":{"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{}}],["86.000616",{"_index":2564,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86.000685",{"_index":2536,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["86.557352",{"_index":2583,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86.557381",{"_index":2581,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86.559921",{"_index":2585,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86.562336",{"_index":2579,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86.562684",{"_index":2573,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86.562797",{"_index":2575,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86.562957",{"_index":2577,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86.564827",{"_index":2587,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86.567582",{"_index":2589,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86.570572",{"_index":2591,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86.573618",{"_index":2593,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["86.574172",{"_index":2571,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87",{"_index":3840,"text":{"setup/release-notes/":{},"setup/release-notes/#flink_1":{}},"title":{}}],["87.603673",{"_index":2409,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.603696",{"_index":2407,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.603716",{"_index":2405,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.60372",{"_index":2411,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.603879",{"_index":2413,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.603888",{"_index":2415,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.603889",{"_index":2417,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.604018",{"_index":2403,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.604033",{"_index":2395,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.604049",{"_index":2393,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.60415",{"_index":2397,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.604218",{"_index":2399,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.604409",{"_index":2401,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.6123",{"_index":2391,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["87.613127",{"_index":2419,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.616451",{"_index":2421,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.617535",{"_index":2389,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["87.621041",{"_index":2423,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.621056",{"_index":2425,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.62112",{"_index":2427,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.62119",{"_index":2439,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.62129",{"_index":2437,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.621359",{"_index":2435,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.621383",{"_index":2433,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.62144",{"_index":2441,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.62158",{"_index":2431,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.621603",{"_index":2429,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["87.621765",{"_index":2387,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["88.175933",{"_index":2355,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["88.175933,32.360763",{"_index":2338,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["88.175933,32.360763,ga",{"_index":2327,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["88.175933,32.360763,testattribute1,testattribute2",{"_index":4094,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["88.175933|32.360763",{"_index":2751,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["88.221102",{"_index":2359,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"tutorial/rdd/":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["88.221102,32.35078",{"_index":2340,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["88.221102,32.35078,restaur",{"_index":2329,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["88.331492",{"_index":2353,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["88.331492,32.324142",{"_index":2337,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["88.331492,32.324142,hotel",{"_index":2326,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["88.331492,32.324142,testattribute1,testattribute2",{"_index":4093,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["88.331492|32.324142",{"_index":2750,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["88.388954",{"_index":2357,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["88.388954,32.357073",{"_index":2339,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["88.388954,32.357073,bar",{"_index":2328,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["88.388954,32.357073,testattribute1,testattribute2",{"_index":4095,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["88.388954|32.357073",{"_index":2752,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["89",{"_index":3838,"text":{"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{}}],["9",{"_index":366,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/rdd/":{},"community/publish/":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{"community/publish/#9-release-sedona-python-and-zeppelin":{}}}],["9.5",{"_index":4297,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#retrieve-geometries":{}},"title":{}}],["9.x",{"_index":3548,"text":{"setup/databricks/":{}},"title":{}}],["90",{"_index":3837,"text":{"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{}}],["90.01",{"_index":2072,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["91",{"_index":1590,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["93",{"_index":3841,"text":{"setup/release-notes/":{},"setup/release-notes/#flink_1":{}},"title":{}}],["94",{"_index":3755,"text":{"setup/release-notes/":{},"setup/release-notes/#new-features":{}},"title":{}}],["94.28469348539744",{"_index":726,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{}},"title":{}}],["949d",{"_index":3494,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["949dd6275c69ab954b1872fc6c883ca80e7fd299",{"_index":3485,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["95",{"_index":3815,"text":{"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["96",{"_index":3802,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["96.910",{"_index":2683,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["963",{"_index":3167,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{}},"title":{}}],["97",{"_index":1672,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["97.019",{"_index":2668,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["98",{"_index":3820,"text":{"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["994",{"_index":3168,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{}},"title":{}}],["999",{"_index":1265,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{}},"title":{}}],["9x",{"_index":3119,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["_",{"_index":4206,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["_c0",{"_index":143,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["_c0|_c1|_c2",{"_index":2657,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["_c1",{"_index":571,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["_c11|_c12|_c13",{"_index":2663,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["_c14",{"_index":2664,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["_c15",{"_index":2665,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["_c16",{"_index":2666,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["_c17",{"_index":2667,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["_c2",{"_index":572,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["_c3",{"_index":2658,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["_c4",{"_index":2659,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["_c5",{"_index":2660,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["_c6",{"_index":2054,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/core-python/":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["_c6|_c7",{"_index":2696,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["_c6|_c7|_c8",{"_index":2661,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["_c7",{"_index":2692,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["_c9|_c10",{"_index":2662,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["a:geometri",{"_index":237,"text":{"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_area":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_distance":{},"api/flink/Function/#st_envelope":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_issimple":{},"api/flink/Function/#st_isvalid":{},"api/flink/Function/#st_length":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_transform":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_within":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_area":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_convexhull":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_length":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_npoints":{},"api/sql/Function/#st_numgeometries":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_pixelize":{}},"title":{}}],["a:geometrycolumn",{"_index":112,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Aggregator/#st_union_aggr":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{}},"title":{}}],["a:imag",{"_index":1289,"text":{"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{}},"title":{}}],["a:pixel",{"_index":1303,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{}},"title":{}}],["aa38e0",{"_index":1276,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{}},"title":{}}],["ab",{"_index":3262,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["ab95",{"_index":3497,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["abov",{"_index":919,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{}},"title":{}}],["abovement",{"_index":3625,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["absenc",{"_index":3433,"text":{"community/rule/":{},"community/rule/#develop-a-code-contribution":{}},"title":{}}],["absolute/path/geospark/geospark",{"_index":1899,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{}},"title":{}}],["absolute/path/incub",{"_index":3904,"text":{"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}},"title":{}}],["acceler",{"_index":1666,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["accept",{"_index":1487,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#pass-email":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/rule/":{},"community/rule/#pick-annouce-a-task-using-jira":{},"setup/release-notes/":{},"setup/release-notes/#v110":{},"setup/release-notes/#v120":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{"community/contributor/#pmc-accept-and-icla-instruction":{}}}],["access",{"_index":2865,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#committers":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{}},"title":{"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/release-manager/#5-get-github-personal-access-token-classic":{}}}],["accessor",{"_index":3776,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["accord",{"_index":1262,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["accordingli",{"_index":3280,"text":{"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["account",{"_index":3030,"text":{"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#committer-done-template":{},"community/contributor/#create-asf-account":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{"community/contributor/#create-asf-account":{}}}],["accur",{"_index":1678,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["accuraci",{"_index":1604,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["achiev",{"_index":1977,"text":{"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{}},"title":{}}],["acm",{"_index":3148,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["action",{"_index":69,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"download/":{},"download/#github-repository":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#download-staged-jars":{}},"title":{}}],["action\"",{"_index":1940,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["activ",{"_index":2922,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#send-the-invitation":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["activation><activebydefault",{"_index":1393,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{}},"title":{}}],["activebydefault></activ",{"_index":1394,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{}},"title":{}}],["activeprofil",{"_index":3426,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["activeprofile>gpg</activeprofil",{"_index":3427,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["actual",{"_index":2691,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{}},"title":{}}],["ad",{"_index":245,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"community/rule/#review-a-pull-request":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v101":{},"setup/release-notes/#v112":{},"tutorial/python-vector-osm/":{}},"title":{"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}}}],["adam",{"_index":2870,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["adapt",{"_index":566,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-python/#setup-environment-variables":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/rdd/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{"setup/install-python/#prepare-python-adapter-jar":{}}}],["adapter.todf",{"_index":1430,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#core_1":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#v131":{}},"title":{}}],["adapter/target",{"_index":3593,"text":{"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{}},"title":{}}],["adapter/target/sedona",{"_index":3255,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["add",{"_index":6,"text":{"":{},"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/zeppelin/":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"archive/tutorial/viz/#set-up-dependencies":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#become-a-committer":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#announce-email":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global_3":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#new-feature":{},"setup/release-notes/#new-features":{},"setup/release-notes/#r":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_1":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v100":{},"setup/release-notes/#v110":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"setup/zeppelin/":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/flink/sql/#set-up-dependencies":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#register-sedonasql":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{},"tutorial/viz/#set-up-dependencies":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"archive/download/zeppelin/#add-geospark-dependencies-in-zeppelin-spark-interpreter":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"community/contributor/#add-to-the-system":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{},"setup/zeppelin/#add-sedona-dependencies-in-zeppelin-spark-interpreter":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}}}],["addit",{"_index":241,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#introduction":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/publish/":{},"community/publish/#announce-email":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["addition",{"_index":3067,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["address",{"_index":1782,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#core_1":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}},"title":{}}],["adher",{"_index":3039,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["adjac",{"_index":1959,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["admin",{"_index":3311,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["admin123",{"_index":3314,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["admin:org",{"_index":3411,"text":{"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{}},"title":{}}],["admind123",{"_index":3312,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["advanc",{"_index":980,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{}},"title":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"setup/databricks/#advanced-editions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{}}}],["affgeoid",{"_index":2377,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["affili",{"_index":3454,"text":{"community/rule/":{},"community/rule/#code-of-conduct":{}},"title":{}}],["ag",{"_index":1320,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["again",{"_index":3297,"text":{"community/publish/":{},"community/publish/#announce-email":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{}},"title":{}}],["against",{"_index":1645,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["aggreg",{"_index":18,"text":{"":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#other-queries":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sedona-sql":{},"tutorial/sql/":{},"tutorial/sql/#other-queries":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"api/flink/Aggregator/":{},"api/sql/AggregateFunction/":{},"api/viz/sql/#aggregate-functions":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/viz/sql/#aggregate-functions":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{}}}],["agreement",{"_index":3019,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["aka",{"_index":1677,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["al",{"_index":2796,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{}}],["aland",{"_index":2383,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["alfon",{"_index":3131,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["algebra",{"_index":49,"text":{"":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sql_2":{},"tutorial/raster/":{},"tutorial/raster/#api-docs":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"tutorial/raster/":{}}}],["algo",{"_index":3382,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["algorithm",{"_index":3449,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{}},"title":{}}],["alia",{"_index":160,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_multi":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["align",{"_index":2986,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["all.sh",{"_index":1813,"text":{"archive/download/cluster/":{},"archive/download/cluster/#start-your-cluster":{},"setup/cluster/":{},"setup/cluster/#start-your-cluster":{}},"title":{}}],["all/</url",{"_index":3668,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["all</id",{"_index":3664,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["all</nam",{"_index":3666,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["allbandvalu",{"_index":1109,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{}},"title":{}}],["alloc",{"_index":1793,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["allow",{"_index":1392,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/project/":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#new-features":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v081-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["allowtopologyinvalidgeometri",{"_index":2365,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["along",{"_index":695,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"community/contact/":{},"community/contact/#bug-reports":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/release-notes/":{},"setup/release-notes/#v081-geospark-core":{}},"title":{}}],["alphaband",{"_index":1090,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["alreadi",{"_index":1056,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publish/":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["altern",{"_index":933,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["although",{"_index":1100,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"setup/platform/":{},"setup/release-notes/":{},"tutorial/demo/":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["alway",{"_index":1862,"text":{"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/rdd/":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["amazon",{"_index":1756,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"tutorial/core-python/":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/rdd/":{},"tutorial/rdd/#save-to-permanent-storage":{}},"title":{}}],["amount",{"_index":1796,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["analisi",{"_index":4014,"text":{"tutorial/python-vector-osm/":{}},"title":{"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}}}],["analyt",{"_index":3124,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{},"setup/overview/":{}},"title":{"setup/overview/#rich-spatial-analytics-tools":{}}}],["analyz",{"_index":1721,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["andrea",{"_index":3127,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["andvalu",{"_index":1150,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_bitwiseand":{}},"title":{}}],["aniqu",{"_index":3154,"text":{"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["annouc",{"_index":3047,"text":{"community/contributor/":{},"community/publish/":{},"community/publish/#pass-email_1":{},"community/rule/":{}},"title":{"community/contributor/#pmc-annoucement":{},"community/rule/#pick-annouce-a-task-using-jira":{}}}],["announc",{"_index":1731,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/publish/":{},"community/publish/#announce-email":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{"community/publish/#announce-email":{}}}],["anoth",{"_index":2086,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format":{},"community/publish/":{},"community/publish/#7-failed-vote":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format":{}},"title":{}}],["answser",{"_index":3437,"text":{"community/rule/":{},"community/rule/#make-a-pull-request":{}},"title":{}}],["anti",{"_index":892,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["anton",{"_index":1501,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["any.whl",{"_index":2026,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{}},"title":{}}],["anyon",{"_index":2920,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{}},"title":{}}],["anyth",{"_index":1861,"text":{"archive/download/project/":{},"archive/download/project/#try-geospark-sql-functions":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{}},"title":{}}],["apach",{"_index":36,"text":{"":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/cluster/":{},"archive/download/cluster/#start-your-cluster":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#compatibility":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#set-up-dependencies":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"asf/asf/":{},"asf/asf/#copyright":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contact/":{},"community/contact/#discord-server":{},"community/contact/#feedback":{},"community/contact/#twitter":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#committer-done-template":{},"community/contributor/#mentors":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#project-management-committee-pmc":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{},"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{},"community/publication/#publication":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#announce-email":{},"community/publish/#fix-signature-issues":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#upload-releases":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"community/rule/#develop-a-code-contribution":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"community/vote/#run-the-verify-script":{},"setup/cluster/":{},"setup/cluster/#start-your-cluster":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/install-scala/":{},"setup/flink/modules/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#buildsbt":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/overview/":{},"setup/overview/#download-statistics":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#new-features":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v110":{},"setup/release-notes/#v120":{},"setup/zeppelin/":{},"setup/zeppelin/#compatibility":{},"setup/zeppelin/#installation":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{},"tutorial/viz/#set-up-dependencies":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions":{},"archive/download/cluster/#set-up-your-apache-spark-cluster":{},"archive/tutorial/geospark-core-python/#apache-spark":{},"archive/tutorial/geospark-sql-python/#apache-spark":{},"community/rule/#contributing-to-apache-sedona":{},"setup/cluster/#set-up-your-apache-spark-cluster":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/modules/#sedona-modules-for-apache-spark":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/zeppelin/":{}}}],["apache.sedona",{"_index":3599,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["apache.sedona::sedona_read_geojson",{"_index":4102,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["apache.sedona::sedona_read_wkb",{"_index":4101,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["apache.sedona::sedona_read_wkt",{"_index":4100,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["apache.sedona::sedona_render_choropleth_map",{"_index":4259,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["apache.sedona::sedona_render_heatmap",{"_index":4258,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["apache.sedona::sedona_render_scatter_plot",{"_index":4257,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["apache.sedona_*.tar.gz",{"_index":3340,"text":{"community/publish/":{},"community/publish/#10-release-sedona-r-to-cran":{}},"title":{}}],["api",{"_index":12,"text":{"":{},"api/java-api/":{},"api/viz/java-api/":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"setup/databricks/":{},"setup/flink/modules/":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#highlights":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#new-features":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sedona-viz":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"setup/release-notes/#viz_1":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/raster/":{},"tutorial/rdd/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#range-query":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"setup/flink/modules/#api-availability":{},"setup/modules/#api-availability":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{},"tutorial/raster/#api-docs":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/#dataframe-style-api":{}}}],["api.de/api/interpret",{"_index":3993,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["api/behavior",{"_index":3899,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-python":{}},"title":{}}],["api/sedonasql",{"_index":4138,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["app",{"_index":528,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["append",{"_index":480,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"community/develop/":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"setup/compile/":{},"setup/compile/#compile-with-different-targets":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["appli",{"_index":4167,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["applic",{"_index":943,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/core-python/":{},"tutorial/rdd-r/":{},"tutorial/sql-python/":{},"tutorial/sql-r/":{},"tutorial/viz-r/":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/geospark-core-python/#spatial-rdd-applications-in-python":{},"archive/tutorial/geospark-sql-python/#spatial-sql-application-in-python":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/core-python/#spatial-rdd-applications-in-python":{},"tutorial/rdd-r/#spatial-rdd-applications-in-r-language":{},"tutorial/sql-python/#spatial-sql-application-in-python":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}}}],["appnam",{"_index":956,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["appname(\"overpass",{"_index":3964,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["approach",{"_index":1062,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["approv",{"_index":2952,"text":{"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/publish/":{},"community/publish/#pass-email":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["approxim",{"_index":1669,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["approximatetotalcount",{"_index":1942,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["approxmi",{"_index":1670,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["apr",{"_index":3481,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["apt",{"_index":3353,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{},"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["arcgi",{"_index":2734,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["architect",{"_index":3110,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["archiv",{"_index":84,"text":{"download/":{},"download/#past-releases":{},"setup/overview/":{},"setup/overview/#download-statistics":{}},"title":{}}],["area",{"_index":255,"text":{"api/flink/Function/":{},"api/flink/Function/#st_area":{},"api/sql/Function/":{},"api/sql/Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["area[nam",{"_index":3996,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["areal",{"_index":303,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{}},"title":{}}],["arealandmark",{"_index":117,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_within":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{}},"title":{}}],["arealm",{"_index":4086,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["arealm.csv",{"_index":2797,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{}}],["argument",{"_index":697,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makevalid":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/tutorial/geospark-core-python/":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"tutorial/core-python/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["arizona",{"_index":3088,"text":{"community/publication/":{},"community/publication/#publication":{}},"title":{}}],["armor",{"_index":3394,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{}},"title":{}}],["around",{"_index":1568,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"setup/release-notes/":{},"setup/release-notes/#v110":{}},"title":{}}],["arrang",{"_index":3029,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["array",{"_index":643,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_normalize":{},"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"tutorial/core-python/":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["array(0.0",{"_index":4152,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["array<geometri",{"_index":646,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_makepolygon":{}},"title":{}}],["array[doubl",{"_index":1087,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{}},"title":{}}],["array[int",{"_index":1169,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{}}],["array_max",{"_index":4156,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["array_min",{"_index":4154,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["arrayindexoutofboundsexcept",{"_index":1474,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["arrays_zip",{"_index":4015,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["arrays_zip(\"elements.id",{"_index":4035,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["arrays_zip(\"geom.lat",{"_index":4055,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["arraytyp",{"_index":3952,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["articl",{"_index":1407,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["artifact",{"_index":1898,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/compile/":{},"setup/compile/#download-staged-jars":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}},"title":{}}],["artifactid",{"_index":1369,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["artifactid>apache</artifactid",{"_index":3077,"text":{"community/develop/":{}},"title":{}}],["asc",{"_index":81,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{},"download/":{},"download/#121-incubating":{},"download/#130-incubating":{}},"title":{}}],["ascii",{"_index":596,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["asf",{"_index":76,"text":{"asf/asf/":{},"asf/asf/#copyright":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#committer-done-template":{},"community/contributor/#create-asf-account":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#make-a-sedona-release":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"download/":{},"download/#121-incubating":{},"download/#130-incubating":{}},"title":{"community/contributor/#create-asf-account":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{}}}],["asinstanceof",{"_index":2611,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{}},"title":{}}],["ask",{"_index":1984,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/develop/":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{"archive/tutorial/faq/":{}}}],["assembl",{"_index":1540,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/release-notes/":{},"setup/release-notes/#v112":{},"tutorial/demo/":{},"tutorial/demo/#compile":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["assign",{"_index":2763,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#colorize-pixels_1":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#colorize-pixels_1":{}},"title":{}}],["associ",{"_index":1956,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["assum",{"_index":582,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#load-data-from-files":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["atm",{"_index":2223,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["attach",{"_index":3629,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["attitud",{"_index":2929,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{}},"title":{}}],["attr",{"_index":3590,"text":{"setup/install-python/":{}},"title":{}}],["attribut",{"_index":1027,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{}}}],["atualizar",{"_index":4046,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["authent",{"_index":3056,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{}}],["author",{"_index":3107,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["authority[\"epsg\",\"4326",{"_index":3742,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["authority[\"epsg\",\"6326",{"_index":3737,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["authority[\"epsg\",\"7030",{"_index":3736,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["authority[\"epsg\",\"8901",{"_index":3739,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["authority[\"epsg\",\"9122",{"_index":3741,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["autocorrel",{"_index":1957,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["automat",{"_index":60,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/rule/":{},"community/rule/#pick-annouce-a-task-using-jira":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"download/":{},"download/#github-repository":{},"setup/compile/":{},"setup/compile/#compile-the-documentation":{},"setup/compile/#download-staged-jars":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v120":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{"archive/download/scalashell/#download-geospark-jar-automatically":{},"setup/install-scala/#download-sedona-jar-automatically":{}}}],["avail",{"_index":44,"text":{"":{},"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_transform":{},"api/python-api/":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_transform":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/GeoSpark-Python-API/":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#join-query":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/modules/":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/modules/":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/flink/sql/":{},"tutorial/raster/":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#join-query":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/viz/":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"setup/flink/modules/#api-availability":{},"setup/modules/#api-availability":{}}}],["averag",{"_index":4177,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["avoid",{"_index":1643,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["avshalom",{"_index":1503,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["awar",{"_index":1966,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{}},"title":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{}}}],["awat",{"_index":2385,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["awt",{"_index":1279,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{}},"title":{}}],["axi",{"_index":329,"text":{"api/flink/Function/":{},"api/flink/Function/#st_flipcoordinates":{},"api/sql/Function/":{},"api/sql/Function/#st_flipcoordinates":{},"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{}},"title":{}}],["azimuth",{"_index":280,"text":{"api/flink/Function/":{},"api/flink/Function/#st_azimuth":{},"api/sql/Function/":{},"api/sql/Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{}},"title":{}}],["a|1477895811|10447360|+41.9158651",{"_index":2673,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["a|2169240202|22877180|+40.7835474",{"_index":2687,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["a|6015539696|29159492|+34.3592729",{"_index":2681,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["b",{"_index":236,"text":{"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_distance":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_orderingequals":{},"api/flink/Predicate/#st_within":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_union":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#range-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{}}],["b:color",{"_index":1309,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_render":{}},"title":{}}],["b:geometri",{"_index":238,"text":{"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_distance":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_within":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_union":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{}},"title":{}}],["b:int",{"_index":778,"text":{"api/sql/Function/":{},"api/sql/Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{}},"title":{}}],["b:integ",{"_index":435,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointn":{}},"title":{}}],["babylon",{"_index":1382,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v100":{}},"title":{}}],["babylonimagegener",{"_index":1758,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["baca",{"_index":2653,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["back",{"_index":1738,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/rdd/":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{}}],["background",{"_index":2790,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["backward",{"_index":432,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_setpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_setpoint":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{}},"title":{}}],["baixo",{"_index":4048,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["balanc",{"_index":1616,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["band",{"_index":1035,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalize":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{},"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["band1",{"_index":1094,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_subtract":{}},"title":{}}],["band2",{"_index":1095,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_subtract":{}},"title":{}}],["banddf",{"_index":1091,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{}},"title":{}}],["bands(band2",{"_index":1220,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_normalizeddifference":{}},"title":{}}],["baptist",{"_index":2911,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["bar",{"_index":2042,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd/":{}},"title":{}}],["base",{"_index":355,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_setpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels":{}},"title":{"archive/tutorial/geospark-sql-python/#creating-spark-dataframe-based-on-shapely-objects":{},"tutorial/sql-python/#creating-spark-dataframe-based-on-shapely-objects":{}}}],["base64",{"_index":1083,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_html":{},"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{}},"title":{}}],["base_color",{"_index":4242,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["basegeometri",{"_index":2180,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["basestr",{"_index":1097,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["bashrc",{"_index":3219,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/release-manager/":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["basi",{"_index":4164,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["basic",{"_index":766,"text":{"api/sql/Function/":{},"api/sql/Function/#st_multi":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{}},"title":{}}],["batch",{"_index":2243,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["bdist_wheel",{"_index":3335,"text":{"community/publish/":{},"community/publish/#9-release-sedona-python-and-zeppelin":{}},"title":{}}],["be",{"_index":717,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{},"community/contributor/":{},"community/contributor/#pmc-annoucement":{},"community/release-manager/":{},"community/release-manager/#become-a-release-manager":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{}},"title":{}}],["beak",{"_index":2367,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["beauti",{"_index":2725,"text":{"archive/tutorial/viz/":{},"tutorial/viz/":{}},"title":{}}],["becam",{"_index":408,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["becom",{"_index":1686,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/release-manager/":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{"community/contributor/#become-a-committer":{},"community/release-manager/":{},"community/release-manager/#become-a-release-manager":{}}}],["befor",{"_index":604,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/flink/install-scala/":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#register-package":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["begin",{"_index":2645,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["behavior",{"_index":1490,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#v120":{}},"title":{}}],["behaviour",{"_index":747,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{}},"title":{}}],["behavoir",{"_index":2346,"text":{"archive/tutorial/rdd/":{}},"title":{"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{}}}],["behind",{"_index":2958,"text":{"community/contributor/":{}},"title":{}}],["belief",{"_index":3011,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["belong",{"_index":3490,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["below",{"_index":1070,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories":{},"community/develop/":{},"community/publish/":{},"community/publish/#compile-r-html-docs":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/databricks/":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["bench",{"_index":2253,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["benchmark",{"_index":1973,"text":{"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{}},"title":{"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{}}}],["besid",{"_index":1784,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#range-query-window":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"tutorial/core-python/":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/rdd/":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#range-query-window":{}},"title":{}}],["best",{"_index":1978,"text":{"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{}},"title":{}}],["better",{"_index":1955,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"community/contributor/":{},"community/contributor/#pmc-annoucement":{},"setup/databricks/":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{}},"title":{}}],["between",{"_index":235,"text":{"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_distance":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_symdifference":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/sql/":{},"archive/tutorial/zeppelin/":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v120":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/zeppelin/":{}},"title":{"archive/tutorial/sql/#convert-between-dataframe-and-spatialrdd":{},"tutorial/sql/#convert-between-dataframe-and-spatialrdd":{}}}],["beyond",{"_index":3092,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#key-publications":{}},"title":{}}],["bg",{"_index":2382,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["bi",{"_index":1777,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["big",{"_index":1871,"text":{"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"setup/release-notes/":{},"setup/release-notes/#sedona-viz":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["bigdf",{"_index":309,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{}},"title":{}}],["billion",{"_index":2791,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["bin",{"_index":82,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"download/":{},"download/#121-incubating":{},"download/#130-incubating":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{}},"title":{}}],["bin.tar.gz",{"_index":3199,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["bin.tar.gz.asc",{"_index":3265,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["bin.tar.gz.sha512",{"_index":3260,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["bin/bash",{"_index":3182,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#10-release-sedona-r-to-cran":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#compile-r-html-docs":{},"community/publish/#fix-signature-issues":{},"community/publish/#upload-releases":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["bin/flink",{"_index":3906,"text":{"setup/flink/install-scala/":{}},"title":{}}],["bin/spark",{"_index":1846,"text":{"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/install-scala/#self-contained-spark-projects":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}},"title":{}}],["binari",{"_index":62,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Function/":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Function/":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"download/":{},"download/#121-incubating":{},"download/#130-incubating":{},"download/#github-repository":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/flink/platform/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/platform/":{},"setup/release-notes/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["bind",{"_index":2964,"text":{"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"tutorial/raster/":{}},"title":{}}],["binder",{"_index":3911,"text":{"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{}},"title":{}}],["binford",{"_index":2871,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["bit",{"_index":3381,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["bitwis",{"_index":1147,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{}},"title":{}}],["biwiseanddf",{"_index":1148,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_bitwiseand":{}},"title":{}}],["biwiseordf",{"_index":1152,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_bitwiseor":{}},"title":{}}],["blackband",{"_index":1089,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["blank",{"_index":1630,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"community/contact/":{},"community/contact/#mailing-list":{},"setup/release-notes/":{},"setup/release-notes/#v081-geospark-core":{}},"title":{}}],["blkgrpce",{"_index":2376,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["block",{"_index":3396,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{}},"title":{}}],["blocker",{"_index":3294,"text":{"community/publish/":{},"community/publish/#vote-email_1":{}},"title":{}}],["blue",{"_index":4251,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["board",{"_index":2957,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["bodi",{"_index":2974,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{}},"title":{}}],["bolzano",{"_index":3159,"text":{"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["bool",{"_index":2173,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{}},"title":{}}],["boolean",{"_index":481,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["both",{"_index":889,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["bottom",{"_index":3218,"text":{"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["bound",{"_index":1002,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-the-image":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-the-image":{}},"title":{}}],["boundari",{"_index":109,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Function/":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_envelope":{},"api/flink/Function/#st_issimple":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/Function/":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_issimple":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-the-image":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["boundary:geometri",{"_index":1295,"text":{"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_pixelize":{}},"title":{}}],["boundaryenvelop",{"_index":2059,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{}},"title":{}}],["boundtabl",{"_index":2754,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-the-image":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["bozen",{"_index":3160,"text":{"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["branch",{"_index":67,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#make-a-sedona-release":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/snapshot/#publish-a-snapshot-version":{},"download/":{},"download/#github-repository":{}},"title":{}}],["break",{"_index":3192,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["brew",{"_index":3351,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#install-necessary-software":{}},"title":{}}],["bridg",{"_index":2776,"text":{"archive/tutorial/zeppelin/":{},"tutorial/zeppelin/":{}},"title":{}}],["brief",{"_index":3428,"text":{"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{}},"title":{}}],["bring",{"_index":1918,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"community/publish/":{},"community/publish/#pass-email":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["broadcast",{"_index":879,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#sql_3":{}},"title":{"api/sql/Optimizer/#broadcast-join":{}}}],["broadcastindexjoin",{"_index":897,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["brought",{"_index":2717,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["brows",{"_index":4243,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["browser",{"_index":3217,"text":{"community/publish/":{},"community/publish/#3-update-mkdocsyml":{}},"title":{}}],["bsd",{"_index":1900,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}},"title":{}}],["buffer",{"_index":300,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buffer":{},"api/sql/Function/":{},"api/sql/Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{}},"title":{}}],["bufferedimag",{"_index":1283,"text":{"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_render":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_render":{}},"title":{}}],["bug",{"_index":1403,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v130":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contact/#community":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"setup/release-notes/":{},"setup/release-notes/#core":{},"setup/release-notes/#core_1":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#python":{},"setup/release-notes/#python_1":{},"setup/release-notes/#rdd":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-111":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#sedona-131":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_1":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v130":{},"setup/release-notes/#v131":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{"community/contact/#bug-reports":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#bug-fixes_1":{}}}],["build",{"_index":981,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"community/develop/":{},"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#key-publications":{},"community/publish/":{},"community/publish/#10-release-sedona-r-to-cran":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v131":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["build.sbt",{"_index":946,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#package-the-project":{},"archive/download/project/#self-contained-spark-projects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#set-up-dependencies":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#buildsbt":{},"setup/maven-coordinates/#buildsbt":{}}}],["build_on_spatial_partitioned_rdd",{"_index":2084,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{}},"title":{}}],["builder",{"_index":949,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["buildindex",{"_index":2085,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{}},"title":{}}],["buildleft",{"_index":913,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["buildonspatialpartitionedrdd",{"_index":2625,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{}},"title":{}}],["buildright",{"_index":899,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["built",{"_index":999,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{},"setup/compile/":{},"setup/compile/#compile-the-documentation":{},"setup/compile/#mkdocs-website":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_2":{}},"title":{}}],["bursa",{"_index":472,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#v110":{}},"title":{}}],["busi",{"_index":2363,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["button",{"_index":3083,"text":{"community/develop/":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["byte",{"_index":2137,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["c",{"_index":1536,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"setup/release-notes/":{},"setup/release-notes/#v112":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["c.county_cod",{"_index":2230,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["c.geometri",{"_index":2234,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["c1",{"_index":658,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{}},"title":{}}],["c2",{"_index":659,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{}},"title":{}}],["c:integ",{"_index":1310,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{}},"title":{}}],["cach",{"_index":1720,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}}}],["calcul",{"_index":533,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{}},"title":{}}],["call",{"_index":96,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/java-api/":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/java-api/":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/download/zeppelin/#create-helium-folder-optional":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"community/contributor/":{},"community/contributor/#nominate-a-committer-or-pmc-member":{},"community/publication/":{},"community/publication/#publication":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"setup/zeppelin/#create-helium-folder-optional":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/flink/sql/":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{}},"title":{"community/contributor/#call-for-a-vote":{}}}],["camp_sit",{"_index":2263,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["camp_site|point",{"_index":2214,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["can't",{"_index":714,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{}},"title":{}}],["candid",{"_index":2955,"text":{"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#7-failed-vote":{}},"title":{"community/publish/#4-stage-and-upload-release-candidates":{}}}],["can\u2019t",{"_index":3452,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["capabl",{"_index":3622,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{}},"title":{}}],["capit",{"_index":3416,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["care",{"_index":1922,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["carri",{"_index":1318,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v120":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{}},"title":{}}],["carry_other_attribut",{"_index":2039,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{}},"title":{}}],["carryinputdata",{"_index":1936,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{}},"title":{}}],["carryotherattribut",{"_index":2064,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["cartesian",{"_index":233,"text":{"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{}},"title":{}}],["cartograph",{"_index":4260,"text":{"tutorial/viz/":{}},"title":{}}],["case",{"_index":1068,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/sql/":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/viz/sql/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#generate-a-single-image":{},"community/contact/":{},"community/contact/#community":{},"community/develop/":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#generate-a-single-image":{}},"title":{}}],["cast",{"_index":628,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["cast(_c1#1",{"_index":850,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{}},"title":{}}],["cast(_c1#22",{"_index":871,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{}},"title":{}}],["cast(_c1#23",{"_index":908,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["cast(_c1#32",{"_index":856,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{}},"title":{}}],["cast(_c1#49",{"_index":902,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["cast(_c2#2",{"_index":851,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{}},"title":{}}],["cast(_c2#24",{"_index":909,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["cast(_c3#25",{"_index":910,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["cast(_c3#3",{"_index":852,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{}},"title":{}}],["cat",{"_index":3473,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["catalog",{"_index":1553,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["categori",{"_index":4212,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["cc",{"_index":2972,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["cced",{"_index":3295,"text":{"community/publish/":{},"community/publish/#announce-email":{}},"title":{}}],["cd",{"_index":3248,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#compile-r-html-docs":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["cdm",{"_index":3669,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["cell",{"_index":3563,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/databricks/#pure-sql-environment":{}},"title":{}}],["center",{"_index":762,"text":{"api/sql/Function/":{},"api/sql/Function/#st_minimumboundingradius":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"tutorial/core-python/":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/rdd/":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/rdd/#query-center-geometry":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/rdd/#query-center-geometry":{}}}],["central",{"_index":1364,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v111":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#set-up-dependencies":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#global_2":{},"setup/release-notes/#v110":{},"setup/release-notes/#v111":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#set-up-dependencies":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{},"tutorial/viz/#set-up-dependencies":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"setup/maven-coordinates/":{}}}],["centroid",{"_index":639,"text":{"api/sql/Function/":{},"api/sql/Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_3":{}},"title":{}}],["certain",{"_index":840,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{}},"title":{}}],["certifi",{"_index":3488,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["chair",{"_index":3043,"text":{"community/contributor/":{},"community/contributor/#create-asf-account":{}},"title":{}}],["chalet",{"_index":2217,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["chanc",{"_index":2858,"text":{"community/contact/":{},"community/contact/#feature-requests":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{}},"title":{}}],["chang",{"_index":878,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"community/develop/":{},"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"community/rule/#review-a-pull-request":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#global_3":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sedona-viz":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v120":{},"setup/release-notes/#viz_1":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{}}}],["channel",{"_index":4247,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["charact",{"_index":597,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/tutorial/rdd/":{},"setup/release-notes/":{},"setup/release-notes/#v110":{},"tutorial/rdd/":{}},"title":{}}],["charg",{"_index":2869,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["charset",{"_index":3363,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["check",{"_index":21,"text":{"":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/publish/":{},"community/publish/#10-release-sedona-r-to-cran":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#vote-email":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"community/vote/":{},"community/vote/#check-files-manually":{},"community/vote/#install-necessary-software":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/vote/#check-files-manually":{}}}],["checkin",{"_index":2362,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["checkin.csv",{"_index":2037,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd/":{}},"title":{}}],["checkin.tsv",{"_index":2351,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["checkinshape.csv",{"_index":2335,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["checklist",{"_index":3273,"text":{"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["checkout",{"_index":3220,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["checksum",{"_index":77,"text":{"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"download/":{},"download/#121-incubating":{},"download/#130-incubating":{}},"title":{}}],["cherri",{"_index":3550,"text":{"setup/databricks/":{}},"title":{}}],["cheung",{"_index":2905,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["chines",{"_index":1565,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#v110":{}},"title":{}}],["chmod",{"_index":3184,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["choic",{"_index":2627,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{}},"title":{}}],["choos",{"_index":1656,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"community/contact/":{},"community/contact/#community":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/develop/":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{}},"title":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}}}],["choropleth",{"_index":4256,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["chowdhuri",{"_index":2875,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["circl",{"_index":757,"text":{"api/sql/Function/":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{}},"title":{}}],["circle_rdd",{"_index":2124,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{}},"title":{}}],["circlerdd",{"_index":1994,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{}},"title":{}}],["circular",{"_index":428,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointn":{},"api/sql/Function/":{},"api/sql/Function/#st_pointn":{}},"title":{}}],["circularstring(1",{"_index":436,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointn":{}},"title":{}}],["cite",{"_index":3097,"text":{"community/publication/":{},"community/publication/#key-publications":{}},"title":{}}],["citi",{"_index":2634,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{}}],["ck",{"_index":2629,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["cla",{"_index":3020,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["claim",{"_index":3453,"text":{"community/rule/":{},"community/rule/#code-of-conduct":{}},"title":{}}],["class",{"_index":1582,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global_3":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v100":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{}}}],["class='fa",{"_index":1902,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}},"title":{}}],["classic",{"_index":2731,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{"community/release-manager/#5-get-github-personal-access-token-classic":{}}}],["classof",{"_index":1343,"text":{"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["classpath",{"_index":1436,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["claus",{"_index":920,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}},"title":{}}],["clean",{"_index":1823,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"community/develop/":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{}},"title":{}}],["cleanup",{"_index":3779,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["click",{"_index":3080,"text":{"community/develop/":{},"community/publish/":{},"community/publish/#manually-close-and-release-the-package":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/compile/":{},"setup/compile/#download-staged-jars":{},"setup/install-python/":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{}},"title":{}}],["client",{"_index":1285,"text":{"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["clipboard.j",{"_index":3191,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{}},"title":{}}],["clone",{"_index":1817,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-manually":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["close",{"_index":226,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_makepolygon":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/contributor/#nominate-a-committer-or-pmc-member":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#manually-close-and-release-the-package":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{}},"title":{"community/contributor/#close-a-vote":{},"community/publish/#manually-close-and-release-the-package":{}}}],["closest",{"_index":2102,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["closur",{"_index":290,"text":{"api/flink/Function/":{},"api/flink/Function/#st_boundary":{},"api/sql/Function/":{},"api/sql/Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{}},"title":{}}],["cluser",{"_index":1772,"text":{},"title":{"archive/download/cluster/":{},"setup/cluster/":{}}}],["cluster",{"_index":1621,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/cluster/#start-your-cluster":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publish/":{},"community/publish/#announce-email":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/cluster/#start-your-cluster":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/databricks/#pure-sql-environment":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/release-notes/":{},"setup/release-notes/#v082-geospark-core":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{"archive/download/cluster/#set-up-your-apache-spark-cluster":{},"archive/download/cluster/#start-your-cluster":{},"setup/cluster/#set-up-your-apache-spark-cluster":{},"setup/cluster/#start-your-cluster":{}}}],["cluster'",{"_index":3573,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["cmap",{"_index":2277,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["cmd",{"_index":3339,"text":{"community/publish/":{},"community/publish/#10-release-sedona-r-to-cran":{}},"title":{}}],["co",{"_index":417,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["coalesc",{"_index":1067,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["code",{"_index":57,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contact/":{},"community/contact/#community":{},"community/contributor/":{},"community/contributor/#committers":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"community/rule/#contributing-to-apache-sedona":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#develop-a-document-contribution":{},"community/vote/":{},"community/vote/#check-files-manually":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"download/":{},"download/#121-incubating":{},"download/#130-incubating":{},"download/#github-repository":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#mkdocs-website":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#global":{},"setup/release-notes/#global_3":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#register-package":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"community/publish/#8-release-source-code-and-maven-package":{},"community/rule/#code-of-conduct":{},"community/rule/#develop-a-code-contribution":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-sedona-source-code":{}}}],["cogroup",{"_index":1650,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["col",{"_index":1433,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["col1",{"_index":3918,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["collabor",{"_index":3106,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["collaps",{"_index":739,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{}},"title":{}}],["collect",{"_index":653,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#rdd":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["collect_list(concat(p1.lat,',',p1.lon",{"_index":4063,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["coln",{"_index":3919,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["coloc",{"_index":3935,"text":{"tutorial/demo/":{},"tutorial/demo/#folder-structure":{}},"title":{}}],["color",{"_index":1250,"text":{"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"api/viz/sql/#st_render":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/api/viz/sql/#st_render":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#colorize-pixels_1":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#render-the-image":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#colorize-pixels_1":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#render-the-image":{}},"title":{"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#colorize-pixels_1":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#colorize-pixels_1":{}}}],["color_of_vari",{"_index":4254,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["column",{"_index":532,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#run-spatial-queries":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql-for-spark":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#output-format":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#get-spatial-table":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#run-spatial-queries":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#range-query":{},"tutorial/sql/#run-spatial-queries":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-the-image":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/tutorial/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/sql/#create-a-geometry-type-column":{}}}],["column/",{"_index":642,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collect":{}},"title":{}}],["com.fasterxml.jackson.cor",{"_index":3685,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{}},"title":{}}],["combin",{"_index":886,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#other-queries":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/sql/":{},"tutorial/sql/#other-queries":{}},"title":{}}],["combinatori",{"_index":291,"text":{"api/flink/Function/":{},"api/flink/Function/#st_boundary":{},"api/sql/Function/":{},"api/sql/Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{}},"title":{}}],["come",{"_index":1986,"text":{"archive/tutorial/faq/":{},"community/develop/":{},"community/develop/#python-developers":{},"community/develop/#r-developers":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{}},"title":{}}],["comma",{"_index":4096,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["command",{"_index":1821,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#colorize-pixels_1":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{},"setup/compile/#mkdocs-website":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#setup-environment-variables":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#self-contained-spark-projects":{},"tutorial/demo/":{},"tutorial/demo/#compile":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#colorize-pixels_1":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#store-map-tiles-on-disk":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["commenc",{"_index":2954,"text":{"community/contributor/":{}},"title":{}}],["comment",{"_index":3073,"text":{"community/develop/":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["commerci",{"_index":3549,"text":{"setup/databricks/":{}},"title":{}}],["commit",{"_index":68,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"download/":{},"download/#github-repository":{},"setup/compile/":{},"setup/compile/#compile-the-documentation":{},"setup/compile/#download-staged-jars":{}},"title":{}}],["commit'",{"_index":3514,"text":{"setup/compile/":{},"setup/compile/#download-staged-jars":{}},"title":{}}],["committ",{"_index":2863,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#committer-done-template":{},"community/contributor/#committers":{},"community/contributor/#nominate-a-committer-or-pmc-member":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#project-management-committee-pmc":{},"community/contributor/#send-the-invitation":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{"community/contributor/#become-a-committer":{},"community/contributor/#committer-done-template":{},"community/contributor/#committers":{},"community/contributor/#nominate-a-committer-or-pmc-member":{}}}],["committe",{"_index":2861,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-the-invitation":{}},"title":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}}}],["committership",{"_index":3009,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["common",{"_index":2604,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["commonli",{"_index":4217,"text":{"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["commun",{"_index":2814,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contact/":{},"community/contact/#community":{},"community/contact/#discord-server":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#project-management-committee-pmc":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#vote-email_1":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"community/rule/#review-a-pull-request":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/databricks/":{}},"title":{"community/contact/":{},"community/contact/#community":{},"setup/databricks/#community-edition-free-tier":{}}}],["compat",{"_index":1892,"text":{"archive/download/zeppelin/":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#rdd":{},"setup/zeppelin/":{}},"title":{"archive/download/zeppelin/#compatibility":{},"setup/zeppelin/#compatibility":{}}}],["compil",{"_index":1690,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"community/develop/":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#mkdocs-website":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/flink/install-scala/":{},"setup/flink/platform/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#highlights":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#v01-v07":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}},"title":{"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/#submit-the-compiled-jar":{},"community/publish/#compile-r-html-docs":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-sedona-source-code":{},"setup/compile/#compile-the-documentation":{},"setup/compile/#compile-with-different-targets":{},"tutorial/demo/#compile":{},"tutorial/demo/#compile-and-package":{}}}],["complain",{"_index":1967,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{}},"title":{}}],["complet",{"_index":1646,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["complex",{"_index":1648,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"archive/download/project/#self-contained-spark-projects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"community/develop/":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/overview/":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{}},"title":{"setup/overview/#complex-spatial-objects":{}}}],["compon",{"_index":672,"text":{"api/sql/Function/":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["compos",{"_index":2620,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{}},"title":{}}],["compress",{"_index":1596,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["comput",{"_index":2736,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publish/":{},"community/publish/#announce-email":{},"tutorial/viz/":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["concaten",{"_index":4332,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["concept",{"_index":1601,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["concret",{"_index":2856,"text":{"community/contact/":{},"community/contact/#feature-requests":{}},"title":{}}],["condit",{"_index":4124,"text":{"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["conduct",{"_index":3040,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/rule/":{},"community/rule/#code-of-conduct":{}},"title":{"community/rule/#code-of-conduct":{}}}],["conf",{"_index":970,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#python":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#register-package":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{}}],["conf/slav",{"_index":1783,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["conf/spark",{"_index":1786,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["confer",{"_index":3141,"text":{"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["config",{"_index":950,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["config(\"spark.driver.maxresults",{"_index":3970,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["config(\"spark.executor.memori",{"_index":3968,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["config(\"spark.jars.packag",{"_index":3984,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["config(\"spark.kryo.registr",{"_index":3982,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["config(\"spark.seri",{"_index":3981,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["config(\"spark.sql.execution.arrow.fallback.en",{"_index":3978,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["config(\"spark.sql.execution.arrow.pyspark.en",{"_index":3977,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["config(\"spark.sql.shuffle.partit",{"_index":3972,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["config('spark.kryoserializer.buffer.max",{"_index":3979,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["config('spark.sql.adaptive.coalescepartitions.initialpartitionnum",{"_index":3976,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["config('spark.sql.adaptive.en",{"_index":3975,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["configur",{"_index":967,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v111":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/develop/":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#python":{},"setup/release-notes/#v111":{},"tutorial/demo/":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/python-vector-osm/":{}},"title":{"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}}}],["confirm",{"_index":3430,"text":{"community/rule/":{},"community/rule/#pick-annouce-a-task-using-jira":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["conflict",{"_index":1483,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#v110":{},"setup/release-notes/#v120":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}},"title":{}}],["conform",{"_index":3789,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["conjunct",{"_index":3605,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["conneciton",{"_index":3631,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["connect",{"_index":1499,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"tutorial/python-vector-osm/":{}},"title":{"setup/install-r/#connect-to-spark":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}}}],["consensu",{"_index":2951,"text":{"community/contributor/":{},"community/contributor/#call-for-a-vote":{}},"title":{}}],["consid",{"_index":860,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/viz/sql/":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/viz/sql/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{}},"title":{}}],["consider_boundary_intersect",{"_index":2076,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["considerar",{"_index":4049,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["considerboundaryintersect",{"_index":1709,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["consist",{"_index":676,"text":{"api/sql/Function/":{},"api/sql/Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#sedona-130":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["consolid",{"_index":3811,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["constant",{"_index":4159,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["constitu",{"_index":305,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{}},"title":{}}],["constrcutor",{"_index":1736,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["construct",{"_index":138,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Constructor/#st_geomfromgml":{},"api/flink/Constructor/#st_geomfromkml":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/flink/Constructor/#st_point":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromgml":{},"api/sql/Constructor/#st_geomfromkml":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#send-the-invitation":{},"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["constructor",{"_index":124,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#range-query":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v112":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#range-query":{}},"title":{"api/flink/Constructor/":{},"api/sql/Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}}}],["consult",{"_index":3946,"text":{"tutorial/python-vector-osm/":{}},"title":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}}}],["consumpt",{"_index":2031,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{}},"title":{}}],["contact",{"_index":3507,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["contain",{"_index":538,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Function/":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#self-contained-spark-projects":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#render-the-image":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/demo/":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/viz/":{},"tutorial/viz/#render-the-image":{}},"title":{"archive/download/project/":{},"archive/download/project/#self-contained-spark-projects":{},"setup/install-scala/#self-contained-spark-projects":{}}}],["containsnul",{"_index":1012,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["content",{"_index":1897,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"community/contact/":{},"community/contact/#mailing-list":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#11-publish-the-doc-website":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}},"title":{}}],["content/org/apache/sedona/sedona",{"_index":3326,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["context",{"_index":1635,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["contin",{"_index":4191,"text":{"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{}},"title":{}}],["continu",{"_index":2997,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{}},"title":{}}],["contribut",{"_index":2832,"text":{"community/contact/":{},"community/contact/#community":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#committers":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#develop-a-document-contribution":{},"community/rule/#make-a-pull-request":{},"community/rule/#pick-annouce-a-task-using-jira":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{"community/rule/#contributing-to-apache-sedona":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#develop-a-document-contribution":{}}}],["contributor",{"_index":1438,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#committers":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{}},"title":{}}],["control",{"_index":873,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v082-geospark-core":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["conver",{"_index":2755,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["convers",{"_index":3687,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/release-notes/":{},"setup/release-notes/#flink_1":{}},"title":{}}],["convert",{"_index":730,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_makevalid":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/tutorial/sql/#convert-between-dataframe-and-spatialrdd":{},"tutorial/flink/sql/#convert-spatial-datastream-to-spatial-table":{},"tutorial/flink/sql/#convert-spatial-table-to-spatial-datastream":{},"tutorial/sql/#convert-between-dataframe-and-spatialrdd":{}}}],["convex",{"_index":662,"text":{"api/sql/Function/":{},"api/sql/Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{}},"title":{}}],["coordiant",{"_index":2758,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["coordin",{"_index":335,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_transform":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_z":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#set-up-dependencies":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v101":{},"setup/release-notes/#v110":{},"setup/release-notes/#v120":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#set-up-dependencies":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#set-up-dependencies":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}}}],["coordinates_tb",{"_index":4062,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["coordinates_tb.createorreplacetempview(\"coordinates_tb",{"_index":4074,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["coordinates_tb.show(5",{"_index":4075,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["copi",{"_index":2007,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#11-publish-the-doc-website":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-python/#setup-environment-variables":{}},"title":{}}],["copy/past",{"_index":3190,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{}},"title":{}}],["copyright",{"_index":2800,"text":{"asf/asf/":{},"community/publish/":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{}},"title":{"asf/asf/#copyright":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{}}}],["core",{"_index":944,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#compatibility":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#set-up-dependencies":{},"community/publication/":{},"community/publication/#key-publications":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#v100":{},"setup/release-notes/#v101":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"setup/zeppelin/":{},"setup/zeppelin/#compatibility":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{},"tutorial/viz/#set-up-dependencies":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/release-notes/#core":{},"setup/release-notes/#core_1":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{}}}],["core/rdd",{"_index":3692,"text":{"setup/modules/":{},"setup/modules/#api-availability":{}},"title":{}}],["core:1.18.0",{"_index":3639,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["corner",{"_index":3720,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{}},"title":{}}],["corpor",{"_index":3021,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["correct",{"_index":884,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#make-a-pull-request":{},"community/rule/#review-a-pull-request":{},"community/vote/":{},"community/vote/#check-files-manually":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#highlights":{}},"title":{}}],["correctli",{"_index":4099,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["correspond",{"_index":1069,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/tutorial/rdd/":{},"community/publish/":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["costli",{"_index":3923,"text":{"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{}},"title":{}}],["count",{"_index":431,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_setpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_setpoint":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_count":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"community/publish/":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{}},"title":{}}],["countdf",{"_index":1155,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_count":{}},"title":{}}],["counti",{"_index":2051,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/core-python/":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#range-query":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["counties.csv",{"_index":2195,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["counties_geom",{"_index":2196,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["county.tsv",{"_index":2649,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["county_cod",{"_index":2197,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["county_code#230",{"_index":2235,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["county_code#230,geom#232",{"_index":2242,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["county_code|fclass",{"_index":2251,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["county_nam",{"_index":2055,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{}},"title":{}}],["countyfp",{"_index":2372,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["countynam",{"_index":2703,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{}},"title":{}}],["countyshap",{"_index":239,"text":{"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_area":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_distance":{},"api/flink/Function/#st_envelope":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_issimple":{},"api/flink/Function/#st_isvalid":{},"api/flink/Function/#st_length":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_transform":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_area":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_convexhull":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_length":{},"api/sql/Function/#st_npoints":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{}},"title":{}}],["countyshape|_c1|_c2",{"_index":2690,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{}},"title":{}}],["cover",{"_index":550,"text":{"api/flink/Predicate/":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["covered/intersect",{"_index":2109,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{}}],["covered_bi",{"_index":4120,"text":{"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["covers/covered_bi",{"_index":3791,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["cp",{"_index":3245,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["cr",{"_index":1024,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#new-features":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v081-geospark-core":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["cran",{"_index":45,"text":{"":{},"community/publish/":{},"community/publish/#10-release-sedona-r-to-cran":{},"setup/overview/":{},"setup/overview/#download-statistics":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"community/publish/#10-release-sedona-r-to-cran":{}}}],["cran.r",{"_index":3600,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["crash",{"_index":2740,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["creat",{"_index":126,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Function/":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Function/":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_makevalid":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-loader/#rs_base64":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/project/":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/download/zeppelin/#create-helium-folder-optional":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#run-spatial-queries":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#generate-map-tiles":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/contributor/":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#7-failed-vote":{},"community/publish/#compile-r-html-docs":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"community/rule/#pick-annouce-a-task-using-jira":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/install-scala/":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"setup/zeppelin/#create-helium-folder-optional":{},"tutorial/core-python/":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/flink/sql/#run-spatial-queries":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#range-query":{},"tutorial/sql/#run-spatial-queries":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#generate-map-tiles":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#render-the-image":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/download/zeppelin/#create-helium-folder-optional":{},"archive/tutorial/geospark-core-python/#create-a-spatialrdd":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-sql-python/#creating-spark-dataframe-based-on-shapely-objects":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#create-a-spatialrdd":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#create-tile-name":{},"community/contributor/#create-asf-account":{},"setup/zeppelin/#create-helium-folder-optional":{},"tutorial/core-python/#create-a-spatialrdd":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#create-a-spatialrdd":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/sql-python/#creating-spark-dataframe-based-on-shapely-objects":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#create-tile-name":{}}}],["createdatafram",{"_index":2212,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["createlinestr",{"_index":2624,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{}},"title":{}}],["createorreplacetempview",{"_index":568,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/core-python/":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#range-query":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["createpoint",{"_index":2619,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["createpolygon",{"_index":2622,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{}},"title":{}}],["createtemporaryview",{"_index":4299,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{}},"title":{}}],["credenti",{"_index":3413,"text":{"community/release-manager/":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{}},"title":{"community/release-manager/#6-set-up-credentials-for-maven":{}}}],["critic",{"_index":1519,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/release-notes/":{},"setup/release-notes/#sedona-131":{},"setup/release-notes/#v113":{}},"title":{}}],["cross",{"_index":989,"text":{"api/sql/Predicate/":{},"api/sql/Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["crstransform",{"_index":1563,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v110":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["crstransform(sourcecrscod",{"_index":4116,"text":{"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["csv",{"_index":613,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v120":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["csv/tsv",{"_index":2323,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["csv_point_input_loc",{"_index":2049,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{}},"title":{}}],["csvpointinputloc",{"_index":2597,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["cume",{"_index":2651,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["cumul",{"_index":1523,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"setup/release-notes/":{},"setup/release-notes/#v113":{}},"title":{}}],["curl",{"_index":3328,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{},"community/publish/#fix-signature-issues":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["current",{"_index":402,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#supported-versions":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-versions":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#project-management-committee-pmc":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["curv",{"_index":1842,"text":{"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"setup/install-scala/":{}},"title":{}}],["custom",{"_index":1567,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/release-notes/":{},"setup/release-notes/#new-features":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["czf",{"_index":3246,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{}},"title":{}}],["d",{"_index":3204,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{}},"title":{}}],["d299",{"_index":3503,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["d3bdfd4d870838ebe63f21cb93634d2421ec1ac1b8184636206a5dc0d89a78a88257798b1f17371ad3cfcc3b1eb79c69e1410afdefeb4d9b52fc8bb5ea18dd2",{"_index":3505,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["d627",{"_index":3495,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["danger",{"_index":2781,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["daqui",{"_index":4047,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["dargument",{"_index":3230,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["data",{"_index":47,"text":{"":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{},"community/publication/#publication":{},"community/publish/":{},"community/publish/#announce-email":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#core_1":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-viz":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v120":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format_3":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/flink/sql/":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{},"tutorial/raster/":{},"tutorial/raster/#api-docs":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"archive/tutorial/sql/#load-data-from-files":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/raster/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/sql/#load-data-from-files":{}}}],["data:im",{"_index":1126,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_html":{}},"title":{}}],["databas",{"_index":1608,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#third-party-evaluation":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["databrick",{"_index":3532,"text":{"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#community-edition-free-tier":{},"setup/release-notes/":{},"setup/release-notes/#python":{}},"title":{"setup/databricks/":{}}}],["databricks/jar",{"_index":3585,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["dataedit",{"_index":1145,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{}},"title":{}}],["datafram",{"_index":10,"text":{"":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#new-features":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v120":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/raster/":{},"tutorial/raster/#api-docs":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#render-the-image":{},"tutorial/viz/#store-the-image-on-disk":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/tutorial/geospark-sql-python/#creating-spark-dataframe-based-on-shapely-objects":{},"archive/tutorial/sql/#convert-between-dataframe-and-spatialrdd":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"tutorial/sql-python/#creating-spark-dataframe-based-on-shapely-objects":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/#convert-between-dataframe-and-spatialrdd":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/#create-spatial-dataframe":{}}}],["dataframe.join",{"_index":4148,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["dataframe.select",{"_index":4147,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["dataframe/rdd",{"_index":1241,"text":{"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{}},"title":{}}],["dataframe/sql",{"_index":1239,"text":{"setup/modules/":{},"setup/modules/#api-availability":{},"setup/overview/":{},"setup/overview/#distributed-spatial-datasets":{}},"title":{"api/viz/sql/":{},"archive/api/viz/sql/":{}}}],["dataset",{"_index":1668,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#generate-a-single-image":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/overview/":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/viz/":{},"tutorial/viz/#generate-a-single-image":{}},"title":{"setup/overview/#distributed-spatial-datasets":{}}}],["datasetboundari",{"_index":1941,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["datastream",{"_index":3696,"text":{"setup/flink/modules/":{},"setup/flink/modules/#api-availability":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/overview/":{},"setup/overview/#distributed-spatial-datasets":{},"setup/release-notes/":{},"setup/release-notes/#flink_1":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#get-datastream":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{"tutorial/flink/sql/#convert-spatial-datastream-to-spatial-table":{},"tutorial/flink/sql/#convert-spatial-table-to-spatial-datastream":{},"tutorial/flink/sql/#get-datastream":{}}}],["data|band",{"_index":1038,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["date",{"_index":3509,"text":{"community/vote/":{},"community/vote/#check-files-manually":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["datetim",{"_index":3962,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["datum",{"_index":3886,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["datum[\"wgs_1984",{"_index":3733,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["dautoversionsubmodul",{"_index":3228,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["day",{"_index":3003,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["dbf",{"_index":580,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/tutorial/rdd/":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"tutorial/rdd/":{}},"title":{}}],["dbfs/filestore/jars/sedona/1.3.0",{"_index":3565,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["dbfs/filestore/sedona",{"_index":3574,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["dbfs/filestore/sedona/sedona",{"_index":3575,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["dbfs:/filestore/sedona/sedona",{"_index":3586,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["dbl",{"_index":4180,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["dbplyr",{"_index":4174,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["dbr",{"_index":3537,"text":{"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#install-sedona-from-the-web-ui":{}},"title":{"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}}}],["dconnectionurl",{"_index":3236,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{}},"title":{}}],["ddevelopmentvers",{"_index":3227,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["ddryrun",{"_index":3458,"text":{"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["de",{"_index":2264,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["debat",{"_index":3443,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["decim",{"_index":629,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{},"api/sql/Function/":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_array":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["decimal(24,20",{"_index":849,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["decimal(24,20)),cast(inputtable._c1",{"_index":2600,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["decis",{"_index":2815,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["declar",{"_index":947,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{}}],["decreas",{"_index":1653,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["dedupparam",{"_index":3850,"text":{"setup/release-notes/":{},"setup/release-notes/#global_1":{}},"title":{}}],["default",{"_index":467,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_transform":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/databricks/":{},"setup/databricks/#community-edition-free-tier":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{}},"title":{}}],["defaults.conf",{"_index":1787,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["defin",{"_index":1019,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{}}],["degre",{"_index":876,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{}},"title":{}}],["delet",{"_index":1600,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["delimit",{"_index":173,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/core-python/":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["delimiter:char",{"_index":175,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{}},"title":{}}],["demo",{"_index":1865,"text":{"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/zeppelin/":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparkviz-visualization-system":{},"tutorial/zeppelin/":{}},"title":{"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}}}],["demonstr",{"_index":2795,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{}}],["dep",{"_index":3873,"text":{"setup/release-notes/":{},"setup/release-notes/#known-issue":{}},"title":{}}],["depend",{"_index":1366,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#select-an-ide":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/zeppelin/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#global_2":{},"setup/release-notes/#global_3":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#python":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v131":{},"setup/zeppelin/":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#set-up-dependencies":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/raster/":{},"tutorial/raster/#initial-setup":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{"archive/download/zeppelin/#add-geospark-dependencies-in-zeppelin-spark-interpreter":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/#set-up-dependencies":{},"setup/zeppelin/#add-sedona-dependencies-in-zeppelin-spark-interpreter":{},"tutorial/flink/sql/#set-up-dependencies":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/#set-up-dependencies":{}}}],["deploy",{"_index":3348,"text":{"community/publish/":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["deprec",{"_index":1716,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["depth",{"_index":3400,"text":{"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{}},"title":{}}],["desc",{"_index":2632,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{}},"title":{}}],["describ",{"_index":1136,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{}},"title":{}}],["descript",{"_index":1895,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels":{}},"title":{"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}}}],["deseri",{"_index":2179,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"setup/databricks/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["design",{"_index":2724,"text":{"archive/tutorial/viz/":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"tutorial/viz/":{}},"title":{}}],["desir",{"_index":1681,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["destination_path",{"_index":1060,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["detail",{"_index":489,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#join-query":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contributor/":{},"community/contributor/#pmc-annoucement":{},"community/develop/":{},"community/develop/#python-developers":{},"community/develop/#r-developers":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#develop-a-document-contribution":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#join-query":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["determin",{"_index":2762,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{}},"title":{}}],["dev",{"_index":2844,"text":{"community/contact/":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/publish/":{},"community/publish/#compile-r-html-docs":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{"community/publish/#5-vote-in-dev-sedonaapacheorg":{}}}],["dev/key",{"_index":3402,"text":{"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{}},"title":{}}],["dev@sedona.apache.org",{"_index":2837,"text":{"community/contact/":{},"community/contact/#feature-requests":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/publish/":{},"community/publish/#announce-email":{},"community/rule/":{},"community/rule/#pick-annouce-a-task-using-jira":{}},"title":{}}],["develop",{"_index":1551,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/develop/":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{"community/develop/":{},"community/develop/#develop-sedona":{},"community/develop/#python-developers":{},"community/develop/#r-developers":{},"community/develop/#scalajava-developers":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#develop-a-document-contribution":{}}}],["df",{"_index":327,"text":{"api/flink/Function/":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/sql/Function/":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_numgeometries":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_html":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"tutorial/core-python/":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#save-geoparquet":{}},"title":{}}],["df.createorreplacetempview(\"df",{"_index":4016,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["df.select(st_point(min_valu",{"_index":3726,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["df.write.format(\"geoparquet\").save(\"path/to/myfile.parquet",{"_index":3724,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["dfappend",{"_index":1143,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{}},"title":{}}],["dftowrit",{"_index":1058,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["dgeotool",{"_index":3512,"text":{"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{},"setup/compile/#run-python-test":{}},"title":{}}],["dict",{"_index":3689,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{}},"title":{}}],["didn't",{"_index":3942,"text":{"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["differ",{"_index":620,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Function/":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_symdifference":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/viz/sql/":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/viz/sql/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#generate-map-tiles":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/compile/":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v112":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#generate-map-tiles":{}},"title":{"setup/compile/#compile-with-different-targets":{}}}],["differenceofofband",{"_index":1237,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_subtract":{}},"title":{}}],["dimens",{"_index":399,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"tutorial/viz/":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{}},"title":{}}],["dimension",{"_index":231,"text":{"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_force_2d":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["dimenst",{"_index":1170,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{}}],["direct",{"_index":1778,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/overview/":{},"community/contributor/":{},"community/contributor/#pmc-annoucement":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{"archive/download/overview/#direct-download":{}}}],["directli",{"_index":929,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/viz/sql/":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/viz/sql/":{},"archive/tutorial/sql/":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{},"tutorial/flink/sql/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["director",{"_index":2993,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["directori",{"_index":1001,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"community/develop/":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#compile-r-html-docs":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["disabl",{"_index":477,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{}},"title":{}}],["disableerror",{"_index":484,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{}},"title":{}}],["disableerrorincr",{"_index":1021,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["disapprov",{"_index":3281,"text":{"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["disclaim",{"_index":2805,"text":{"asf/disclaimer/":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#check-files-manually":{},"community/vote/#vote-a-sedona-release":{}},"title":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{}}}],["discord",{"_index":2835,"text":{"community/contact/":{}},"title":{"community/contact/#discord-server":{}}}],["discuss",{"_index":2944,"text":{"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["disjoint",{"_index":541,"text":{"api/flink/Predicate/":{},"api/flink/Predicate/#st_disjoint":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_disjoint":{}},"title":{}}],["disk",{"_index":1539,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v112":{},"tutorial/viz/":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{"archive/tutorial/viz/#store-map-tiles-on-disk":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"tutorial/viz/#store-map-tiles-on-disk":{},"tutorial/viz/#store-the-image-on-disk":{}}}],["display",{"_index":1908,"text":{"archive/download/zeppelin/":{},"setup/zeppelin/":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{"archive/download/zeppelin/#display-geosparkviz-results":{},"setup/zeppelin/#display-sedonaviz-results":{}}}],["dissect",{"_index":3163,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{}},"title":{}}],["dist",{"_index":3337,"text":{"community/publish/":{},"community/publish/#9-release-sedona-python-and-zeppelin":{}},"title":{}}],["dist/geospark",{"_index":2024,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{}},"title":{}}],["distanc",{"_index":234,"text":{"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_distance":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_distance":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"setup/overview/":{},"setup/overview/#distributed-spatial-queries":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#highlights":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-distance-join-query":{}}}],["distance'",{"_index":874,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{}},"title":{}}],["distancejoin",{"_index":865,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["distancejoinqueryflat",{"_index":2125,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{}},"title":{}}],["distancetoler",{"_index":785,"text":{"api/sql/Function/":{},"api/sql/Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{}},"title":{}}],["distinct",{"_index":3001,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["distort",{"_index":2760,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["distribut",{"_index":1066,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/download/cluster/":{},"archive/download/cluster/#set-up-your-apache-spark-cluster":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#reload-a-saved-spatialrdd":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publish/":{},"community/publish/#make-a-sedona-release":{},"setup/cluster/":{},"setup/cluster/#set-up-your-apache-spark-cluster":{},"setup/flink/install-scala/":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/overview/":{},"tutorial/core-python/":{},"tutorial/core-python/#reload-a-saved-spatialrdd":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#reload-a-saved-spatialrdd":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{"setup/overview/#distributed-spatial-datasets":{},"setup/overview/#distributed-spatial-queries":{}}}],["distriut",{"_index":3651,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["divid",{"_index":790,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_divide":{}},"title":{}}],["divideband",{"_index":1160,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_divide":{}},"title":{}}],["divis",{"_index":4265,"text":{"tutorial/viz/":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{}},"title":{}}],["do",{"_index":1743,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["doc",{"_index":93,"text":{"api/r-api/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"community/publish/":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#v120":{},"tutorial/core-python/":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/raster/":{}},"title":{"api/java-api/":{},"api/python-api/":{},"api/r-api/":{},"archive/api/GeoSpark-Python-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#compile-r-html-docs":{},"tutorial/raster/#api-docs":{}}}],["docs.r",{"_index":3360,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["docs/api/rdoc",{"_index":3358,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["docstr",{"_index":4160,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["document",{"_index":937,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"community/contact/":{},"community/contact/#community":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#develop-a-document-contribution":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{"archive/download/compile/#compile-the-documentation":{},"community/rule/#develop-a-document-contribution":{},"setup/compile/#compile-the-documentation":{}}}],["doesn't",{"_index":872,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#v110":{},"setup/release-notes/#v120":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["domin",{"_index":986,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{}},"title":{}}],["don't",{"_index":1860,"text":{"archive/download/project/":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{}},"title":{}}],["done",{"_index":2606,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"community/publish/#pass-email_1":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{"community/contributor/#committer-done-template":{}}}],["doubl",{"_index":301,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buffer":{},"api/sql/Function/":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_modulo":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#load-geoparquet":{}},"title":{}}],["double.max",{"_index":3706,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{}},"title":{}}],["doubletyp",{"_index":3951,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["down",{"_index":2785,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["download",{"_index":52,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/download/cluster/":{},"archive/download/cluster/#set-up-your-apache-spark-cluster":{},"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/overview/":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#announce-email":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#check-files-manually":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"download/":{},"download/#121-incubating":{},"download/#130-incubating":{},"setup/cluster/":{},"setup/cluster/#set-up-your-apache-spark-cluster":{},"setup/compile/":{},"setup/compile/#compile-the-documentation":{},"setup/compile/#download-staged-jars":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/overview/":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/python-vector-osm/":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"archive/download/overview/#direct-download":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"download/":{},"setup/compile/#download-staged-jars":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/overview/#download-statistics":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}}}],["download/checkin.csv",{"_index":2325,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["download/checkin.tsv",{"_index":2352,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["download/checkinshape.csv",{"_index":2336,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["download/myshapefil",{"_index":2596,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["download/polygon.json",{"_index":2369,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["download/usa",{"_index":2650,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["downloads/spark",{"_index":3598,"text":{"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{}},"title":{}}],["dplyr",{"_index":3607,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["dreleasevers",{"_index":3225,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["dresum",{"_index":3229,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["driver",{"_index":1795,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["drop",{"_index":407,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"setup/release-notes/":{},"setup/release-notes/#sedona-viz":{},"setup/release-notes/#task":{},"setup/release-notes/#v120":{}},"title":{}}],["dropinvalid",{"_index":1005,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["dscala",{"_index":3249,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["dscala=2.12",{"_index":3238,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"setup/compile/":{},"setup/compile/#compile-with-different-targets":{}},"title":{}}],["dscala=2.13",{"_index":3239,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"setup/compile/":{},"setup/compile/#compile-with-different-targets":{}},"title":{}}],["dskiptest",{"_index":1824,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"community/develop/":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{}},"title":{}}],["dspark=3.0",{"_index":3513,"text":{"setup/compile/":{},"setup/compile/#compile-with-different-targets":{}},"title":{}}],["dtag",{"_index":3223,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["due",{"_index":1463,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v111":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v130":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"setup/databricks/":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v111":{},"setup/release-notes/#v130":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{}},"title":{}}],["duplic",{"_index":1544,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v112":{}},"title":{}}],["durdev",{"_index":3579,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["dure",{"_index":1945,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["e.g",{"_index":456,"text":{"api/flink/Function/":{},"api/flink/Function/#st_setpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_setpoint":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/publish/":{},"community/publish/#7-failed-vote":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["each",{"_index":65,"text":{"api/sql/Function/":{},"api/sql/Function/#st_dump":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#range-join":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"download/":{},"download/#github-repository":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-the-documentation":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v112":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/demo/":{},"tutorial/demo/#compile":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/viz/":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{}},"title":{}}],["earil",{"_index":3868,"text":{"setup/release-notes/":{},"setup/release-notes/#known-issue":{}},"title":{}}],["earlier",{"_index":1137,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier":{}}}],["earth",{"_index":1696,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["earthdatahdfpointmapp",{"_index":1693,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["easi",{"_index":1837,"text":{"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/tutorial/rdd/":{},"setup/install-scala/":{},"tutorial/rdd/":{}},"title":{}}],["easier",{"_index":3048,"text":{"community/contributor/":{},"community/contributor/#pmc-annoucement":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["easiest",{"_index":3435,"text":{"community/rule/":{},"community/rule/#make-a-pull-request":{}},"title":{}}],["easili",{"_index":2143,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#reload-a-saved-spatialrdd":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"tutorial/core-python/":{},"tutorial/core-python/#reload-a-saved-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#reload-a-saved-spatialrdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["echo",{"_index":3181,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#fix-signature-issues":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{}},"title":{}}],["eclips",{"_index":1855,"text":{"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{}},"title":{}}],["ecosystem",{"_index":3096,"text":{"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{}},"title":{"community/publication/#geospark-ecosystem":{}}}],["edg",{"_index":4122,"text":{"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["edgecolor",{"_index":2281,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["edit",{"_index":3081,"text":{"community/develop/":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{"setup/databricks/#advanced-editions":{},"setup/databricks/#community-edition-free-tier":{}}}],["editor",{"_index":3188,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{}},"title":{}}],["edu.ucar",{"_index":3670,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["effect",{"_index":2726,"text":{"archive/tutorial/viz/":{},"tutorial/viz/":{}},"title":{}}],["effici",{"_index":1559,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{}},"title":{}}],["effort",{"_index":2806,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{}},"title":{}}],["eg",{"_index":690,"text":{"api/sql/Function/":{},"api/sql/Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{}},"title":{}}],["elect",{"_index":3068,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{}}],["element",{"_index":1011,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{}},"title":{}}],["elements.geometri",{"_index":4036,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["elements.nod",{"_index":4037,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["elements.tag",{"_index":4038,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["elimin",{"_index":1602,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["email",{"_index":2840,"text":{"community/contact/":{},"community/contact/#feature-requests":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#7-failed-vote":{},"community/publish/#announce-email":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{"community/publish/#announce-email":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}}}],["embarass",{"_index":2983,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{}},"title":{}}],["embed",{"_index":1120,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_html":{}},"title":{}}],["empti",{"_index":378,"text":{"api/flink/Function/":{},"api/flink/Function/#st_isempty":{},"api/sql/Function/":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"community/publish/":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/snapshot/":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#sql":{},"setup/release-notes/#v112":{}},"title":{"community/publish/#0-prepare-an-empty-script-file":{},"community/snapshot/#0-prepare-an-empty-script-file":{}}}],["enabl",{"_index":1905,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#enable-geospark-zeppelin":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql_2":{},"setup/zeppelin/":{},"setup/zeppelin/#enable-sedona-zeppelin":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{"archive/download/zeppelin/#enable-geospark-zeppelin":{},"setup/zeppelin/#enable-sedona-zeppelin":{}}}],["enabled></releas",{"_index":1398,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#pomxml":{}},"title":{}}],["enabled></snapshot",{"_index":1400,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#pomxml":{}},"title":{}}],["enablehivesupport",{"_index":3965,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["encapsul",{"_index":2742,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["encod",{"_index":600,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/tutorial/rdd/":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"tutorial/rdd/":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["encourag",{"_index":3444,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["end",{"_index":246,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_transform":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/tutorial/rdd/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/publish/":{},"community/publish/#pass-email":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["endfract",{"_index":722,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{}},"title":{}}],["endors",{"_index":2822,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{}},"title":{}}],["enforc",{"_index":2936,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{}},"title":{}}],["engin",{"_index":3142,"text":{"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparkviz-visualization-system":{},"setup/release-notes/":{},"setup/release-notes/#sql_2":{}},"title":{}}],["enhanc",{"_index":1637,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"community/contact/":{},"community/contact/#feature-requests":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["enjoy",{"_index":1733,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{}},"title":{}}],["enough",{"_index":1794,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"community/contributor/":{},"community/contributor/#committers":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["ensur",{"_index":781,"text":{"api/sql/Function/":{},"api/sql/Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["enter",{"_index":1274,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contact/#feature-requests":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#send-the-invitation":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{}},"title":{}}],["entir",{"_index":107,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"community/publication/":{},"community/publication/#key-publications":{},"community/publish/":{},"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["enumer",{"_index":2033,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{}},"title":{}}],["env",{"_index":4176,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["envelop",{"_index":108,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Function/":{},"api/flink/Function/#st_envelope":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/Function/":{},"api/sql/Function/#st_envelope":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["environ",{"_index":1286,"text":{"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"community/release-manager/":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/flink/platform/":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{},"setup/install-scala/":{},"setup/install-scala/#spark-sql-shell":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{},"tutorial/flink/sql/":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/sql-pure-sql/":{}},"title":{"community/release-manager/#4-add-gpg_tty-environment-variable":{},"setup/databricks/#pure-sql-environment":{},"setup/install-python/#setup-environment-variables":{},"tutorial/flink/sql/#initiate-stream-environment":{}}}],["environmentset",{"_index":4272,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#initiate-stream-environment":{}},"title":{}}],["eof",{"_index":3577,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["epl",{"_index":3675,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{}},"title":{}}],["epsg",{"_index":490,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["epsg.io",{"_index":493,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["epsg:3857",{"_index":487,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["epsg:4326",{"_index":486,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["epsg:4499",{"_index":1025,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["epsg:5070",{"_index":2046,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{}},"title":{}}],["eq",{"_index":3323,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["equal",{"_index":299,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buffer":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/Function/":{},"api/sql/Function/#st_buffer":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicalover":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"setup/release-notes/":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql_3":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["equip",{"_index":2778,"text":{"archive/tutorial/zeppelin/":{},"tutorial/zeppelin/":{}},"title":{}}],["equival",{"_index":3759,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["erni",{"_index":3578,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["error",{"_index":478,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"community/develop/":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#python":{},"setup/release-notes/#rdd":{},"setup/release-notes/#v081-geospark-core":{}},"title":{}}],["especi",{"_index":1537,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["esri",{"_index":554,"text":{"api/sql/Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{}}}],["essenti",{"_index":4226,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["establish",{"_index":3051,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{}},"title":{}}],["etc",{"_index":669,"text":{"api/sql/Function/":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-other-geometry-files":{}},"title":{}}],["euclidean",{"_index":320,"text":{"api/flink/Function/":{},"api/flink/Function/#st_distance":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_distance":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{}},"title":{}}],["evalu",{"_index":918,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{"community/publication/#third-party-evaluation":{}}}],["even",{"_index":3445,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["eventu",{"_index":2771,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#generate-map-tiles":{},"tutorial/viz/":{},"tutorial/viz/#generate-map-tiles":{}},"title":{}}],["everyon",{"_index":3438,"text":{"community/rule/":{},"community/rule/#code-of-conduct":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["everyth",{"_index":3031,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"setup/databricks/":{},"setup/databricks/#community-edition-free-tier":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{}}],["ewkb",{"_index":262,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["ewkt",{"_index":272,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkt":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkt":{}},"title":{}}],["ex",{"_index":2034,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#output-format_3":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["exact",{"_index":4220,"text":{"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["exactli",{"_index":1053,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["exampl",{"_index":114,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Aggregator/#st_union_aggr":{},"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Constructor/#st_geomfromgml":{},"api/flink/Constructor/#st_geomfromkml":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/flink/Constructor/#st_point":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_area":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_distance":{},"api/flink/Function/#st_envelope":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_issimple":{},"api/flink/Function/#st_isvalid":{},"api/flink/Function/#st_length":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_transform":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_z":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_orderingequals":{},"api/flink/Predicate/#st_within":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromgml":{},"api/sql/Constructor/#st_geomfromkml":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_area":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_convexhull":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_length":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_within":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-loader/#rs_html":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalize":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{},"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_pixelize":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/develop/":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-python/#setup-environment-variables":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global_2":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v120":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/demo/":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/python-vector-osm/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#range-query":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{"archive/tutorial/geospark-sql-python/#example-usage-for-shapely-objects":{},"archive/tutorial/geospark-sql-python/#examples":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql-python/#example-usage-for-shapely-objects":{},"tutorial/sql-python/#examples":{}}}],["examples/sql",{"_index":4128,"text":{"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{}},"title":{}}],["except",{"_index":471,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v110":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["exclud",{"_index":3680,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/release-notes/":{},"setup/release-notes/#rdd":{}},"title":{}}],["exclus",{"_index":3684,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{}},"title":{}}],["exec",{"_index":3372,"text":{"community/release-manager/":{},"community/release-manager/#0-software-requirement":{}},"title":{}}],["execut",{"_index":531,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{}},"title":{}}],["executor",{"_index":2017,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#installation":{},"tutorial/python-vector-osm/":{}},"title":{"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}}}],["exhibit",{"_index":2998,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["exist",{"_index":984,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contributor/":{},"community/develop/":{},"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"community/rule/":{},"community/rule/#pick-annouce-a-task-using-jira":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["existingrdd[fclass#239,geometry#240",{"_index":2240,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["exmapl",{"_index":4262,"text":{"tutorial/viz/":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{}}],["expand",{"_index":668,"text":{"api/sql/Function/":{},"api/sql/Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{}},"title":{}}],["expect",{"_index":2932,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#send-the-invitation":{},"community/rule/":{},"community/rule/#code-of-conduct":{}},"title":{}}],["expertis",{"_index":2928,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{}},"title":{}}],["expir",{"_index":3388,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#5-get-github-personal-access-token-classic":{}},"title":{}}],["explain",{"_index":1408,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels_1":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"setup/release-notes/":{},"setup/release-notes/#v131":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels_1":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{}}],["explan",{"_index":940,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/project/":{},"archive/download/project/#quick-start":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{}}}],["explicitli",{"_index":599,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["explod",{"_index":1292,"text":{"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["explode(\"elements.id",{"_index":4032,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["explode(\"new",{"_index":4039,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["export",{"_index":3393,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{}},"title":{}}],["expos",{"_index":1982,"text":{"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["expr",{"_index":894,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["express",{"_index":917,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["extend",{"_index":261,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"setup/install-python/":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["extens",{"_index":577,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{}},"title":{}}],["exterior",{"_index":323,"text":{"api/flink/Function/":{},"api/flink/Function/#st_exteriorring":{},"api/sql/Function/":{},"api/sql/Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{}},"title":{}}],["exterior_p1",{"_index":2315,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multipolygon":{}},"title":{}}],["exterior_p2",{"_index":2318,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multipolygon":{}},"title":{}}],["extra",{"_index":1972,"text":{"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{}},"title":{}}],["extract",{"_index":1063,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["extractor",{"_index":3619,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["extrem",{"_index":2730,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["f",{"_index":2610,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["fa",{"_index":1903,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}},"title":{}}],["facilit",{"_index":4084,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{}},"title":{}}],["fact",{"_index":2848,"text":{"community/contact/":{},"community/contact/#bug-reports":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["factor",{"_index":1214,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{}}],["fail",{"_index":1471,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publish/":{},"community/publish/#7-failed-vote":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#global_2":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v120":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"community/publish/#7-failed-vote":{}}}],["failur",{"_index":2982,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{}},"title":{}}],["failuremessag",{"_index":3322,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["fairli",{"_index":3626,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["fals",{"_index":488,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Function/":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_transform":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Parameter/#usage":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#pomxml":{},"setup/release-notes/":{},"setup/release-notes/#core":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-wkb-file":{},"tutorial/core-python/#read-from-wkt-file":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["famili",{"_index":3621,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["familiar",{"_index":4172,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["faq",{"_index":1987,"text":{"archive/tutorial/faq/":{}},"title":{}}],["far",{"_index":2999,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["fast_food|5",{"_index":2258,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["faster",{"_index":1571,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"setup/release-notes/":{},"setup/release-notes/#v110":{}},"title":{}}],["fat",{"_index":1687,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}},"title":{"setup/maven-coordinates/#use-sedona-fat-jars":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}}}],["favorit",{"_index":3401,"text":{"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{}},"title":{}}],["favourit",{"_index":3186,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{}},"title":{}}],["fclass",{"_index":2213,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["fclass#239",{"_index":2236,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["feather",{"_index":2801,"text":{"asf/asf/":{},"asf/asf/#copyright":{}},"title":{}}],["featur",{"_index":833,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/rdd/":{},"community/contact/":{},"community/contact/#feature-requests":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_1":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{"community/contact/#feature-requests":{},"setup/release-notes/#new-feature":{},"setup/release-notes/#new-features":{}}}],["feedback",{"_index":2830,"text":{"community/contact/":{},"community/contact/#community":{},"community/contact/#feedback":{}},"title":{"community/contact/#feedback":{}}}],["felix",{"_index":2904,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["felixcheung@apache.org",{"_index":2906,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["fetch",{"_index":1162,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/viz/":{},"tutorial/viz/#store-map-tiles-on-disk":{},"tutorial/viz/#store-the-image-on-disk":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["few",{"_index":3703,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-111":{},"setup/release-notes/#sedona-131":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{}},"title":{}}],["fi",{"_index":3146,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["field",{"_index":1050,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{}},"title":{}}],["fielddata",{"_index":1078,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["fieldgeometri",{"_index":1077,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{}},"title":{}}],["fieldheight",{"_index":1076,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["fieldimag",{"_index":1072,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["fieldnam",{"_index":4208,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["fieldnband",{"_index":1074,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["fieldorigin",{"_index":1073,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["fieldwidth",{"_index":1075,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["figsiz",{"_index":2275,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["figur",{"_index":3084,"text":{"community/develop/":{},"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["file",{"_index":576,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#reload-a-saved-spatialrdd":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/contributor/":{},"community/contributor/#create-asf-account":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#fix-signature-issues":{},"community/publish/#make-a-sedona-release":{},"community/publish/#upload-releases":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#check-files-manually":{},"community/vote/#run-the-verify-script":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#mkdocs-website":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v081-geospark-core":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"tutorial/core-python/":{},"tutorial/core-python/#reload-a-saved-spatialrdd":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/demo/":{},"tutorial/demo/#scala":{},"tutorial/python-vector-osm/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#reload-a-saved-spatialrdd":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#save-geoparquet":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-core-python/#read-from-geojson-file":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{},"archive/tutorial/sql/#load-data-from-files":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/#check-files-manually":{},"tutorial/core-python/#read-from-geojson-file":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/core-python/#read-from-wkb-file":{},"tutorial/core-python/#read-from-wkt-file":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{},"tutorial/sql/#load-data-from-files":{}}}],["file:///home/hp/d...|polygon",{"_index":1039,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["file_nam",{"_index":4007,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["filedatasplitt",{"_index":1934,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/rdd/":{}},"title":{}}],["filenam",{"_index":3319,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["filescan",{"_index":854,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["fill",{"_index":1080,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_array":{}},"title":{}}],["filter",{"_index":921,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["final",{"_index":1708,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/zeppelin/":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/develop/":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/zeppelin/":{}},"title":{}}],["find",{"_index":836,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#range-join":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_squareroot":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/download/project/":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#range-query":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#range-query":{}},"title":{}}],["findspark",{"_index":2015,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#installation":{}},"title":{}}],["fine",{"_index":1856,"text":{"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["fingerprint",{"_index":3493,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["finish",{"_index":3464,"text":{"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["fiona",{"_index":2169,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["firebrick",{"_index":1275,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{}},"title":{}}],["first",{"_index":696,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_startpoint":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"community/contact/":{},"community/contact/#mailing-list":{},"community/publish/":{},"community/release-manager/":{},"community/release-manager/#become-a-release-manager":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/release-notes/":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["first_spatial_col_index",{"_index":4090,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["fit",{"_index":1661,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["five",{"_index":1992,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{}},"title":{}}],["fix",{"_index":1404,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/develop/":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#make-a-pull-request":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#core":{},"setup/release-notes/#core_1":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global_2":{},"setup/release-notes/#highlights":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#python":{},"setup/release-notes/#python_1":{},"setup/release-notes/#rdd":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-111":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#sedona-131":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_1":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v101":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"setup/release-notes/#viz_1":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{"community/publish/#fix-signature-issues":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#bug-fixes_1":{}}}],["flag",{"_index":1335,"text":{"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{}},"title":{}}],["flat",{"_index":1607,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["flatmaptopair",{"_index":1655,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["flatten",{"_index":3959,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["flege",{"_index":1891,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{}},"title":{}}],["flexibl",{"_index":2723,"text":{"archive/tutorial/viz/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/viz/":{}},"title":{}}],["flink",{"_index":19,"text":{"":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"setup/flink/install-scala/":{},"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/flink/platform/":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/overview/":{},"setup/overview/#distributed-spatial-datasets":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#flink":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#highlights":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#rdd":{},"setup/release-notes/#sedona-120":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#set-up-dependencies":{}},"title":{"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink":{},"#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112":{},"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/release-notes/#flink":{},"setup/release-notes/#flink_1":{}}}],["flink_2.12",{"_index":3318,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["flip",{"_index":330,"text":{"api/flink/Function/":{},"api/flink/Function/#st_flipcoordinates":{},"api/sql/Function/":{},"api/sql/Function/#st_flipcoordinates":{}},"title":{}}],["focus",{"_index":2747,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"tutorial/viz/":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{}}],["folder",{"_index":1315,"text":{"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/cluster/":{},"archive/download/cluster/#start-your-cluster":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/download/zeppelin/#create-helium-folder-optional":{},"community/develop/":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#compile-r-html-docs":{},"community/publish/#upload-releases":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"community/vote/":{},"community/vote/#check-files-manually":{},"community/vote/#run-the-verify-script":{},"setup/cluster/":{},"setup/cluster/#start-your-cluster":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#mkdocs-website":{},"setup/compile/#run-python-test":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-python/#setup-environment-variables":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/release-notes/":{},"setup/release-notes/#v100":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"setup/zeppelin/#create-helium-folder-optional":{},"tutorial/demo/":{},"tutorial/demo/#compile":{},"tutorial/demo/#folder-structure":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}},"title":{"archive/download/zeppelin/#create-helium-folder-optional":{},"setup/zeppelin/#create-helium-folder-optional":{},"tutorial/demo/#folder-structure":{}}}],["follow",{"_index":530,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Overview/#quick-start":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#supported-versions":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#supported-versions":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#initiate-sparksession":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/contact/":{},"community/contact/#community":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#committer-done-template":{},"community/contributor/#mentors":{},"community/contributor/#nominate-a-committer-or-pmc-member":{},"community/contributor/#project-management-committee-pmc":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/develop/":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#7-failed-vote":{},"community/publish/#fix-signature-issues":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#develop-a-document-contribution":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#pure-sql-environment":{},"setup/flink/install-scala/":{},"setup/flink/platform/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/demo/#prerequisites":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#register-package":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#range-query":{},"tutorial/sql/#register-sedonasql":{},"tutorial/sql/#save-geoparquet":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#initiate-sparksession":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["footprint",{"_index":1595,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{}},"title":{}}],["forc",{"_index":333,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["forev",{"_index":2741,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["forget",{"_index":1869,"text":{"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{}},"title":{}}],["form",{"_index":304,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_isvalid":{},"api/flink/Function/#st_normalize":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_normalize":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_mode":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"community/contact/":{},"community/contact/#feedback":{},"community/contributor/":{},"community/contributor/#create-asf-account":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#10-release-sedona-r-to-cran":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["formal",{"_index":2979,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/rule/":{},"community/rule/#code-of-conduct":{}},"title":{}}],["format",{"_index":111,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Aggregator/#st_union_aggr":{},"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Constructor/#st_geomfromgml":{},"api/flink/Constructor/#st_geomfromkml":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/flink/Constructor/#st_point":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_area":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_distance":{},"api/flink/Function/#st_envelope":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_issimple":{},"api/flink/Function/#st_isvalid":{},"api/flink/Function/#st_length":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_transform":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_z":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_orderingequals":{},"api/flink/Predicate/#st_within":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromgml":{},"api/sql/Constructor/#st_geomfromkml":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_area":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_convexhull":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_length":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_npoints":{},"api/sql/Function/#st_numgeometries":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-loader/#rs_html":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_pixelize":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/#output-format":{},"archive/tutorial/rdd/#output-format_1":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#highlights":{},"setup/release-notes/#rdd":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v112":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#output-format_2":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/rdd/#output-format":{},"tutorial/rdd/#output-format_1":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#save-geoparquet":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/rdd/#output-format":{},"archive/tutorial/rdd/#output-format_1":{},"archive/tutorial/rdd/#output-format_2":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#output-format_3":{},"tutorial/rdd/#output-format":{},"tutorial/rdd/#output-format_1":{},"tutorial/rdd/#output-format_2":{}}}],["format=long",{"_index":3391,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["formatted_df",{"_index":4030,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["formatted_df.createorreplacetempview(\"formatted_df",{"_index":4044,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["formatted_df.printschema",{"_index":4040,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["formatted_df.select(\"new.0\",\"new.1\",\"new.2\",\"new.3.maxspeed\",\"new.3.incline\",\"new.3.surfac",{"_index":4041,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["formatted_df.show(5",{"_index":4033,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["formatted_df.withcolumnrenamed(\"0\",\"id\").withcolumnrenamed(\"1\",\"geom\").withcolumnrenamed(\"2\",\"nodes\").withcolumnrenamed(\"3\",\"tag",{"_index":4043,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["formatutil",{"_index":4335,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{}},"title":{"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{}}}],["former",{"_index":3612,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["formerli",{"_index":3087,"text":{"community/publication/":{},"community/publication/#publication":{}},"title":{}}],["forward",{"_index":3065,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{}},"title":{}}],["found",{"_index":85,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/develop/":{},"download/":{},"download/#past-releases":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{}}],["foundat",{"_index":2799,"text":{"asf/asf/":{},"asf/asf/#copyright":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#buildsbt":{}},"title":{"asf/asf/":{}}}],["four",{"_index":927,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/sql/":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{}},"title":{}}],["foz",{"_index":3997,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["foz_roads_osm.json",{"_index":4008,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["fraction",{"_index":699,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{}},"title":{}}],["framework",{"_index":2783,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["frank",{"_index":2946,"text":{"community/contributor/":{},"community/contributor/#call-for-a-vote":{}},"title":{}}],["free",{"_index":3533,"text":{"setup/databricks/":{}},"title":{"setup/databricks/#community-edition-free-tier":{}}}],["frequent",{"_index":1983,"text":{},"title":{"archive/tutorial/faq/":{}}}],["friendli",{"_index":2713,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["fromdatastream",{"_index":4344,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#get-spatial-table":{}},"title":{}}],["front",{"_index":2782,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["fu",{"_index":3165,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{}},"title":{}}],["full",{"_index":1890,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/publication/":{},"community/publication/#key-publications":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"community/publication/#full-publications":{}}}],["fulli",{"_index":537,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"setup/release-notes/":{},"setup/release-notes/#v100":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["function",{"_index":51,"text":{"":{},"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_transform":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/viz/sql/":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/viz/sql/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#other-queries":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/databricks/#pure-sql-environment":{},"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#rdd":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-111":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sedona-viz":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/core-python/#tips":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#get-datastream":{},"tutorial/flink/sql/#get-spatial-table":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#register-package":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#other-queries":{},"tutorial/sql/#register-sedonasql":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"api/flink/Function/":{},"api/sql/AggregateFunction/":{},"api/sql/Function/":{},"api/sql/Overview/#function-list":{},"api/viz/sql/#aggregate-functions":{},"api/viz/sql/#regular-functions":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/viz/sql/#aggregate-functions":{},"archive/api/viz/sql/#regular-functions":{},"archive/download/project/#try-geospark-sql-functions":{}}}],["funtion",{"_index":2087,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{}},"title":{}}],["further",{"_index":2811,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{}},"title":{}}],["futur",{"_index":2860,"text":{"community/contact/":{},"community/contact/#feature-requests":{}},"title":{}}],["ga",{"_index":2041,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd/":{}},"title":{}}],["galleri",{"_index":4224,"text":{},"title":{"tutorial/viz-gallery/":{}}}],["gap",{"_index":2777,"text":{"archive/tutorial/zeppelin/":{},"tutorial/zeppelin/":{}},"title":{}}],["gb",{"_index":1798,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["gdf",{"_index":2260,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{}},"title":{}}],["gdp_md_est",{"_index":4193,"text":{"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{}},"title":{}}],["gemeotri",{"_index":2077,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["gemetri",{"_index":2347,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{}},"title":{}}],["gen",{"_index":3383,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["gener",{"_index":61,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels_1":{},"archive/tutorial/viz/#generate-map-tiles":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"community/contact/":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#create-asf-account":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#7-failed-vote":{},"community/publish/#compile-r-html-docs":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"download/":{},"download/#github-repository":{},"setup/compile/":{},"setup/compile/#download-staged-jars":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sedona-viz":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-an-spatialrdd-not-indexed":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels_1":{},"tutorial/viz/#generate-map-tiles":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#store-map-tiles-on-disk":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{}},"title":{"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/viz/#generate-a-single-image":{},"archive/tutorial/viz/#generate-map-tiles":{},"community/publish/#6-vote-in-general-incubatorapacheorg":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/viz/#generate-a-single-image":{},"tutorial/viz/#generate-map-tiles":{}}}],["general@incubator.apache.org",{"_index":3292,"text":{"community/publish/":{},"community/publish/#pass-email":{}},"title":{}}],["geo_json_file_loc",{"_index":2159,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-geojson-file":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-geojson-file":{}},"title":{}}],["geo_wrapper.jar",{"_index":2006,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{}},"title":{}}],["geodata",{"_index":1997,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#write-a-spatial-join-query":{}},"title":{}}],["geodatafram",{"_index":2097,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["geogcs[\"wg",{"_index":3731,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["geograph",{"_index":1679,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["geohash",{"_index":127,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Function/":{},"api/flink/Function/#st_geohash":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Function/":{},"api/sql/Function/#st_geohash":{}},"title":{}}],["geoid",{"_index":2379,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["geoinformatica",{"_index":3136,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["geojson",{"_index":139,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Function/":{},"api/flink/Function/#st_asgeojson":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Function/":{},"api/sql/Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#load-shapefile-and-geojson":{}},"title":{"archive/tutorial/geospark-core-python/#read-from-geojson-file":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/core-python/#read-from-geojson-file":{},"tutorial/sql/#load-shapefile-and-geojson":{}}}],["geojson:str",{"_index":140,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{}},"title":{}}],["geojsongeominputloc",{"_index":617,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{}},"title":{}}],["geojsonread",{"_index":2158,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-geojson-file":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-geojson-file":{},"tutorial/rdd/":{}},"title":{}}],["geom",{"_index":136,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_setpoint":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_3":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#get-spatial-table":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["geom.lon",{"_index":4056,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["geom_a",{"_index":990,"text":{"api/sql/Predicate/":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{}},"title":{}}],["geom_b",{"_index":991,"text":{"api/sql/Predicate/":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{}},"title":{}}],["geom_nam",{"_index":4345,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#get-spatial-table":{}},"title":{}}],["geom_point",{"_index":4306,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["geom_polygon",{"_index":4280,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["geometr",{"_index":1680,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{}},"title":{}}],["geometri",{"_index":110,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Constructor/#st_geomfromgml":{},"api/flink/Constructor/#st_geomfromkml":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_isvalid":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromgml":{},"api/sql/Constructor/#st_geomfromkml":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_npoints":{},"api/sql/Function/#st_numgeometries":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#output-format_1":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#run-spatial-queries":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v131":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#run-spatial-queries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#output-format_1":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#range-query":{},"tutorial/sql/#run-spatial-queries":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/sql/#create-a-geometry-type-column":{}}}],["geometry#236",{"_index":2238,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["geometry#240",{"_index":2237,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["geometry'",{"_index":382,"text":{"api/flink/Function/":{},"api/flink/Function/#st_issimple":{},"api/sql/Function/":{},"api/sql/Function/#st_issimple":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["geometry/geographi",{"_index":295,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buffer":{},"api/sql/Function/":{},"api/sql/Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{}},"title":{}}],["geometrycollect",{"_index":357,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_numgeometries":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{}},"title":{}}],["geometrycollection(point(40",{"_index":657,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{}},"title":{}}],["geometryfactori",{"_index":2617,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["geometryfix",{"_index":3803,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["geometrytyp",{"_index":2178,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["geometryudt",{"_index":3839,"text":{"setup/release-notes/":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql_3":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["geometryvalid",{"_index":1337,"text":{"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{}},"title":{}}],["geomstream",{"_index":4328,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#get-datastream":{},"tutorial/flink/sql/#get-spatial-table":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["geomtabl",{"_index":4325,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#get-datastream":{},"tutorial/flink/sql/#get-spatial-table":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{}},"title":{}}],["geomtbl",{"_index":4300,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{}},"title":{}}],["geomtbl3857",{"_index":4303,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["geomtri",{"_index":754,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["geom|height|width",{"_index":1037,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["geopanda",{"_index":2096,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#writing-application":{}},"title":{"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}}}],["geoparquet",{"_index":9,"text":{"":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#new-features":{},"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#save-geoparquet":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#save-geoparquet":{}}}],["geoparquet_file_name.parquet",{"_index":4197,"text":{"tutorial/sql/":{},"tutorial/sql/#save-geoparquet":{}},"title":{}}],["geoparquetdatalocation1",{"_index":4189,"text":{"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{}},"title":{}}],["geoparquetiotests.scala",{"_index":3778,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["geoparquetoutputloc",{"_index":4196,"text":{"tutorial/sql/":{},"tutorial/sql/#save-geoparquet":{}},"title":{}}],["georg",{"_index":2914,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["geospark",{"_index":59,"text":{"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v130":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#select-an-ide":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/download/zeppelin/#compatibility":{},"archive/download/zeppelin/#display-geosparkviz-results":{},"archive/download/zeppelin/#enable-geospark-zeppelin":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/download/zeppelin/#installation":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/faq/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-core-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#supported-versions":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#supported-versions":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#initiate-sparksession":{},"archive/tutorial/viz/#set-up-dependencies":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#key-publications":{},"community/publication/#publication":{},"community/publication/#third-party-evaluation":{},"download/":{},"download/#github-repository":{},"setup/overview/":{},"setup/overview/#download-statistics":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v100":{},"setup/release-notes/#v101":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v130":{},"setup/release-notes/#v131":{},"setup/zeppelin/":{},"setup/zeppelin/#installation":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-sql":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-120-and-later":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/compile/#compile-geospark":{},"archive/download/overview/#install-geospark":{},"archive/download/project/#how-to-use-geospark-in-an-ide":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-dependencies-in-zeppelin-spark-interpreter":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/download/zeppelin/#enable-geospark-zeppelin":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/geospark-core-python/#geospark":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/zeppelin/":{},"community/publication/#geospark-ecosystem":{},"setup/release-notes/#geospark-legacy-release-notes":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{}}}],["geospark.core.enum",{"_index":2035,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{}},"title":{}}],["geospark.core.formatmapp",{"_index":2152,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-geojson-file":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{}},"title":{}}],["geospark.core.formatmapper.disc_util",{"_index":2145,"text":{"archive/tutorial/geospark-core-python/":{}},"title":{}}],["geospark.core.formatmapper.shapefilepars",{"_index":2161,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-shapefile":{}},"title":{}}],["geospark.core.geom.envelop",{"_index":2068,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{}},"title":{}}],["geospark.core.geom_types.envelop",{"_index":2060,"text":{"archive/tutorial/geospark-core-python/":{}},"title":{}}],["geospark.core.spatialoper",{"_index":2069,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{}},"title":{}}],["geospark.core.spatialrdd",{"_index":1996,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{}},"title":{}}],["geospark.core.spatialrdd.spatial_rdd.spatialrdd",{"_index":2154,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-geojson-file":{},"archive/tutorial/geospark-core-python/#read-from-shapefile":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{}},"title":{}}],["geospark.global.charset",{"_index":1325,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{}},"title":{}}],["geospark.global.index",{"_index":1349,"text":{"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{}},"title":{}}],["geospark.global.indextyp",{"_index":1352,"text":{"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{}},"title":{}}],["geospark.jar",{"_index":2005,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{}},"title":{}}],["geospark.join.gridtyp",{"_index":1353,"text":{"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{}},"title":{}}],["geospark.join.indexbuildsid",{"_index":1356,"text":{"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{}},"title":{}}],["geospark.join.numpartit",{"_index":1355,"text":{"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{}},"title":{}}],["geospark.join.spatitionsid",{"_index":1357,"text":{"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{}},"title":{}}],["geospark.regist",{"_index":2013,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["geospark.sql.typ",{"_index":2284,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{}},"title":{}}],["geospark.utils.adapt",{"_index":2056,"text":{"archive/tutorial/geospark-core-python/":{}},"title":{}}],["geospark/jar",{"_index":2008,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{}},"title":{}}],["geospark/jars/../geospark",{"_index":2009,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{}},"title":{}}],["geosparkconf",{"_index":1350,"text":{"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"setup/release-notes/":{},"setup/release-notes/#v100":{}},"title":{}}],["geosparkkryoregistr",{"_index":1346,"text":{"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{}},"title":{}}],["geosparkkryoregistrator.getnam",{"_index":2182,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#writing-application":{}},"title":{}}],["geosparkregistr",{"_index":2014,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["geosparkregistrator.registeral",{"_index":2188,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{}},"title":{}}],["geosparkregistrator.registerall(spark",{"_index":2171,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#writing-application":{}},"title":{}}],["geosparkrunnableexampl",{"_index":2321,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{}},"title":{}}],["geosparksim",{"_index":3102,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#key-publications":{}},"title":{"community/publication/#geosparksim-traffic-simulator":{}}}],["geosparksql",{"_index":1324,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#package-the-project":{},"archive/download/zeppelin/":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#other-queries":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"archive/tutorial/viz/#set-up-dependencies":{}},"title":{"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/download/zeppelin/#visualize-geosparksql-results":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#geosparksql_1":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{}}}],["geosparksqlregistr",{"_index":1348,"text":{"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{}},"title":{}}],["geosparksqlscalatempl",{"_index":1874,"text":{"archive/download/project/":{},"archive/download/project/#submit-the-compiled-jar":{}},"title":{}}],["geosparkviz",{"_index":1257,"text":{"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"api/viz/sql/#st_encodeimage":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/api/viz/sql/#st_colorize":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"archive/tutorial/viz/#set-up-dependencies":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{},"setup/release-notes/":{},"setup/release-notes/#v100":{},"setup/release-notes/#v110":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{}},"title":{"archive/download/zeppelin/#display-geosparkviz-results":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publication/#geosparkviz-visualization-system":{}}}],["geosparkvizkryo",{"_index":2748,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{}},"title":{}}],["geosparkvizkryoregistr",{"_index":1360,"text":{"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{}},"title":{}}],["geosparkvizregistr",{"_index":1362,"text":{"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{}},"title":{}}],["geospati",{"_index":33,"text":{"":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{},"setup/release-notes/":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#v01-v07":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{}}}],["geotiff",{"_index":997,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_2":{}},"title":{"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}}}],["geotiffdatafram",{"_index":1036,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#rs_getband":{}},"title":{}}],["geotiffdf",{"_index":1004,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["geotool",{"_index":3511,"text":{"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#global_2":{},"setup/release-notes/#global_3":{}},"title":{"setup/maven-coordinates/#geotools-240":{}}}],["geotyp",{"_index":2147,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{}},"title":{}}],["geoviz",{"_index":2745,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["get",{"_index":1911,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_3":{}},"title":{}}],["getconf",{"_index":1351,"text":{"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{}},"title":{}}],["getexecutionenviron",{"_index":4271,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#initiate-stream-environment":{}},"title":{}}],["getfield",{"_index":4331,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["getnam",{"_index":1345,"text":{"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["getorcr",{"_index":958,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["getpartition",{"_index":2114,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{}}],["getproperti",{"_index":2766,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"tutorial/viz/":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{}}],["getter",{"_index":1626,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v082-geospark-core":{}},"title":{}}],["getuserdata",{"_index":2001,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{}},"title":{}}],["gi",{"_index":267,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["gigapixel",{"_index":1753,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["gis_osm_pois_free_1.shp",{"_index":2210,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["git",{"_index":1816,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#make-a-sedona-release":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-manually":{}},"title":{}}],["gitbox",{"_index":3058,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{}}],["github",{"_index":53,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/faq/":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#project-management-committee-pmc":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"community/rule/#make-a-pull-request":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"download/":{},"download/#github-repository":{},"setup/compile/":{},"setup/compile/#download-staged-jars":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"download/#github-repository":{}}}],["gitter",{"_index":2930,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/publish/":{},"community/publish/#announce-email":{}},"title":{}}],["give",{"_index":1634,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["given",{"_index":242,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_z":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"api/viz/sql/#st_pixelize":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#range-query":{}},"title":{}}],["global",{"_index":1748,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#python_1":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{}},"title":{"setup/release-notes/#global":{},"setup/release-notes/#global_1":{},"setup/release-notes/#global_2":{},"setup/release-notes/#global_3":{}}}],["globe'></i",{"_index":1904,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}},"title":{}}],["gml",{"_index":145,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgml":{},"api/flink/Function/":{},"api/flink/Function/#st_asgml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgml":{},"api/sql/Function/":{},"api/sql/Function/#st_asgml":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["gml:linestr",{"_index":147,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgml":{}},"title":{}}],["gml:string",{"_index":146,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgml":{}},"title":{}}],["gnu",{"_index":3654,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["gnugpg",{"_index":3376,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["gnupg",{"_index":3377,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#install-necessary-software":{}},"title":{}}],["gnupg2",{"_index":3378,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#install-necessary-software":{}},"title":{}}],["go",{"_index":1809,"text":{"archive/download/cluster/":{},"archive/download/cluster/#start-your-cluster":{},"archive/download/project/":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#display-geosparkviz-results":{},"community/contributor/":{},"community/contributor/#pmc-annoucement":{},"community/develop/":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"setup/cluster/":{},"setup/cluster/#start-your-cluster":{},"setup/compile/":{},"setup/compile/#download-staged-jars":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/zeppelin/":{},"setup/zeppelin/#display-sedonaviz-results":{}},"title":{}}],["goal",{"_index":2987,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["gonzalez",{"_index":1440,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["good",{"_index":1800,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#display-geosparkviz-results":{},"community/contributor/":{},"community/contributor/#mentors":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-scala/":{},"setup/release-notes/":{},"setup/release-notes/#sedona-viz":{},"setup/zeppelin/":{},"setup/zeppelin/#display-sedonaviz-results":{}},"title":{}}],["googl",{"_index":2732,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contact/":{},"community/contact/#feedback":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["gosl",{"_index":2908,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["govindan",{"_index":2918,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["gpd",{"_index":2098,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["gpg",{"_index":3261,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#fix-signature-issues":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"community/vote/#run-the-verify-script":{}},"title":{"community/release-manager/#2-prepare-secret-gpg-key":{}}}],["gpg.passphrase>your_gpg_passphrase</gpg.passphras",{"_index":3425,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["gpg_tti",{"_index":3404,"text":{"community/release-manager/":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{}},"title":{"community/release-manager/#4-add-gpg_tty-environment-variable":{}}}],["grace",{"_index":2976,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{}},"title":{}}],["graduat",{"_index":2995,"text":{"community/contributor/":{},"community/contributor/#create-asf-account":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["grain",{"_index":3613,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["grant",{"_index":3410,"text":{"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{}},"title":{}}],["granular",{"_index":1623,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v082-geospark-core":{}},"title":{}}],["gray",{"_index":4253,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["great",{"_index":2852,"text":{"community/contact/":{},"community/contact/#bug-reports":{}},"title":{}}],["greater",{"_index":1175,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"community/contact/":{},"community/contact/#feature-requests":{}},"title":{}}],["greaterdf",{"_index":1176,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_greaterthan":{}},"title":{}}],["greaterequaldf",{"_index":1180,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_greaterthanequal":{}},"title":{}}],["green",{"_index":3060,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["greenband",{"_index":1088,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["grid",{"_index":977,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["gridtyp",{"_index":2110,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{}}],["gridtype.quadtre",{"_index":1639,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["ground",{"_index":4187,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["group",{"_index":1306,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_render":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#render-map-tiles":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#render-map-tiles":{}},"title":{}}],["groupbi",{"_index":2250,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["groupid",{"_index":1367,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["groupid>org.apache</groupid",{"_index":3076,"text":{"community/develop/":{}},"title":{}}],["gt",{"_index":3587,"text":{},"title":{"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}}}],["guarante",{"_index":438,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointonsurface":{},"api/sql/Function/":{},"api/sql/Function/#st_pointonsurface":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["gui",{"_index":3187,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{}},"title":{}}],["guid",{"_index":527,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"community/contributor/":{},"community/contributor/#pmc-annoucement":{},"setup/flink/install-scala/":{}},"title":{}}],["guidanc",{"_index":2934,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{}},"title":{}}],["guidelin",{"_index":2960,"text":{"community/contributor/":{},"community/publish/":{},"community/publish/#make-a-sedona-release":{}},"title":{}}],["h",{"_index":1105,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["h1|g4020",{"_index":2685,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["h1|g4020|null",{"_index":2671,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["hacker",{"_index":1814,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{}},"title":{}}],["hadoop",{"_index":3812,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["hadoop2.7",{"_index":3519,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{}},"title":{}}],["hand",{"_index":1909,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#display-geosparkviz-results":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/zeppelin/":{},"setup/zeppelin/#display-sedonaviz-results":{}},"title":{}}],["handl",{"_index":1413,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{}},"title":{}}],["hao",{"_index":1515,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["happen",{"_index":4185,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["happi",{"_index":3296,"text":{"community/publish/":{},"community/publish/#announce-email":{}},"title":{}}],["hard",{"_index":3937,"text":{"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}},"title":{}}],["hardcod",{"_index":1863,"text":{"archive/download/project/":{},"archive/download/project/#package-the-project":{}},"title":{}}],["harri",{"_index":1458,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["has_non_spatial_attr",{"_index":4091,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["hashset",{"_index":3891,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-core":{}},"title":{}}],["have",{"_index":782,"text":{"api/sql/Function/":{},"api/sql/Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"setup/databricks/":{},"setup/databricks/#pure-sql-environment":{}},"title":{}}],["hdf",{"_index":1633,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global_1":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{},"tutorial/rdd/":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}}}],["hdf/netcdf",{"_index":3660,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["hdfs.create_file(file_nam",{"_index":4010,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["hdfs.delete_file_dir(file_nam",{"_index":4009,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["hdfs://776faf4d6a1e:8020/\"+file_nam",{"_index":4012,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{}},"title":{}}],["hdfs://path",{"_index":2133,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["he/sh",{"_index":2868,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["header",{"_index":615,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"tutorial/core-python/":{},"tutorial/rdd/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{}},"title":{"community/publish/#1-check-asf-copyright-in-all-file-headers":{}}}],["heat",{"_index":1261,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/viz/":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/viz/":{}},"title":{}}],["height",{"_index":1008,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{}}],["height:int",{"_index":1084,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["helium",{"_index":1894,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#create-helium-folder-optional":{},"archive/download/zeppelin/#enable-geospark-zeppelin":{},"archive/download/zeppelin/#installation":{},"archive/tutorial/zeppelin/":{},"setup/zeppelin/":{},"setup/zeppelin/#create-helium-folder-optional":{},"setup/zeppelin/#enable-sedona-zeppelin":{},"setup/zeppelin/#installation":{},"tutorial/zeppelin/":{}},"title":{"archive/download/zeppelin/#create-helium-folder-optional":{},"setup/zeppelin/#create-helium-folder-optional":{}}}],["help",{"_index":1943,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#mentors":{},"community/contributor/#pmc-annoucement":{},"community/publish/":{},"community/publish/#announce-email":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{}},"title":{}}],["helsinki",{"_index":3145,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["henc",{"_index":2738,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["here",{"_index":86,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Overview/#quick-start":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#join-query":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"download/":{},"download/#past-releases":{},"setup/compile/":{},"setup/compile/#compile-the-documentation":{},"setup/compile/#download-staged-jars":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#v01-v07":{},"tutorial/flink/sql/":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql/":{},"tutorial/sql/#join-query":{}},"title":{}}],["hero",{"_index":2636,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{}}],["heterogen",{"_index":1614,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["hi",{"_index":3266,"text":{"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["hierarchi",{"_index":3008,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["high",{"_index":2030,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz-gallery/":{},"tutorial/viz/":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["higher",{"_index":3545,"text":{"setup/databricks/":{}},"title":{}}],["highest",{"_index":654,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{}},"title":{}}],["highli",{"_index":1926,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["highlight",{"_index":3718,"text":{"setup/release-notes/":{}},"title":{"setup/release-notes/#highlights":{}}}],["hint",{"_index":885,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["his/her",{"_index":3044,"text":{"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{}},"title":{}}],["histori",{"_index":2925,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{}},"title":{}}],["hit",{"_index":3543,"text":{"setup/databricks/":{},"setup/databricks/#advanced-editions":{}},"title":{}}],["hive",{"_index":2706,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{}}],["hold",{"_index":2000,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format_3":{}},"title":{}}],["hole",{"_index":731,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makepolygon":{}},"title":{}}],["home",{"_index":0,"text":{},"title":{"":{}}}],["homogen",{"_index":652,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{}},"title":{}}],["honor",{"_index":3455,"text":{"community/rule/":{},"community/rule/#code-of-conduct":{}},"title":{}}],["hopefulli",{"_index":1919,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{}},"title":{}}],["host",{"_index":1833,"text":{"archive/download/overview/":{},"archive/download/overview/#direct-download":{}},"title":{}}],["hotel",{"_index":2040,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["hour",{"_index":2978,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["html",{"_index":1117,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_html":{},"community/publish/":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{"community/publish/#compile-r-html-docs":{}}}],["htmlstring",{"_index":1125,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_html":{}},"title":{}}],["http",{"_index":1417,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["http://overpass",{"_index":3992,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["http://sedona.apache.org",{"_index":3298,"text":{"community/publish/":{},"community/publish/#announce-email":{}},"title":{}}],["http://sedona.apache.org/setup/overview",{"_index":3300,"text":{"community/publish/":{},"community/publish/#announce-email":{}},"title":{}}],["http://sedona.apache.org/tutorial/rdd",{"_index":3301,"text":{"community/publish/":{},"community/publish/#announce-email":{}},"title":{}}],["http://www.public.asu.edu/~jiayu2/geospark/javadoc",{"_index":1313,"text":{"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{}},"title":{}}],["http://www.public.asu.edu/~jiayu2/geosparksql/javadoc",{"_index":1358,"text":{"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{}},"title":{}}],["http://www.public.asu.edu/~jiayu2/geosparkviz/javadoc",{"_index":1359,"text":{"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{}},"title":{}}],["https://archive.apache.org/dist/incubator/sedona",{"_index":87,"text":{"download/":{},"download/#past-releases":{}},"title":{}}],["https://cwiki.apache.org/confluence/display/incubator/incubator+release+checklist",{"_index":3283,"text":{"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["https://dist.apache.org/repos/dist/dev/incubator/sedona",{"_index":3240,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["https://dist.apache.org/repos/dist/dev/incubator/sedona/1.3.1",{"_index":3242,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["https://dist.apache.org/repos/dist/dev/incubator/sedona/key",{"_index":3398,"text":{"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{}},"title":{}}],["https://dist.apache.org/repos/dist/release/incubator/sedona",{"_index":3308,"text":{"community/publish/":{},"community/publish/#upload-releases":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{}},"title":{}}],["https://dist.apache.org/repos/dist/release/incubator/sedona/1.3.1",{"_index":3309,"text":{"community/publish/":{},"community/publish/#upload-releases":{}},"title":{}}],["https://dist.apache.org/repos/dist/release/incubator/sedona/key",{"_index":3399,"text":{"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{}},"title":{}}],["https://dlcdn.apache.org//creadur/apach",{"_index":3195,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{}},"title":{}}],["https://downloads.apache.org/incubator/sedona/key",{"_index":3272,"text":{"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["https://gitbox.apache.org/setup",{"_index":3059,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{}}],["https://github.com/apache/incub",{"_index":3053,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#announce-email":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["https://github.com/datasystemslab/geospark",{"_index":2167,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#introduction":{}},"title":{}}],["https://github.com/datasystemslab/geospark/issues/115",{"_index":1622,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v082-geospark-core":{}},"title":{}}],["https://github.com/orgs/apache/teams/sedona",{"_index":3063,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{}}],["https://gitter.im/apache/sedona",{"_index":3303,"text":{"community/publish/":{},"community/publish/#announce-email":{}},"title":{}}],["https://help.github.com/articles/secur",{"_index":3055,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{}}],["https://id.apache.org",{"_index":3057,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{}}],["https://incubator.apache.org/guides/committer.html",{"_index":3038,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["https://incubator.apache.org/guides/distribution.html",{"_index":3174,"text":{"community/publish/":{},"community/publish/#make-a-sedona-release":{}},"title":{}}],["https://incubator.apache.org/guides/ppmc.html",{"_index":2961,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["https://infra.apache.org/releas",{"_index":3175,"text":{"community/publish/":{},"community/publish/#make-a-sedona-release":{}},"title":{}}],["https://issues.apache.org/jira/browse/leg",{"_index":3177,"text":{"community/publish/":{},"community/publish/#make-a-sedona-release":{}},"title":{}}],["https://keyserver.pgp.com",{"_index":3397,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["https://lists.apache.org/list.html",{"_index":3285,"text":{"community/publish/":{},"community/publish/#announce-email":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["https://lists.apache.org/list.html?private@sedona.apache.org",{"_index":2963,"text":{"community/contributor/":{},"community/contributor/#close-a-vote":{}},"title":{}}],["https://mvnrepository.com/artifact/org.datasyslab/geotool",{"_index":3657,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["https://mvnrepository.com/artifact/org.datasyslab/sernetcdf",{"_index":3671,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["https://mvnrepository.com/artifact/org.locationtech.jts/jt",{"_index":3676,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{}},"title":{}}],["https://mvnrepository.com/artifact/org.wololo/jts2geojson",{"_index":3682,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{}},"title":{}}],["https://mybinder.org/v2/gh/jiayuasu/sedona",{"_index":3277,"text":{"community/publish/":{},"community/publish/#vote-email":{}},"title":{}}],["https://oss.sonatype.org/content/repositories/snapshot",{"_index":1389,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#buildsbt":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{}},"title":{}}],["https://people.apache.org/committ",{"_index":3024,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["https://pypi.org/project/apach",{"_index":3332,"text":{"community/publish/":{},"community/publish/#9-release-sedona-python-and-zeppelin":{}},"title":{}}],["https://pypi.org/project/pyspark",{"_index":2004,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{}},"title":{}}],["https://repo1.maven.org/maven2/org/apache/sedona/sedona",{"_index":3571,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["https://repo1.maven.org/maven2/org/datasyslab/geotool",{"_index":3568,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["https://repository.apache.org",{"_index":3231,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#fix-signature-issues":{},"community/publish/#manually-close-and-release-the-package":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{}},"title":{}}],["https://repository.apache.org/content/groups/snapshot",{"_index":3691,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#buildsbt":{},"setup/maven-coordinates/#pomxml":{}},"title":{}}],["https://repository.apache.org/service/local/repositories/orgapachesedona",{"_index":3325,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["https://sedona.apache.org/community/vot",{"_index":3274,"text":{"community/publish/":{},"community/publish/#vote-email":{}},"title":{}}],["https://sedona.apache.org/tutorial/sql/#datafram",{"_index":3725,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["https://sedona.apache.org/tutorial/sql/#load",{"_index":3721,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["https://therinspark.com/connections.html",{"_index":3642,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["https://twitter.com/apachesedona",{"_index":3302,"text":{"community/publish/":{},"community/publish/#announce-email":{}},"title":{}}],["https://whimsy.apache.org/roster/ppmc/sedona",{"_index":3046,"text":{"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{}}],["https://www.apache.org/dev",{"_index":3037,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["https://www.apache.org/dev/#committ",{"_index":3066,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{}},"title":{}}],["https://www.apache.org/foundation/how",{"_index":3035,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["https://www.apache.org/foundation/policies/conduct.html",{"_index":3041,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["https://www.apache.org/licenses/#cla",{"_index":3022,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["https://www.apache.org/secur",{"_index":91,"text":{"download/":{},"download/#security":{}},"title":{}}],["https://www.npmjs.com/package/apach",{"_index":3333,"text":{"community/publish/":{},"community/publish/#9-release-sedona-python-and-zeppelin":{}},"title":{}}],["huge",{"_index":3938,"text":{"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}},"title":{}}],["hui",{"_index":1453,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["hull",{"_index":663,"text":{"api/sql/Function/":{},"api/sql/Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{}},"title":{}}],["human",{"_index":2138,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["humid",{"_index":1253,"text":{"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{}},"title":{}}],["i.",{"_index":1914,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["i/o",{"_index":3858,"text":{"setup/release-notes/":{},"setup/release-notes/#sql_2":{}},"title":{}}],["icd",{"_index":3143,"text":{"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["icla",{"_index":3017,"text":{"community/contributor/":{},"community/contributor/#create-asf-account":{}},"title":{"community/contributor/#pmc-accept-and-icla-instruction":{}}}],["icon",{"_index":1901,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}},"title":{}}],["id",{"_index":1391,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#package-the-project":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#mentors":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#project-management-committee-pmc":{},"community/develop/":{},"community/publish/":{},"community/publish/#7-failed-vote":{},"community/publish/#fix-signature-issues":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#pomxml":{},"setup/release-notes/":{},"setup/release-notes/#v131":{},"tutorial/core-python/":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/sql-python/":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{},"tutorial/sql-python/#supported-shapely-objects":{}},"title":{"archive/download/project/#how-to-use-geospark-in-an-ide":{},"archive/download/project/#select-an-ide":{},"community/develop/#ide":{},"community/develop/#ide_1":{},"community/develop/#ide_2":{}}}],["id=#1068",{"_index":916,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["id=#62",{"_index":906,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["id>apache.releases.https</id",{"_index":3423,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["id>apache.snapshots.https</id",{"_index":3420,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["id>github</id",{"_index":3417,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["id>gpg</id",{"_index":3424,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["id>unidata",{"_index":3663,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["idea",{"_index":1852,"text":{"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"community/develop/":{},"community/develop/#ide":{},"community/publish/":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{}},"title":{}}],["identifi",{"_index":460,"text":{"api/flink/Function/":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/sql/Function/":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_srid":{}},"title":{}}],["idiomat",{"_index":3604,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["ieee",{"_index":3140,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["ignor",{"_index":1023,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#sedona-core":{}},"title":{}}],["igua\u00e7u",{"_index":3998,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["illegalargumentexcept",{"_index":1546,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["ilya",{"_index":1460,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["imag",{"_index":1000,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_render":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels_1":{},"archive/tutorial/viz/#generate-a-single-image":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#sedona-viz":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v120":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels_1":{},"tutorial/viz/#generate-a-single-image":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#render-the-image":{},"tutorial/viz/#store-map-tiles-on-disk":{},"tutorial/viz/#store-the-image-on-disk":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{"archive/tutorial/viz/#generate-a-single-image":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"tutorial/viz/#generate-a-single-image":{},"tutorial/viz/#render-the-image":{},"tutorial/viz/#store-the-image-on-disk":{}}}],["image(band2",{"_index":1234,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_subtract":{}},"title":{}}],["image(exampl",{"_index":1221,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_normalizeddifference":{}},"title":{}}],["image.data",{"_index":1033,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["image.geometri",{"_index":1065,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["image.height",{"_index":1031,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["image.nband",{"_index":1034,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["image.origin",{"_index":1029,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["image.width",{"_index":1032,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["imagegener",{"_index":1757,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"tutorial/viz/":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{}}],["imagetyp",{"_index":2769,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"tutorial/viz/":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{}}],["imbruc",{"_index":2878,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["imbruced@apache.org",{"_index":2879,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["img",{"_index":1118,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_html":{},"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{}},"title":{}}],["immedi",{"_index":3589,"text":{"setup/install-python/":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{}},"title":{}}],["impact",{"_index":2184,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["implement",{"_index":750,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["implicitli",{"_index":3000,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["import",{"_index":959,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#read-from-geojson-file":{},"archive/tutorial/geospark-core-python/#read-from-shapefile":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{},"community/develop/":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/rule/":{},"community/rule/#pick-annouce-a-task-using-jira":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#read-from-geojson-file":{},"tutorial/core-python/#read-from-shapefile":{},"tutorial/core-python/#read-from-wkb-file":{},"tutorial/core-python/#read-from-wkt-file":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/demo/":{},"tutorial/demo/#scala":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{},"tutorial/sql-python/#register-package":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"community/develop/#import-the-project":{},"community/develop/#import-the-project_1":{},"community/develop/#import-the-project_2":{}}}],["improv",{"_index":1529,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"community/contact/":{},"community/contact/#feedback":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#python":{},"setup/release-notes/#rdd":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v112":{},"setup/release-notes/#viz_1":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{}},"title":{"setup/release-notes/#improvement":{},"setup/release-notes/#improvement_1":{}}}],["inaccur",{"_index":1723,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["inclin",{"_index":4079,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["includ",{"_index":263,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_makevalid":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#review-a-pull-request":{},"community/vote/":{},"community/vote/#check-files-manually":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"setup/compile/":{},"setup/compile/#compile-with-different-targets":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-111":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#v131":{},"tutorial/flink/sql/":{},"tutorial/raster/":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{}},"title":{}}],["incompat",{"_index":1725,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#sedona-viz":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["incorpor",{"_index":2859,"text":{"community/contact/":{},"community/contact/#feature-requests":{}},"title":{}}],["increas",{"_index":1968,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{}},"title":{}}],["increment",{"_index":3305,"text":{"community/publish/":{},"community/publish/#7-failed-vote":{}},"title":{}}],["incub",{"_index":4,"text":{"":{},"asf/asf/":{},"asf/asf/#copyright":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#mentors":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{},"community/develop/":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#7-failed-vote":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#announce-email":{},"community/publish/#fix-signature-issues":{},"community/publish/#make-a-sedona-release":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#upload-releases":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"download/":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#sedona-100":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{}},"title":{"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink":{},"#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112":{},"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"#11232021-sedona-111-incubating-is-released-it-now-supports-spark-32":{},"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"download/#121-incubating":{},"download/#130-incubating":{}}}],["incubating,org.apache.sedona:sedona",{"_index":3645,"text":{"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{}},"title":{}}],["incubating,org.datasyslab:geotool",{"_index":3646,"text":{"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["incubating.jar",{"_index":3251,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{}},"title":{}}],["incubating/*.jar",{"_index":3584,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["incubating/apach",{"_index":3310,"text":{"community/publish/":{},"community/publish/#upload-releases":{}},"title":{}}],["incubating/docs/setup/releas",{"_index":3299,"text":{"community/publish/":{},"community/publish/#announce-email":{}},"title":{}}],["incubating/geotool",{"_index":3566,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["incubating/sedona",{"_index":3327,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["incubator.apache.org",{"_index":2971,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/publish/":{}},"title":{"community/publish/#6-vote-in-general-incubatorapacheorg":{}}}],["incur",{"_index":1651,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["index",{"_index":243,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_setpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_setpoint":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_fetchregion":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/overview/":{},"setup/overview/#distributed-spatial-queries":{},"setup/release-notes/":{},"setup/release-notes/#python_1":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{}},"title":{"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-an-spatialrdd-not-indexed":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{}}}],["index.html",{"_index":3025,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["indexedrawrdd",{"_index":1949,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["indexedrdd",{"_index":1950,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["indextyp",{"_index":2083,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{}},"title":{}}],["indic",{"_index":982,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{}},"title":{}}],["individu",{"_index":1028,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["infer",{"_index":4157,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["inform",{"_index":491,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["infra",{"_index":3457,"text":{"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{}},"title":{}}],["infrastructur",{"_index":2813,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contributor/":{},"community/contributor/#committer-done-template":{}},"title":{}}],["init",{"_index":3546,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/databricks/#pure-sql-environment":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{}},"title":{"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}}}],["init.sh",{"_index":3576,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["initi",{"_index":1583,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"community/publication/":{},"community/publication/#publication":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v100":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/raster/":{},"tutorial/raster/#initial-setup":{},"tutorial/rdd/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/#initiate-sparksession":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/raster/#initial-setup":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/#initiate-sparksession":{}}}],["initialis",{"_index":3558,"text":{"setup/databricks/":{}},"title":{"setup/databricks/#initialise":{}}}],["inlcud",{"_index":3460,"text":{"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["inmemoryfileindex[file:/projects/geospark/counties.csv",{"_index":2244,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{}},"title":{}}],["inmemoryfileindex[file:/projects/sedona/counties.csv",{"_index":4139,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["inner",{"_index":858,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{}},"title":{}}],["input",{"_index":121,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_union_aggr":{},"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#rs_base64":{},"api/viz/sql/":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/viz/sql/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"api/sql/Raster-loader/":{}}}],["input_loc",{"_index":2036,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{}},"title":{}}],["inputloc",{"_index":1932,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd/":{}},"title":{}}],["inputt",{"_index":2598,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["insid",{"_index":2187,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["inspect",{"_index":3635,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["instac",{"_index":2607,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["instal",{"_index":1779,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/overview/":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/download/zeppelin/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-core-python/#installing-from-source":{},"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-sql-python/#installing-from-source":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{},"archive/tutorial/zeppelin/":{},"community/develop/":{},"community/develop/#ide":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#compile-r-html-docs":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"community/vote/#run-the-verify-script":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{},"setup/compile/#mkdocs-website":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#community-edition-free-tier":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/databricks/#pure-sql-environment":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"setup/zeppelin/":{},"tutorial/core-python/":{},"tutorial/core-python/#installation":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/sql-python/":{},"tutorial/sql-python/#installation":{},"tutorial/zeppelin/":{}},"title":{"archive/download/overview/#install-geospark":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/download/zeppelin/#installation":{},"archive/tutorial/geospark-core-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-core-python/#installing-from-source":{},"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-sql-python/#installing-from-source":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{},"community/vote/#install-necessary-software":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-r/":{},"setup/install-scala/":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"setup/zeppelin/#installation":{},"tutorial/core-python/#installation":{},"tutorial/sql-python/#installation":{}}}],["instanc",{"_index":1981,"text":{"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["instanti",{"_index":3630,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["instead",{"_index":823,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{},"api/viz/sql/":{},"api/viz/sql/#st_render":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"community/develop/":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/release-notes/":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{}},"title":{}}],["instreamingmod",{"_index":4274,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#initiate-stream-environment":{}},"title":{}}],["instruct",{"_index":74,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"download/":{},"download/#verify-the-integrity":{}},"title":{"community/contributor/#pmc-accept-and-icla-instruction":{}}}],["int",{"_index":132,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Function/":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{}},"title":{}}],["integ",{"_index":248,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_setsrid":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_setsrid":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#supported-shapely-objects":{}},"title":{}}],["integertyp",{"_index":2287,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["integr",{"_index":71,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-sql-python/":{},"download/":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v131":{},"tutorial/sql-python/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"download/#verify-the-integrity":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}}}],["integrat",{"_index":4146,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["inteira",{"_index":4051,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["intelij",{"_index":3344,"text":{"community/publish/":{}},"title":{}}],["intellij",{"_index":1851,"text":{"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"community/develop/":{},"community/develop/#ide":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{}},"title":{}}],["inter",{"_index":4173,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["interact",{"_index":1803,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#send-the-invitation":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-python/":{},"setup/install-scala/":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{}},"title":{}}],["interchang",{"_index":4218,"text":{"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["interest",{"_index":4184,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["interfac",{"_index":1907,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#enable-geospark-zeppelin":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#introduction":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/release-notes/":{},"setup/release-notes/#r":{},"setup/zeppelin/":{},"setup/zeppelin/#enable-sedona-zeppelin":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["interior",{"_index":368,"text":{"api/flink/Function/":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_numinteriorrings":{},"api/sql/Function/":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["interior_p1",{"_index":2316,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multipolygon":{}},"title":{}}],["intern",{"_index":859,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["interpol",{"_index":694,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{}},"title":{}}],["interpret",{"_index":751,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"archive/download/zeppelin/":{},"setup/zeppelin/":{}},"title":{"archive/download/zeppelin/#add-geospark-dependencies-in-zeppelin-spark-interpreter":{},"setup/zeppelin/#add-sedona-dependencies-in-zeppelin-spark-interpreter":{}}}],["intersect",{"_index":384,"text":{"api/flink/Function/":{},"api/flink/Function/#st_issimple":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_intersects":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/Function/":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_symdifference":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["introduct",{"_index":105,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Aggregator/#st_union_aggr":{},"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Constructor/#st_geomfromgml":{},"api/flink/Constructor/#st_geomfromkml":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/flink/Constructor/#st_point":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_area":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_distance":{},"api/flink/Function/#st_envelope":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_issimple":{},"api/flink/Function/#st_isvalid":{},"api/flink/Function/#st_length":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_transform":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_z":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/flink/Overview/":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_orderingequals":{},"api/flink/Predicate/#st_within":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromgml":{},"api/sql/Constructor/#st_geomfromkml":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_area":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_convexhull":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_length":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_npoints":{},"api/sql/Function/#st_numgeometries":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Overview/":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-loader/#rs_html":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalize":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_pixelize":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/install-r/":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"tutorial/core-python/":{},"tutorial/sql-python/":{}},"title":{"api/flink/Overview/#introduction":{},"api/sql/Overview/#introduction":{},"archive/api/sql/GeoSparkSQL-Overview/#introduction":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-sql-python/#introduction":{},"setup/install-r/#introduction":{},"tutorial/core-python/#introduction":{},"tutorial/sql-python/#introduction":{}}}],["invalid",{"_index":737,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["invis",{"_index":3005,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["invit",{"_index":2826,"text":{"community/contact/":{},"community/contact/#community":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#nominate-a-committer-or-pmc-member":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{"community/contributor/#send-the-invitation":{}}}],["invok",{"_index":1952,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["involv",{"_index":2825,"text":{"community/contact/":{},"community/contact/#community":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#send-a-notice-to-ipmc":{}},"title":{}}],["io",{"_index":4082,"text":{"tutorial/raster/":{},"tutorial/raster/#api-docs":{}},"title":{}}],["ip",{"_index":1781,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{}},"title":{}}],["ip:7077",{"_index":1848,"text":{"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/download/project/#submit-the-compiled-jar":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{}},"title":{}}],["ipmc",{"_index":2966,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/publish/":{},"community/publish/#pass-email":{}},"title":{"community/contributor/#send-a-notice-to-ipmc":{}}}],["ipykernel",{"_index":3941,"text":{"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["ipython.display",{"_index":3947,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["isn't",{"_index":1340,"text":{"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{}},"title":{}}],["iso_a3",{"_index":4192,"text":{"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{}},"title":{}}],["isolate_id",{"_index":4026,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["isolate_total_nod",{"_index":4022,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["isolate_total_nodes[\"total_nodes\"].iloc[0",{"_index":4024,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["issu",{"_index":89,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/faq/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contact/#feature-requests":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"download/":{},"download/#security":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#core_1":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global_1":{},"setup/release-notes/#python":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v101":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{"community/contact/#issue-tracker":{},"community/publish/#fix-signature-issues":{},"setup/release-notes/#known-issue":{}}}],["issuer",{"_index":3486,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["it'",{"_index":1193,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_logicalover":{}},"title":{}}],["itali",{"_index":3161,"text":{"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["item",{"_index":2948,"text":{"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["iter",{"_index":1609,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["itself",{"_index":670,"text":{"api/sql/Function/":{},"api/sql/Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{}},"title":{}}],["jackson",{"_index":3681,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{}},"title":{}}],["jar",{"_index":63,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"community/develop/":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#fix-signature-issues":{},"download/":{},"download/#github-repository":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{},"setup/compile/#download-staged-jars":{},"setup/databricks/":{},"setup/databricks/#community-edition-free-tier":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-python/#setup-environment-variables":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#global_3":{},"setup/release-notes/#v01-v07":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{"archive/download/project/#submit-the-compiled-jar":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"setup/compile/#download-staged-jars":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}}}],["java",{"_index":97,"text":{"api/java-api/":{},"api/viz/java-api/":{},"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_render":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_render":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"archive/download/project/#self-contained-spark-projects":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/viz/":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#run-python-test":{},"setup/flink/install-scala/":{},"setup/flink/platform/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/flink/sql/":{},"tutorial/raster/":{},"tutorial/rdd/":{},"tutorial/sql/":{},"tutorial/viz/":{}},"title":{"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"setup/compile/#compile-scala-java-source-code":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"tutorial/demo/#scala-and-java-examples":{}}}],["java.lang.illegalaccesserror",{"_index":3795,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["java/scala",{"_index":1988,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{}},"title":{}}],["java_hom",{"_index":3374,"text":{"community/release-manager/":{},"community/release-manager/#0-software-requirement":{}},"title":{}}],["java_home=\"${java_hom",{"_index":3371,"text":{"community/release-manager/":{},"community/release-manager/#0-software-requirement":{}},"title":{}}],["javaconvers",{"_index":4205,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["javadoc",{"_index":95,"text":{"api/java-api/":{},"api/viz/java-api/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"community/publish/":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{"archive/api/sql/GeoSparkSQL-javadoc/":{},"community/publish/#javadoc-and-scaladoc":{}}}],["javadoc.jar",{"_index":3321,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["javardd",{"_index":1938,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["javasparkcontext",{"_index":1931,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["jbonofre@apache.org",{"_index":2913,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["jdk",{"_index":1691,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#v01-v07":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{}},"title":{}}],["jdk/jre",{"_index":1688,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["jean",{"_index":2910,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["jia",{"_index":1456,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{}},"title":{}}],["jiayu@apache.org",{"_index":2898,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["jiayuasu",{"_index":2897,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["jinxuan",{"_index":2894,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["jinxuanw@apache.org",{"_index":2896,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["jira",{"_index":2847,"text":{"community/contact/":{},"community/contact/#bug-reports":{},"community/contact/#feature-requests":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"community/rule/#pick-annouce-a-task-using-jira":{}},"title":{"community/rule/#pick-annouce-a-task-using-jira":{}}}],["job",{"_index":1964,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["jobj",{"_index":4110,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["jobj[70",{"_index":4111,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["join",{"_index":831,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#join-query":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"community/contact/":{},"community/contact/#discord-server":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/overview/":{},"setup/overview/#distributed-spatial-queries":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#global_1":{},"setup/release-notes/#highlights":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#python_1":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#join-query":{},"tutorial/sql/#register-sedonasql":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/sql/#join-query":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/sql/#join-query":{}}}],["join_typ",{"_index":4238,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["joinqueri",{"_index":1703,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{}}],["joinquery.distancejoinqueryflat",{"_index":3933,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{}},"title":{}}],["joinquery.spatialjoin",{"_index":3932,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{}},"title":{}}],["joinquery.spatialjoinqueri",{"_index":3793,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["joinquery.spatialjoinquery/distancejoinqueri",{"_index":3890,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-core":{}},"title":{}}],["joinquery.spatialjoinqueryflat",{"_index":3934,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{}},"title":{}}],["joinquerypartitioningtyp",{"_index":2637,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_2":{}},"title":{}}],["joinqueryraw",{"_index":3921,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{}},"title":{}}],["joinresultdf",{"_index":2720,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["joinresultpairrdd",{"_index":2721,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["jonathan",{"_index":1445,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["jordan",{"_index":1505,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["journal",{"_index":3137,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{}},"title":{}}],["journey",{"_index":1834,"text":{"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"setup/flink/install-scala/":{},"setup/install-scala/":{}},"title":{}}],["jpg",{"_index":1727,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["jre",{"_index":1780,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["js",{"_index":1888,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{}},"title":{}}],["json",{"_index":2595,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/rdd/":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{}}],["json.dumps(data",{"_index":4011,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["jt",{"_index":1482,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#v120":{}},"title":{"setup/maven-coordinates/#locationtech-jts-core-1180":{}}}],["jts2geojson",{"_index":3678,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/release-notes/":{},"setup/release-notes/#global_2":{},"setup/release-notes/#global_3":{}},"title":{"setup/maven-coordinates/#jts2geojson-0161":{}}}],["jtsplu",{"_index":1740,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["judgement",{"_index":536,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{}},"title":{}}],["juli",{"_index":3162,"text":{"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["julienpeloton",{"_index":1508,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["junit",{"_index":3434,"text":{"community/rule/":{},"community/rule/#develop-a-code-contribution":{}},"title":{}}],["jupyt",{"_index":3275,"text":{"community/publish/":{},"community/publish/#vote-email":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{},"setup/release-notes/":{},"setup/release-notes/#global_2":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/raster/":{},"tutorial/raster/#tutorials":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{}},"title":{"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}}}],["jvm",{"_index":1853,"text":{"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["k",{"_index":1724,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_1":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"setup/overview/":{},"setup/overview/#distributed-spatial-queries":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_1":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["kanchan",{"_index":2874,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["kanchanchi",{"_index":2876,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["kanchanchy@apache.org",{"_index":2877,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["kdb",{"_index":1615,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-partitioning":{}},"title":{}}],["kdbtree",{"_index":978,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{}}],["keep",{"_index":3032,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{}},"title":{}}],["keepcollaped=tru",{"_index":740,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{}},"title":{}}],["keepcollapsed:boolean",{"_index":743,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{}},"title":{}}],["keepcollapsed=fals",{"_index":742,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{}},"title":{}}],["keivan",{"_index":1449,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["kemper",{"_index":3132,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["kengo",{"_index":2888,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["kept",{"_index":2718,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{}},"title":{}}],["kernel",{"_index":3940,"text":{"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["key",{"_index":73,"text":{"community/publication/":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"download/":{},"download/#verify-the-integrity":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{}},"title":{"community/publication/#key-publications":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{}}}],["key'",{"_index":3487,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["keyid",{"_index":3390,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["kimahriman",{"_index":2872,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["kimahriman@apache.org",{"_index":2873,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["kind",{"_index":928,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{}},"title":{}}],["kipf",{"_index":3128,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["kml",{"_index":153,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromkml":{},"api/flink/Function/":{},"api/flink/Function/#st_askml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromkml":{},"api/sql/Function/":{},"api/sql/Function/#st_askml":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["kml:string",{"_index":154,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromkml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromkml":{}},"title":{}}],["knn",{"_index":1617,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_1":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/flink/sql/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_1":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql/":{}},"title":{"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/#knn-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/flink/sql/#knn-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql/#knn-query":{}}}],["knnqueri",{"_index":2103,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["know",{"_index":1667,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#send-the-invitation":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["known",{"_index":258,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_astext":{},"api/sql/Function/":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/release-notes/":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{}},"title":{"setup/release-notes/#known-issue":{}}}],["koci\u0144ski",{"_index":1442,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["komissarov",{"_index":1444,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["kroon|point",{"_index":2265,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["kryo",{"_index":1572,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["kryoseri",{"_index":1344,"text":{"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["kryoserializer.getnam",{"_index":2181,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["kryp",{"_index":1578,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#v110":{}},"title":{}}],["kyro",{"_index":1969,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{}},"title":{}}],["l",{"_index":3361,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["lab",{"_index":3090,"text":{"community/publication/":{},"community/publication/#publication":{}},"title":{}}],["lack",{"_index":269,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["lambda",{"_index":2067,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{}},"title":{}}],["lancast",{"_index":2654,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["lang",{"_index":43,"text":{"":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{}}}],["languag",{"_index":1854,"text":{"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"setup/release-notes/":{},"setup/release-notes/#sedona-110":{},"tutorial/raster/":{},"tutorial/rdd-r/":{},"tutorial/sql-r/":{},"tutorial/viz-r/":{}},"title":{"setup/flink/platform/":{},"setup/platform/":{},"tutorial/rdd-r/#spatial-rdd-applications-in-r-language":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}}}],["larg",{"_index":1497,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publish/":{},"community/publish/#announce-email":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-scala/":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v120":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}}}],["larger",{"_index":1876,"text":{"archive/download/project/":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_2":{}},"title":{}}],["last",{"_index":433,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_setpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_setpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"community/contributor/":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{}},"title":{}}],["lat/lon",{"_index":468,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["later",{"_index":825,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivideexplode":{},"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-120-and-later":{}}}],["latest",{"_index":55,"text":{"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"download/":{},"download/#github-repository":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{}},"title":{}}],["latter",{"_index":3615,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["launch",{"_index":3943,"text":{"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["layer",{"_index":2772,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#generate-map-tiles":{},"tutorial/viz/":{},"tutorial/viz/#generate-map-tiles":{}},"title":{}}],["ldap",{"_index":3070,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{}}],["lead",{"_index":1870,"text":{"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#python":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{}},"title":{}}],["leaflet",{"_index":1887,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{}},"title":{}}],["learn",{"_index":1841,"text":{"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/zeppelin/":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"setup/install-scala/":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd/":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/sql/":{},"tutorial/sql/#range-query":{},"tutorial/zeppelin/":{}},"title":{}}],["learner",{"_index":1838,"text":{"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"setup/install-scala/":{}},"title":{}}],["leav",{"_index":2842,"text":{"community/contact/":{},"community/contact/#mailing-list":{}},"title":{}}],["lefcoln",{"_index":3925,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{}},"title":{}}],["left",{"_index":888,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["left_attribute1",{"_index":4201,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["left_attribute2",{"_index":4202,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["left_col1",{"_index":3924,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{}},"title":{}}],["leftcoveredbyright",{"_index":3854,"text":{"setup/release-notes/":{},"setup/release-notes/#core":{}},"title":{}}],["leftgeometri",{"_index":4210,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["leftrdd",{"_index":4207,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["legaci",{"_index":3903,"text":{"setup/release-notes/":{}},"title":{"setup/release-notes/#geospark-legacy-release-notes":{}}}],["legal",{"_index":2937,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["legend",{"_index":2276,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["leitschuh",{"_index":1446,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["length",{"_index":701,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/rdd/":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/rdd/":{}},"title":{}}],["lenient",{"_index":4118,"text":{"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["less",{"_index":298,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buffer":{},"api/sql/Function/":{},"api/sql/Function/#st_buffer":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["lessdf",{"_index":1183,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_lessthan":{}},"title":{}}],["lessequaldf",{"_index":1186,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_lessthanequal":{}},"title":{}}],["lesser",{"_index":3655,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["level",{"_index":1300,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#generate-map-tiles":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#generate-map-tiles":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["leverag",{"_index":2779,"text":{"archive/tutorial/zeppelin/":{},"tutorial/zeppelin/":{}},"title":{}}],["le\u015bn",{"_index":2267,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["lgpl",{"_index":3597,"text":{"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["li",{"_index":2881,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["libari",{"_index":3653,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["libcurl4",{"_index":3355,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["libgeo",{"_index":3522,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["librari",{"_index":1836,"text":{"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/databricks/#pure-sql-environment":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#rdd":{},"setup/release-notes/#sedona-viz":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["licens",{"_index":1466,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#sedona-viz":{},"setup/release-notes/#v120":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}},"title":{}}],["lie",{"_index":439,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointonsurface":{},"api/sql/Function/":{},"api/sql/Function/#st_pointonsurface":{}},"title":{}}],["life",{"_index":3461,"text":{"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["light",{"_index":4250,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["lightgray",{"_index":2282,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["limit",{"_index":1806,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["line",{"_index":179,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_removepoint":{},"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"community/develop/":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/release-notes/":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-111":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#sedona-131":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/sql-python/":{},"tutorial/sql-python/#linestring":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{}}],["line1",{"_index":2304,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multilinestring":{}},"title":{}}],["line2",{"_index":2305,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multilinestring":{}},"title":{}}],["linear",{"_index":293,"text":{"api/flink/Function/":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_interiorringn":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["lineshap",{"_index":624,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_linefromtext":{}},"title":{}}],["linestr",{"_index":171,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_setpoint":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#query-center-geometry":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/sql-python/":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#supported-shapely-objects":{}},"title":{"archive/tutorial/geospark-sql-python/#linestring":{},"tutorial/sql-python/#linestring":{}}}],["linestring(0",{"_index":249,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_removepoint":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{}},"title":{}}],["linestring(1",{"_index":176,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_zmin":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_zmin":{}},"title":{}}],["linestring(10",{"_index":817,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{}},"title":{}}],["linestring(100",{"_index":680,"text":{"api/sql/Function/":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{}},"title":{}}],["linestring(21",{"_index":818,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{}},"title":{}}],["linestring(25",{"_index":704,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{}},"title":{}}],["linestring(5",{"_index":816,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{}},"title":{}}],["linestring(6",{"_index":735,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makepolygon":{}},"title":{}}],["linestring(60",{"_index":819,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{}},"title":{}}],["linestring(7",{"_index":734,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makepolygon":{}},"title":{}}],["linestring(85",{"_index":820,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{}},"title":{}}],["linestring,linestr",{"_index":2121,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{}},"title":{}}],["linestring><coordin",{"_index":155,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromkml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromkml":{}},"title":{}}],["linestring_rdd",{"_index":2149,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{}},"title":{}}],["linestringobject",{"_index":2623,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{}},"title":{}}],["linestringrdd",{"_index":1737,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{}},"title":{}}],["linestringshap",{"_index":626,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{}},"title":{}}],["linestringt",{"_index":625,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{}},"title":{}}],["linet",{"_index":623,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_linefromtext":{}},"title":{}}],["linework",{"_index":306,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{}},"title":{}}],["linha",{"_index":4050,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["link",{"_index":2975,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#announce-email":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["linux/mac",{"_index":3510,"text":{"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{}},"title":{}}],["list",{"_index":675,"text":{"api/sql/Function/":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Overview/":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/sql/":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/viz/sql/":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#installation":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_1":{},"community/contact/":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#become-a-committer":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#7-failed-vote":{},"community/publish/#announce-email":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"setup/zeppelin/":{},"setup/zeppelin/#installation":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_1":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"community/contact/#mailing-list":{}}}],["lit",{"_index":3958,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["liter",{"_index":4158,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["littl",{"_index":2829,"text":{"community/contact/":{},"community/contact/#community":{}},"title":{}}],["littler",{"_index":3354,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["liu",{"_index":1516,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["live",{"_index":3440,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["livi",{"_index":1963,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["load",{"_index":616,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v112":{},"setup/release-notes/#v120":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#load-shapefile-and-geojson":{}}}],["load_spatial_index_rdd_from_disc",{"_index":2151,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{}},"title":{}}],["load_spatial_rdd_from_disc",{"_index":2146,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{}},"title":{}}],["loader",{"_index":998,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#rs_getband":{}},"title":{"api/sql/Raster-loader/#geotiff-dataframe-loader":{}}}],["local",{"_index":955,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#make-a-sedona-release":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{"tutorial/demo/#run-template-projects-locally":{}}}],["locat",{"_index":702,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/release-notes/":{},"setup/release-notes/#v110":{},"setup/release-notes/#v120":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{}},"title":{}}],["locationtech",{"_index":3673,"text":{"setup/maven-coordinates/":{}},"title":{"setup/maven-coordinates/#locationtech-jts-core-1180":{}}}],["lock",{"_index":3892,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{}}],["log",{"_index":1647,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#python":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["logdiffer",{"_index":1191,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_logicaldifference":{}},"title":{}}],["logic",{"_index":535,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/project/":{},"archive/download/project/#self-contained-spark-projects":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{}},"title":{}}],["logicaldiffer",{"_index":1189,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_logicaldifference":{}},"title":{}}],["logicalov",{"_index":1194,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_logicalover":{}},"title":{}}],["logo",{"_index":2802,"text":{"asf/asf/":{},"asf/asf/#copyright":{}},"title":{}}],["logov",{"_index":1196,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_logicalover":{}},"title":{}}],["long",{"_index":2063,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["long/lat",{"_index":2038,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd/":{}},"title":{}}],["longer",{"_index":1658,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["longitude/latitud",{"_index":1330,"text":{"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["longtyp",{"_index":3950,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["look",{"_index":2003,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["loop",{"_index":1660,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["lot",{"_index":2705,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#other-queries":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#other-queries":{}},"title":{}}],["low",{"_index":3614,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{}},"title":{}}],["lower",{"_index":741,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["lowercas",{"_index":581,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["lsad",{"_index":2381,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["lt",{"_index":3538,"text":{"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#install-sedona-from-the-web-ui":{}},"title":{}}],["luca",{"_index":1535,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["l\u00f3gica",{"_index":4053,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["m",{"_index":404,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["m2",{"_index":3415,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["m2/settings.xml",{"_index":3414,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["mac",{"_index":3350,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#install-necessary-software":{}},"title":{}}],["machin",{"_index":1820,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#compile-r-html-docs":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"community/vote/#vote-a-sedona-release":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#mkdocs-website":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["maco",{"_index":3459,"text":{"community/vote/":{},"community/vote/#install-necessary-software":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["macro",{"_index":3530,"text":{"setup/compile/":{},"setup/compile/#mkdocs-website":{}},"title":{}}],["made",{"_index":3479,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["magnitud",{"_index":4249,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["mail",{"_index":2836,"text":{"community/contact/":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#become-a-committer":{},"community/publish/":{},"community/publish/#announce-email":{}},"title":{"community/contact/#mailing-list":{}}}],["main",{"_index":2743,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contributor/":{},"community/contributor/#committers":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"tutorial/demo/":{},"tutorial/demo/#scala":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["mainli",{"_index":2746,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"tutorial/viz/":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{}}],["maintain",{"_index":881,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"community/publish/":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"tutorial/core-python/":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{}},"title":{}}],["mainten",{"_index":3799,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-111":{},"setup/release-notes/#sedona-121":{}},"title":{}}],["major",{"_index":1701,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#project-management-committee-pmc":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/release-notes/":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#r":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["make",{"_index":592,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/rdd/":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#create-asf-account":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/develop/":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#compile-r-html-docs":{},"community/publish/#pass-email_1":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"community/rule/#review-a-pull-request":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#python":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{"community/publish/":{},"community/publish/#make-a-sedona-release":{},"community/rule/#make-a-pull-request":{}}}],["malka",{"_index":1448,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{}},"title":{}}],["malka@apache.org",{"_index":2884,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["manag",{"_index":1819,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"archive/tutorial/sql/":{},"community/contributor/":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-the-invitation":{},"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{},"community/release-manager/":{},"community/release-manager/#become-a-release-manager":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/install-scala/":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"tutorial/flink/sql/":{},"tutorial/sql/":{}},"title":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/release-manager/":{},"community/release-manager/#become-a-release-manager":{}}}],["mandatori",{"_index":1102,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{}},"title":{}}],["mani",{"_index":266,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/release-notes/":{},"setup/release-notes/#sedona-130":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/rdd/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["manipul",{"_index":3609,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["manner",{"_index":2817,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{}},"title":{}}],["manual",{"_index":1628,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/scalashell/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"community/publish/":{},"community/vote/":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{},"setup/install-scala/":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#v082-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{"archive/download/scalashell/#download-geospark-jar-manually":{},"community/publish/#manually-close-and-release-the-package":{},"community/vote/#check-files-manually":{},"setup/install-scala/#download-sedona-jar-manually":{}}}],["map",{"_index":48,"text":{"":{},"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#generate-map-tiles":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"community/publication/":{},"community/publication/#key-publications":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/release-notes/":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sql_2":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/raster/":{},"tutorial/raster/#api-docs":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/viz-gallery/":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#generate-map-tiles":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#store-map-tiles-on-disk":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"archive/tutorial/viz/#generate-map-tiles":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/raster/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/#generate-map-tiles":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#store-map-tiles-on-disk":{},"tutorial/viz/#why-scalable-map-visualization":{}}}],["mapbox",{"_index":2733,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["mapfunct",{"_index":4330,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["mappartit",{"_index":1654,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["mapper",{"_index":1657,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["mariano",{"_index":1439,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["markdown",{"_index":1827,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{}},"title":{}}],["mask",{"_index":1174,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{}},"title":{}}],["maskedvalu",{"_index":1178,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{}},"title":{}}],["massiv",{"_index":2744,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["master",{"_index":66,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#make-a-sedona-release":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/snapshot/#publish-a-snapshot-version":{},"download/":{},"download/#github-repository":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/install-scala/#self-contained-spark-projects":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["master(\"loc",{"_index":1864,"text":{"archive/download/project/":{},"archive/download/project/#package-the-project":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["master(\"spark://spark",{"_index":3966,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["master:7077",{"_index":3967,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["match",{"_index":1054,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"setup/databricks/":{}},"title":{}}],["materi",{"_index":1830,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{}},"title":{}}],["matrix",{"_index":1960,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["matter",{"_index":2350,"text":{"archive/tutorial/rdd/":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"tutorial/rdd/":{}},"title":{}}],["matur",{"_index":3661,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["maven",{"_index":1363,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v111":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#select-an-ide":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#set-up-dependencies":{},"community/develop/":{},"community/publish/":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/overview/":{},"setup/overview/#download-statistics":{},"setup/release-notes/":{},"setup/release-notes/#global_2":{},"setup/release-notes/#v101":{},"setup/release-notes/#v110":{},"setup/release-notes/#v111":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#set-up-dependencies":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{},"tutorial/viz/#set-up-dependencies":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"community/publish/#8-release-source-code-and-maven-package":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{}}}],["mavencoordiant",{"_index":3644,"text":{"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{}},"title":{}}],["max",{"_index":1263,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels":{}},"title":{}}],["max_valu",{"_index":4155,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["max_value).as(\"point",{"_index":3727,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["maxi",{"_index":213,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{}},"title":{}}],["maxima",{"_index":514,"text":{"api/flink/Function/":{},"api/flink/Function/#st_zmax":{},"api/sql/Function/":{},"api/sql/Function/#st_zmax":{}},"title":{}}],["maximum",{"_index":498,"text":{"api/flink/Function/":{},"api/flink/Function/#st_xmax":{},"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_xmax":{}},"title":{}}],["maximumi",{"_index":1168,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{}}],["maximumx",{"_index":1167,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{}}],["maxspe",{"_index":4078,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["maxvertic",{"_index":793,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{}},"title":{}}],["maxweight:doubl",{"_index":1259,"text":{"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{}},"title":{}}],["maxx",{"_index":212,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{}},"title":{}}],["maxx:decim",{"_index":216,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{}},"title":{}}],["maxy:decim",{"_index":217,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{}},"title":{}}],["mbr",{"_index":1707,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["mdm",{"_index":3173,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{}},"title":{}}],["mean",{"_index":99,"text":{"api/java-api/":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_mean":{},"api/viz/java-api/":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["mean_area",{"_index":4179,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["mean_area_sdf",{"_index":4178,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["meandf",{"_index":1198,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_mean":{}},"title":{}}],["meant",{"_index":3007,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["meantim",{"_index":2727,"text":{"archive/tutorial/viz/":{}},"title":{}}],["measur",{"_index":3774,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["mechan",{"_index":2938,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{}},"title":{}}],["megapixel",{"_index":1754,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["member",{"_index":1611,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#project-management-committee-pmc":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{"community/contributor/#nominate-a-committer-or-pmc-member":{}}}],["membership",{"_index":2988,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["memori",{"_index":1594,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{}},"title":{}}],["memory_onli",{"_index":2043,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{}},"title":{}}],["mention",{"_index":2283,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"community/publication/":{},"community/publication/#key-publications":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{}},"title":{}}],["mentor",{"_index":2903,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#create-asf-account":{},"community/contributor/#mentors":{}},"title":{"community/contributor/#mentors":{}}}],["menu",{"_index":3409,"text":{"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{}},"title":{}}],["merg",{"_index":715,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linemerge":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#improvement":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v112":{}},"title":{}}],["messag",{"_index":2968,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{}},"title":{}}],["meta",{"_index":1989,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{}},"title":{}}],["meter",{"_index":877,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["method",{"_index":1522,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{}}}],["mgmt",{"_index":3069,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{}},"title":{}}],["microscop",{"_index":3098,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#key-publications":{}},"title":{}}],["migrat",{"_index":3704,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-131":{}},"title":{}}],["mikhtoniuk",{"_index":1510,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["mile",{"_index":2641,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{}},"title":{}}],["min/max",{"_index":4340,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{}},"title":{}}],["min_valu",{"_index":4153,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["mind",{"_index":3448,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["mine",{"_index":1749,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{}},"title":{}}],["mini",{"_index":211,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{}},"title":{}}],["minima",{"_index":518,"text":{"api/flink/Function/":{},"api/flink/Function/#st_zmin":{},"api/sql/Function/":{},"api/sql/Function/#st_zmin":{}},"title":{}}],["minimum",{"_index":232,"text":{"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{}},"title":{}}],["minimumi",{"_index":1166,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{}}],["minimumx",{"_index":1165,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{}}],["minor",{"_index":3701,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-131":{}},"title":{}}],["minut",{"_index":1826,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/develop/":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{}},"title":{}}],["minx",{"_index":210,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{}},"title":{}}],["minx:decim",{"_index":214,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{}},"title":{}}],["miny:decim",{"_index":215,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{}},"title":{}}],["mishra",{"_index":1512,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["miss",{"_index":1587,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["mistak",{"_index":3754,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#python":{}},"title":{}}],["mit",{"_index":1467,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["mix",{"_index":1818,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["mixtur",{"_index":4221,"text":{"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["mkdir",{"_index":3241,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["mkdoc",{"_index":1828,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#3-update-mkdocsyml":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{}},"title":{"setup/compile/#mkdocs-website":{}}}],["mkdocs.yml",{"_index":1832,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#7-failed-vote":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{}},"title":{"community/publish/#3-update-mkdocsyml":{}}}],["ml",{"_index":3618,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["ml_",{"_index":3620,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["mobil",{"_index":3172,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{}},"title":{}}],["mode",{"_index":334,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_mode":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/release-notes/":{},"setup/release-notes/#v082-geospark-core":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["modedf",{"_index":1201,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_mode":{}},"title":{}}],["model",{"_index":1610,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["modern",{"_index":3123,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["modif",{"_index":3439,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["modifi",{"_index":2798,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{}}],["modified_polygon_sdf",{"_index":4182,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["modul",{"_index":1465,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"community/develop/":{},"community/publish/":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/flink/modules/":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/modules/":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#v120":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#supported-shapely-objects":{}},"title":{"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{}}}],["modulo",{"_index":1204,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_modulo":{}},"title":{}}],["modulodf",{"_index":1207,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_modulo":{}},"title":{}}],["moham",{"_index":2885,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["moment",{"_index":3627,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["mon",{"_index":3480,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["monitor",{"_index":3027,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["monotonically_increasing_id",{"_index":3963,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["more",{"_index":1014,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/viz/":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"community/contact/":{},"community/contact/#feature-requests":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/develop/":{},"community/develop/#python-developers":{},"community/develop/#r-developers":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["moreov",{"_index":2189,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["mosarwat@apache.org",{"_index":2887,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["motel",{"_index":2220,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["move",{"_index":1923,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"community/publish/":{},"community/publish/#upload-releases":{},"setup/release-notes/":{},"setup/release-notes/#sedona-python":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["much",{"_index":2828,"text":{"community/contact/":{},"community/contact/#community":{}},"title":{}}],["multi",{"_index":423,"text":{"api/flink/Function/":{},"api/flink/Function/#st_numgeometries":{},"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{}},"title":{}}],["multi)linestr",{"_index":359,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{}},"title":{}}],["multi)point",{"_index":358,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{}},"title":{}}],["multi)polygon",{"_index":361,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{}},"title":{}}],["multicurv",{"_index":360,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{}},"title":{}}],["multigeometri",{"_index":640,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_multi":{}},"title":{}}],["multilin",{"_index":189,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mlinefromtext":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{}},"title":{}}],["multilinestr",{"_index":182,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#supported-shapely-objects":{}},"title":{"archive/tutorial/geospark-sql-python/#multilinestring":{},"tutorial/sql-python/#multilinestring":{}}}],["multilinestring((0",{"_index":310,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{}},"title":{}}],["multilinestring((1",{"_index":185,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mlinefromtext":{}},"title":{}}],["multipartit",{"_index":3884,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-core":{}},"title":{}}],["multipl",{"_index":753,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/download/project/":{},"archive/download/project/#self-contained-spark-projects":{},"archive/tutorial/rdd/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"tutorial/rdd/":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["multipli",{"_index":1210,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{}},"title":{}}],["multiplyband",{"_index":1212,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_multiply":{}},"title":{}}],["multiplydf",{"_index":1158,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_multiply":{}},"title":{}}],["multiplyfactor",{"_index":1217,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_multiplyfactor":{}},"title":{}}],["multiplyfactordf",{"_index":1215,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_multiplyfactor":{}},"title":{}}],["multipoint",{"_index":389,"text":{"api/flink/Function/":{},"api/flink/Function/#st_linefrommultipoint":{},"api/sql/Function/":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_multi":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#supported-shapely-objects":{}},"title":{"archive/tutorial/geospark-sql-python/#multipoint":{},"tutorial/sql-python/#multipoint":{}}}],["multipoint((1",{"_index":364,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{}},"title":{}}],["multipoint((10",{"_index":390,"text":{"api/flink/Function/":{},"api/flink/Function/#st_linefrommultipoint":{},"api/sql/Function/":{},"api/sql/Function/#st_linefrommultipoint":{}},"title":{}}],["multipoint(40",{"_index":660,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{}},"title":{}}],["multipolygon",{"_index":192,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_symdifference":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#supported-shapely-objects":{}},"title":{"archive/tutorial/geospark-sql-python/#multipolygon":{},"tutorial/sql-python/#multipolygon":{}}}],["multipolygon(((0",{"_index":314,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{}},"title":{}}],["munich",{"_index":3134,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["museum",{"_index":2256,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["mutabl",{"_index":3878,"text":{"setup/release-notes/":{},"setup/release-notes/#core_1":{}},"title":{}}],["mutat",{"_index":4183,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["mvn",{"_index":1822,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"community/develop/":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"community/vote/#run-the-verify-script":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{}},"title":{}}],["mybind",{"_index":3276,"text":{"community/publish/":{},"community/publish/#vote-email":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["mydatafram",{"_index":931,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/tutorial/sql/":{},"tutorial/sql/":{}},"title":{}}],["mygeometrycolumn\").load(\"path/to/myfile.parquet",{"_index":3723,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["mygeosparksqldemo",{"_index":1347,"text":{"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{}},"title":{}}],["mygeosparkvizdemo",{"_index":1361,"text":{"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{}},"title":{}}],["myloc",{"_index":2631,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["mynam",{"_index":4342,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-row-objects":{}},"title":{}}],["mypointid",{"_index":857,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{}},"title":{}}],["mypolygonid",{"_index":853,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{}},"title":{}}],["mysedonasqldemo",{"_index":957,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{}},"title":{}}],["mysedonavizdemo",{"_index":1245,"text":{"api/viz/sql/":{},"api/viz/sql/#quick-start":{}},"title":{}}],["myshapefil",{"_index":584,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["myshapefile.dbf",{"_index":590,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["myshapefile.shp",{"_index":588,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["myshapefile.shx",{"_index":589,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["mytabl",{"_index":4267,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["n",{"_index":363,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_pointn":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["n/a",{"_index":3862,"text":{"setup/release-notes/":{},"setup/release-notes/#viz":{}},"title":{}}],["na",{"_index":4052,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["name",{"_index":1051,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#initiate-sparksession":{},"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/contributor/#committer-done-template":{},"community/contributor/#mentors":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#project-management-committee-pmc":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#get-spatial-table":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#initiate-sparksession":{}},"title":{"archive/tutorial/viz/#create-tile-name":{},"tutorial/viz/#create-tile-name":{}}}],["name1",{"_index":3288,"text":{"community/publish/":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{}},"title":{}}],["name2",{"_index":3289,"text":{"community/publish/":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{}},"title":{}}],["name3",{"_index":3290,"text":{"community/publish/":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{}},"title":{}}],["name4",{"_index":3291,"text":{"community/publish/":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{}},"title":{}}],["name>unidata",{"_index":3665,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["name_point",{"_index":4307,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["name_polygon",{"_index":4281,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["nasa",{"_index":1694,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global_1":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["nativ",{"_index":7,"text":{"":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#save-geoparquet":{},"tutorial/viz/":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{}}}],["nativejavagener",{"_index":1767,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["nband",{"_index":1010,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{}},"title":{}}],["nbr",{"_index":1133,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{}},"title":{}}],["nd",{"_index":4097,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["ndbi",{"_index":1134,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_normalizeddifference":{}},"title":{}}],["ndvi",{"_index":1222,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_normalizeddifference":{}},"title":{}}],["ne",{"_index":3324,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["nearest",{"_index":2107,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"setup/overview/":{},"setup/overview/#distributed-spatial-queries":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{}},"title":{}}],["nearnest",{"_index":2100,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["neat",{"_index":1768,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["necessari",{"_index":1785,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#develop-a-document-contribution":{},"community/vote/":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-python/":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{"community/vote/#install-necessary-software":{}}}],["necessarili",{"_index":2820,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{}},"title":{}}],["need",{"_index":476,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/download/zeppelin/#installation":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#generate-map-tiles":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-the-invitation":{},"community/develop/":{},"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/release-manager/#become-a-release-manager":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/databricks/":{},"setup/databricks/#community-edition-free-tier":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/databricks/#pure-sql-environment":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-python/#setup-environment-variables":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v120":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"setup/zeppelin/#installation":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#generate-map-tiles":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-map-tiles":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{}}],["neg",{"_index":429,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_setpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_setpoint":{}},"title":{}}],["neighbor",{"_index":2101,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"setup/overview/":{},"setup/overview/#distributed-spatial-queries":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{}},"title":{}}],["nest",{"_index":1064,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["nestedloopjudg",{"_index":3848,"text":{"setup/release-notes/":{},"setup/release-notes/#global_1":{}},"title":{}}],["netanel",{"_index":1447,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{}},"title":{}}],["netanel246",{"_index":2883,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["netcdf",{"_index":3658,"text":{"setup/maven-coordinates/":{}},"title":{"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}}}],["netcdf/hdf",{"_index":1683,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{}},"title":{}}],["network",{"_index":1802,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#key-publications":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["neumann",{"_index":3130,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["never",{"_index":3387,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["new",{"_index":412,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"community/contact/":{},"community/contact/#feature-requests":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#become-a-committer":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#close-a-vote":{},"community/contributor/#committer-done-template":{},"community/contributor/#create-asf-account":{},"community/contributor/#nominate-a-committer-or-pmc-member":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/rule/":{},"community/rule/#pick-annouce-a-task-using-jira":{},"setup/install-scala/":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-111":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_1":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/viz/":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{"setup/release-notes/#new-feature":{},"setup/release-notes/#new-features":{}}}],["new.3.nam",{"_index":4042,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["new_geometri",{"_index":4194,"text":{"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{}},"title":{}}],["newband",{"_index":1142,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{}},"title":{}}],["newcountyshap",{"_index":2694,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#range-query":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["newcountyshape|_c1|_c2",{"_index":2695,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["newer",{"_index":2931,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{}},"title":{}}],["newest",{"_index":2010,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#installation":{}},"title":{}}],["newinst",{"_index":4273,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#initiate-stream-environment":{}},"title":{}}],["newlevel",{"_index":1937,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["newli",{"_index":2809,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["next",{"_index":3018,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{}},"title":{}}],["node",{"_index":2018,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#installation":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}}}],["nodepattern",{"_index":3540,"text":{"setup/databricks/":{},"setup/databricks/#advanced-editions":{}},"title":{}}],["nomin",{"_index":2942,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{}},"title":{"community/contributor/#nominate-a-committer-or-pmc-member":{}}}],["non",{"_index":595,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"community/publish/":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}}}],["none",{"_index":1525,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{},"setup/release-notes/":{},"setup/release-notes/#v101":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{}},"title":{}}],["nonsens",{"_index":1255,"text":{"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{}},"title":{}}],["noreport",{"_index":3362,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["noreturn",{"_index":2177,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{}},"title":{}}],["normal",{"_index":394,"text":{"api/flink/Function/":{},"api/flink/Function/#st_normalize":{},"api/sql/Function/":{},"api/sql/Function/#st_normalize":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_normalize":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/project/":{},"archive/download/project/#submit-the-compiled-jar":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["normalizeddf",{"_index":1223,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_normalizeddifference":{}},"title":{}}],["normalizeddiffer",{"_index":1144,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{}},"title":{}}],["normdiffer",{"_index":1225,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_normalizeddifference":{}},"title":{}}],["notabl",{"_index":2947,"text":{"community/contributor/":{},"community/contributor/#call-for-a-vote":{}},"title":{}}],["note",{"_index":22,"text":{"":{},"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/java-api/":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Function/":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_transform":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#range-join":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/viz/java-api/":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"api/viz/sql/#st_tilename":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#installation":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#python":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#announce-email":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/release-notes/":{},"setup/zeppelin/":{},"setup/zeppelin/#installation":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/demo/":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#range-query":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{},"setup/release-notes/#geospark-legacy-release-notes":{}}}],["notebook",{"_index":2786,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/publish/":{},"community/publish/#vote-email":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{},"setup/release-notes/":{},"setup/release-notes/#global_2":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/raster/":{},"tutorial/raster/#tutorials":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}}}],["notes.md",{"_index":3269,"text":{"community/publish/":{},"community/publish/#announce-email":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["noth",{"_index":1671,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["notic",{"_index":1939,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/vote/":{},"community/vote/#check-files-manually":{},"community/vote/#vote-a-sedona-release":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{"community/contributor/#send-a-notice-to-ipmc":{}}}],["notif",{"_index":479,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{}},"title":{}}],["notifi",{"_index":3026,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["novemb",{"_index":3153,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["now",{"_index":32,"text":{"":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#display-geosparkviz-results":{},"archive/tutorial/faq/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#render-map-tiles":{},"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#v01-v07":{},"setup/zeppelin/":{},"setup/zeppelin/#display-sedonaviz-results":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#render-map-tiles":{}},"title":{"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink":{},"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"#11232021-sedona-111-incubating-is-released-it-now-supports-spark-32":{}}}],["npm",{"_index":3338,"text":{"community/publish/":{},"community/publish/#9-release-sedona-python-and-zeppelin":{}},"title":{}}],["nth",{"_index":356,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_setpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_setpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["null",{"_index":283,"text":{"api/flink/Function/":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_z":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/sql/Function/":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["nullabl",{"_index":1007,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"tutorial/core-python/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["nullpointerexcept",{"_index":3857,"text":{"setup/release-notes/":{},"setup/release-notes/#core":{}},"title":{}}],["nullpointexcept",{"_index":1494,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["null|nul",{"_index":2672,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["null|point",{"_index":2270,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["num_partit",{"_index":3902,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-python":{}},"title":{}}],["number",{"_index":397,"text":{"api/flink/Function/":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_numinteriorrings":{},"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_numgeometries":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_subdivide":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#rs_getband":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/rdd/":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#v112":{},"setup/release-notes/#v131":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["numer",{"_index":1464,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"community/contributor/":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["o",{"_index":3365,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["object",{"_index":641,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_multi":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_1":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#reload-a-saved-spatialrdd":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/overview/":{},"setup/release-notes/":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/core-python/#reload-a-saved-spatialrdd":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_1":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#reload-a-saved-spatialrdd":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/tutorial/geospark-sql-python/#creating-spark-dataframe-based-on-shapely-objects":{},"archive/tutorial/geospark-sql-python/#example-usage-for-shapely-objects":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"setup/overview/#complex-spatial-objects":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/sql-python/#creating-spark-dataframe-based-on-shapely-objects":{},"tutorial/sql-python/#example-usage-for-shapely-objects":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/viz/#pixelize-spatial-objects":{}}}],["object['current_snapshot",{"_index":3690,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{}},"title":{}}],["object_rdd",{"_index":2066,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{}},"title":{}}],["objectfil",{"_index":2644,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["objectrdd",{"_index":2333,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["objectrdd.indexedrawrdd.saveasobjectfile(\"hdfs://path",{"_index":2642,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["objectrdda",{"_index":2638,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{}},"title":{}}],["objectrddb",{"_index":2639,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{}},"title":{}}],["observ",{"_index":1251,"text":{"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{}},"title":{}}],["obtain",{"_index":1108,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{},"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/download/project/":{},"archive/download/project/#quick-start":{},"community/contact/":{},"community/contact/#community":{},"community/release-manager/":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{}},"title":{"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}}}],["occasion",{"_index":3033,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["occupi",{"_index":2349,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["offer",{"_index":2722,"text":{"archive/tutorial/viz/":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"tutorial/viz/":{}},"title":{}}],["offici",{"_index":1401,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#introduction":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#v131":{},"tutorial/core-python/":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{}},"title":{}}],["offset",{"_index":1933,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd/":{}},"title":{}}],["ogc",{"_index":3790,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["old",{"_index":58,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/rdd/":{},"download/":{},"download/#github-repository":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/rdd/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/#geospark-viz-old":{}}}],["omit",{"_index":451,"text":{"api/flink/Function/":{},"api/flink/Function/#st_removepoint":{},"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{}},"title":{}}],["on",{"_index":452,"text":{"api/flink/Function/":{},"api/flink/Function/#st_removepoint":{},"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_removepoint":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#self-contained-spark-projects":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"archive/tutorial/zeppelin/":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#call-for-a-vote":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/release-notes/":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#render-the-image":{},"tutorial/viz/#store-map-tiles-on-disk":{},"tutorial/zeppelin/":{}},"title":{}}],["onc",{"_index":2082,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#create-asf-account":{},"community/contributor/#pmc-annoucement":{},"community/publish/":{},"community/publish/#manually-close-and-release-the-package":{},"community/publish/#pass-email_1":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["onlin",{"_index":3462,"text":{"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["onofr",{"_index":2912,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["op",{"_index":4279,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["open",{"_index":1857,"text":{"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#enable-geospark-zeppelin":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"community/develop/":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/zeppelin/":{},"setup/zeppelin/#enable-sedona-zeppelin":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{"archive/download/project/#open-geospark-template-project":{}}}],["openjdk",{"_index":1729,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["openjdk@8",{"_index":3366,"text":{"community/release-manager/":{},"community/release-manager/#0-software-requirement":{}},"title":{}}],["openssl",{"_index":3356,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["openstreetmap",{"_index":1301,"text":{"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{}},"title":{}}],["oper",{"_index":529,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/raster/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{"api/sql/Raster-operators/":{}}}],["opinion",{"_index":3013,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["optim",{"_index":832,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"setup/release-notes/":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#v01-v07":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{}}}],["option",{"_index":129,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Function/":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_transform":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_html":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"api/viz/sql/#st_render":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/download/zeppelin/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"setup/compile/":{},"setup/compile/#compile-with-different-targets":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#python":{},"setup/release-notes/#v01-v07":{},"setup/zeppelin/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{}},"title":{"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/download/zeppelin/#create-helium-folder-optional":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"setup/zeppelin/#create-helium-folder-optional":{}}}],["order",{"_index":446,"text":{"api/flink/Function/":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_transform":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/Function/":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_transform":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_orderingequals":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/databricks/#pure-sql-environment":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#improvement_1":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{}},"title":{}}],["ordin",{"_index":421,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{}},"title":{}}],["orenstein",{"_index":1504,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["org",{"_index":960,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"setup/databricks/":{},"setup/databricks/#initialise":{}},"title":{}}],["org.apache.flink.types.row",{"_index":4343,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-row-objects":{}},"title":{}}],["org.apache.maven.plugins:maven",{"_index":3234,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{}},"title":{}}],["org.apache.sedona",{"_index":3656,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["org.apache.sedona.core.formatmapper.formatutil",{"_index":4336,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{}},"title":{}}],["org.apache.sedona.core.serde.sedonakryoregistr",{"_index":954,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{}},"title":{}}],["org.apache.sedona.core.spatialrdd.spatialrdd",{"_index":4112,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["org.apache.sedona.core.spatialrdd.spatialrdd@422afc5a",{"_index":4113,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["org.apache.sedona.viz.core.serde.sedonavizkryoregistr",{"_index":1244,"text":{"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["org.apache.sedona.viz.sql.sedonavizextensions,org.apache.sedona.sql.sedonasqlextens",{"_index":3583,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{}},"title":{}}],["org.apache.sedona:sedona",{"_index":3552,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{}},"title":{}}],["org.apache.spark",{"_index":1867,"text":{"archive/download/project/":{},"archive/download/project/#package-the-project":{}},"title":{}}],["org.apache.spark.serializer.kryoseri",{"_index":952,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["org.apache.spark.sql.catalyst.expressions.gener",{"_index":3539,"text":{"setup/databricks/":{},"setup/databricks/#advanced-editions":{}},"title":{}}],["org.apache.spark.sql.geosparksql.expressions.st_contain",{"_index":1342,"text":{"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{}},"title":{}}],["org.apache.spark.sql.sedona_sql.expressions.st_aggreg",{"_index":4216,"text":{"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["org.apache.spark.sql.sedona_sql.expressions.st_constructor",{"_index":4214,"text":{"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["org.apache.spark.sql.sedona_sql.expressions.st_contain",{"_index":925,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{}},"title":{}}],["org.apache.spark.sql.sedona_sql.expressions.st_funct",{"_index":4213,"text":{"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["org.apache.spark.sql.sedona_sql.expressions.st_pred",{"_index":4215,"text":{"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["org.apache.spark.storage.storageutil",{"_index":3796,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["org.datasyslab",{"_index":1368,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["org.datasyslab.geospark.serde.geosparkkryoregistr",{"_index":2183,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{}},"title":{}}],["org.datasyslab.sernetcdf",{"_index":3715,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement":{}},"title":{}}],["org.datasyslab:geospark:1.2.0,org.datasyslab:geospark",{"_index":1879,"text":{"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{}},"title":{}}],["org.datasyslab:geospark:geospark_vers",{"_index":1878,"text":{"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{}},"title":{}}],["org.datasyslab:geotool",{"_index":3554,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["org.datasyslab:sernetcdf:0.1.0",{"_index":3637,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["org.locationtech.jt",{"_index":3677,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{}},"title":{}}],["org.locationtech.jts.geom.geometri",{"_index":4329,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["org.locationtech.jts.geom.geometryfactori",{"_index":4341,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{}},"title":{}}],["org.locationtech.jts:jt",{"_index":3638,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["org.wololo",{"_index":3683,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{}},"title":{}}],["org.wololo:jts2geojson:0.14.3",{"_index":3640,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["organ",{"_index":3061,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"tutorial/python-vector-osm/":{}},"title":{"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}}}],["origin",{"_index":264,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_linemerge":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v01-v07":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/core-python/":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{}},"title":{}}],["osgeo",{"_index":3652,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["osm",{"_index":3945,"text":{"tutorial/python-vector-osm/":{}},"title":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}}}],["osm_id|cod",{"_index":2261,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["oss",{"_index":1388,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#buildsbt":{}},"title":{}}],["other",{"_index":3830,"text":{"setup/release-notes/":{},"setup/release-notes/#rdd":{}},"title":{}}],["otherwis",{"_index":284,"text":{"api/flink/Function/":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_z":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Function/":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_z":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["othwerwis",{"_index":3650,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["ouput",{"_index":1270,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{}},"title":{}}],["out",{"_index":369,"text":{"api/flink/Function/":{},"api/flink/Function/#st_interiorringn":{},"api/sql/Function/":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#generate-a-single-image":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/develop/":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{},"tutorial/viz/":{},"tutorial/viz/#generate-a-single-image":{}},"title":{}}],["out:json",{"_index":3995,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["outcom",{"_index":3446,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["outer",{"_index":893,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["outlin",{"_index":2319,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/viz/":{},"tutorial/flink/sql/":{},"tutorial/rdd/":{},"tutorial/sql/":{},"tutorial/viz/":{}},"title":{}}],["outofmemori",{"_index":1496,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["output",{"_index":252,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_z":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-loader/#rs_html":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format":{},"archive/tutorial/rdd/#output-format_1":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#output-format_2":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format":{},"tutorial/rdd/#output-format_1":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{"api/sql/Raster-loader/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/rdd/#output-format":{},"archive/tutorial/rdd/#output-format_1":{},"archive/tutorial/rdd/#output-format_2":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#output-format_3":{},"tutorial/rdd/#output-format":{},"tutorial/rdd/#output-format_1":{},"tutorial/rdd/#output-format_2":{}}}],["output_loc",{"_index":4240,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["outsid",{"_index":4123,"text":{"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["over",{"_index":1797,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#range-query":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/sql/":{},"tutorial/sql/#range-query":{}},"title":{}}],["overal",{"_index":2981,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{}},"title":{}}],["overflow",{"_index":1644,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["overhead",{"_index":1652,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["overlap",{"_index":994,"text":{"api/sql/Predicate/":{},"api/sql/Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["overlay",{"_index":2780,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["overlayoper",{"_index":1762,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["overload",{"_index":1990,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["overpass",{"_index":3990,"text":{"tutorial/python-vector-osm/":{}},"title":{"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}}}],["overpass_queri",{"_index":3994,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["overpass_url",{"_index":3991,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["overrid",{"_index":1061,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["oversight",{"_index":2994,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["overview",{"_index":521,"text":{},"title":{"api/flink/Overview/":{},"setup/overview/":{}}}],["overwrit",{"_index":1057,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["owner",{"_index":3491,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["p",{"_index":2232,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["p.fclass",{"_index":2231,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["p1",{"_index":4064,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["p1.id",{"_index":4065,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["p2",{"_index":4073,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["p2.id",{"_index":4066,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["p2.inclin",{"_index":4068,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["p2.maxspe",{"_index":4067,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["p2.name",{"_index":4070,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["p2.node",{"_index":4071,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["p2.surfac",{"_index":4069,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["p2.total_nod",{"_index":4072,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["packag",{"_index":1843,"text":{"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#installation":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#introduction":{},"community/publish/":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#improvement_1":{},"setup/zeppelin/":{},"setup/zeppelin/#installation":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{}},"title":{"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"community/publish/#8-release-source-code-and-maven-package":{},"community/publish/#manually-close-and-release-the-package":{},"tutorial/demo/#compile-and-package":{},"tutorial/sql-python/#register-package":{}}}],["page",{"_index":1138,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"archive/download/cluster/":{},"archive/download/cluster/#set-up-your-apache-spark-cluster":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/viz/":{},"community/contributor/":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#make-a-sedona-release":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/cluster/":{},"setup/cluster/#set-up-your-apache-spark-cluster":{},"tutorial/flink/sql/":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/viz/":{}},"title":{}}],["pair",{"_index":838,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{}},"title":{}}],["pair_rdd",{"_index":4236,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["pairrdd",{"_index":2118,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["panda",{"_index":2191,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["pandey",{"_index":3126,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["paper",{"_index":3094,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["para",{"_index":3855,"text":{"setup/release-notes/":{},"setup/release-notes/#core":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["paragraph",{"_index":2787,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["parallel",{"_index":1760,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"tutorial/viz/":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["param",{"_index":2176,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{}},"title":{}}],["paramet",{"_index":474,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_transform":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/sql/":{},"api/viz/sql/#st_render":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v110":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{"api/sql/Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/":{}}}],["params={'data",{"_index":4003,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["parent",{"_index":3075,"text":{"community/develop/":{},"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["parquet",{"_index":3880,"text":{"setup/release-notes/":{},"setup/release-notes/#sql_3":{}},"title":{}}],["pars",{"_index":4098,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["part",{"_index":666,"text":{"api/sql/Function/":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_symdifference":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#v112":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["part3",{"_index":524,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/tutorial/sql/":{},"setup/release-notes/":{},"setup/release-notes/#v100":{},"tutorial/flink/sql/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{}},"title":{}}],["parti",{"_index":3103,"text":{"community/publication/":{},"setup/maven-coordinates/":{}},"title":{"community/publication/#third-party-evaluation":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{}}}],["partial",{"_index":2166,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#python":{}},"title":{}}],["particip",{"_index":2827,"text":{"community/contact/":{},"community/contact/#community":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{},"community/rule/":{},"community/rule/#code-of-conduct":{}},"title":{}}],["particular",{"_index":1107,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_modulo":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#v110":{}},"title":{}}],["partit",{"_index":882,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#rdd":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v112":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{}},"title":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/rdd/#use-spatial-partitioning":{}}}],["partition",{"_index":2116,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-partitioning":{}},"title":{}}],["partitionfilt",{"_index":2245,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["pass",{"_index":1492,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"community/publish/":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"community/vote/#vote-a-sedona-release":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v120":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#register-package":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{"community/publish/#pass-email":{},"community/publish/#pass-email_1":{}}}],["passphras",{"_index":3389,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["password",{"_index":1774,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["password>your_asf_password</password",{"_index":3422,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["password>your_github_token</password",{"_index":3419,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["past",{"_index":83,"text":{"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"download/":{},"download/#past-releases":{}},"title":{"download/#past-releases":{}}}],["patch",{"_index":1534,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contact/#community":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#pmc-annoucement":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["path",{"_index":225,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/develop/":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#v080-geospark-core":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{},"tutorial/rdd/":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{}}],["path/to/geosparkjars.jar",{"_index":1884,"text":{"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{}},"title":{}}],["path/to/sedonajars.jar",{"_index":3647,"text":{"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-manually":{}},"title":{}}],["path/to/yourjar.jar",{"_index":1849,"text":{"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/download/project/#submit-the-compiled-jar":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{}},"title":{}}],["path>/incub",{"_index":4130,"text":{"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{}},"title":{}}],["path_to_input_geotiff_imag",{"_index":1059,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["patienc",{"_index":1804,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["pattern",{"_index":1958,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["paw",{"_index":1441,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["pawelkocinski",{"_index":3476,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["pd",{"_index":3948,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["pd.dataframe(isolate_ids[\"id\"].iloc[0]).drop_dupl",{"_index":4028,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["pdt",{"_index":3484,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["peer",{"_index":3006,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["peniaziev",{"_index":1502,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["peopl",{"_index":1975,"text":{"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"community/contact/":{},"community/contact/#community":{},"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{}},"title":{}}],["per",{"_index":64,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"download/":{},"download/#github-repository":{},"setup/compile/":{},"setup/compile/#download-staged-jars":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-to-spatialrdd":{}},"title":{}}],["percival",{"_index":2915,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["percivall@apache.org",{"_index":2916,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["perform",{"_index":834,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#vote-email":{},"community/release-manager/":{},"community/release-manager/#become-a-release-manager":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global_1":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v131":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{}},"title":{}}],["perimet",{"_index":387,"text":{"api/flink/Function/":{},"api/flink/Function/#st_length":{},"api/sql/Function/":{},"api/sql/Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{}},"title":{}}],["period",{"_index":2939,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#send-a-notice-to-ipmc":{}},"title":{}}],["permalink",{"_index":3284,"text":{"community/publish/":{},"community/publish/#announce-email":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["perman",{"_index":2131,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"tutorial/core-python/":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-an-spatialrdd-not-indexed":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql/#save-to-permanent-storage":{}}}],["permiss",{"_index":3470,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["perr",{"_index":1506,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["persist",{"_index":1538,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v112":{}},"title":{}}],["person",{"_index":3406,"text":{"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{}},"title":{"community/release-manager/#5-get-github-personal-access-token-classic":{}}}],["perspect",{"_index":3091,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#key-publications":{}},"title":{}}],["petabyt",{"_index":1695,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["pgp",{"_index":3282,"text":{"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["phase",{"_index":1705,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["physic",{"_index":842,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["pick",{"_index":1912,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"community/rule/":{},"community/rule/#pick-annouce-a-task-using-jira":{},"setup/databricks/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"community/rule/#pick-annouce-a-task-using-jira":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}}}],["pid",{"_index":2773,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#render-map-tiles":{},"tutorial/viz/":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#render-map-tiles":{}},"title":{}}],["pip",{"_index":2021,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{}},"title":{}}],["pip3",{"_index":3523,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["pipelin",{"_index":1759,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["pipenv",{"_index":2023,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["pipfil",{"_index":3591,"text":{"setup/install-python/":{}},"title":{}}],["pixel",{"_index":1205,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_modulo":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"api/viz/sql/#st_pixelize":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#render-the-image":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#colorize-pixels_1":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#colorize-pixels_1":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#pixelize-spatial-objects":{}}}],["pixelaggreg",{"_index":2761,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#render-the-image":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#render-the-image":{}},"title":{}}],["place",{"_index":776,"text":{"api/sql/Function/":{},"api/sql/Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#self-contained-spark-projects":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{}},"title":{}}],["plain",{"_index":2707,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{}}],["plan",{"_index":843,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["platform",{"_index":3592,"text":{"setup/install-python/":{},"setup/install-python/#install-sedona":{}},"title":{}}],["play",{"_index":3588,"text":{"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["pleas",{"_index":20,"text":{"":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/java-api/":{},"api/r-api/":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/viz/java-api/":{},"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#display-geosparkviz-results":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/faq/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"archive/tutorial/sql/#other-queries":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-the-invitation":{},"community/develop/":{},"community/publication/":{},"community/publication/#key-publications":{},"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#7-failed-vote":{},"community/publish/#announce-email":{},"community/publish/#fix-signature-issues":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"community/rule/#develop-a-document-contribution":{},"community/rule/#make-a-pull-request":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"download/":{},"download/#security":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#mkdocs-website":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/install-scala/#spark-sql-shell":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v120":{},"setup/zeppelin/":{},"setup/zeppelin/#display-sedonaviz-results":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#installation":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#installation":{},"tutorial/sql-python/#register-package":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/sql/#other-queries":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#visualize-spatialrdd":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{}}}],["plot",{"_index":1268,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#sedona-viz":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#render-the-image":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["plug",{"_index":3939,"text":{"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{}},"title":{}}],["plugin",{"_index":2774,"text":{"archive/tutorial/zeppelin/":{},"community/develop/":{},"community/develop/#ide":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"tutorial/zeppelin/":{}},"title":{}}],["plugin:2.3.2:perform",{"_index":3235,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{}},"title":{}}],["pmc",{"_index":2866,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#close-a-vote":{},"community/contributor/#committer-done-template":{},"community/contributor/#create-asf-account":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#project-management-committee-pmc":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{"community/contributor/#nominate-a-committer-or-pmc-member":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#project-management-committee-pmc":{}}}],["pmc/ppmc'",{"_index":3014,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["png",{"_index":1282,"text":{"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_render":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_render":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"tutorial/viz/":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{}}],["podl",{"_index":2989,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["poi",{"_index":2228,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["point",{"_index":200,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_point":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_issimple":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_z":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_npoints":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_z":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/tutorial/geospark-sql-python/#point":{},"tutorial/sql-python/#point":{}}}],["point(0",{"_index":770,"text":{"api/sql/Function/":{},"api/sql/Function/#st_pointonsurface":{}},"title":{}}],["point(1",{"_index":420,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_ndims":{}},"title":{}}],["point(100",{"_index":788,"text":{"api/sql/Function/":{},"api/sql/Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{}},"title":{}}],["point(160",{"_index":687,"text":{"api/sql/Function/":{},"api/sql/Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{}},"title":{}}],["point(2.5",{"_index":773,"text":{"api/sql/Function/":{},"api/sql/Function/#st_pointonsurface":{}},"title":{}}],["point(21",{"_index":250,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{}},"title":{}}],["point(21.427834",{"_index":350,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geohash":{},"api/sql/Function/":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_geohash":{}},"title":{}}],["point(40.7128",{"_index":163,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{}},"title":{}}],["point(45.342524",{"_index":647,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collect":{}},"title":{}}],["point,polygon",{"_index":2119,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{}},"title":{}}],["point/polygon/linestr",{"_index":2616,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{}},"title":{}}],["point_df",{"_index":4223,"text":{"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["point_rdd",{"_index":2047,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{}},"title":{}}],["pointb",{"_index":286,"text":{"api/flink/Function/":{},"api/flink/Function/#st_azimuth":{},"api/sql/Function/":{},"api/sql/Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{}},"title":{}}],["pointdata",{"_index":4134,"text":{"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-pure-sql/#work-with-data":{}},"title":{}}],["pointdf",{"_index":116,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_within":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{}},"title":{}}],["pointdf.pointshap",{"_index":896,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["pointdf1",{"_index":861,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{}},"title":{}}],["pointdf2",{"_index":862,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{}},"title":{}}],["pointdf2.pointshap",{"_index":912,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["pointer",{"_index":1619,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v082-geospark-core":{}},"title":{}}],["pointobject",{"_index":2618,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["pointraw",{"_index":4129,"text":{"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-pure-sql/#transform-the-data":{}},"title":{}}],["pointrdd",{"_index":1928,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["pointrdd/polygonrdd/linestringrdd",{"_index":2144,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["pointrddinputloc",{"_index":2330,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["pointrddoffset",{"_index":2331,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["pointrddsplitt",{"_index":2332,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["points_geom",{"_index":2211,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["points_tb",{"_index":4054,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["points_tb.createorreplacetempview(\"points_tb",{"_index":4060,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["points_tb.printschema",{"_index":4059,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["points_tb.select(\"new.0\",\"new.1",{"_index":4057,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["points_tb.show(5",{"_index":4061,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["points_tb.withcolumnrenamed(\"0\",\"lat\").withcolumnrenamed(\"1\",\"lon",{"_index":4058,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["pointshap",{"_index":205,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_point":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-pure-sql/#work-with-data":{}},"title":{}}],["pointshape#415",{"_index":915,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["pointshape#43",{"_index":846,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{}},"title":{}}],["pointshape#52",{"_index":898,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["pointshape1",{"_index":863,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{}},"title":{}}],["pointshape1#12",{"_index":866,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{}},"title":{}}],["pointshape2",{"_index":864,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{}},"title":{}}],["pointshape2#33",{"_index":867,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{}},"title":{}}],["pointtabl",{"_index":206,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_point":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_pixelize":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["pois_per_counti",{"_index":2249,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["polgyon",{"_index":664,"text":{"api/sql/Function/":{},"api/sql/Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{}},"title":{}}],["polit",{"_index":3441,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["polygon",{"_index":119,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_union_aggr":{},"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#polygon":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#polygon":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#range-query":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/sql-python/#polygon":{}}}],["polygon((0",{"_index":336,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_zmax":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_zmax":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_orderingequals":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{}},"title":{}}],["polygon((1",{"_index":632,"text":{"api/sql/Function/":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{}},"title":{}}],["polygon((15",{"_index":800,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["polygon((2",{"_index":548,"text":{"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_orderingequals":{}},"title":{}}],["polygon((20",{"_index":801,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["polygon((26.428571428571427",{"_index":802,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["polygon((30",{"_index":811,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["polygon((34.0476190",{"_index":809,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["polygon((35",{"_index":794,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["polygon((37.8571428",{"_index":806,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["polygon((37.857142857142854",{"_index":798,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["polygon((45",{"_index":813,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["polygon,linestr",{"_index":2122,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{}},"title":{}}],["polygon,polygon",{"_index":2120,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{}},"title":{}}],["polygon.csv",{"_index":4235,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["polygon.json",{"_index":2368,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["polygon0",{"_index":4282,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["polygon1",{"_index":4283,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["polygon2",{"_index":4284,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["polygon3",{"_index":4286,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["polygon4",{"_index":4288,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["polygon5",{"_index":4290,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["polygon6",{"_index":4292,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["polygon7",{"_index":4294,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["polygon8",{"_index":4296,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["polygon9",{"_index":4298,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["polygon_rdd",{"_index":2148,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["polygon_sdf",{"_index":4170,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["polygondata",{"_index":4135,"text":{"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-pure-sql/#work-with-data":{}},"title":{}}],["polygondf",{"_index":122,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_union_aggr":{},"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_area":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_distance":{},"api/flink/Function/#st_envelope":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_issimple":{},"api/flink/Function/#st_isvalid":{},"api/flink/Function/#st_length":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_transform":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_area":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_convexhull":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_length":{},"api/sql/Function/#st_npoints":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_transform":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_pixelize":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{}}],["polygonjsondf",{"_index":612,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{}},"title":{}}],["polygonobject",{"_index":2621,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{}},"title":{}}],["polygonraw",{"_index":4132,"text":{"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-pure-sql/#transform-the-data":{}},"title":{}}],["polygonrdd",{"_index":1929,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{}},"title":{}}],["polygonrdd/linestringrdd",{"_index":2334,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["polygonrddendoffset",{"_index":2344,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["polygonrddinputloc",{"_index":2342,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["polygonrddsplitt",{"_index":2345,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["polygonrddstartoffset",{"_index":2343,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["polygonshap",{"_index":123,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_union_aggr":{},"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-pure-sql/#work-with-data":{}},"title":{}}],["polygonshape#20",{"_index":845,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{}},"title":{}}],["polygonshape#30",{"_index":904,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["polygont",{"_index":142,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{}},"title":{}}],["polyon",{"_index":2341,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["pom",{"_index":3320,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["pom.xml",{"_index":945,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"community/develop/":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#snapshot-versions":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#set-up-dependencies":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"setup/maven-coordinates/#pomxml":{}}}],["pop_est",{"_index":4190,"text":{"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{}},"title":{}}],["posit",{"_index":244,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_removepoint":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#nominate-a-committer-or-pmc-member":{}},"title":{}}],["possess",{"_index":1272,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/rdd/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/rdd/":{}},"title":{}}],["possibl",{"_index":973,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format_3":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["post",{"_index":2839,"text":{"community/contact/":{},"community/contact/#mailing-list":{}},"title":{}}],["postfix",{"_index":3208,"text":{"community/publish/":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{}},"title":{}}],["postgi",{"_index":265,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{}},"title":{}}],["ppmc",{"_index":2967,"text":{"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#make-a-sedona-release":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["ppmc/pmc",{"_index":3010,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["pr",{"_index":1410,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"community/rule/#review-a-pull-request":{},"setup/release-notes/":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{}},"title":{}}],["practic",{"_index":2194,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["pre",{"_index":1280,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-manually":{}},"title":{}}],["precis",{"_index":130,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Function/":{},"api/flink/Function/#st_geohash":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Function/":{},"api/sql/Function/#st_geohash":{}},"title":{}}],["predic",{"_index":534,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql-for-spark":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{"api/flink/Predicate/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Predicate/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Predicate/":{}}}],["predict",{"_index":4186,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["prefer",{"_index":887,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["preliminari",{"_index":1773,"text":{"archive/download/cluster/":{},"setup/cluster/":{}},"title":{"archive/download/cluster/#preliminary":{},"setup/cluster/#preliminary":{}}}],["prepar",{"_index":3180,"text":{"community/publish/":{},"community/release-manager/":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"setup/install-python/":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{"community/publish/#0-prepare-an-empty-script-file":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"setup/install-python/#prepare-python-adapter-jar":{}}}],["prerequisit",{"_index":3936,"text":{"tutorial/demo/":{}},"title":{"tutorial/demo/#prerequisites":{}}}],["present",{"_index":3603,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["preserv",{"_index":3835,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sql":{}},"title":{}}],["press",{"_index":3386,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["previou",{"_index":749,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"tutorial/viz/":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{}}],["previous",{"_index":1631,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v081-geospark-core":{}},"title":{}}],["price",{"_index":1319,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["primari",{"_index":3492,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["primaryroad",{"_index":4234,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["primem[\"greenwich\",0",{"_index":3738,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["print",{"_index":1254,"text":{"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v112":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{}},"title":{}}],["print(ids[0].iloc[1",{"_index":4029,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["print(total_nod",{"_index":4025,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["println",{"_index":971,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{}},"title":{}}],["printschema",{"_index":575,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"tutorial/core-python/":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-geoparquet":{}},"title":{}}],["privat",{"_index":2970,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-a-notice-to-ipmc":{},"setup/databricks/":{}},"title":{}}],["private@incubator.apache.org",{"_index":2969,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{}},"title":{}}],["private@sedona.apache.org",{"_index":2945,"text":{"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#close-a-vote":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["priviledg",{"_index":3331,"text":{"community/publish/":{},"community/publish/#9-release-sedona-python-and-zeppelin":{}},"title":{}}],["problem",{"_index":3016,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/rule/":{},"community/rule/#make-a-pull-request":{}},"title":{}}],["problemat",{"_index":3864,"text":{"setup/release-notes/":{},"setup/release-notes/#python":{}},"title":{}}],["proceed",{"_index":3139,"text":{"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["process",{"_index":35,"text":{"":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contributor/":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publish/":{},"community/publish/#announce-email":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#v01-v07":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink":{}}}],["produc",{"_index":270,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{}},"title":{}}],["product",{"_index":3050,"text":{"community/contributor/":{},"community/contributor/#pmc-annoucement":{}},"title":{}}],["profession",{"_index":2770,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#generate-map-tiles":{},"tutorial/viz/":{},"tutorial/viz/#generate-map-tiles":{}},"title":{}}],["profil",{"_index":1390,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["program",{"_index":526,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{}},"title":{}}],["progress",{"_index":3028,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["project",{"_index":847,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#select-an-ide":{},"archive/download/project/#self-contained-spark-projects":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"asf/asf/":{},"asf/asf/#copyright":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contact/":{},"community/contact/#community":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#close-a-vote":{},"community/contributor/#committer-done-template":{},"community/contributor/#mentors":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#project-management-committee-pmc":{},"community/contributor/#send-the-invitation":{},"community/develop/":{},"community/publish/":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#v01-v07":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/demo/#scala":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#package-the-project":{},"archive/download/project/#self-contained-spark-projects":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/develop/#import-the-project":{},"community/develop/#import-the-project_1":{},"community/develop/#import-the-project_2":{},"setup/install-scala/#self-contained-spark-projects":{},"tutorial/demo/#run-template-projects-locally":{}}}],["project.org/package=apache.sedona",{"_index":3601,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["promot",{"_index":2864,"text":{"community/contributor/":{},"community/contributor/#committers":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["prompt",{"_index":3384,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["proof",{"_index":3450,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["proper",{"_index":1858,"text":{"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}}}],["properli",{"_index":1971,"text":{"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/demo/#scala-and-java-examples":{}},"title":{}}],["properti",{"_index":603,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"setup/release-notes/":{},"setup/release-notes/#v131":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["propos",{"_index":2980,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{}},"title":{}}],["provid",{"_index":938,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/contact/":{},"community/contact/#community":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publish/":{},"community/publish/#vote-email":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/release-notes/":{},"setup/release-notes/#new-features":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v131":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{}}],["pt_rdd",{"_index":4088,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["public",{"_index":72,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/publication/":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"download/":{},"download/#verify-the-integrity":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{"community/publication/":{},"community/publication/#full-publications":{},"community/publication/#key-publications":{},"community/publication/#publication":{}}}],["publish",{"_index":1581,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#make-a-sedona-release":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/release-notes/":{},"setup/release-notes/#v101":{}},"title":{"community/publish/#11-publish-the-doc-website":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{}}}],["publishing.html",{"_index":3176,"text":{"community/publish/":{},"community/publish/#make-a-sedona-release":{}},"title":{}}],["pull",{"_index":3221,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"community/rule/#make-a-pull-request":{},"community/rule/#review-a-pull-request":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{"community/rule/#make-a-pull-request":{},"community/rule/#review-a-pull-request":{}}}],["purdu",{"_index":3116,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["pure",{"_index":3561,"text":{"setup/databricks/":{},"setup/install-scala/":{},"setup/install-scala/#spark-sql-shell":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{},"tutorial/sql-pure-sql/":{}},"title":{"setup/databricks/#pure-sql-environment":{},"tutorial/sql-pure-sql/":{}}}],["purpl",{"_index":4252,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["purpos",{"_index":1976,"text":{"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{}},"title":{}}],["push",{"_index":3342,"text":{"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["pushdown",{"_index":835,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{}},"title":{"api/sql/Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{}}}],["pushedfilt",{"_index":2246,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["put",{"_index":1269,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["pvldb",{"_index":3121,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["px",{"_index":1264,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{}},"title":{}}],["py3",{"_index":2025,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{}},"title":{}}],["pycharm",{"_index":3085,"text":{"community/develop/":{},"community/develop/#ide_1":{}},"title":{}}],["pypi",{"_index":2020,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/overview/":{},"setup/overview/#download-statistics":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{"archive/tutorial/geospark-core-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories":{}}}],["pyspark",{"_index":2002,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#python":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["pyspark'",{"_index":4140,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["pyspark.sql",{"_index":2012,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["pyspark.sql.funct",{"_index":3953,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["pyspark.sql.functions.lit",{"_index":4163,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["pyspark.sql.sparksess",{"_index":2172,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["pyspark.sql.typ",{"_index":2286,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{}},"title":{}}],["pyspark==3.0.1",{"_index":3528,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["pysparksql",{"_index":3594,"text":{"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{}},"title":{}}],["pytest",{"_index":3529,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["python",{"_index":15,"text":{"":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v130":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#supported-versions":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#supported-versions":{},"community/develop/":{},"community/publish/":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#fix-signature-issues":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#community-edition-free-tier":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/modules/":{},"setup/flink/modules/#api-availability":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-python/#setup-environment-variables":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/modules/":{},"setup/modules/#api-availability":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#global_3":{},"setup/release-notes/#highlights":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#python":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#v130":{},"setup/release-notes/#v131":{},"tutorial/core-python/":{},"tutorial/core-python/#installation":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/raster/":{},"tutorial/raster/#tutorials":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#installation":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#sedonasql":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"api/python-api/":{},"archive/api/GeoSpark-Python-API/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#python":{},"archive/tutorial/geospark-core-python/#spatial-rdd-applications-in-python":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#python":{},"archive/tutorial/geospark-sql-python/#spatial-sql-application-in-python":{},"community/develop/#python-developers":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/release-notes/#python":{},"setup/release-notes/#python_1":{},"setup/release-notes/#sedona-python":{},"tutorial/core-python/":{},"tutorial/core-python/#spatial-rdd-applications-in-python":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/sql-python/":{},"tutorial/sql-python/#spatial-sql-application-in-python":{}}}],["python/scala",{"_index":3562,"text":{"setup/databricks/":{},"setup/databricks/#pure-sql-environment":{}},"title":{}}],["python3",{"_index":2027,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-source":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installing-from-source":{},"community/publish/":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{}},"title":{}}],["pythonpath",{"_index":3516,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["pythonpath=$spark_home/python",{"_index":3520,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["pywebhdfs.webhdf",{"_index":3960,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["pywebhdfscli",{"_index":3961,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["pywebhdfsclient(host='179.106.229.159',port='50070",{"_index":4005,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["q",{"_index":3194,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["qjciaaaaaabakdwaa",{"_index":1098,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["qjooaaaaaabalegaa",{"_index":1099,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["qt",{"_index":4001,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["quad",{"_index":1561,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"setup/overview/":{},"setup/overview/#distributed-spatial-queries":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-partitioning":{}},"title":{}}],["quadrantsegments:int",{"_index":759,"text":{"api/sql/Function/":{},"api/sql/Function/#st_minimumboundingcircle":{}},"title":{}}],["quadtre",{"_index":905,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_2":{}},"title":{}}],["qualif",{"_index":2923,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{}},"title":{}}],["qualiti",{"_index":2926,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{}},"title":{}}],["quantil",{"_index":2280,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["queri",{"_index":349,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geohash":{},"api/sql/Function/":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/project/":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format":{},"archive/tutorial/rdd/#output-format_1":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#join-query":{},"archive/tutorial/sql/#other-queries":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/sql/#run-spatial-queries":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/overview/":{},"setup/overview/#distributed-spatial-queries":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#global_1":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#run-spatial-queries":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format":{},"tutorial/rdd/#output-format_1":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#join-query":{},"tutorial/sql/#other-queries":{},"tutorial/sql/#range-query":{},"tutorial/sql/#register-sedonasql":{},"tutorial/sql/#run-spatial-queries":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/viz/":{}},"title":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/#join-query":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#other-queries":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#run-spatial-queries":{},"setup/overview/#distributed-spatial-queries":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#run-spatial-queries":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql/#join-query":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#other-queries":{},"tutorial/sql/#range-query":{},"tutorial/sql/#run-spatial-queries":{}}}],["query_result",{"_index":2079,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["query_window_rdd",{"_index":2113,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-spatial-join-query":{}},"title":{}}],["queryresult",{"_index":2614,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["querywindow",{"_index":2615,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["querywindowrdd",{"_index":2111,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{}}],["question",{"_index":1985,"text":{"community/contact/":{},"community/contact/#mailing-list":{},"community/rule/":{},"community/rule/#make-a-pull-request":{}},"title":{"archive/tutorial/faq/":{}}}],["quick",{"_index":926,"text":{"api/sql/Overview/":{},"api/viz/sql/":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/viz/sql/":{},"archive/download/project/":{},"tutorial/core-python/":{},"tutorial/core-python/#installation":{},"tutorial/sql-python/":{},"tutorial/sql-python/#installation":{}},"title":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/#quick-start":{},"archive/download/overview/":{},"archive/download/project/#quick-start":{}}}],["quickli",{"_index":2854,"text":{"community/contact/":{},"community/contact/#bug-reports":{}},"title":{}}],["quot",{"_index":3135,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["r",{"_index":42,"text":{"":{},"api/r-api/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"community/develop/":{},"community/publish/":{},"community/publish/#10-release-sedona-r-to-cran":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#compile-r-html-docs":{},"setup/flink/modules/":{},"setup/flink/modules/#api-availability":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/modules/":{},"setup/modules/#api-availability":{},"setup/overview/":{},"setup/overview/#distributed-spatial-queries":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#r":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#v110":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/raster/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"api/r-api/":{},"community/develop/#r-developers":{},"community/publish/#10-release-sedona-r-to-cran":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#compile-r-html-docs":{},"setup/install-r/":{},"setup/release-notes/#r":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#spatial-rdd-applications-in-r-language":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}}}],["radian",{"_index":282,"text":{"api/flink/Function/":{},"api/flink/Function/#st_azimuth":{},"api/sql/Function/":{},"api/sql/Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{}},"title":{}}],["radiu",{"_index":763,"text":{"api/sql/Function/":{},"api/sql/Function/#st_minimumboundingradius":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{}},"title":{}}],["radius'",{"_index":1329,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{}},"title":{}}],["radius:decim",{"_index":1327,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{}},"title":{}}],["rang",{"_index":370,"text":{"api/flink/Function/":{},"api/flink/Function/#st_interiorringn":{},"api/sql/Function/":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#range-join":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#range-query":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/overview/":{},"setup/overview/#distributed-spatial-queries":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql/":{},"tutorial/sql/#range-query":{}},"title":{"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/#range-query":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql/#range-query":{}}}],["range_query_window",{"_index":2071,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["rangefilt",{"_index":3853,"text":{"setup/release-notes/":{},"setup/release-notes/#core":{}},"title":{}}],["rangejoin",{"_index":844,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"setup/release-notes/":{},"setup/release-notes/#v112":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["rangequeri",{"_index":2070,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["rangequery.spatialrangequeri",{"_index":3792,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{}},"title":{}}],["rangequeryraw",{"_index":3917,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["rangequerywindow",{"_index":2612,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["rank",{"_index":2702,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{}},"title":{}}],["rapid",{"_index":3442,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["raster",{"_index":46,"text":{"":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_count":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sql_2":{},"tutorial/raster/":{},"tutorial/raster/#api-docs":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"api/sql/Raster-loader/":{},"api/sql/Raster-operators/":{},"tutorial/raster/":{}}}],["rasteroverlayoper",{"_index":1764,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["rat",{"_index":3196,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["rat_vers",{"_index":3197,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{}},"title":{}}],["rate",{"_index":2630,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["rational",{"_index":2857,"text":{"community/contact/":{},"community/contact/#feature-requests":{}},"title":{}}],["raw",{"_index":2655,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["raw('org.locationtech.jts.geom.geometri",{"_index":4302,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{}},"title":{}}],["rawdf",{"_index":2656,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["rawjvmspatialrdd",{"_index":2135,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{}},"title":{}}],["rawspatialdf",{"_index":565,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{}},"title":{}}],["rawspatialrdd",{"_index":559,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{}},"title":{}}],["rawspatialrdd/indexedrawrdd",{"_index":1965,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["rc1",{"_index":3224,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#upload-releases":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["rc1.tar.gz",{"_index":3244,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{}},"title":{}}],["rc1/apach",{"_index":3263,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{}},"title":{}}],["rc1/docs/setup/compile.md",{"_index":3270,"text":{"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["rc1/docs/setup/releas",{"_index":3268,"text":{"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["rc2",{"_index":3306,"text":{"community/publish/":{},"community/publish/#7-failed-vote":{}},"title":{}}],["rd",{"_index":1307,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["rdd",{"_index":1238,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/overview/":{},"setup/overview/#distributed-spatial-datasets":{},"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{"api/viz/java-api/":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#spatial-rdd-applications-in-python":{},"archive/tutorial/rdd/":{},"setup/release-notes/#rdd":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/#spatial-rdd-applications-in-python":{},"tutorial/rdd-r/#spatial-rdd-applications-in-r-language":{}}}],["rdd/sql",{"_index":3693,"text":{"setup/modules/":{},"setup/modules/#api-availability":{}},"title":{}}],["rdd1.partitiontre",{"_index":1641,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["rdd1.spatialpartit",{"_index":1640,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["rdd2.spatialpartit",{"_index":1642,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["rdd_with_other_attribut",{"_index":2065,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{}},"title":{}}],["rddwithotherattribut",{"_index":2609,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{}},"title":{}}],["rdoc",{"_index":3357,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["re",{"_index":2715,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/develop/":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"community/publish/#upload-releases":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["read",{"_index":94,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/java-api/":{},"api/r-api/":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/java-api/":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#display-geosparkviz-results":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/faq/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"archive/tutorial/sql/#other-queries":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#set-up-dependencies":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#make-a-sedona-release":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"community/rule/#develop-a-document-contribution":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#rdd":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v100":{},"setup/release-notes/#v120":{},"setup/zeppelin/":{},"setup/zeppelin/#display-sedonaviz-results":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/core-python/":{},"tutorial/core-python/#installation":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#set-up-dependencies":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql-python/":{},"tutorial/sql-python/#installation":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/sql/#other-queries":{},"tutorial/sql/#range-query":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#set-up-dependencies":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/geospark-core-python/#read-from-geojson-file":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/geospark-core-python/#read-from-shapefile":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#read-from-geojson-file":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/core-python/#read-from-shapefile":{},"tutorial/core-python/#read-from-wkb-file":{},"tutorial/core-python/#read-from-wkt-file":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{}}}],["read_fil",{"_index":2209,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["readabl",{"_index":2139,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["reader",{"_index":1412,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#rdd":{},"setup/release-notes/#v110":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{}},"title":{}}],["reader/writ",{"_index":3773,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["readers/writ",{"_index":3907,"text":{"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{}},"title":{}}],["readfromcr",{"_index":1015,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["readgeometri",{"_index":4337,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{}},"title":{}}],["readi",{"_index":1835,"text":{"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["reading/writ",{"_index":3628,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["readschema",{"_index":2247,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["readtestscala",{"_index":2646,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{}},"title":{}}],["readtocr",{"_index":1016,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["readtogeometryrdd",{"_index":561,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-geojson-file":{},"archive/tutorial/geospark-core-python/#read-from-shapefile":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-geojson-file":{},"tutorial/core-python/#read-from-shapefile":{},"tutorial/core-python/#read-from-wkb-file":{},"tutorial/core-python/#read-from-wkt-file":{},"tutorial/rdd/":{}},"title":{}}],["real",{"_index":1706,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/viz-gallery/":{}},"title":{}}],["reason",{"_index":1339,"text":{"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["receiv",{"_index":2862,"text":{"community/contributor/":{}},"title":{}}],["recognit",{"_index":2985,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["recommend",{"_index":1717,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"community/develop/":{},"community/develop/#ide":{},"community/develop/#ide_1":{},"community/develop/#ide_2":{},"community/publish/":{},"community/publish/#vote-email":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{}},"title":{}}],["record",{"_index":671,"text":{"api/sql/Function/":{},"api/sql/Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{}},"title":{}}],["recov",{"_index":4333,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["rectangl",{"_index":2081,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"tutorial/core-python/":{},"tutorial/core-python/#range-query-window":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{}},"title":{}}],["rectanglerdd",{"_index":1995,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{}},"title":{}}],["red",{"_index":1273,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{}},"title":{}}],["redband",{"_index":1086,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["redesign",{"_index":1917,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["redirect",{"_index":3471,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["reduc",{"_index":775,"text":{"api/sql/Function/":{},"api/sql/Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["refactor",{"_index":1735,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#rdd":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["refenc",{"_index":458,"text":{"api/flink/Function/":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/sql/Function/":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_srid":{}},"title":{}}],["refer",{"_index":90,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"download/":{},"download/#security":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}}}],["reffer",{"_index":2185,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{}},"title":{}}],["refin",{"_index":1704,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["reflect",{"_index":2821,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["regard",{"_index":3304,"text":{"community/publish/":{},"community/publish/#announce-email":{}},"title":{}}],["regexp_replac",{"_index":3954,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["region",{"_index":1164,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{}}],["regist",{"_index":2175,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"asf/asf/":{},"asf/asf/#copyright":{},"setup/databricks/":{},"setup/databricks/#pure-sql-environment":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/python-vector-osm/":{},"tutorial/raster/":{},"tutorial/raster/#initial-setup":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#register-package":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/sql-python/#register-package":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}}}],["registeral",{"_index":963,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#register-package":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{}}],["registerfunc",{"_index":4278,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{}},"title":{}}],["registertyp",{"_index":4277,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{}},"title":{}}],["registr",{"_index":1555,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v112":{},"tutorial/python-vector-osm/":{}},"title":{"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}}}],["regress",{"_index":3708,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{}},"title":{}}],["regular",{"_index":1247,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{}},"title":{"api/viz/sql/#regular-functions":{},"archive/api/viz/sql/#regular-functions":{}}}],["regularli",{"_index":2921,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{}},"title":{}}],["reinstal",{"_index":3872,"text":{"setup/release-notes/":{},"setup/release-notes/#known-issue":{}},"title":{}}],["reject",{"_index":3447,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["rel",{"_index":4248,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["relat",{"_index":2602,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["relationship",{"_index":784,"text":{"api/sql/Function/":{},"api/sql/Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["relativepath",{"_index":3079,"text":{"community/develop/":{}},"title":{}}],["releas",{"_index":5,"text":{"":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v111":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v130":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"community/contact/":{},"community/contact/#feature-requests":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#7-failed-vote":{},"community/publish/#announce-email":{},"community/publish/#make-a-sedona-release":{},"community/publish/#manually-close-and-release-the-package":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#upload-releases":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/release-manager/#become-a-release-manager":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"download/":{},"download/#github-repository":{},"download/#past-releases":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/flink/platform/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/overview/":{},"setup/overview/#download-statistics":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#highlights":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-111":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#sedona-131":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v100":{},"setup/release-notes/#v111":{},"setup/release-notes/#v130":{},"setup/release-notes/#v131":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink":{},"#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112":{},"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"#11232021-sedona-111-incubating-is-released-it-now-supports-spark-32":{},"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"community/publish/":{},"community/publish/#10-release-sedona-r-to-cran":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#8-release-source-code-and-maven-package":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#make-a-sedona-release":{},"community/publish/#manually-close-and-release-the-package":{},"community/publish/#upload-releases":{},"community/release-manager/":{},"community/release-manager/#become-a-release-manager":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"download/#past-releases":{},"setup/release-notes/":{},"setup/release-notes/#geospark-legacy-release-notes":{}}}],["release.ipynb",{"_index":3279,"text":{"community/publish/":{},"community/publish/#vote-email":{}},"title":{}}],["release.sh",{"_index":3183,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{}},"title":{}}],["release/key",{"_index":3403,"text":{"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{}},"title":{}}],["release:prepar",{"_index":3222,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["releases><en",{"_index":1397,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#pomxml":{}},"title":{}}],["reli",{"_index":3541,"text":{"setup/databricks/":{},"setup/databricks/#advanced-editions":{}},"title":{}}],["reliabl",{"_index":3920,"text":{"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{}},"title":{}}],["reload",{"_index":2142,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#reload-a-saved-spatialrdd":{},"community/develop/":{},"tutorial/core-python/":{},"tutorial/core-python/#reload-a-saved-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#reload-a-saved-spatialrdd":{}},"title":{"archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd":{},"archive/tutorial/rdd/#reload-a-saved-spatialrdd":{},"tutorial/core-python/#reload-a-saved-spatialrdd":{},"tutorial/rdd/#reload-a-saved-spatialrdd":{}}}],["remain",{"_index":2728,"text":{"archive/tutorial/viz/":{}},"title":{}}],["rememb",{"_index":3074,"text":{"community/develop/":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["remov",{"_index":450,"text":{"api/flink/Function/":{},"api/flink/Function/#st_removepoint":{},"api/sql/Function/":{},"api/sql/Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"community/develop/":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#python":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["removehol",{"_index":1334,"text":{"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{}},"title":{}}],["removeholes:boolean",{"_index":1336,"text":{"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{}},"title":{}}],["renam",{"_index":1052,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["render",{"_index":1308,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"tutorial/viz/":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#render-the-image":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#render-the-image":{}}}],["repeatedli",{"_index":1946,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{}},"title":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}}}],["replac",{"_index":455,"text":{"api/flink/Function/":{},"api/flink/Function/#st_setpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_setpoint":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/tutorial/rdd/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#fix-signature-issues":{},"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v100":{},"tutorial/rdd/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#render-the-image":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["repli",{"_index":2990,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["replic",{"_index":1948,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["repo",{"_index":1395,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#make-a-sedona-release":{},"community/publish/#manually-close-and-release-the-package":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"community/rule/#make-a-pull-request":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#pomxml":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}}}],["report",{"_index":2831,"text":{"community/contact/":{},"community/contact/#bug-reports":{},"community/contact/#community":{},"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#announce-email":{},"community/rule/":{},"community/rule/#make-a-pull-request":{}},"title":{"community/contact/#bug-reports":{}}}],["report.txt",{"_index":3205,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{}},"title":{}}],["repositori",{"_index":54,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#introduction":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#committers":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"community/publish/#manually-close-and-release-the-package":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"download/":{},"download/#github-repository":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#pomxml":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{}},"title":{"archive/tutorial/geospark-core-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories":{},"download/#github-repository":{}}}],["repres",{"_index":296,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_exteriorring":{},"api/sql/Function/":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["represent",{"_index":259,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_makevalid":{},"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{}},"title":{}}],["republish",{"_index":1584,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"setup/release-notes/":{},"setup/release-notes/#v100":{}},"title":{}}],["request",{"_index":2855,"text":{"community/contact/":{},"community/contact/#feature-requests":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#create-asf-account":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"community/rule/#make-a-pull-request":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{"community/contact/#feature-requests":{},"community/rule/#make-a-pull-request":{},"community/rule/#review-a-pull-request":{}}}],["requests.get(overpass_url",{"_index":4002,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["request\u2019",{"_index":3451,"text":{"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["requir",{"_index":475,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/release-manager/":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"community/rule/#review-a-pull-request":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#sedona-viz":{},"setup/release-notes/#v01-v07":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{"community/release-manager/#0-software-requirement":{}}}],["research",{"_index":3093,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{}},"title":{}}],["reserv",{"_index":3766,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["resili",{"_index":3610,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["resolut",{"_index":1291,"text":{"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_pixelize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"tutorial/viz-gallery/":{},"tutorial/viz/":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["resolution_i",{"_index":4228,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["resolution_x",{"_index":4227,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["resolutionx:int",{"_index":1293,"text":{"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_pixelize":{}},"title":{}}],["resolutiony:int",{"_index":1294,"text":{"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_pixelize":{}},"title":{}}],["resolv",{"_index":413,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#buildsbt":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#buildsbt":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["resourc",{"_index":2737,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publish/":{},"community/publish/#announce-email":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["respect",{"_index":1206,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_modulo":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{}},"title":{}}],["respons",{"_index":2933,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#send-the-invitation":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["response.json",{"_index":4004,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["rest",{"_index":2640,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{}},"title":{}}],["restart",{"_index":1906,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#enable-geospark-zeppelin":{},"community/publish/":{},"community/publish/#7-failed-vote":{},"community/release-manager/":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{},"setup/zeppelin/":{},"setup/zeppelin/#enable-sedona-zeppelin":{}},"title":{}}],["restaur",{"_index":2361,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["result",{"_index":352,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_setpoint":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_union":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/zeppelin/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#close-a-vote":{},"community/contributor/#nominate-a-committer-or-pmc-member":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/publish/":{},"community/publish/#announce-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v112":{},"setup/zeppelin/":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{"archive/download/zeppelin/#display-geosparkviz-results":{},"archive/download/zeppelin/#visualize-geosparksql-results":{},"setup/zeppelin/#display-sedonaviz-results":{},"setup/zeppelin/#visualize-sedonasql-results":{}}}],["result][vot",{"_index":3286,"text":{"community/publish/":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{}},"title":{}}],["retriev",{"_index":1140,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/flink/sql/":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{}},"title":{"tutorial/flink/sql/#retrieve-geometries":{}}}],["return",{"_index":106,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Aggregator/#st_union_aggr":{},"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_area":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_distance":{},"api/flink/Function/#st_envelope":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_length":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_z":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_orderingequals":{},"api/flink/Predicate/#st_within":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_area":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_convexhull":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_length":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_npoints":{},"api/sql/Function/#st_numgeometries":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-loader/#rs_html":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#knn-query":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["revers",{"_index":447,"text":{"api/flink/Function/":{},"api/flink/Function/#st_reverse":{},"api/sql/Function/":{},"api/sql/Function/#st_reverse":{}},"title":{}}],["review",{"_index":2812,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{"community/rule/#review-a-pull-request":{}}}],["revis",{"_index":3531,"text":{"setup/compile/":{},"setup/compile/#mkdocs-website":{}},"title":{}}],["rewrit",{"_index":3898,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{}}],["rf",{"_index":3207,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{}},"title":{}}],["rgb",{"_index":1101,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["rgba(112,36,228,0.9",{"_index":1278,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{}},"title":{}}],["rich",{"_index":3699,"text":{"setup/overview/":{}},"title":{"setup/overview/#rich-spatial-analytics-tools":{}}}],["right",{"_index":891,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"community/develop/":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["right_attribute1",{"_index":4203,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["right_attribute2",{"_index":4204,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["rightcol1",{"_index":3926,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{}},"title":{}}],["rightcol2",{"_index":3927,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{}},"title":{}}],["rightgeometri",{"_index":4211,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["rightrdd",{"_index":4209,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["ring",{"_index":324,"text":{"api/flink/Function/":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_numinteriorrings":{},"api/sql/Function/":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{}},"title":{}}],["rishabh",{"_index":1511,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["rm",{"_index":3206,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#fix-signature-issues":{},"community/publish/#upload-releases":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{}},"title":{}}],["road",{"_index":3099,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#key-publications":{}},"title":{}}],["roads_tb",{"_index":4076,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["roads_tb.createorreplacetempview(\"roads_tb",{"_index":4080,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["roads_tb.show(5",{"_index":4081,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["rodin",{"_index":418,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{}},"title":{}}],["role",{"_index":3034,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/rule/":{},"community/rule/#code-of-conduct":{}},"title":{}}],["rompf",{"_index":3115,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["root",{"_index":1228,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_squareroot":{},"archive/download/cluster/":{},"archive/download/cluster/#start-your-cluster":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#create-helium-folder-optional":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"community/develop/":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#compile-r-html-docs":{},"setup/cluster/":{},"setup/cluster/#start-your-cluster":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#mkdocs-website":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/zeppelin/":{},"setup/zeppelin/#create-helium-folder-optional":{},"tutorial/core-python/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#point":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-geoparquet":{}},"title":{}}],["rootdf",{"_index":1229,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_squareroot":{}},"title":{}}],["round",{"_index":777,"text":{"api/sql/Function/":{},"api/sql/Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{}},"title":{}}],["routin",{"_index":3611,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["row",{"_index":822,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivideexplode":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#get-datastream":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{"tutorial/flink/sql/#create-row-objects":{}}}],["rs_add",{"_index":1127,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{}},"title":{"api/sql/Raster-operators/#rs_add":{}}}],["rs_add(band1",{"_index":1130,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{}},"title":{}}],["rs_append",{"_index":1132,"text":{"api/sql/Raster-operators/":{}},"title":{"api/sql/Raster-operators/#rs_append":{}}}],["rs_append(data",{"_index":1141,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{}},"title":{}}],["rs_appendnormalizeddiffer",{"_index":3819,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["rs_array",{"_index":1079,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_array":{}},"title":{"api/sql/Raster-loader/#rs_array":{}}}],["rs_array(h*w",{"_index":1096,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["rs_array(length:int",{"_index":1081,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_array":{}},"title":{}}],["rs_base64",{"_index":1082,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{"api/sql/Raster-loader/#rs_base64":{}}}],["rs_base64(h",{"_index":1092,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["rs_bitwiseand",{"_index":1146,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_bitwiseand":{}},"title":{"api/sql/Raster-operators/#rs_bitwiseand":{}}}],["rs_bitwiseand(band1",{"_index":1149,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_bitwiseand":{}},"title":{}}],["rs_bitwiseor",{"_index":1151,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_bitwiseor":{}},"title":{"api/sql/Raster-operators/#rs_bitwiseor":{}}}],["rs_bitwiseor(band1",{"_index":1153,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_bitwiseor":{}},"title":{}}],["rs_count",{"_index":1154,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_count":{}},"title":{"api/sql/Raster-operators/#rs_count":{}}}],["rs_count(band1",{"_index":1156,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_count":{}},"title":{}}],["rs_divid",{"_index":1157,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_divide":{}},"title":{"api/sql/Raster-operators/#rs_divide":{}}}],["rs_divide(band1",{"_index":1159,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_divide":{}},"title":{}}],["rs_fetchregion",{"_index":1161,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{"api/sql/Raster-operators/#rs_fetchregion":{}}}],["rs_fetchregion(band,array(0",{"_index":1171,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{}}],["rs_getband",{"_index":1106,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{}},"title":{"api/sql/Raster-loader/#rs_getband":{}}}],["rs_getband(data",{"_index":1113,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{}},"title":{}}],["rs_greaterthan",{"_index":1173,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_greaterthan":{}},"title":{"api/sql/Raster-operators/#rs_greaterthan":{}}}],["rs_greaterthan(band",{"_index":1177,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_greaterthan":{}},"title":{}}],["rs_greaterthanequ",{"_index":1179,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_greaterthanequal":{}},"title":{"api/sql/Raster-operators/#rs_greaterthanequal":{}}}],["rs_greaterthanequal(band",{"_index":1181,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_greaterthanequal":{}},"title":{}}],["rs_html",{"_index":1116,"text":{"api/sql/Raster-loader/":{}},"title":{"api/sql/Raster-loader/#rs_html":{}}}],["rs_html(base64:str",{"_index":1121,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_html":{}},"title":{}}],["rs_html(encodedstr",{"_index":1123,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_html":{}},"title":{}}],["rs_lessthan",{"_index":1182,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_lessthan":{}},"title":{"api/sql/Raster-operators/#rs_lessthan":{}}}],["rs_lessthan(band",{"_index":1184,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_lessthan":{}},"title":{}}],["rs_lessthanequ",{"_index":1185,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_lessthanequal":{}},"title":{"api/sql/Raster-operators/#rs_lessthanequal":{}}}],["rs_lessthanequal(band",{"_index":1187,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_lessthanequal":{}},"title":{}}],["rs_logicaldiffer",{"_index":1188,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_logicaldifference":{}},"title":{"api/sql/Raster-operators/#rs_logicaldifference":{}}}],["rs_logicaldifference(band1",{"_index":1190,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_logicaldifference":{}},"title":{}}],["rs_logicalov",{"_index":1192,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_logicalover":{}},"title":{"api/sql/Raster-operators/#rs_logicalover":{}}}],["rs_logicalover(band1",{"_index":1195,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_logicalover":{}},"title":{}}],["rs_mean",{"_index":1197,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_mean":{}},"title":{"api/sql/Raster-operators/#rs_mean":{}}}],["rs_mean(band",{"_index":1199,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_mean":{}},"title":{}}],["rs_mode",{"_index":1200,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_mode":{}},"title":{"api/sql/Raster-operators/#rs_mode":{}}}],["rs_mode(band",{"_index":1202,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_mode":{}},"title":{}}],["rs_modulo",{"_index":1203,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_modulo":{}},"title":{"api/sql/Raster-operators/#rs_modulo":{}}}],["rs_modulo(band",{"_index":1208,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_modulo":{}},"title":{}}],["rs_multipli",{"_index":1209,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_multiply":{}},"title":{"api/sql/Raster-operators/#rs_multiply":{}}}],["rs_multiply(band1",{"_index":1211,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_multiply":{}},"title":{}}],["rs_multiplyfactor",{"_index":1213,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_multiplyfactor":{}},"title":{"api/sql/Raster-operators/#rs_multiplyfactor":{}}}],["rs_multiplyfactor(band1",{"_index":1216,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_multiplyfactor":{}},"title":{}}],["rs_normal",{"_index":1218,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_normalize":{}},"title":{"api/sql/Raster-operators/#rs_normalize":{}}}],["rs_normalizeddiffer",{"_index":1135,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_normalizeddifference":{}},"title":{"api/sql/Raster-operators/#rs_normalizeddifference":{}}}],["rs_normalizeddifference(band1",{"_index":1224,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_normalizeddifference":{}},"title":{}}],["rs_squareroot",{"_index":1226,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_squareroot":{}},"title":{"api/sql/Raster-operators/#rs_squareroot":{}}}],["rs_squareroot(band",{"_index":1230,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_squareroot":{}},"title":{}}],["rs_subtract",{"_index":1232,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_subtract":{}},"title":{"api/sql/Raster-operators/#rs_subtract":{}}}],["rs_subtract(band1",{"_index":1236,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_subtract":{}},"title":{}}],["rsa",{"_index":3385,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["rsa4096",{"_index":3379,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["rscript",{"_index":3359,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["rstudio",{"_index":3086,"text":{"community/develop/":{},"community/develop/#ide_2":{}},"title":{}}],["rtree",{"_index":975,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_1":{}},"title":{}}],["rubi",{"_index":3112,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["rule",{"_index":1597,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{"community/rule/":{}}}],["run",{"_index":1620,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#run-spatial-queries":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#initiate-sparksession":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/develop/":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#compile-r-html-docs":{},"community/publish/#fix-signature-issues":{},"community/publish/#make-a-sedona-release":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#setup-environment-variables":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/release-notes/":{},"setup/release-notes/#v082-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/demo/":{},"tutorial/demo/#compile":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/demo/#scala":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#run-spatial-queries":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#range-query":{},"tutorial/sql/#run-spatial-queries":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#initiate-sparksession":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{"archive/tutorial/sql/#run-spatial-queries":{},"archive/tutorial/zeppelin/":{},"community/develop/#run-unit-tests":{},"community/vote/#run-the-verify-script":{},"setup/compile/#run-python-test":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/flink/sql/#run-spatial-queries":{},"tutorial/sql/#run-spatial-queries":{}}}],["runtim",{"_index":972,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{}},"title":{}}],["runtimeconfig",{"_index":3717,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement":{}},"title":{}}],["s",{"_index":4083,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["s00twy01mt",{"_index":134,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{}},"title":{}}],["s3",{"_index":1437,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v131":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/rdd/":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["s_epsg",{"_index":2044,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{}},"title":{}}],["sachio",{"_index":1451,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["safe",{"_index":1925,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"setup/release-notes/":{},"setup/release-notes/#new-features":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["safeti",{"_index":3807,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["sagar1993",{"_index":1513,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["same",{"_index":102,"text":{"api/flink/Function/":{},"api/flink/Function/#st_isclosed":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/java-api/":{},"api/sql/Function/":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_orderingequals":{},"api/viz/java-api/":{},"api/viz/sql/":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/api/viz/sql/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels_1":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/core-python/":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/demo/":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels_1":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#store-map-tiles-on-disk":{}},"title":{}}],["sampl",{"_index":1624,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v082-geospark-core":{}},"title":{}}],["samplenumb",{"_index":1627,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v082-geospark-core":{}},"title":{}}],["saniti",{"_index":3636,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["sarwat",{"_index":2886,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["satisfi",{"_index":839,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["sauer",{"_index":1507,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["save",{"_index":1055,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#reload-a-saved-spatialrdd":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#reload-a-saved-spatialrdd":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-an-spatialrdd-not-indexed":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/python-vector-osm/":{},"tutorial/rdd/":{},"tutorial/rdd/#reload-a-saved-spatialrdd":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#save-geoparquet":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{"archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/#reload-a-saved-spatialrdd":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"tutorial/core-python/#reload-a-saved-spatialrdd":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-an-spatialrdd-not-indexed":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{},"tutorial/rdd/#reload-a-saved-spatialrdd":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql/#save-geoparquet":{},"tutorial/sql/#save-to-permanent-storage":{}}}],["saveasgeojson",{"_index":2134,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["saveasobjectfil",{"_index":2136,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["saveastextfil",{"_index":2132,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["saveaswkb",{"_index":1420,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"setup/release-notes/":{},"setup/release-notes/#v131":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["saveaswkt",{"_index":1422,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"setup/release-notes/":{},"setup/release-notes/#v131":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["saved_rdd",{"_index":2150,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{}},"title":{}}],["savedrdd",{"_index":2643,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["saver",{"_index":2853,"text":{"community/contact/":{},"community/contact/#bug-reports":{}},"title":{}}],["saverasterimageaslocalfil",{"_index":2765,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"tutorial/viz/":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{}}],["sbin/start",{"_index":1812,"text":{"archive/download/cluster/":{},"archive/download/cluster/#start-your-cluster":{},"setup/cluster/":{},"setup/cluster/#start-your-cluster":{}},"title":{}}],["sbt",{"_index":1844,"text":{"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/download/project/#select-an-ide":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"tutorial/demo/":{},"tutorial/demo/#compile":{},"tutorial/demo/#prerequisites":{},"tutorial/demo/#scala":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}},"title":{}}],["sc",{"_index":2048,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#read-from-geojson-file":{},"archive/tutorial/geospark-core-python/#read-from-shapefile":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#read-from-geojson-file":{},"tutorial/core-python/#read-from-shapefile":{},"tutorial/core-python/#read-from-wkb-file":{},"tutorial/core-python/#read-from-wkt-file":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["scala",{"_index":13,"text":{"":{},"api/java-api/":{},"api/viz/java-api/":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#select-an-ide":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/viz/":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/develop/":{},"community/develop/#ide":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"setup/flink/install-scala/":{},"setup/flink/platform/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global":{},"setup/release-notes/#global_3":{},"setup/release-notes/#highlights":{},"setup/release-notes/#rdd":{},"setup/release-notes/#task":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/demo/#prerequisites":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/demo/#scala":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/flink/sql/":{},"tutorial/raster/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"setup/compile/#compile-scala-java-source-code":{},"setup/install-scala/#spark-scala-shell":{},"tutorial/demo/#scala":{},"tutorial/demo/#scala-and-java-examples":{}}}],["scala/java",{"_index":92,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"community/develop/":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/flink/modules/":{},"setup/flink/modules/#api-availability":{},"setup/flink/platform/":{},"setup/modules/":{},"setup/modules/#api-availability":{},"setup/platform/":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{}},"title":{"api/java-api/":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"community/develop/#scalajava-developers":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"tutorial/demo/":{},"tutorial/flink/sql/":{},"tutorial/rdd/":{},"tutorial/sql/":{},"tutorial/viz/":{}}}],["scala/java/python/r",{"_index":3649,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-fat-jars":{}},"title":{}}],["scalabl",{"_index":1889,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/viz/":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/viz/":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/viz/#why-scalable-map-visualization":{}}}],["scaladoc",{"_index":939,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"community/publish/":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{"community/publish/#javadoc-and-scaladoc":{}}}],["scalaexample.scala",{"_index":1859,"text":{"archive/download/project/":{},"archive/download/project/#try-geospark-sql-functions":{}},"title":{}}],["scale",{"_index":1732,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publish/":{},"community/publish/#announce-email":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}}}],["scan",{"_index":2239,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["scatter",{"_index":1267,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/viz/":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{}},"title":{}}],["scenario",{"_index":1815,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["schema",{"_index":1048,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/sql-python/":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["scheme",{"_index":2279,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["scientif",{"_index":3156,"text":{"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["scm:git:https://github.com/apache/incub",{"_index":3237,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{}},"title":{}}],["scope",{"_index":1866,"text":{"archive/download/project/":{},"archive/download/project/#package-the-project":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}},"title":{}}],["script",{"_index":3179,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#7-failed-vote":{},"community/publish/#compile-r-html-docs":{},"community/publish/#fix-signature-issues":{},"community/publish/#make-a-sedona-release":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/databricks/#pure-sql-environment":{}},"title":{"community/publish/#0-prepare-an-empty-script-file":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/#run-the-verify-script":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}}}],["scroll",{"_index":2784,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["sdf",{"_index":4104,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["sdf_regist",{"_index":4166,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["sdist",{"_index":3334,"text":{"community/publish/":{},"community/publish/#9-release-sedona-python-and-zeppelin":{}},"title":{}}],["se",{"_index":631,"text":{"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{}},"title":{}}],["seamlessli",{"_index":98,"text":{"api/java-api/":{},"api/viz/java-api/":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["search",{"_index":492,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"community/contact/":{},"community/contact/#bug-reports":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/python-vector-osm/":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}}}],["seattl",{"_index":3151,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["second",{"_index":698,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makevalid":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/zeppelin/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/core-python/":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/zeppelin/":{}},"title":{}}],["secret",{"_index":3375,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{"community/release-manager/#2-prepare-secret-gpg-key":{}}}],["section",{"_index":1406,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/release-notes/":{},"setup/release-notes/#v131":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["secur",{"_index":88,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"download/":{},"download/#security":{}},"title":{"download/#security":{}}}],["sedoma",{"_index":3702,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-131":{}},"title":{}}],["sedona",{"_index":2,"text":{"":{},"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_ndims":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Parameter/#usage":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"asf/asf/":{},"asf/asf/#copyright":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contact/#discord-server":{},"community/contact/#feature-requests":{},"community/contact/#feedback":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#become-a-committer":{},"community/contributor/#committer-done-template":{},"community/contributor/#committers":{},"community/contributor/#create-asf-account":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#project-management-committee-pmc":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{},"community/develop/":{},"community/publication/":{},"community/publication/#publication":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#announce-email":{},"community/publish/#compile-r-html-docs":{},"community/publish/#fix-signature-issues":{},"community/publish/#make-a-sedona-release":{},"community/publish/#manually-close-and-release-the-package":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#upload-releases":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#develop-a-document-contribution":{},"community/rule/#make-a-pull-request":{},"community/rule/#review-a-pull-request":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"download/":{},"download/#past-releases":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{},"setup/compile/#download-staged-jars":{},"setup/compile/#mkdocs-website":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#community-edition-free-tier":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/databricks/#pure-sql-environment":{},"setup/flink/install-scala/":{},"setup/flink/modules/":{},"setup/flink/platform/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-python/#setup-environment-variables":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/install-scala/#spark-sql-shell":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/overview/":{},"setup/overview/#download-statistics":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#core":{},"setup/release-notes/#core_1":{},"setup/release-notes/#flink":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#global":{},"setup/release-notes/#global_1":{},"setup/release-notes/#global_2":{},"setup/release-notes/#global_3":{},"setup/release-notes/#highlights":{},"setup/release-notes/#improvement":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#new-feature":{},"setup/release-notes/#new-features":{},"setup/release-notes/#python":{},"setup/release-notes/#python_1":{},"setup/release-notes/#r":{},"setup/release-notes/#rdd":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-111":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_1":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#task":{},"setup/release-notes/#viz_1":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"setup/zeppelin/#compatibility":{},"setup/zeppelin/#display-sedonaviz-results":{},"setup/zeppelin/#enable-sedona-zeppelin":{},"setup/zeppelin/#install-sedona-zeppelin":{},"setup/zeppelin/#installation":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#installation":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/flink/sql/#set-up-dependencies":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/python-vector-osm/":{},"tutorial/raster/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#installation":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#register-package":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#register-sedonasql":{},"tutorial/sql/#save-geoparquet":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#initiate-sparksession":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#set-up-dependencies":{},"tutorial/viz/#store-the-image-on-disk":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink":{},"#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112":{},"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"#11232021-sedona-111-incubating-is-released-it-now-supports-spark-32":{},"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"community/develop/#develop-sedona":{},"community/publish/#10-release-sedona-r-to-cran":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#make-a-sedona-release":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/rule/#contributing-to-apache-sedona":{},"community/vote/#vote-a-sedona-release":{},"setup/compile/#compile-sedona-source-code":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/install-scala/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-r/":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/overview/#what-can-sedona-do":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-111":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#sedona-131":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sedona-viz":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-dependencies-in-zeppelin-spark-interpreter":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"setup/zeppelin/#enable-sedona-zeppelin":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}}}],["sedona.apache.org",{"_index":2973,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{}},"title":{"community/publish/#5-vote-in-dev-sedonaapacheorg":{}}}],["sedona.core.enum",{"_index":3912,"text":{"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{}},"title":{}}],["sedona.core.formatmapp",{"_index":3929,"text":{"tutorial/core-python/":{},"tutorial/core-python/#read-from-geojson-file":{},"tutorial/core-python/#read-from-wkb-file":{},"tutorial/core-python/#read-from-wkt-file":{}},"title":{}}],["sedona.core.formatmapper.disc_util",{"_index":3928,"text":{"tutorial/core-python/":{}},"title":{}}],["sedona.core.formatmapper.shapefilepars",{"_index":3931,"text":{"tutorial/core-python/":{},"tutorial/core-python/#read-from-shapefile":{}},"title":{}}],["sedona.core.geom.envelop",{"_index":3915,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["sedona.core.geom_types.envelop",{"_index":3914,"text":{"tutorial/core-python/":{}},"title":{}}],["sedona.core.spatialoper",{"_index":3916,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["sedona.core.spatialrdd",{"_index":3910,"text":{"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{}},"title":{}}],["sedona.core.spatialrdd.spatial_rdd.spatialrdd",{"_index":3930,"text":{"tutorial/core-python/":{},"tutorial/core-python/#read-from-geojson-file":{},"tutorial/core-python/#read-from-shapefile":{},"tutorial/core-python/#read-from-wkb-file":{},"tutorial/core-python/#read-from-wkt-file":{}},"title":{}}],["sedona.git",{"_index":3202,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#upload-releases":{}},"title":{}}],["sedona.global.charset",{"_index":602,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"tutorial/rdd/":{}},"title":{}}],["sedona.global.index",{"_index":966,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Parameter/#usage":{}},"title":{}}],["sedona.global.indextyp",{"_index":974,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{}},"title":{}}],["sedona.join.gridtyp",{"_index":976,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{}},"title":{}}],["sedona.join.indexbuildsid",{"_index":979,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{}},"title":{}}],["sedona.join.numpartit",{"_index":983,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{}},"title":{}}],["sedona.join.spatitionsid",{"_index":985,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{}},"title":{}}],["sedona.regist",{"_index":3955,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#register-package":{}},"title":{}}],["sedona.register.geo_registr",{"_index":3559,"text":{"setup/databricks/":{},"setup/databricks/#initialise":{}},"title":{}}],["sedona.sql",{"_index":4149,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["sedona.sql.st_aggreg",{"_index":4145,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["sedona.sql.st_constructor",{"_index":4142,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["sedona.sql.st_funct",{"_index":4143,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["sedona.sql.st_pred",{"_index":4144,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["sedona.sql.typ",{"_index":4165,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{}},"title":{}}],["sedona.staged.apache.org",{"_index":3343,"text":{"community/publish/":{},"community/publish/#11-publish-the-doc-website":{}},"title":{}}],["sedona.util",{"_index":3956,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["sedona.utils.adapt",{"_index":3913,"text":{"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["sedona/archive/refs/tags/sedona",{"_index":3243,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{}},"title":{}}],["sedona/blob/master/python/sedona/version.pi",{"_index":3209,"text":{"community/publish/":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{}},"title":{}}],["sedona/blob/master/r/descript",{"_index":3210,"text":{"community/publish/":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{}},"title":{}}],["sedona/blob/master/zeppelin/package.json",{"_index":3211,"text":{"community/publish/":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{}},"title":{}}],["sedona/blob/sedona",{"_index":3267,"text":{"community/publish/":{},"community/publish/#announce-email":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["sedona/examples/sql/src/test/resources/testenvelope.csv",{"_index":4133,"text":{"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{}},"title":{}}],["sedona/examples/sql/src/test/resources/testpoint.csv",{"_index":4131,"text":{"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{}},"title":{}}],["sedona/releases/tag/sedona",{"_index":3271,"text":{"community/publish/":{},"community/publish/#announce-email":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{}},"title":{}}],["sedona/sql",{"_index":3082,"text":{"community/develop/":{}},"title":{}}],["sedona/zeppelin",{"_index":3905,"text":{"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}},"title":{}}],["sedona@twitt",{"_index":2834,"text":{"community/contact/":{},"community/contact/#twitter":{}},"title":{}}],["sedona_create_release.current_git_tag",{"_index":3215,"text":{"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#7-failed-vote":{}},"title":{}}],["sedona_create_release.current_rc",{"_index":3214,"text":{"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#7-failed-vote":{}},"title":{}}],["sedona_create_release.current_snapshot",{"_index":3216,"text":{"community/publish/":{},"community/publish/#3-update-mkdocsyml":{}},"title":{}}],["sedona_create_release.current_vers",{"_index":3213,"text":{"community/publish/":{},"community/publish/#3-update-mkdocsyml":{}},"title":{}}],["sedona_current_rc",{"_index":3467,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["sedona_current_vers",{"_index":3468,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["sedona_read_dsv_to_typed_rdd",{"_index":4089,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["sedona_read_geojson",{"_index":4168,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["sedona_render_choropleth_map",{"_index":4244,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["sedona_render_scatter_plot",{"_index":4239,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["sedona_spatial_join_count_by_key",{"_index":4237,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["sedonaconf",{"_index":969,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"setup/release-notes/":{},"setup/release-notes/#improvement":{}},"title":{}}],["sedonaflinkregistr",{"_index":4276,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{}},"title":{}}],["sedonakryoregistr",{"_index":3595,"text":{"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{}},"title":{}}],["sedonakryoregistrator.getnam",{"_index":3983,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["sedonaregistr",{"_index":3560,"text":{"setup/databricks/":{},"setup/databricks/#initialise":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#register-package":{}},"title":{}}],["sedonaregistrator.registeral",{"_index":4137,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["sedonaregistrator.registerall(spark",{"_index":3988,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["sedonarunnableexampl",{"_index":4114,"text":{"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{}},"title":{}}],["sedonasql",{"_index":522,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#range-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"setup/zeppelin/":{},"tutorial/core-python/":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/raster/":{},"tutorial/raster/#initial-setup":{},"tutorial/rdd/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#other-queries":{},"tutorial/sql/#range-query":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{"api/sql/Optimizer/#sedonasql-query-optimizer":{},"setup/zeppelin/#visualize-sedonasql-results":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}}}],["sedonasqlregistr",{"_index":962,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{}}],["sedonaviz",{"_index":3648,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{},"tutorial/viz/#visualize-spatialrdd":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"setup/zeppelin/#display-sedonaviz-results":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}}}],["sedonavizkryoregistr",{"_index":4115,"text":{"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["sedonavizregistr",{"_index":1246,"text":{"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{}}],["sedona\u2019",{"_index":2851,"text":{"community/contact/":{},"community/contact/#bug-reports":{}},"title":{}}],["see",{"_index":273,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkt":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkt":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#installation":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#generate-a-single-image":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/install-python/":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/install-scala/#spark-sql-shell":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/zeppelin/":{},"setup/zeppelin/#installation":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#generate-a-single-image":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{}}],["seki",{"_index":2889,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["sekikn",{"_index":2890,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["sekikn@apache.org",{"_index":2891,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["select",{"_index":115,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Aggregator/#st_union_aggr":{},"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Constructor/#st_geomfromgml":{},"api/flink/Constructor/#st_geomfromkml":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/flink/Constructor/#st_point":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_area":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_distance":{},"api/flink/Function/#st_envelope":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_issimple":{},"api/flink/Function/#st_isvalid":{},"api/flink/Function/#st_length":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_transform":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_z":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_orderingequals":{},"api/flink/Predicate/#st_within":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromgml":{},"api/sql/Constructor/#st_geomfromkml":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_area":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_convexhull":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_length":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_npoints":{},"api/sql/Function/#st_numgeometries":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalize":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{},"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_pixelize":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/develop/":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#range-query":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#render-the-image":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/download/project/#select-an-ide":{}}}],["selectexpr",{"_index":934,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_html":{}},"title":{}}],["self",{"_index":383,"text":{"api/flink/Function/":{},"api/flink/Function/#st_issimple":{},"api/sql/Function/":{},"api/sql/Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#self-contained-spark-projects":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{"archive/download/project/":{},"archive/download/project/#self-contained-spark-projects":{},"setup/install-scala/#self-contained-spark-projects":{}}}],["semen",{"_index":1443,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["semi",{"_index":890,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["send",{"_index":2841,"text":{"community/contact/":{},"community/contact/#feature-requests":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-a-notice-to-ipmc":{}},"title":{"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{}}}],["sent",{"_index":3432,"text":{"community/rule/":{},"community/rule/#pick-annouce-a-task-using-jira":{}},"title":{}}],["separ",{"_index":1552,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#v101":{},"setup/release-notes/#v112":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{}}}],["seq",{"_index":4200,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}},"title":{}}],["sequenc",{"_index":2192,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["serd",{"_index":3753,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["sergii",{"_index":1509,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["serhuela",{"_index":1517,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["serial",{"_index":403,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#sql":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{"archive/tutorial/geospark-core-python/#geospark-serializers":{},"tutorial/core-python/#apache-sedona-serializers":{}}}],["sernetcdf",{"_index":1684,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["serv",{"_index":1747,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["server",{"_index":1284,"text":{"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"community/contact/":{},"community/contact/#discord-server":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{"community/contact/#discord-server":{}}}],["session",{"_index":948,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/python-vector-osm/":{},"tutorial/raster/":{},"tutorial/raster/#initial-setup":{},"tutorial/sql-pure-sql/":{}},"title":{"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/sql-pure-sql/#initiate-session":{}}}],["set",{"_index":457,"text":{"api/flink/Function/":{},"api/flink/Function/#st_setsrid":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_symdifference":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/raster/":{},"tutorial/raster/#initial-setup":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql/":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{"archive/download/cluster/":{},"archive/download/cluster/#set-up-your-apache-spark-cluster":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/#set-up-dependencies":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"setup/cluster/":{},"setup/cluster/#set-up-your-apache-spark-cluster":{},"tutorial/flink/sql/#set-up-dependencies":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/#set-up-dependencies":{}}}],["setappnam",{"_index":2320,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{}},"title":{}}],["setmast",{"_index":2322,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{}},"title":{}}],["setnetcdf",{"_index":1685,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["setproperti",{"_index":606,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["setter",{"_index":1625,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v082-geospark-core":{}},"title":{}}],["setup",{"_index":3456,"text":{"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/raster/":{}},"title":{"setup/install-python/#setup-environment-variables":{},"tutorial/raster/#initial-setup":{}}}],["setup.pi",{"_index":2028,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-from-source":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installing-from-source":{},"community/publish/":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#python":{}},"title":{}}],["setuptool",{"_index":3524,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["setuserdata",{"_index":4334,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["sever",{"_index":1527,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"setup/release-notes/":{},"setup/release-notes/#v112":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["sew",{"_index":712,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{}},"title":{}}],["sh",{"_index":3564,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["sha512",{"_index":80,"text":{"download/":{},"download/#121-incubating":{},"download/#130-incubating":{}},"title":{}}],["shahida",{"_index":1450,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["shape",{"_index":583,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_pixelize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"community/contributor/":{},"community/contributor/#mentors":{},"setup/install-python/":{},"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{"archive/tutorial/geospark-sql-python/#creating-spark-dataframe-based-on-shapely-objects":{},"archive/tutorial/geospark-sql-python/#example-usage-for-shapely-objects":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#creating-spark-dataframe-based-on-shapely-objects":{},"tutorial/sql-python/#example-usage-for-shapely-objects":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#supported-shapely-objects":{}}}],["shape_file_loc",{"_index":2162,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-shapefile":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-shapefile":{}},"title":{}}],["shapefiel",{"_index":1470,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["shapefil",{"_index":555,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#rdd":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql/":{},"tutorial/sql/#load-shapefile-and-geojson":{}},"title":{"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/geospark-core-python/#read-from-shapefile":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/core-python/#read-from-shapefile":{},"tutorial/sql/#load-shapefile-and-geojson":{}}}],["shapefile1",{"_index":586,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["shapefile2",{"_index":587,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["shapefileinputloc",{"_index":564,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["shapefilerdd.getspatialrdd",{"_index":1636,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["shapefileread",{"_index":560,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-shapefile":{},"archive/tutorial/rdd/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-shapefile":{},"tutorial/rdd/":{}},"title":{}}],["shapefilereader.readtogeometryrdd",{"_index":605,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["shapely.geometri",{"_index":2104,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{}},"title":{}}],["shapely.geometry.basegeometri",{"_index":1998,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{}},"title":{}}],["shapely.geometry.point.point",{"_index":2126,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_3":{}},"title":{}}],["share",{"_index":1962,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["shasum",{"_index":3257,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["shell",{"_index":325,"text":{"api/flink/Function/":{},"api/flink/Function/#st_exteriorring":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/download/scalashell/#spark-scala-shell":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/sql-python/":{},"tutorial/sql-python/#register-package":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"setup/install-scala/#spark-scala-shell":{},"setup/install-scala/#spark-sql-shell":{}}}],["shi",{"_index":1514,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["shift",{"_index":3887,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-core":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["short",{"_index":3147,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["shorten",{"_index":1745,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["shouldn't",{"_index":3002,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["show",{"_index":574,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-loader/#rs_html":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/develop/":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#range-query":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["shown",{"_index":2940,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/develop/":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["shp",{"_index":578,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/rdd/":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/rdd/":{}},"title":{}}],["shuffl",{"_index":883,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["shx",{"_index":579,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/tutorial/rdd/":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"tutorial/rdd/":{}},"title":{}}],["side",{"_index":880,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v120":{}},"title":{}}],["sidebar",{"_index":3408,"text":{"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{}},"title":{}}],["siginicantli",{"_index":1665,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["sigmod",{"_index":3108,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["sign",{"_index":3478,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["signatur",{"_index":78,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"download/":{},"download/#121-incubating":{},"download/#130-incubating":{}},"title":{"community/publish/#fix-signature-issues":{}}}],["signific",{"_index":1921,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["significantli",{"_index":1593,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-partitioning":{}},"title":{}}],["sigspati",{"_index":3149,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["simba",{"_index":3120,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["simialr",{"_index":1480,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["similar",{"_index":1991,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/rdd/":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["simpl",{"_index":485,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"setup/install-scala/":{}},"title":{}}],["simpler",{"_index":3616,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["simpli",{"_index":1825,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/compile/":{},"setup/compile/#compile-with-different-targets":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd/":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{}}],["simplifi",{"_index":780,"text":{"api/sql/Function/":{},"api/sql/Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v112":{}},"title":{}}],["simul",{"_index":3101,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#key-publications":{}},"title":{"community/publication/#geosparksim-traffic-simulator":{}}}],["singl",{"_index":424,"text":{"api/flink/Function/":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_pointn":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_numgeometries":{},"api/sql/Function/#st_pointn":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/sql/":{},"api/viz/sql/#st_render":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_render":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels_1":{},"archive/tutorial/viz/#generate-a-single-image":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"community/develop/":{},"community/publish/":{},"community/publish/#make-a-sedona-release":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/rdd/":{},"tutorial/sql/":{},"tutorial/sql/#range-query":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels_1":{},"tutorial/viz/#generate-a-single-image":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#render-the-image":{},"tutorial/viz/#store-map-tiles-on-disk":{}},"title":{"archive/tutorial/viz/#generate-a-single-image":{},"tutorial/viz/#generate-a-single-image":{}}}],["site",{"_index":3341,"text":{"community/publish/":{},"community/publish/#11-publish-the-doc-website":{}},"title":{}}],["site/api/javadoc",{"_index":3347,"text":{"community/publish/":{}},"title":{}}],["site/api/javadoc/sql",{"_index":3345,"text":{"community/publish/":{}},"title":{}}],["situat",{"_index":2984,"text":{"community/contributor/":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["six",{"_index":1970,"text":{"archive/tutorial/GeoSpark-Runnable-DEMO/":{}},"title":{}}],["size",{"_index":1104,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v110":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["size(el",{"_index":4019,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["skel",{"_index":4000,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["skew",{"_index":1746,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["skip",{"_index":1462,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v111":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v130":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#v111":{},"setup/release-notes/#v130":{}},"title":{}}],["skipsyntaxinvalidgeometri",{"_index":2366,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["slave",{"_index":3944,"text":{"tutorial/python-vector-osm/":{}},"title":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}}}],["slight",{"_index":1924,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["slow",{"_index":1944,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["small",{"_index":1528,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v112":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}}}],["small.csv",{"_index":4087,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["smalldf",{"_index":308,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{}},"title":{}}],["smaller",{"_index":1570,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#v110":{}},"title":{}}],["smallest",{"_index":756,"text":{"api/sql/Function/":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{}},"title":{}}],["snapshot",{"_index":1314,"text":{"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#buildsbt":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#buildsbt":{},"setup/maven-coordinates/#pomxml":{},"setup/maven-coordinates/#snapshot-versions":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/maven-coordinates/#snapshot-versions":{}}}],["snapshots><en",{"_index":1399,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#pomxml":{}},"title":{}}],["softwar",{"_index":2804,"text":{"asf/asf/":{},"asf/asf/#copyright":{},"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/release-manager/":{},"community/rule/":{},"community/rule/#code-of-conduct":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#buildsbt":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{}},"title":{"community/release-manager/#0-software-requirement":{},"community/vote/#install-necessary-software":{}}}],["solut",{"_index":2141,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/core-python/":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["solv",{"_index":1589,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["someth",{"_index":2608,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{}},"title":{}}],["sometim",{"_index":752,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{}},"title":{}}],["somewher",{"_index":3412,"text":{"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{}},"title":{}}],["sonatyp",{"_index":1387,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#buildsbt":{}},"title":{}}],["soon",{"_index":103,"text":{"api/python-api/":{},"archive/api/GeoSpark-Python-API/":{},"archive/tutorial/faq/":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["sourc",{"_index":56,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/overview/":{},"archive/download/overview/#direct-download":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/vote/":{},"community/vote/#check-files-manually":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"download/":{},"download/#121-incubating":{},"download/#130-incubating":{},"download/#github-repository":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#global":{},"setup/release-notes/#global_3":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/raster/":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/geospark-core-python/#installing-from-source":{},"archive/tutorial/geospark-sql-python/#installing-from-source":{},"community/publish/#8-release-source-code-and-maven-package":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-sedona-source-code":{}}}],["sourcecr",{"_index":465,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{}},"title":{}}],["sourcecrs:str",{"_index":482,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{}},"title":{}}],["sourcecrscod",{"_index":2603,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["spark",{"_index":26,"text":{"":{},"api/flink/Constructor/":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_distance":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_transform":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_disjoint":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_area":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_convexhull":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_length":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_within":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-loader/#rs_html":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalize":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_pixelize":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/cluster/#set-up-your-apache-spark-cluster":{},"archive/download/cluster/#start-your-cluster":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#compatibility":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#supported-versions":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#linestring":{},"archive/tutorial/geospark-sql-python/#multilinestring":{},"archive/tutorial/geospark-sql-python/#multipoint":{},"archive/tutorial/geospark-sql-python/#multipolygon":{},"archive/tutorial/geospark-sql-python/#point":{},"archive/tutorial/geospark-sql-python/#polygon":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#supported-versions":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#set-up-dependencies":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/cluster/#set-up-your-apache-spark-cluster":{},"setup/cluster/#start-your-cluster":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#compile-with-different-targets":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/modules/":{},"setup/overview/":{},"setup/overview/#distributed-spatial-datasets":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#global_2":{},"setup/release-notes/#global_3":{},"setup/release-notes/#highlights":{},"setup/release-notes/#improvement":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#python":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_1":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#task":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v101":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v120":{},"setup/release-notes/#viz_1":{},"setup/zeppelin/":{},"setup/zeppelin/#compatibility":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/raster/":{},"tutorial/raster/#initial-setup":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#linestring":{},"tutorial/sql-python/#multilinestring":{},"tutorial/sql-python/#multipoint":{},"tutorial/sql-python/#multipolygon":{},"tutorial/sql-python/#point":{},"tutorial/sql-python/#polygon":{},"tutorial/sql-python/#register-package":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#register-sedonasql":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{},"tutorial/viz/#set-up-dependencies":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112":{},"#11232021-sedona-111-incubating-is-released-it-now-supports-spark-32":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions":{},"archive/download/cluster/":{},"archive/download/cluster/#set-up-your-apache-spark-cluster":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/download/zeppelin/#add-geospark-dependencies-in-zeppelin-spark-interpreter":{},"archive/tutorial/geospark-core-python/#apache-spark":{},"archive/tutorial/geospark-sql-python/#apache-spark":{},"archive/tutorial/geospark-sql-python/#creating-spark-dataframe-based-on-shapely-objects":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"setup/cluster/":{},"setup/cluster/#set-up-your-apache-spark-cluster":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/install-scala/#spark-scala-shell":{},"setup/install-scala/#spark-sql-shell":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/release-notes/#sql-for-spark":{},"setup/zeppelin/#add-sedona-dependencies-in-zeppelin-spark-interpreter":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/sql-python/#creating-spark-dataframe-based-on-shapely-objects":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}}}],["spark.createdatafram",{"_index":2193,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["spark.driver.maxresults",{"_index":1791,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["spark.driver.memori",{"_index":1788,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["spark.jars.packag",{"_index":3596,"text":{"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{}},"title":{}}],["spark.kryo.registr",{"_index":953,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["spark.network.timeout",{"_index":1790,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["spark.read.format(\"geoparquet\").option(\"fieldgeometri",{"_index":3722,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["spark.read.json(path",{"_index":4013,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{}},"title":{}}],["spark.seri",{"_index":951,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{}},"title":{}}],["spark.sparkcontext",{"_index":3989,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["spark.sql",{"_index":2792,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["spark.sql(\"select",{"_index":4018,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["spark.sql.adaptive.coalescepartitions.en",{"_index":3974,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["spark.sql.extens",{"_index":3582,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{}},"title":{}}],["spark.sql.extensions=org.apache.sedona.sql.sedonasqlextens",{"_index":4136,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#register-package":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{}},"title":{}}],["spark.sql.extensions=org.apache.sedona.viz.sql.sedonavizextensions,org.apache.sedona.sql.sedonasqlextens",{"_index":4263,"text":{"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{}}],["spark1.x",{"_index":1915,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{}},"title":{}}],["spark://localhost:7077",{"_index":1882,"text":{"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{}},"title":{}}],["spark://your",{"_index":1847,"text":{"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/download/project/#submit-the-compiled-jar":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{}},"title":{}}],["spark_connect",{"_index":3633,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["spark_hom",{"_index":3515,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{}}],["spark_home/jar",{"_index":2019,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-python/#setup-environment-variables":{}},"title":{}}],["spark_home=$pwd/spark",{"_index":3517,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["spark_sess",{"_index":3641,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["sparkconf",{"_index":965,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"setup/release-notes/":{},"setup/release-notes/#v100":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{}},"title":{}}],["sparkcontext",{"_index":563,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{}},"title":{"archive/tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#initiate-sparkcontext":{}}}],["sparkimagegener",{"_index":1766,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["sparklyr",{"_index":3602,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["sparklyr::spark_connect",{"_index":3643,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["sparksess",{"_index":562,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#range-query":{},"tutorial/sql/#register-sedonasql":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/#initiate-sparksession":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/#initiate-sparksession":{}}}],["sparksession.table(\"images\").take(1)(0)(0).asinstanceof[imageserializablewrapper].getimag",{"_index":2764,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"tutorial/viz/":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{}}],["sparksql",{"_index":556,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#set-up-dependencies":{},"setup/release-notes/":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#v101":{},"setup/release-notes/#v110":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{},"tutorial/viz/#set-up-dependencies":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23_1":{}}}],["sparkvers",{"_index":1868,"text":{"archive/download/project/":{},"archive/download/project/#package-the-project":{}},"title":{}}],["spatailrdd",{"_index":4085,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{}},"title":{}}],["spatial",{"_index":17,"text":{"":{},"api/flink/Function/":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_transform":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_transform":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"api/viz/sql/#st_colorize":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/api/viz/sql/#st_colorize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_1":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#output-format":{},"archive/tutorial/rdd/#output-format_1":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#run-spatial-queries":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#generate-a-single-image":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#key-publications":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#announce-email":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/overview/":{},"setup/overview/#distributed-spatial-datasets":{},"setup/overview/#distributed-spatial-queries":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#rdd":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v100":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_1":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#run-spatial-queries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#output-format":{},"tutorial/rdd/#output-format_1":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#run-spatial-queries":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#generate-a-single-image":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#spatial-rdd-applications-in-python":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#spatial-sql-application-in-python":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#run-spatial-queries":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"setup/overview/#complex-spatial-objects":{},"setup/overview/#distributed-spatial-datasets":{},"setup/overview/#distributed-spatial-queries":{},"setup/overview/#rich-spatial-analytics-tools":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/#spatial-rdd-applications-in-python":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/flink/sql/#convert-spatial-datastream-to-spatial-table":{},"tutorial/flink/sql/#convert-spatial-table-to-spatial-datastream":{},"tutorial/flink/sql/#get-spatial-table":{},"tutorial/flink/sql/#run-spatial-queries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd-r/#spatial-rdd-applications-in-r-language":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-python/#spatial-sql-application-in-python":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/#run-spatial-queries":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#pixelize-spatial-objects":{}}}],["spatial_col",{"_index":4109,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["spatial_df",{"_index":2052,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{}},"title":{}}],["spatial_join_result",{"_index":2229,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["spatial_rdd",{"_index":2057,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["spatial_rdd.spatialpartitioning(grid_typ",{"_index":3901,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-python":{}},"title":{}}],["spatialddf",{"_index":2689,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{}},"title":{}}],["spatialdf",{"_index":569,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/rdd/":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#range-query":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["spatialindex",{"_index":903,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["spatialjoin",{"_index":3922,"text":{"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{}},"title":{}}],["spatialjoinqueri",{"_index":2115,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{}}],["spatialjoinqueryflat",{"_index":2117,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_2":{}},"title":{}}],["spatialjoinqueryflat/distancejoinqueryflat",{"_index":1606,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["spatialknnqueri",{"_index":2108,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"setup/release-notes/":{},"setup/release-notes/#core":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["spatialpairrdd",{"_index":2719,"text":{"archive/tutorial/sql/":{},"tutorial/sql/":{}},"title":{"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{}}}],["spatialpartit",{"_index":2112,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"setup/release-notes/":{},"setup/release-notes/#sedona-python":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{}}}],["spatialpartitionedrdd",{"_index":1947,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["spatialpartitionedrdd/indexedrdd",{"_index":1961,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["spatialpred",{"_index":4119,"text":{"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["spatialpredicate.intersect",{"_index":4121,"text":{"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["spatialrangequeri",{"_index":2080,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["spatialrdd",{"_index":558,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/#output-format":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#reload-a-saved-spatialrdd":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/viz/":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v112":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#reload-a-saved-spatialrdd":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-an-spatialrdd-not-indexed":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/rdd/#output-format":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#reload-a-saved-spatialrdd":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{}},"title":{"archive/tutorial/geospark-core-python/#create-a-spatialrdd":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#reload-a-saved-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#create-a-spatialrdd":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#reload-a-saved-spatialrdd":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/sql/#convert-between-dataframe-and-spatialrdd":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"tutorial/core-python/#create-a-spatialrdd":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#reload-a-saved-spatialrdd":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-an-spatialrdd-not-indexed":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#create-a-spatialrdd":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#reload-a-saved-spatialrdd":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/sql/#convert-between-dataframe-and-spatialrdd":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/#visualize-spatialrdd":{}}}],["spatialrdd'",{"_index":2123,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{}},"title":{}}],["spatialrdd.flipcoordin",{"_index":3888,"text":{"setup/release-notes/":{},"setup/release-notes/#sedona-core":{}},"title":{}}],["speak",{"_index":3608,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["special",{"_index":1993,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{}},"title":{}}],["specif",{"_index":1139,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-annoucement":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["specifi",{"_index":1498,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v120":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{}},"title":{}}],["spectral",{"_index":1128,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_subtract":{}},"title":{}}],["speed",{"_index":1638,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#viz_1":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-partitioning":{}},"title":{}}],["spheroid[\"wg",{"_index":3734,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["split",{"_index":3957,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["splitter",{"_index":1935,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{}},"title":{}}],["sponsor",{"_index":2808,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{}},"title":{}}],["spread",{"_index":4141,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["sql",{"_index":50,"text":{"":{},"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Aggregator/#st_union_aggr":{},"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Constructor/#st_geomfromgml":{},"api/flink/Constructor/#st_geomfromkml":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/flink/Constructor/#st_point":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_distance":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_transform":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_orderingequals":{},"api/flink/Predicate/#st_within":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromgml":{},"api/sql/Constructor/#st_geomfromkml":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_area":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_convexhull":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_length":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Overview/#quick-start":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_within":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-loader/#rs_html":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalize":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{},"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_pixelize":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#compatibility":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#initialise":{},"setup/databricks/#pure-sql-environment":{},"setup/flink/modules/":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#spark-sql-shell":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/modules/":{},"setup/modules/#api-availability":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#python_1":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v100":{},"setup/release-notes/#v101":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"setup/zeppelin/":{},"setup/zeppelin/#compatibility":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/raster/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#range-query":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#set-up-dependencies":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-sql":{},"archive/download/project/#try-geospark-sql-functions":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#spatial-sql-application-in-python":{},"archive/tutorial/sql/":{},"setup/databricks/#pure-sql-environment":{},"setup/install-scala/#spark-sql-shell":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_1":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#sql_3":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-python/#spatial-sql-application-in-python":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}}}],["sql,sedona",{"_index":1242,"text":{"api/viz/sql/":{},"api/viz/sql/#quick-start":{}},"title":{}}],["sql.jar",{"_index":2170,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{}},"title":{}}],["sql/datafram",{"_index":942,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"tutorial/viz/":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{}}],["sql/mm",{"_index":523,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/tutorial/sql/":{},"setup/release-notes/":{},"setup/release-notes/#v100":{},"tutorial/flink/sql/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{}},"title":{}}],["sql/src/main/scala/org/apache/sedona/sql/utils/*.scala",{"_index":3346,"text":{"community/publish/":{}},"title":{}}],["sql_2.1",{"_index":1375,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21":{}},"title":{}}],["sql_2.2",{"_index":1373,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22":{}},"title":{}}],["sql_2.3",{"_index":1371,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{}},"title":{}}],["sql_2.3:1.2.0,org.datasyslab:geospark",{"_index":1880,"text":{"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{}},"title":{}}],["sqlqueri",{"_index":4269,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["squar",{"_index":1227,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_squareroot":{}},"title":{}}],["squareroot",{"_index":1231,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_squareroot":{}},"title":{}}],["src",{"_index":79,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_html":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"download/":{},"download/#121-incubating":{},"download/#130-incubating":{}},"title":{}}],["src.tar.gz",{"_index":3247,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["src.tar.gz.asc",{"_index":3264,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["src.tar.gz.sha512",{"_index":3259,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["src/core/target/sedona",{"_index":3250,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{}},"title":{}}],["src/flink/target/sedona",{"_index":3256,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{}},"title":{}}],["src/python",{"_index":3254,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{}},"title":{}}],["src/sql/target/sedona",{"_index":3252,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{}},"title":{}}],["src/viz/target/sedona",{"_index":3253,"text":{"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{}},"title":{}}],["srcwktstring",{"_index":3729,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["srdd",{"_index":1718,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["srid",{"_index":183,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_srid":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["srid:integ",{"_index":622,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{}},"title":{}}],["srsname=\"epsg:4269\"><gml:coordin",{"_index":148,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgml":{}},"title":{}}],["ssdbm",{"_index":3158,"text":{"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["ssh",{"_index":1775,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["sstd",{"_index":3171,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{}},"title":{}}],["st",{"_index":1491,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v120":{}},"title":{}}],["st_",{"_index":936,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"setup/databricks/#pure-sql-environment":{}},"title":{}}],["st_3ddistanc",{"_index":230,"text":{"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{"api/flink/Function/#st_3ddistance":{},"api/sql/Function/#st_3ddistance":{}}}],["st_addpoint",{"_index":240,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_addpoint":{},"api/sql/Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{}}}],["st_addpoint(geom",{"_index":247,"text":{"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{}},"title":{}}],["st_area",{"_index":254,"text":{"api/flink/Function/":{},"api/flink/Function/#st_area":{},"api/sql/Function/":{},"api/sql/Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{"api/flink/Function/#st_area":{},"api/sql/Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{}}}],["st_asbinari",{"_index":256,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asbinary":{},"api/sql/Function/":{},"api/sql/Function/#st_asbinary":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql_1":{}},"title":{"api/flink/Function/#st_asbinary":{},"api/sql/Function/#st_asbinary":{}}}],["st_asewkb",{"_index":260,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"setup/release-notes/":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql_1":{}},"title":{"api/flink/Function/#st_asewkb":{},"api/sql/Function/#st_asewkb":{}}}],["st_asewkt",{"_index":271,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_normalize":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_normalize":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Function/#st_asewkt":{},"api/sql/Function/#st_asewkt":{}}}],["st_asgeojson",{"_index":275,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asgeojson":{},"api/sql/Function/":{},"api/sql/Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sedona-sql":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{"api/flink/Function/#st_asgeojson":{},"api/sql/Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{}}}],["st_asgml",{"_index":276,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asgml":{},"api/sql/Function/":{},"api/sql/Function/#st_asgml":{}},"title":{"api/flink/Function/#st_asgml":{},"api/sql/Function/#st_asgml":{}}}],["st_askml",{"_index":277,"text":{"api/flink/Function/":{},"api/flink/Function/#st_askml":{},"api/sql/Function/":{},"api/sql/Function/#st_askml":{}},"title":{"api/flink/Function/#st_askml":{},"api/sql/Function/#st_askml":{}}}],["st_astext",{"_index":278,"text":{"api/flink/Function/":{},"api/flink/Function/#st_astext":{},"api/sql/Function/":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_reverse":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#render-the-image":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#sql":{},"setup/release-notes/#v120":{},"tutorial/viz/":{},"tutorial/viz/#render-the-image":{}},"title":{"api/flink/Function/#st_astext":{},"api/sql/Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{}}}],["st_astext(bound",{"_index":2794,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["st_astext(countyshap",{"_index":4195,"text":{"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{}}],["st_astext(shap",{"_index":2789,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["st_astext(st_pointonsurface(st_geomfromtext('linestring(0",{"_index":771,"text":{"api/sql/Function/":{},"api/sql/Function/#st_pointonsurface":{}},"title":{}}],["st_astext(st_pointonsurface(st_geomfromtext('point(0",{"_index":769,"text":{"api/sql/Function/":{},"api/sql/Function/#st_pointonsurface":{}},"title":{}}],["st_astext(st_pointonsurface(st_geomfromtext('polygon((0",{"_index":772,"text":{"api/sql/Function/":{},"api/sql/Function/#st_pointonsurface":{}},"title":{}}],["st_azimuth",{"_index":279,"text":{"api/flink/Function/":{},"api/flink/Function/#st_azimuth":{},"api/sql/Function/":{},"api/sql/Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_azimuth":{},"api/sql/Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{}}}],["st_azimuth(pointa",{"_index":285,"text":{"api/flink/Function/":{},"api/flink/Function/#st_azimuth":{},"api/sql/Function/":{},"api/sql/Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{}},"title":{}}],["st_boundari",{"_index":289,"text":{"api/flink/Function/":{},"api/flink/Function/#st_boundary":{},"api/sql/Function/":{},"api/sql/Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_boundary":{},"api/sql/Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{}}}],["st_boundary(geom",{"_index":292,"text":{"api/flink/Function/":{},"api/flink/Function/#st_boundary":{},"api/sql/Function/":{},"api/sql/Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{}},"title":{}}],["st_buffer",{"_index":294,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buffer":{},"api/sql/Function/":{},"api/sql/Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{"api/flink/Function/#st_buffer":{},"api/sql/Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{}}}],["st_buildarea",{"_index":302,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/sql/Function/":{},"api/sql/Function/#st_buildarea":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Function/#st_buildarea":{},"api/sql/Function/#st_buildarea":{}}}],["st_centroid",{"_index":638,"text":{"api/sql/Function/":{},"api/sql/Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{}},"title":{"api/sql/Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{}}}],["st_circl",{"_index":1326,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{}}}],["st_collect",{"_index":307,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buildarea":{},"api/sql/Function/":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_multi":{},"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{"api/sql/Function/#st_collect":{}}}],["st_collect(*geom",{"_index":644,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collect":{}},"title":{}}],["st_collect(geom",{"_index":645,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collect":{}},"title":{}}],["st_collectionextract",{"_index":651,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{},"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/sql/Function/#st_collectionextract":{}}}],["st_color",{"_index":1248,"text":{"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels":{}},"title":{"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/#st_colorize":{}}}],["st_constructor",{"_index":4150,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["st_contain",{"_index":218,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#range-query":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/sql/":{},"tutorial/sql/#range-query":{}},"title":{"api/flink/Predicate/#st_contains":{},"api/sql/Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{}}}],["st_contains(polygondf.polygonshap",{"_index":895,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["st_contains(polygonshape#30",{"_index":900,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["st_convexhul",{"_index":661,"text":{"api/sql/Function/":{},"api/sql/Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#v110":{}},"title":{"api/sql/Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{}}}],["st_cover",{"_index":549,"text":{"api/flink/Predicate/":{},"api/flink/Predicate/#st_covers":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_covers":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{"api/flink/Predicate/#st_covers":{},"api/sql/Predicate/#st_covers":{}}}],["st_coveredbi",{"_index":551,"text":{"api/flink/Predicate/":{},"api/flink/Predicate/#st_coveredby":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_coveredby":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{"api/flink/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_coveredby":{}}}],["st_cross",{"_index":988,"text":{"api/sql/Predicate/":{},"api/sql/Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{"api/sql/Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{}}}],["st_differ",{"_index":665,"text":{"api/sql/Function/":{},"api/sql/Function/#st_difference":{},"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{"api/sql/Function/#st_difference":{}}}],["st_disjoinnt",{"_index":542,"text":{"api/flink/Predicate/":{},"api/flink/Predicate/#st_disjoint":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_disjoint":{}},"title":{}}],["st_disjoint",{"_index":540,"text":{"api/flink/Predicate/":{},"api/flink/Predicate/#st_disjoint":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_disjoint":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_disjoint":{}}}],["st_distanc",{"_index":319,"text":{"api/flink/Function/":{},"api/flink/Function/#st_distance":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_distance":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{}},"title":{"api/flink/Function/#st_distance":{},"api/sql/Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{}}}],["st_distance(pointdf1.pointshap",{"_index":911,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["st_distance(pointshape#52",{"_index":914,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["st_distance(st_polygonfromenvelope(1.0,100.0,1000.0,1100.0",{"_index":2704,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#knn-query":{},"tutorial/sql/":{},"tutorial/sql/#knn-query":{}},"title":{}}],["st_dump",{"_index":667,"text":{"api/sql/Function/":{},"api/sql/Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/sql/Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{}}}],["st_dump(geom",{"_index":673,"text":{"api/sql/Function/":{},"api/sql/Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{}},"title":{}}],["st_dumppoint",{"_index":674,"text":{"api/sql/Function/":{},"api/sql/Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/sql/Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{}}}],["st_dumppoints(geom",{"_index":677,"text":{"api/sql/Function/":{},"api/sql/Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{}},"title":{}}],["st_encodeimag",{"_index":1281,"text":{"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{"api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_encodeimage":{}}}],["st_encodeimage(imag",{"_index":2793,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["st_endpoint",{"_index":678,"text":{"api/sql/Function/":{},"api/sql/Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/sql/Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{}}}],["st_endpoint(geom",{"_index":679,"text":{"api/sql/Function/":{},"api/sql/Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{}},"title":{}}],["st_envelop",{"_index":321,"text":{"api/flink/Function/":{},"api/flink/Function/#st_envelope":{},"api/sql/Function/":{},"api/sql/Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{"api/flink/Function/#st_envelope":{},"api/sql/Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{}}}],["st_envelope_aggr",{"_index":104,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_pixelize":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{"api/flink/Aggregator/#st_envelope_aggr":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{}}}],["st_equal",{"_index":992,"text":{"api/sql/Predicate/":{},"api/sql/Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{"api/sql/Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{}}}],["st_exterior",{"_index":322,"text":{"api/flink/Function/":{},"api/flink/Function/#st_exteriorring":{},"api/sql/Function/":{},"api/sql/Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_exteriorring":{},"api/sql/Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{}}}],["st_exteriorring(a:geometri",{"_index":326,"text":{"api/flink/Function/":{},"api/flink/Function/#st_exteriorring":{}},"title":{}}],["st_exteriorring(geom",{"_index":688,"text":{"api/sql/Function/":{},"api/sql/Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{}},"title":{}}],["st_flipcoordin",{"_index":328,"text":{"api/flink/Function/":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_transform":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_flipcoordinates":{},"api/sql/Function/#st_flipcoordinates":{}}}],["st_flipcoordinates(a:geometri",{"_index":331,"text":{"api/flink/Function/":{},"api/flink/Function/#st_flipcoordinates":{},"api/sql/Function/":{},"api/sql/Function/#st_flipcoordinates":{}},"title":{}}],["st_force3d",{"_index":3712,"text":{"setup/release-notes/":{},"setup/release-notes/#new-feature":{}},"title":{}}],["st_force_2d",{"_index":332,"text":{"api/flink/Function/":{},"api/flink/Function/#st_force_2d":{},"api/sql/Function/":{},"api/sql/Function/#st_force_2d":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Function/#st_force_2d":{},"api/sql/Function/#st_force_2d":{}}}],["st_geohash",{"_index":347,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geohash":{},"api/sql/Function/":{},"api/sql/Function/#st_geohash":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_1":{}},"title":{"api/flink/Function/#st_geohash":{},"api/sql/Function/#st_geohash":{}}}],["st_geohash(geom",{"_index":348,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geohash":{},"api/sql/Function/":{},"api/sql/Function/#st_geohash":{}},"title":{}}],["st_geometryn",{"_index":354,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_geometryn":{},"api/sql/Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{}}}],["st_geometryn(geom",{"_index":362,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geometryn":{},"api/sql/Function/":{},"api/sql/Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{}},"title":{}}],["st_geometrytyp",{"_index":689,"text":{"api/sql/Function/":{},"api/sql/Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{"api/sql/Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{}}}],["st_geomfromewkt",{"_index":419,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{}},"title":{}}],["st_geomfromgeohash",{"_index":125,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql_1":{}},"title":{"api/flink/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_geomfromgeohash":{}}}],["st_geomfromgeohash(geohash",{"_index":131,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{}},"title":{}}],["st_geomfromgeojson",{"_index":137,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"setup/release-notes/":{},"setup/release-notes/#flink_1":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{"api/flink/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{}}}],["st_geomfromgeojson(polygontable._c0",{"_index":618,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{}},"title":{}}],["st_geomfromgml",{"_index":144,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgml":{}},"title":{"api/flink/Constructor/#st_geomfromgml":{},"api/sql/Constructor/#st_geomfromgml":{}}}],["st_geomfromkml",{"_index":152,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromkml":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromkml":{}},"title":{"api/flink/Constructor/#st_geomfromkml":{},"api/sql/Constructor/#st_geomfromkml":{}}}],["st_geomfromtext",{"_index":158,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_setpoint":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{}},"title":{"api/flink/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromtext":{}}}],["st_geomfromtext('point",{"_index":4106,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["st_geomfromwkb",{"_index":165,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v112":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{"api/flink/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{}}}],["st_geomfromwkt",{"_index":161,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/flink/Function/":{},"api/flink/Function/#st_normalize":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Function/":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_union":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_orderingequals":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{"api/flink/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{}}}],["st_geomfromwkt(_c0",{"_index":2053,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"tutorial/core-python/":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{}},"title":{}}],["st_geomfromwkt(geom",{"_index":2198,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["st_geomfromwkt(geom#232",{"_index":2241,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["st_geomfromwkt(geom_polygon",{"_index":4301,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{}},"title":{}}],["st_geomfromwkt(image.geometri",{"_index":1030,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["st_geomfromwkt(rddshap",{"_index":570,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{}},"title":{}}],["st_geomfromwkt/st_geomfromtext",{"_index":3798,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["st_geomfromwkt/wkb/text",{"_index":3808,"text":{"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["st_i",{"_index":504,"text":{"api/flink/Function/":{},"api/flink/Function/#st_y":{},"api/sql/Function/":{},"api/sql/Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_y":{},"api/sql/Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{}}}],["st_interiorringn",{"_index":367,"text":{"api/flink/Function/":{},"api/flink/Function/#st_interiorringn":{},"api/sql/Function/":{},"api/sql/Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_interiorringn":{},"api/sql/Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{}}}],["st_interiorringn(geom",{"_index":371,"text":{"api/flink/Function/":{},"api/flink/Function/#st_interiorringn":{},"api/sql/Function/":{},"api/sql/Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{}},"title":{}}],["st_intersect",{"_index":543,"text":{"api/flink/Predicate/":{},"api/flink/Predicate/#st_intersects":{},"api/sql/Function/":{},"api/sql/Function/#st_intersection":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#range-join":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#range-query":{},"setup/release-notes/":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql/":{},"tutorial/sql/#range-query":{}},"title":{"api/flink/Predicate/#st_intersects":{},"api/sql/Function/#st_intersection":{},"api/sql/Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{}}}],["st_intersection_aggr",{"_index":553,"text":{"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{"api/sql/AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{}}}],["st_intersects(p.geometri",{"_index":2233,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["st_isclos",{"_index":372,"text":{"api/flink/Function/":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isring":{},"api/sql/Function/":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_isclosed":{},"api/sql/Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{}}}],["st_isclosed(geom",{"_index":375,"text":{"api/flink/Function/":{},"api/flink/Function/#st_isclosed":{},"api/sql/Function/":{},"api/sql/Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{}},"title":{}}],["st_isempti",{"_index":376,"text":{"api/flink/Function/":{},"api/flink/Function/#st_isempty":{},"api/sql/Function/":{},"api/sql/Function/#st_isempty":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Function/#st_isempty":{},"api/sql/Function/#st_isempty":{}}}],["st_isr",{"_index":379,"text":{"api/flink/Function/":{},"api/flink/Function/#st_isring":{},"api/sql/Function/":{},"api/sql/Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_isring":{},"api/sql/Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{}}}],["st_isring(geom",{"_index":381,"text":{"api/flink/Function/":{},"api/flink/Function/#st_isring":{},"api/sql/Function/":{},"api/sql/Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{}},"title":{}}],["st_issimpl",{"_index":380,"text":{"api/flink/Function/":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_issimple":{},"api/sql/Function/":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{"api/flink/Function/#st_issimple":{},"api/sql/Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{}}}],["st_isvalid",{"_index":385,"text":{"api/flink/Function/":{},"api/flink/Function/#st_isvalid":{},"api/sql/Function/":{},"api/sql/Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{"api/flink/Function/#st_isvalid":{},"api/sql/Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{}}}],["st_length",{"_index":386,"text":{"api/flink/Function/":{},"api/flink/Function/#st_length":{},"api/sql/Function/":{},"api/sql/Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{}},"title":{"api/flink/Function/#st_length":{},"api/sql/Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{}}}],["st_linefrommultipoint",{"_index":388,"text":{"api/flink/Function/":{},"api/flink/Function/#st_linefrommultipoint":{},"api/sql/Function/":{},"api/sql/Function/#st_linefrommultipoint":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{"api/flink/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_linefrommultipoint":{}}}],["st_linefromtext",{"_index":170,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linefromtext":{},"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_linefromtext":{}}}],["st_lineinterpolatepoint",{"_index":693,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{}},"title":{"api/sql/Function/#st_lineinterpolatepoint":{}}}],["st_linemerg",{"_index":711,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/sql/Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{}}}],["st_linestr",{"_index":691,"text":{"api/sql/Function/":{},"api/sql/Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{}},"title":{}}],["st_linestringfromtext",{"_index":180,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{}},"title":{"api/flink/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{}}}],["st_linestringfromtext(replace(replace(cast(coordin",{"_index":4077,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["st_linesubstr",{"_index":716,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{}},"title":{"api/sql/Function/#st_linesubstring":{}}}],["st_makepolygon",{"_index":729,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makepolygon":{},"setup/release-notes/":{},"setup/release-notes/#sql_1":{}},"title":{"api/sql/Function/#st_makepolygon":{}}}],["st_makepolygon(geom",{"_index":732,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makepolygon":{}},"title":{}}],["st_makevalid",{"_index":736,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v131":{}},"title":{"api/sql/Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{}}}],["st_makevalid(geom)|st_makevalid(geom",{"_index":744,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{}},"title":{}}],["st_min",{"_index":3823,"text":{"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{}}],["st_minimumboundingcircl",{"_index":755,"text":{"api/sql/Function/":{},"api/sql/Function/#st_minimumboundingcircle":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{}},"title":{"api/sql/Function/#st_minimumboundingcircle":{}}}],["st_minimumboundingcircle(geom",{"_index":758,"text":{"api/sql/Function/":{},"api/sql/Function/#st_minimumboundingcircle":{}},"title":{}}],["st_minimumboundingradiu",{"_index":760,"text":{"api/sql/Function/":{},"api/sql/Function/#st_minimumboundingradius":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{}},"title":{"api/sql/Function/#st_minimumboundingradius":{}}}],["st_minimumboundingradius(geom",{"_index":764,"text":{"api/sql/Function/":{},"api/sql/Function/#st_minimumboundingradius":{}},"title":{}}],["st_mlinefromtext",{"_index":181,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mlinefromtext":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{}},"title":{"api/flink/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mlinefromtext":{}}}],["st_mpolyfromtext",{"_index":191,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_mpolyfromtext":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{}},"title":{"api/flink/Constructor/#st_mpolyfromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{}}}],["st_multi",{"_index":765,"text":{"api/sql/Function/":{},"api/sql/Function/#st_multi":{},"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{"api/sql/Function/#st_multi":{}}}],["st_multi(geom",{"_index":767,"text":{"api/sql/Function/":{},"api/sql/Function/#st_multi":{}},"title":{}}],["st_ndim",{"_index":398,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"setup/release-notes/":{},"setup/release-notes/#new-feature":{}},"title":{"api/flink/Function/#st_ndims":{},"api/sql/Function/#st_ndims":{}}}],["st_ndims(geom",{"_index":414,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{}},"title":{}}],["st_normal",{"_index":393,"text":{"api/flink/Function/":{},"api/flink/Function/#st_normalize":{},"api/sql/Function/":{},"api/sql/Function/#st_normalize":{},"setup/release-notes/":{},"setup/release-notes/#new-features":{}},"title":{"api/flink/Function/#st_normalize":{},"api/sql/Function/#st_normalize":{}}}],["st_normalize(geom",{"_index":395,"text":{"api/flink/Function/":{},"api/flink/Function/#st_normalize":{},"api/sql/Function/":{},"api/sql/Function/#st_normalize":{}},"title":{}}],["st_npoint",{"_index":396,"text":{"api/flink/Function/":{},"api/flink/Function/#st_npoints":{},"api/sql/Function/":{},"api/sql/Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{"api/flink/Function/#st_npoints":{},"api/sql/Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{}}}],["st_numgeometri",{"_index":422,"text":{"api/flink/Function/":{},"api/flink/Function/#st_numgeometries":{},"api/sql/Function/":{},"api/sql/Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_numgeometries":{},"api/sql/Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{}}}],["st_numinterior",{"_index":425,"text":{"api/flink/Function/":{},"api/flink/Function/#st_numinteriorrings":{},"api/sql/Function/":{},"api/sql/Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_numinteriorrings":{},"api/sql/Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{}}}],["st_numinteriorrings(geom",{"_index":426,"text":{"api/flink/Function/":{},"api/flink/Function/#st_numinteriorrings":{},"api/sql/Function/":{},"api/sql/Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{}},"title":{}}],["st_orderingequ",{"_index":546,"text":{"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_orderingequals":{},"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_orderingequals":{}}}],["st_orderingequals(a",{"_index":547,"text":{"api/flink/Predicate/":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_orderingequals":{}},"title":{}}],["st_overlap",{"_index":993,"text":{"api/sql/Predicate/":{},"api/sql/Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{"api/sql/Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{}}}],["st_pixel",{"_index":1290,"text":{"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_pixelize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"setup/release-notes/#viz_1":{},"tutorial/viz/":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{"api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/#st_pixelize":{}}}],["st_point",{"_index":199,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_point":{},"api/flink/Function/":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_z":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{},"api/sql/Function/":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_z":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#v120":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{"api/flink/Constructor/#st_point":{},"api/sql/Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{}}}],["st_point(cast(_c0#0",{"_index":869,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{}},"title":{}}],["st_point(cast(_c0#21",{"_index":870,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{}},"title":{}}],["st_point(cast(_c0#31",{"_index":855,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{}},"title":{}}],["st_point(cast(_c0#48",{"_index":901,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["st_point(cast(inputtable._c0",{"_index":2599,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["st_pointfromtext",{"_index":207,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_pointfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{}},"title":{"api/flink/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{}}}],["st_pointn",{"_index":427,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointn":{},"api/sql/Function/":{},"api/sql/Function/#st_pointn":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Function/#st_pointn":{},"api/sql/Function/#st_pointn":{}}}],["st_pointn(a:geometri",{"_index":434,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointn":{}},"title":{}}],["st_pointn(geom",{"_index":768,"text":{"api/sql/Function/":{},"api/sql/Function/#st_pointn":{}},"title":{}}],["st_pointonsurfac",{"_index":437,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointonsurface":{},"api/sql/Function/":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Function/#st_pointonsurface":{},"api/sql/Function/#st_pointonsurface":{}}}],["st_pointonsurface(a:geometri",{"_index":441,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointonsurface":{},"api/sql/Function/":{},"api/sql/Function/#st_pointonsurface":{}},"title":{}}],["st_polygon",{"_index":692,"text":{"api/sql/Function/":{},"api/sql/Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{}},"title":{}}],["st_polygonfromenvelop",{"_index":209,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_within":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-pure-sql/#work-with-data":{}},"title":{"api/flink/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{}}}],["st_polygonfromenvelope(1.0,100.0,1000.0,1100.0",{"_index":2701,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#range-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/sql/":{},"tutorial/sql/#range-query":{}},"title":{}}],["st_polygonfromenvelope(cast(_c0#0",{"_index":848,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#predicate-pushdown":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#predicate-pushdown":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{}},"title":{}}],["st_polygonfromenvelope(cast(_c0#22",{"_index":907,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{}},"title":{}}],["st_polygonfromtext",{"_index":224,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{}},"title":{"api/flink/Constructor/#st_polygonfromtext":{},"api/sql/Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{}}}],["st_precisionreduc",{"_index":774,"text":{"api/sql/Function/":{},"api/sql/Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{"api/sql/Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{}}}],["st_removepoint",{"_index":449,"text":{"api/flink/Function/":{},"api/flink/Function/#st_removepoint":{},"api/sql/Function/":{},"api/sql/Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_removepoint":{},"api/sql/Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{}}}],["st_removepoint(geom",{"_index":453,"text":{"api/flink/Function/":{},"api/flink/Function/#st_removepoint":{},"api/sql/Function/":{},"api/sql/Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{}},"title":{}}],["st_render",{"_index":1305,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_render":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#render-the-image":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"setup/release-notes/#viz_1":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#render-the-image":{}},"title":{"api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_render":{}}}],["st_revers",{"_index":444,"text":{"api/flink/Function/":{},"api/flink/Function/#st_reverse":{},"api/sql/Function/":{},"api/sql/Function/#st_reverse":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Function/#st_reverse":{},"api/sql/Function/#st_reverse":{}}}],["st_saveaswkb",{"_index":2714,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{}},"title":{}}],["st_saveaswkt",{"_index":2709,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{}},"title":{}}],["st_saveaswkt(countyshap",{"_index":2712,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{}},"title":{}}],["st_setpoint",{"_index":454,"text":{"api/flink/Function/":{},"api/flink/Function/#st_setpoint":{},"api/sql/Function/":{},"api/sql/Function/#st_setpoint":{},"setup/release-notes/":{},"setup/release-notes/#new-features":{}},"title":{"api/flink/Function/#st_setpoint":{},"api/sql/Function/#st_setpoint":{}}}],["st_setsrid",{"_index":274,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_setsrid":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_setsrid":{},"setup/release-notes/":{},"setup/release-notes/#sql_1":{}},"title":{"api/flink/Function/#st_setsrid":{},"api/sql/Function/#st_setsrid":{}}}],["st_simplifypreservetopolog",{"_index":779,"text":{"api/sql/Function/":{},"api/sql/Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{"api/sql/Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{}}}],["st_srid",{"_index":462,"text":{"api/flink/Function/":{},"api/flink/Function/#st_srid":{},"api/sql/Function/":{},"api/sql/Function/#st_srid":{},"setup/release-notes/":{},"setup/release-notes/#sql_1":{}},"title":{"api/flink/Function/#st_srid":{},"api/sql/Function/#st_srid":{}}}],["st_startpoint",{"_index":786,"text":{"api/sql/Function/":{},"api/sql/Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/sql/Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{}}}],["st_startpoint(geom",{"_index":787,"text":{"api/sql/Function/":{},"api/sql/Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{}},"title":{}}],["st_subdivid",{"_index":789,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"setup/release-notes/":{},"setup/release-notes/#sql_2":{}},"title":{"api/sql/Function/#st_subdivide":{}}}],["st_subdivide(geom",{"_index":792,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["st_subdivideexplod",{"_index":821,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivideexplode":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/release-notes/":{},"setup/release-notes/#sql_2":{}},"title":{"api/sql/Function/#st_subdivideexplode":{}}}],["st_subdivideexplode(geom",{"_index":824,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivideexplode":{}},"title":{}}],["st_symdiffer",{"_index":828,"text":{"api/sql/Function/":{},"api/sql/Function/#st_symdifference":{}},"title":{"api/sql/Function/#st_symdifference":{}}}],["st_symmdiffer",{"_index":3834,"text":{"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{}}],["st_tilenam",{"_index":1297,"text":{"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-tile-name":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"tutorial/viz/":{},"tutorial/viz/#create-tile-name":{}},"title":{"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/#st_tilename":{}}}],["st_touch",{"_index":995,"text":{"api/sql/Predicate/":{},"api/sql/Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#v120":{}},"title":{"api/sql/Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{}}}],["st_transform",{"_index":463,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#highlights":{},"setup/release-notes/#new-features":{},"setup/release-notes/#sedona-sql":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{"api/flink/Function/#st_transform":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{}}}],["st_transform(countyshap",{"_index":2693,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["st_transform(geom",{"_index":3728,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["st_union",{"_index":830,"text":{"api/sql/Function/":{},"api/sql/Function/#st_union":{},"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{"api/sql/Function/#st_union":{}}}],["st_union_aggr",{"_index":118,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_union_aggr":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{"api/flink/Aggregator/#st_union_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{}}}],["st_within",{"_index":544,"text":{"api/flink/Predicate/":{},"api/flink/Predicate/#st_within":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#range-join":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#range-query":{},"setup/release-notes/":{},"setup/release-notes/#sql-for-spark":{},"tutorial/sql/":{},"tutorial/sql/#range-query":{}},"title":{"api/flink/Predicate/#st_within":{},"api/sql/Predicate/#st_within":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{}}}],["st_x",{"_index":494,"text":{"api/flink/Function/":{},"api/flink/Function/#st_x":{},"api/sql/Function/":{},"api/sql/Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{}},"title":{"api/flink/Function/#st_x":{},"api/sql/Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{}}}],["st_x(pointa",{"_index":495,"text":{"api/flink/Function/":{},"api/flink/Function/#st_x":{},"api/sql/Function/":{},"api/sql/Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{}},"title":{}}],["st_xmax",{"_index":497,"text":{"api/flink/Function/":{},"api/flink/Function/#st_xmax":{},"api/sql/Function/":{},"api/sql/Function/#st_xmax":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Function/#st_xmax":{},"api/sql/Function/#st_xmax":{}}}],["st_xmin",{"_index":502,"text":{"api/flink/Function/":{},"api/flink/Function/#st_xmin":{},"api/sql/Function/":{},"api/sql/Function/#st_xmin":{}},"title":{"api/flink/Function/#st_xmin":{},"api/sql/Function/#st_xmin":{}}}],["st_y(pointa",{"_index":505,"text":{"api/flink/Function/":{},"api/flink/Function/#st_y":{},"api/sql/Function/":{},"api/sql/Function/#st_y":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{}},"title":{}}],["st_y_min",{"_index":509,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ymin":{},"api/sql/Function/":{},"api/sql/Function/#st_ymin":{}},"title":{}}],["st_ymax",{"_index":507,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ymax":{},"api/sql/Function/":{},"api/sql/Function/#st_ymax":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Function/#st_ymax":{},"api/sql/Function/#st_ymax":{}}}],["st_ymin",{"_index":508,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ymin":{},"api/sql/Function/":{},"api/sql/Function/#st_ymin":{},"setup/release-notes/":{},"setup/release-notes/#flink":{},"setup/release-notes/#sql-for-spark":{}},"title":{"api/flink/Function/#st_ymin":{},"api/sql/Function/#st_ymin":{}}}],["st_z",{"_index":510,"text":{"api/flink/Function/":{},"api/flink/Function/#st_z":{},"api/sql/Function/":{},"api/sql/Function/#st_z":{},"setup/release-notes/":{},"setup/release-notes/#sql":{}},"title":{"api/flink/Function/#st_z":{},"api/sql/Function/#st_z":{}}}],["st_z(pointa",{"_index":511,"text":{"api/flink/Function/":{},"api/flink/Function/#st_z":{},"api/sql/Function/":{},"api/sql/Function/#st_z":{}},"title":{}}],["st_zmax",{"_index":513,"text":{"api/flink/Function/":{},"api/flink/Function/#st_zmax":{},"api/sql/Function/":{},"api/sql/Function/#st_zmax":{},"setup/release-notes/":{},"setup/release-notes/#new-feature":{}},"title":{"api/flink/Function/#st_zmax":{},"api/sql/Function/#st_zmax":{}}}],["st_zmax(geom",{"_index":515,"text":{"api/flink/Function/":{},"api/flink/Function/#st_zmax":{},"api/sql/Function/":{},"api/sql/Function/#st_zmax":{}},"title":{}}],["st_zmin",{"_index":517,"text":{"api/flink/Function/":{},"api/flink/Function/#st_zmin":{},"api/sql/Function/":{},"api/sql/Function/#st_zmin":{},"setup/release-notes/":{},"setup/release-notes/#new-feature":{}},"title":{"api/flink/Function/#st_zmin":{},"api/sql/Function/#st_zmin":{}}}],["st_zmin(geom",{"_index":519,"text":{"api/flink/Function/":{},"api/flink/Function/#st_zmin":{},"api/sql/Function/":{},"api/sql/Function/#st_zmin":{}},"title":{}}],["stabil",{"_index":2816,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{}},"title":{}}],["stage",{"_index":987,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#fix-signature-issues":{},"community/publish/#manually-close-and-release-the-package":{},"community/publish/#upload-releases":{},"setup/compile/":{}},"title":{"community/publish/#4-stage-and-upload-release-candidates":{},"setup/compile/#download-staged-jars":{}}}],["stagingid",{"_index":3313,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["standalon",{"_index":3829,"text":{"setup/release-notes/":{},"setup/release-notes/#rdd":{}},"title":{}}],["standard",{"_index":525,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/tutorial/sql/":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v100":{},"tutorial/flink/sql/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{}},"title":{}}],["start",{"_index":374,"text":{"api/flink/Function/":{},"api/flink/Function/#st_isclosed":{},"api/sql/Function/":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Overview/":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{},"api/viz/sql/":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/viz/sql/":{},"archive/download/cluster/":{},"archive/download/cluster/#start-your-cluster":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/viz/":{},"archive/tutorial/zeppelin/":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/publish/":{},"community/publish/#announce-email":{},"setup/cluster/":{},"setup/cluster/#start-your-cluster":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#installation":{},"tutorial/raster/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#installation":{}},"title":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/viz/sql/#quick-start":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/api/viz/sql/#quick-start":{},"archive/download/cluster/#start-your-cluster":{},"archive/download/overview/":{},"archive/download/project/#quick-start":{},"setup/cluster/#start-your-cluster":{}}}],["startfract",{"_index":721,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{}},"title":{}}],["startup",{"_index":3581,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["state",{"_index":1979,"text":{"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"community/publication/":{},"community/publication/#publication":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{}},"title":{}}],["statefp",{"_index":2370,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["statement",{"_index":2628,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-knn-query":{}},"title":{}}],["statist",{"_index":3157,"text":{"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{},"setup/overview/":{}},"title":{"setup/overview/#download-statistics":{}}}],["statu",{"_index":2819,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/rule/":{},"community/rule/#make-a-pull-request":{}},"title":{}}],["stay",{"_index":1927,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/core-python/":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{}},"title":{}}],["stc",{"_index":4151,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["steep",{"_index":1840,"text":{"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"setup/install-scala/":{}},"title":{}}],["step",{"_index":1556,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#installation":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/contributor/#nominate-a-committer-or-pmc-member":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#7-failed-vote":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/release-manager/#become-a-release-manager":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v112":{},"setup/zeppelin/":{},"setup/zeppelin/#installation":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/flink/sql/":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd/":{},"tutorial/sql/":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["still",{"_index":1603,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["stitch",{"_index":1755,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["storag",{"_index":1719,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-an-spatialrdd-not-indexed":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql/#save-to-permanent-storage":{}}}],["storagelevel",{"_index":1664,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["store",{"_index":1741,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/viz/":{},"tutorial/viz/#store-map-tiles-on-disk":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{"archive/tutorial/viz/#store-map-tiles-on-disk":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/viz/#store-map-tiles-on-disk":{},"tutorial/viz/#store-the-image-on-disk":{}}}],["str",{"_index":1999,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["straight",{"_index":4161,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["straightforward",{"_index":3617,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["strategi",{"_index":2647,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#register-geosparksql":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{}},"title":{}}],["stream",{"_index":34,"text":{"":{},"setup/release-notes/":{},"setup/release-notes/#flink_1":{},"tutorial/flink/sql/":{}},"title":{"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink":{},"tutorial/flink/sql/#initiate-stream-environment":{}}}],["streamexecutionenviron",{"_index":4270,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/flink/sql/#register-sedonasql":{}},"title":{}}],["streamtableenviron",{"_index":4275,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/flink/sql/#register-sedonasql":{}},"title":{}}],["strength",{"_index":2824,"text":{"community/contact/":{},"community/contact/#community":{}},"title":{}}],["string",{"_index":128,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Function/":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Function/":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_html":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"setup/release-notes/":{},"setup/release-notes/#v100":{},"setup/release-notes/#v112":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["stringdf",{"_index":2711,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{}}],["stringtyp",{"_index":4199,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["stripmargin",{"_index":573,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/rdd/":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#range-query":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["struct",{"_index":761,"text":{"api/sql/Function/":{},"api/sql/Function/#st_minimumboundingradius":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["struct<county_code:string,geom:str",{"_index":2248,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{}},"title":{}}],["structfield",{"_index":2288,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["structfield,stringtyp",{"_index":3949,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}},"title":{}}],["structtyp",{"_index":2289,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["structur",{"_index":585,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/rdd/":{},"community/develop/":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{}},"title":{"tutorial/demo/#folder-structure":{}}}],["style",{"_index":11,"text":{"":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#new-features":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/#dataframe-style-api":{}}}],["sub",{"_index":1026,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["subject",{"_index":2843,"text":{"community/contact/":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/contributor/#committer-done-template":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#pmc-annoucement":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/publish/":{},"community/publish/#announce-email":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["submiss",{"_index":3049,"text":{"community/contributor/":{},"community/contributor/#pmc-annoucement":{}},"title":{}}],["submit",{"_index":1845,"text":{"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#submit-the-compiled-jar":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contact/#community":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/develop/":{},"community/publish/":{},"community/publish/#10-release-sedona-r-to-cran":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/sql-python/":{},"tutorial/sql-python/#register-package":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{"archive/download/project/#submit-the-compiled-jar":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{}}}],["submodul",{"_index":3071,"text":{"community/develop/":{}},"title":{}}],["subscrib",{"_index":2838,"text":{"community/contact/":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["subscribe@sedona.apache.org",{"_index":2845,"text":{"community/contact/":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["subsequ",{"_index":2956,"text":{"community/contributor/":{}},"title":{}}],["subset",{"_index":1163,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{}}],["substitut",{"_index":3395,"text":{"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{}},"title":{}}],["substr",{"_index":718,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{}},"title":{}}],["subtract",{"_index":1233,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_subtract":{}},"title":{}}],["subtractdf",{"_index":1235,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_subtract":{}},"title":{}}],["success",{"_index":2818,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["successful/not",{"_index":2965,"text":{"community/contributor/":{},"community/contributor/#close-a-vote":{}},"title":{}}],["successfulli",{"_index":3463,"text":{"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{}}],["such",{"_index":837,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Optimizer/#range-join":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/core-python/#tips":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["sudo",{"_index":3352,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["suffer",{"_index":2735,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["suffici",{"_index":2927,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["suffix",{"_index":3688,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{}},"title":{}}],["suggest",{"_index":1850,"text":{"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"community/rule/":{},"community/rule/#review-a-pull-request":{},"setup/release-notes/":{},"setup/release-notes/#sedona-131":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["suit",{"_index":2029,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{}},"title":{}}],["sumdf",{"_index":1129,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{}},"title":{}}],["summar",{"_index":2729,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["summari",{"_index":1675,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["sumofband",{"_index":1131,"text":{"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{}},"title":{}}],["sunil",{"_index":2917,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["sunilg@apache.org",{"_index":2919,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["super",{"_index":2635,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/viz/":{}},"title":{}}],["superhero",{"_index":2633,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{}},"title":{}}],["suppli",{"_index":1663,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["supplifi",{"_index":1659,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["support",{"_index":8,"text":{"":{},"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_ndims":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_ndims":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#range-join":{},"api/sql/Optimizer/#sedonasql-query-optimizer":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#geosparksql-query-optimizer":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#supported-versions":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-versions":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/sql/":{},"archive/tutorial/viz/":{},"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global":{},"setup/release-notes/#highlights":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#new-features":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_1":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#task":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v100":{},"setup/release-notes/#v101":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v120":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/flink/sql/":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/raster/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#save-geoparquet":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{}},"title":{"#04162022-sedona-120-incubating-is-released-sedona-now-supports-geospatial-stream-processing-in-apache-flink":{},"#08302022-sedona-121-incubating-is-released-it-supports-spark-24-33-and-flink-112":{},"#10062021-sedona-110-incubating-is-released-r-lang-api-is-available-on-cran-raster-data-and-map-algebra-sql-functions-are-now-supported":{},"#11232021-sedona-111-incubating-is-released-it-now-supports-spark-32":{},"#12012022-sedona-130-incubating-is-released-it-adds-native-support-of-geoparquet-dataframe-style-api-scala-213-python-310-spatial-aggregation-on-flink-please-check-sedona-release-notes":{},"archive/tutorial/geospark-core-python/#supported-versions":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#supported-versions":{},"tutorial/sql-python/#supported-shapely-objects":{}}}],["supported\u2014pleas",{"_index":4198,"text":{"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["suppos",{"_index":2324,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["sure",{"_index":593,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/rdd/":{},"community/develop/":{},"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#compile-r-html-docs":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#jts2geojson-0161":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/demo/":{},"tutorial/demo/#prerequisites":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{}},"title":{}}],["surfac",{"_index":440,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointonsurface":{},"api/sql/Function/":{},"api/sql/Function/#st_pointonsurface":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["sustain",{"_index":2924,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{}},"title":{}}],["svg",{"_index":1770,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#sedona-viz":{}},"title":{}}],["svn",{"_index":3064,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#3-use-svn-to-update-keys":{}},"title":{"community/release-manager/#3-use-svn-to-update-keys":{}}}],["sw186000",{"_index":2892,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["swakai@apache.org",{"_index":2893,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["swap",{"_index":469,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{}},"title":{}}],["switch",{"_index":1613,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["symlink",{"_index":3370,"text":{"community/release-manager/":{},"community/release-manager/#0-software-requirement":{}},"title":{}}],["symmetr",{"_index":829,"text":{"api/sql/Function/":{},"api/sql/Function/#st_symdifference":{}},"title":{}}],["symposium",{"_index":3169,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{}},"title":{}}],["symptom",{"_index":3015,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["sysmt",{"_index":2759,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["system",{"_index":459,"text":{"api/flink/Function/":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_transform":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Function/":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_srid":{},"api/sql/Function/#st_transform":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/project/":{},"archive/download/project/#select-an-ide":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{},"community/publication/#publication":{},"community/publication/#third-party-evaluation":{},"community/publish/":{},"community/publish/#announce-email":{},"setup/install-python/":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#store-the-image-on-disk":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"community/contributor/#add-to-the-system":{},"community/publication/#geosparkviz-visualization-system":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}}}],["t",{"_index":614,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["t_epsg",{"_index":2045,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{}},"title":{}}],["tab",{"_index":3551,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["tabl",{"_index":827,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivideexplode":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"setup/flink/modules/":{},"setup/flink/modules/#api-availability":{},"setup/flink/modules/#sedona-modules-for-apache-flink":{},"setup/release-notes/":{},"setup/release-notes/#flink_1":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#get-spatial-table":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{"tutorial/flink/sql/#convert-spatial-datastream-to-spatial-table":{},"tutorial/flink/sql/#convert-spatial-table-to-spatial-datastream":{},"tutorial/flink/sql/#get-spatial-table":{}}}],["table/sql",{"_index":3697,"text":{"setup/overview/":{},"setup/overview/#distributed-spatial-datasets":{}},"title":{}}],["tableenv",{"_index":4268,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#get-datastream":{},"tutorial/flink/sql/#get-spatial-table":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["tableenv'",{"_index":4326,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#get-datastream":{},"tutorial/flink/sql/#get-spatial-table":{}},"title":{}}],["tag",{"_index":1119,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_html":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"setup/compile/":{},"setup/compile/#download-staged-jars":{}},"title":{}}],["tahboub",{"_index":3113,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["tahir",{"_index":3155,"text":{"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["tailor",{"_index":2775,"text":{"archive/tutorial/zeppelin/":{},"tutorial/zeppelin/":{}},"title":{}}],["take",{"_index":1598,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/develop/":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["taken",{"_index":3023,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["talk",{"_index":3095,"text":{"community/publication/":{},"community/publication/#key-publications":{}},"title":{}}],["tar",{"_index":3200,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["target",{"_index":1020,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_modulo":{},"archive/download/project/":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"setup/compile/":{},"setup/release-notes/":{},"setup/release-notes/#global_3":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{"setup/compile/#compile-with-different-targets":{}}}],["target/point",{"_index":2768,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"tutorial/viz/":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{}}],["target/scala",{"_index":1872,"text":{"archive/download/project/":{},"archive/download/project/#submit-the-compiled-jar":{}},"title":{}}],["targetband",{"_index":1112,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{}},"title":{}}],["targetband:int",{"_index":1110,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{}},"title":{}}],["targetcr",{"_index":466,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{}},"title":{}}],["targetcrs:str",{"_index":483,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{}},"title":{}}],["targetcrscod",{"_index":2605,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["task",{"_index":2992,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#vote-email":{},"community/rule/":{},"setup/release-notes/":{}},"title":{"community/rule/#pick-annouce-a-task-using-jira":{},"setup/release-notes/#task":{}}}],["tb",{"_index":4017,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["tb.select(\"elements.id\").topanda",{"_index":4027,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["tb.select(\"total_nodes\").topanda",{"_index":4023,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["tb.show(5",{"_index":4021,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["tbl",{"_index":4105,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["team",{"_index":3062,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/publish/":{},"community/publish/#announce-email":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{}},"title":{}}],["technic",{"_index":3133,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["tell",{"_index":1710,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"community/develop/":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["temp",{"_index":2753,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#render-the-image":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["temperatur",{"_index":1252,"text":{"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{}},"title":{}}],["tempfil",{"_index":4241,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["templat",{"_index":1831,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#quick-start":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/contributor/":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"tutorial/demo/":{},"tutorial/demo/#compile":{},"tutorial/demo/#folder-structure":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/demo/#scala":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"archive/download/project/#open-geospark-template-project":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"community/contributor/#committer-done-template":{},"tutorial/demo/#run-template-projects-locally":{}}}],["templates/committervote.txt",{"_index":2943,"text":{"community/contributor/":{},"community/contributor/#nominate-a-committer-or-pmc-member":{}},"title":{}}],["tempor",{"_index":3170,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{}},"title":{}}],["temporarili",{"_index":1728,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["termin",{"_index":1811,"text":{"archive/download/cluster/":{},"archive/download/cluster/#start-your-cluster":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"community/develop/":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/cluster/":{},"setup/cluster/#start-your-cluster":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{},"tutorial/demo/":{},"tutorial/demo/#compile":{}},"title":{}}],["test",{"_index":377,"text":{"api/flink/Function/":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_issimple":{},"api/flink/Function/#st_isvalid":{},"api/sql/Function/":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#python":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/develop/":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"community/rule/#review-a-pull-request":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#mkdocs-website":{},"setup/compile/#run-python-test":{},"setup/flink/platform/":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql":{},"setup/release-notes/#v01-v07":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#work-with-data":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"community/develop/#run-unit-tests":{},"setup/compile/#run-python-test":{}}}],["test_data",{"_index":656,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{}},"title":{}}],["testasewkt",{"_index":3745,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["testattribute0",{"_index":4092,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["tests/resources/county_small.tsv",{"_index":2050,"text":{"archive/tutorial/geospark-core-python/":{},"tutorial/core-python/":{}},"title":{}}],["text",{"_index":172,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_astext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{}},"title":{}}],["text:str",{"_index":174,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_mlinefromtext":{},"api/flink/Constructor/#st_mpolyfromtext":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{}},"title":{}}],["tgtwktstring",{"_index":3730,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["thank",{"_index":1533,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"community/contributor/":{},"community/contributor/#mentors":{},"community/publish/":{},"community/publish/#announce-email":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["that'",{"_index":1338,"text":{"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{}},"title":{}}],["themselv",{"_index":1541,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/":{},"setup/release-notes/#v112":{}},"title":{}}],["therefor",{"_index":1953,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/rdd/":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{}},"title":{}}],["think",{"_index":2867,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["third",{"_index":720,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{},"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"community/publication/":{},"setup/maven-coordinates/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{"community/publication/#third-party-evaluation":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{}}}],["thoma",{"_index":3129,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["those",{"_index":3012,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{}},"title":{}}],["thread",{"_index":2949,"text":{"community/contributor/":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#close-a-vote":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/publish/":{},"community/publish/#announce-email":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#vote-email_1":{}},"title":{}}],["three",{"_index":1013,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/rdd/#use-spatial-partitioning":{}},"title":{}}],["through",{"_index":930,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/tutorial/sql/":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"tutorial/flink/sql/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{}},"title":{}}],["throw",{"_index":470,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#v110":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{}},"title":{}}],["tiark",{"_index":3114,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["ticket",{"_index":3431,"text":{"community/rule/":{},"community/rule/#make-a-pull-request":{},"community/rule/#pick-annouce-a-task-using-jira":{}},"title":{}}],["tier",{"_index":3534,"text":{"setup/databricks/":{}},"title":{"setup/databricks/#community-edition-free-tier":{}}}],["tile",{"_index":1298,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#generate-map-tiles":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"tutorial/viz/":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#generate-map-tiles":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#store-map-tiles-on-disk":{}},"title":{"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#generate-map-tiles":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#generate-map-tiles":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#store-map-tiles-on-disk":{}}}],["tileimg",{"_index":1312,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_render":{}},"title":{}}],["tilenam",{"_index":1311,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_render":{}},"title":{}}],["time",{"_index":1569,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#become-a-release-manager":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/release-notes/":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v110":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["timeout",{"_index":1801,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["tip",{"_index":2626,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"setup/compile/":{},"setup/compile/#compile-with-different-targets":{},"tutorial/core-python/":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{}},"title":{"tutorial/core-python/#tips":{}}}],["tmp/choropleth",{"_index":4245,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["tmp/polygon.json",{"_index":4169,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["to_spatial_rdd",{"_index":4103,"text":{"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{}},"title":{}}],["tociek",{"_index":1518,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["todatastream",{"_index":4327,"text":{"tutorial/flink/sql/":{},"tutorial/flink/sql/#get-datastream":{}},"title":{}}],["today",{"_index":2959,"text":{"community/contributor/":{}},"title":{}}],["todf",{"_index":567,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/sql/":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["todo",{"_index":4045,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["togeth",{"_index":713,"text":{"api/sql/Function/":{},"api/sql/Function/#st_linemerge":{},"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{}},"title":{}}],["token",{"_index":3407,"text":{"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{}},"title":{"community/release-manager/#5-get-github-personal-access-token-classic":{}}}],["toler",{"_index":4117,"text":{"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["tool",{"_index":268,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"setup/overview/":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{"setup/overview/#rich-spatial-analytics-tools":{}}}],["tools/head?labpath=binder%2fverifi",{"_index":3278,"text":{"community/publish/":{},"community/publish/#vote-email":{}},"title":{}}],["top",{"_index":2991,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["topanda",{"_index":2190,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["topolog",{"_index":783,"text":{"api/sql/Function/":{},"api/sql/Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{}},"title":{}}],["tordd",{"_index":2601,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{}},"title":{}}],["tospatialrdd",{"_index":2058,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/core-python/":{},"tutorial/rdd/":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-to-spatialrdd":{}},"title":{}}],["tostr",{"_index":1521,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"setup/release-notes/":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{}},"title":{}}],["total",{"_index":700,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"community/contributor/":{},"community/contributor/#close-a-vote":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["total_nod",{"_index":4020,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["totalbands:int",{"_index":1111,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_getband":{}},"title":{}}],["totext",{"_index":2710,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{}},"title":{}}],["touch",{"_index":996,"text":{"api/sql/Predicate/":{},"api/sql/Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["trace",{"_index":1980,"text":{"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{}},"title":{}}],["track",{"_index":2850,"text":{"community/contact/":{},"community/contact/#bug-reports":{}},"title":{}}],["tracker",{"_index":2846,"text":{"community/contact/":{},"community/contact/#bug-reports":{}},"title":{"community/contact/#issue-tracker":{}}}],["tractc",{"_index":2374,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["trademark",{"_index":2803,"text":{"asf/asf/":{},"asf/asf/#copyright":{},"community/contributor/":{},"community/contributor/#become-a-committer":{}},"title":{}}],["traffic",{"_index":3100,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#key-publications":{}},"title":{"community/publication/#geosparksim-traffic-simulator":{}}}],["trajectori",{"_index":3698,"text":{"setup/overview/":{},"setup/overview/#complex-spatial-objects":{}},"title":{}}],["tranform",{"_index":1018,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["transfer",{"_index":1287,"text":{"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{}},"title":{}}],["transform",{"_index":464,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v081-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}}}],["transfrom",{"_index":2757,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["translat",{"_index":4175,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["treat",{"_index":1256,"text":{"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["tree",{"_index":1560,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"community/publish/":{},"community/publish/#compile-r-html-docs":{},"setup/overview/":{},"setup/overview/#distributed-spatial-queries":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v110":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-partitioning":{}},"title":{}}],["tremend",{"_index":2739,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/viz/":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["tri",{"_index":1839,"text":{"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"setup/install-scala/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{}},"title":{"archive/download/project/#try-geospark-sql-functions":{}}}],["trigger",{"_index":841,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#range-join":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#range-join":{}},"title":{}}],["troubl",{"_index":3072,"text":{"community/develop/":{}},"title":{}}],["true",{"_index":373,"text":{"api/flink/Function/":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isring":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_intersects":{},"api/flink/Predicate/#st_orderingequals":{},"api/flink/Predicate/#st_within":{},"api/sql/Function/":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_makevalid":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Parameter/#usage":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#pomxml":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#read-from-wkb-file":{},"tutorial/core-python/#read-from-wkt-file":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-spark-sedona-with-saved-hdfs-file":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["trust",{"_index":3489,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["truth",{"_index":4188,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["tsv",{"_index":2032,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{}},"title":{}}],["tti",{"_index":3405,"text":{"community/release-manager/":{},"community/release-manager/#4-add-gpg_tty-environment-variable":{}},"title":{}}],["tune",{"_index":1910,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/core-python/":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{}},"title":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{}}}],["tupl",{"_index":2285,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{}},"title":{}}],["turn",{"_index":2186,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"community/contributor/":{},"community/contributor/#mentors":{},"tutorial/sql-python/":{},"tutorial/sql-python/#writing-application":{}},"title":{}}],["tutori",{"_index":1405,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#display-geosparkviz-results":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publish/":{},"community/publish/#announce-email":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"setup/release-notes/":{},"setup/release-notes/#v131":{},"setup/zeppelin/":{},"setup/zeppelin/#display-sedonaviz-results":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/raster/":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#advanced-tutorial-tune-your-geospark-rdd-application":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#advanced-tutorial-tune-your-sedona-rdd-application":{},"tutorial/raster/#tutorials":{}}}],["twine",{"_index":3336,"text":{"community/publish/":{},"community/publish/#9-release-sedona-python-and-zeppelin":{}},"title":{}}],["twitter",{"_index":2833,"text":{"community/contact/":{},"community/publish/":{},"community/publish/#announce-email":{}},"title":{"community/contact/#twitter":{}}}],["two",{"_index":281,"text":{"api/flink/Function/":{},"api/flink/Function/#st_azimuth":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_azimuth":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_subtract":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_2":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#output-format_2":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/zeppelin/":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/publish/":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_2":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#get-spatial-table":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#output-format_2":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/zeppelin/":{}},"title":{}}],["tyep",{"_index":2749,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{}},"title":{}}],["type",{"_index":594,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#query-center-geometry":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-indexed":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#save-an-spatialrdd-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/sql/#run-spatial-queries":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#render-the-image":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#new-features":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v120":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"tutorial/core-python/":{},"tutorial/core-python/#query-center-geometry":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#save-an-spatialrdd-indexed":{},"tutorial/core-python/#save-an-spatialrdd-not-indexed":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/flink/sql/#run-spatial-queries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#save-an-spatialrdd-indexed":{},"tutorial/rdd/#save-an-spatialrdd-not-indexed":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#range-query":{},"tutorial/sql/#register-sedonasql":{},"tutorial/sql/#run-spatial-queries":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#render-the-image":{}},"title":{"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/sql/#create-a-geometry-type-column":{}}}],["type:int",{"_index":655,"text":{"api/sql/Function/":{},"api/sql/Function/#st_collectionextract":{}},"title":{}}],["typic",{"_index":1930,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{}},"title":{}}],["typo",{"_index":1699,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["u",{"_index":3330,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{},"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["u3r0p",{"_index":353,"text":{"api/flink/Function/":{},"api/flink/Function/#st_geohash":{},"api/sql/Function/":{},"api/sql/Function/#st_geohash":{}},"title":{}}],["uber",{"_index":3672,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{}},"title":{}}],["ubuntu",{"_index":3349,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["udf",{"_index":1554,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#v112":{},"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["udt",{"_index":2168,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#introduction":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-r/#introduction":{}},"title":{}}],["ui",{"_index":3535,"text":{"setup/databricks/":{},"setup/databricks/#community-edition-free-tier":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{"setup/databricks/#install-sedona-from-the-web-ui":{}}}],["unbalanc",{"_index":1612,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v091-geospark-core":{}},"title":{}}],["unchang",{"_index":3477,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["uncompress",{"_index":1810,"text":{"archive/download/cluster/":{},"archive/download/cluster/#start-your-cluster":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/cluster/":{},"setup/cluster/#start-your-cluster":{}},"title":{}}],["undefin",{"_index":1472,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["under",{"_index":1585,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/project/":{},"archive/download/project/#submit-the-compiled-jar":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#fix-signature-issues":{},"community/publish/#make-a-sedona-release":{},"community/publish/#manually-close-and-release-the-package":{},"community/release-manager/":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#v100":{}},"title":{}}],["undergo",{"_index":2807,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{}},"title":{}}],["understand",{"_index":2941,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/develop/":{},"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["unidata",{"_index":3662,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["uniform",{"_index":1266,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{}},"title":{}}],["union",{"_index":120,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_union_aggr":{},"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Function/":{},"api/sql/Function/#st_union":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{}},"title":{}}],["uniqu",{"_index":1317,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{}},"title":{}}],["unit",{"_index":875,"text":{"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"community/develop/":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#v01-v07":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{"community/develop/#run-unit-tests":{}}}],["unit[\"degree\",0.0174532925199433",{"_index":3740,"text":{"setup/release-notes/":{},"setup/release-notes/#highlights":{}},"title":{}}],["univers",{"_index":3089,"text":{"community/publication/":{},"community/publication/#publication":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["unknown",{"_index":621,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#sql_3":{}},"title":{}}],["unlimit",{"_index":1321,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{}},"title":{}}],["unnecessari",{"_index":1682,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["unstal",{"_index":3869,"text":{"setup/release-notes/":{},"setup/release-notes/#known-issue":{}},"title":{}}],["unsupport",{"_index":3783,"text":{"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["until",{"_index":2810,"text":{"asf/disclaimer/":{},"asf/disclaimer/#disclaimer":{},"community/contributor/":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/rule/":{},"community/rule/#review-a-pull-request":{}},"title":{}}],["unzip",{"_index":3508,"text":{"community/vote/":{},"community/vote/#check-files-manually":{}},"title":{}}],["up",{"_index":745,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/sql/":{},"archive/tutorial/viz/":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/vote/":{},"community/vote/#check-files-manually":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#viz_1":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/flink/sql/":{},"tutorial/raster/":{},"tutorial/raster/#initial-setup":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/viz/":{}},"title":{"archive/download/cluster/":{},"archive/download/cluster/#set-up-your-apache-spark-cluster":{},"archive/tutorial/rdd/#set-up-dependencies":{},"archive/tutorial/sql/#set-up-dependencies":{},"archive/tutorial/viz/#set-up-dependencies":{},"community/release-manager/#6-set-up-credentials-for-maven":{},"setup/cluster/":{},"setup/cluster/#set-up-your-apache-spark-cluster":{},"tutorial/flink/sql/#set-up-dependencies":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/#set-up-dependencies":{}}}],["upcom",{"_index":1384,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#snapshot-versions":{}},"title":{}}],["updat",{"_index":1702,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#7-failed-vote":{},"community/release-manager/":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/rule/":{},"community/rule/#develop-a-code-contribution":{},"setup/release-notes/":{},"setup/release-notes/#flink_1":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#r":{},"setup/release-notes/#sql_2":{},"setup/release-notes/#v01-v07":{}},"title":{"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#3-update-mkdocsyml":{},"community/release-manager/#3-use-svn-to-update-keys":{}}}],["upgrad",{"_index":748,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#global_2":{},"setup/release-notes/#global_3":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#viz_1":{}},"title":{}}],["upload",{"_index":2016,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"community/publish/#fix-signature-issues":{},"community/snapshot/":{}},"title":{"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#upload-releases":{},"community/snapshot/#1-upload-snapshot-versions":{}}}],["upload_jar",{"_index":2011,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#writing-application":{}},"title":{}}],["upon",{"_index":1829,"text":{"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{}},"title":{}}],["uppercas",{"_index":1385,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{}},"title":{}}],["url",{"_index":1396,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#pomxml":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#pomxml":{}},"title":{}}],["url>https://artifacts.unidata.ucar.edu/repository/unidata",{"_index":3667,"text":{"setup/maven-coordinates/":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{}},"title":{}}],["us",{"_index":101,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/java-api/":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Function/":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Function/#st_transform":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"api/viz/java-api/":{},"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"api/viz/sql/#st_render":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#package-the-project":{},"archive/download/project/#quick-start":{},"archive/download/project/#select-an-ide":{},"archive/download/project/#self-contained-spark-projects":{},"archive/download/project/#submit-the-compiled-jar":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#read-from-other-geometry-files":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#installing-from-pypi-repositories":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#knn-query":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#load-shapefile-and-geojson":{},"archive/tutorial/sql/#range-query":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#colorize-pixels_1":{},"archive/tutorial/viz/#initiate-sparksession":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/viz/#store-map-tiles-on-disk":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/contact/":{},"community/contact/#community":{},"community/contact/#mailing-list":{},"community/contributor/":{},"community/contributor/#add-to-the-system":{},"community/contributor/#committer-done-template":{},"community/contributor/#create-asf-account":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#10-release-sedona-r-to-cran":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#upload-releases":{},"community/publish/#vote-email":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"community/vote/":{},"community/vote/#install-necessary-software":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"setup/compile/":{},"setup/compile/#download-staged-jars":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/databricks/#community-edition-free-tier":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/databricks/#pure-sql-environment":{},"setup/flink/install-scala/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/install-scala/#spark-sql-shell":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global_1":{},"setup/release-notes/#global_2":{},"setup/release-notes/#improvement":{},"setup/release-notes/#rdd":{},"setup/release-notes/#sedona-core":{},"setup/release-notes/#sedona-python":{},"setup/release-notes/#sedona-sql":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#sql_3":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v112":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#read-from-other-geometry-files":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#get-datastream":{},"tutorial/flink/sql/#get-spatial-table":{},"tutorial/flink/sql/#initiate-stream-environment":{},"tutorial/flink/sql/#knn-query":{},"tutorial/flink/sql/#range-query":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#load-data":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/#introduction":{},"tutorial/sql-python/#register-package":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-python/#writing-application":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#knn-query":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#load-shapefile-and-geojson":{},"tutorial/sql/#range-query":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/viz/":{},"tutorial/viz/#colorize-pixels_1":{},"tutorial/viz/#initiate-sparksession":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-the-image":{},"tutorial/viz/#store-map-tiles-on-disk":{},"tutorial/viz/#store-the-image-on-disk":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"archive/download/project/#how-to-use-geospark-in-an-ide":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"community/release-manager/#3-use-svn-to-update-keys":{},"community/rule/#pick-annouce-a-task-using-jira":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/zeppelin/":{}}}],["usa",{"_index":2648,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{}},"title":{}}],["usacounti",{"_index":2716,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-to-spatialrdd":{}},"title":{}}],["usag",{"_index":964,"text":{"api/sql/Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-sql-python/":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/sql-python/":{}},"title":{"api/sql/Parameter/#usage":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/tutorial/geospark-sql-python/#example-usage-for-shapely-objects":{},"tutorial/sql-python/#example-usage-for-shapely-objects":{}}}],["uselongitudelatitudeord",{"_index":1332,"text":{"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{}},"title":{}}],["uselongitudelatitudeorder:boolean",{"_index":1333,"text":{"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{}},"title":{}}],["user",{"_index":100,"text":{"api/java-api/":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/viz/java-api/":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#be-aware-of-spatial-rdd-partitions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#register-geosparksql":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#register-geosparksql-and-geosparkviz":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/install-scala/":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#core_1":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global_3":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sedona-131":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v081-geospark-core":{},"setup/release-notes/#v082-geospark-core":{},"setup/release-notes/#v112":{},"setup/release-notes/#v120":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#be-aware-of-spatial-rdd-partitions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#register-sedonasql":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#register-sedonasql-and-sedonaviz":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["user.dir",{"_index":2767,"text":{"archive/tutorial/viz/":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"tutorial/viz/":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{}}],["user_data",{"_index":2099,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{}},"title":{}}],["user_name='root",{"_index":4006,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["userdata",{"_index":1697,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{}},"title":{}}],["usernam",{"_index":3052,"text":{"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/publish/":{},"community/publish/#fix-signature-issues":{}},"title":{}}],["username>your_asf_id</usernam",{"_index":3421,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["username>your_github_username</usernam",{"_index":3418,"text":{"community/release-manager/":{},"community/release-manager/#6-set-up-credentials-for-maven":{}},"title":{}}],["using_index",{"_index":2078,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"tutorial/core-python/":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/#write-a-spatial-range-query":{}},"title":{}}],["usingindex",{"_index":2613,"text":{"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{}},"title":{}}],["usr/lib/spark",{"_index":3632,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["usr/libexec/java_hom",{"_index":3368,"text":{"community/release-manager/":{},"community/release-manager/#0-software-requirement":{}},"title":{}}],["usr/local/cellar/maven/3.6.3/libexec/bin/mvn",{"_index":3373,"text":{"community/release-manager/":{},"community/release-manager/#0-software-requirement":{}},"title":{}}],["ustronie|point",{"_index":2268,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["usual",{"_index":2996,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/develop/":{}},"title":{}}],["utf",{"_index":3364,"text":{"community/publish/":{},"community/publish/#compile-r-html-docs":{}},"title":{}}],["utf8",{"_index":607,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["util",{"_index":961,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_2":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"setup/databricks/":{},"setup/databricks/#initialise":{},"setup/release-notes/":{},"setup/release-notes/#v082-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#use-spatial-indexes_2":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{}},"title":{}}],["uuid",{"_index":1316,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"setup/release-notes/":{},"setup/release-notes/#v120":{}},"title":{}}],["uuid1",{"_index":1322,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{}},"title":{}}],["uuid2",{"_index":1323,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{}},"title":{}}],["v",{"_index":3329,"text":{"community/publish/":{},"community/publish/#fix-signature-issues":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"tutorial/sql/":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#save-geoparquet":{}},"title":{}}],["v0.1",{"_index":1673,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/#v01-v07":{}}}],["v0.7",{"_index":1674,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/#v01-v07":{}}}],["v0.8.0",{"_index":1632,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/#v080-geospark-core":{}}}],["v0.8.1",{"_index":1629,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v081-geospark-core":{},"setup/release-notes/#v081-geospark-core":{}}}],["v0.8.2",{"_index":1618,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v082-geospark-core":{},"setup/release-notes/#v082-geospark-core":{}}}],["v0.9.1",{"_index":1586,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"setup/release-notes/#v091-geospark-core":{}}}],["v1.0.0",{"_index":552,"text":{"api/sql/AggregateFunction/":{},"api/sql/AggregateFunction/#st_envelope_aggr":{},"api/sql/AggregateFunction/#st_intersection_aggr":{},"api/sql/AggregateFunction/#st_union_aggr":{},"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_linestringfromtext":{},"api/sql/Constructor/#st_point":{},"api/sql/Constructor/#st_pointfromtext":{},"api/sql/Constructor/#st_polygonfromenvelope":{},"api/sql/Constructor/#st_polygonfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_addpoint":{},"api/sql/Function/#st_area":{},"api/sql/Function/#st_asgeojson":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_azimuth":{},"api/sql/Function/#st_boundary":{},"api/sql/Function/#st_buffer":{},"api/sql/Function/#st_centroid":{},"api/sql/Function/#st_convexhull":{},"api/sql/Function/#st_distance":{},"api/sql/Function/#st_dump":{},"api/sql/Function/#st_dumppoints":{},"api/sql/Function/#st_endpoint":{},"api/sql/Function/#st_envelope":{},"api/sql/Function/#st_exteriorring":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_geometryn":{},"api/sql/Function/#st_geometrytype":{},"api/sql/Function/#st_interiorringn":{},"api/sql/Function/#st_intersection":{},"api/sql/Function/#st_isclosed":{},"api/sql/Function/#st_isring":{},"api/sql/Function/#st_issimple":{},"api/sql/Function/#st_isvalid":{},"api/sql/Function/#st_length":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_npoints":{},"api/sql/Function/#st_numgeometries":{},"api/sql/Function/#st_numinteriorrings":{},"api/sql/Function/#st_precisionreduce":{},"api/sql/Function/#st_removepoint":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Function/#st_startpoint":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_y":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_contains":{},"api/sql/Predicate/#st_crosses":{},"api/sql/Predicate/#st_equals":{},"api/sql/Predicate/#st_intersects":{},"api/sql/Predicate/#st_overlaps":{},"api/sql/Predicate/#st_touches":{},"api/sql/Predicate/#st_within":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"api/viz/sql/#st_encodeimage":{},"api/viz/sql/#st_pixelize":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_envelope_aggr":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_union_aggr":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_linestringfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_pointfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromenvelope":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_polygonfromtext":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_area":{},"archive/api/sql/GeoSparkSQL-Function/#st_centroid":{},"archive/api/sql/GeoSparkSQL-Function/#st_convexhull":{},"archive/api/sql/GeoSparkSQL-Function/#st_distance":{},"archive/api/sql/GeoSparkSQL-Function/#st_envelope":{},"archive/api/sql/GeoSparkSQL-Function/#st_length":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_contains":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_intersects":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_within":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"setup/release-notes/#v100":{}}}],["v1.0.1",{"_index":703,"text":{"api/sql/Function/":{},"api/sql/Function/#st_lineinterpolatepoint":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_minimumboundingcircle":{},"api/sql/Function/#st_minimumboundingradius":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"tutorial/sql-pure-sql/":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"setup/release-notes/#v101":{}}}],["v1.1.0",{"_index":733,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makepolygon":{},"api/sql/Function/#st_subdivide":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalize":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_intersection":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/release-notes/":{},"tutorial/raster/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/#v110":{}}}],["v1.1.1",{"_index":608,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeohash":{},"api/sql/Function/":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_geohash":{},"api/sql/Function/#st_setsrid":{},"api/sql/Function/#st_srid":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v111":{},"setup/release-notes/#v111":{}}}],["v1.1.2",{"_index":1526,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"setup/release-notes/#v112":{}}}],["v1.1.3",{"_index":1328,"text":{"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_circle":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"setup/release-notes/#v113":{}}}],["v1.2.0",{"_index":141,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeojson":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/flink/Constructor/#st_pointfromtext":{},"api/flink/Constructor/#st_polygonfromenvelope":{},"api/flink/Constructor/#st_polygonfromtext":{},"api/flink/Function/":{},"api/flink/Function/#st_buffer":{},"api/flink/Function/#st_distance":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_geohash":{},"api/flink/Function/#st_transform":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_contains":{},"api/flink/Predicate/#st_intersects":{},"api/sql/Function/":{},"api/sql/Function/#st_3ddistance":{},"api/sql/Function/#st_collect":{},"api/sql/Function/#st_difference":{},"api/sql/Function/#st_multi":{},"api/sql/Function/#st_symdifference":{},"api/sql/Function/#st_union":{},"api/sql/Function/#st_z":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/#st_issimple":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_precisionreduce":{},"archive/api/sql/GeoSparkSQL-Predicate/":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_crosses":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_equals":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_overlaps":{},"archive/api/sql/GeoSparkSQL-Predicate/#st_touches":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/#st_pixelize":{},"archive/api/viz/sql/#st_render":{},"archive/api/viz/sql/#st_tilename":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/tutorial/rdd/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"setup/release-notes/#v120":{}}}],["v1.2.1",{"_index":133,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgeohash":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Constructor/#st_linefromtext":{},"api/flink/Constructor/#st_linestringfromtext":{},"api/flink/Constructor/#st_point":{},"api/flink/Function/":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_buildarea":{},"api/flink/Function/#st_exteriorring":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_isempty":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_pointonsurface":{},"api/flink/Function/#st_reverse":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_disjoint":{},"api/flink/Predicate/#st_orderingequals":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_buildarea":{},"api/sql/Function/#st_collectionextract":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_isempty":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_pointonsurface":{},"api/sql/Function/#st_reverse":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_disjoint":{},"api/sql/Predicate/#st_orderingequals":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_append":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/":{},"archive/api/sql/GeoSparkSQL-AggregateFunction/#st_intersection_aggr":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometrytype":{},"archive/api/sql/GeoSparkSQL-Function/#st_npoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{}},"title":{}}],["v1.3.0",{"_index":113,"text":{"api/flink/Aggregator/":{},"api/flink/Aggregator/#st_envelope_aggr":{},"api/flink/Aggregator/#st_union_aggr":{},"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromgml":{},"api/flink/Constructor/#st_geomfromkml":{},"api/flink/Function/":{},"api/flink/Function/#st_3ddistance":{},"api/flink/Function/#st_addpoint":{},"api/flink/Function/#st_area":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asgeojson":{},"api/flink/Function/#st_asgml":{},"api/flink/Function/#st_askml":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_azimuth":{},"api/flink/Function/#st_boundary":{},"api/flink/Function/#st_envelope":{},"api/flink/Function/#st_geometryn":{},"api/flink/Function/#st_interiorringn":{},"api/flink/Function/#st_isclosed":{},"api/flink/Function/#st_isring":{},"api/flink/Function/#st_issimple":{},"api/flink/Function/#st_isvalid":{},"api/flink/Function/#st_length":{},"api/flink/Function/#st_linefrommultipoint":{},"api/flink/Function/#st_normalize":{},"api/flink/Function/#st_npoints":{},"api/flink/Function/#st_numgeometries":{},"api/flink/Function/#st_numinteriorrings":{},"api/flink/Function/#st_removepoint":{},"api/flink/Function/#st_setpoint":{},"api/flink/Function/#st_setsrid":{},"api/flink/Function/#st_srid":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_z":{},"api/flink/Predicate/":{},"api/flink/Predicate/#st_coveredby":{},"api/flink/Predicate/#st_covers":{},"api/flink/Predicate/#st_within":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgml":{},"api/sql/Constructor/#st_geomfromkml":{},"api/sql/Function/":{},"api/sql/Function/#st_asgml":{},"api/sql/Function/#st_askml":{},"api/sql/Function/#st_linefrommultipoint":{},"api/sql/Function/#st_normalize":{},"api/sql/Function/#st_setpoint":{},"api/sql/Predicate/":{},"api/sql/Predicate/#st_coveredby":{},"api/sql/Predicate/#st_covers":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v130":{},"setup/release-notes/#v130":{}}}],["v1.3.1",{"_index":415,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_transform":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"setup/release-notes/":{}},"title":{"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/#v131":{}}}],["v1.3.2",{"_index":1341,"text":{"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_addpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_asgeojson":{},"archive/api/sql/GeoSparkSQL-Function/#st_azimuth":{},"archive/api/sql/GeoSparkSQL-Function/#st_boundary":{},"archive/api/sql/GeoSparkSQL-Function/#st_dump":{},"archive/api/sql/GeoSparkSQL-Function/#st_dumppoints":{},"archive/api/sql/GeoSparkSQL-Function/#st_endpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_exteriorring":{},"archive/api/sql/GeoSparkSQL-Function/#st_geometryn":{},"archive/api/sql/GeoSparkSQL-Function/#st_interiorringn":{},"archive/api/sql/GeoSparkSQL-Function/#st_isclosed":{},"archive/api/sql/GeoSparkSQL-Function/#st_isring":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/api/sql/GeoSparkSQL-Function/#st_numgeometries":{},"archive/api/sql/GeoSparkSQL-Function/#st_numinteriorrings":{},"archive/api/sql/GeoSparkSQL-Function/#st_removepoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_startpoint":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{}},"title":{}}],["v3.1.0",{"_index":3865,"text":{"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#python":{}},"title":{}}],["val",{"_index":968,"text":{"api/sql/Parameter/":{},"api/sql/Parameter/#usage":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{},"api/sql/Raster-loader/#rs_getband":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_add":{},"api/sql/Raster-operators/#rs_append":{},"api/sql/Raster-operators/#rs_bitwiseand":{},"api/sql/Raster-operators/#rs_bitwiseor":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_divide":{},"api/sql/Raster-operators/#rs_fetchregion":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_mode":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_multiply":{},"api/sql/Raster-operators/#rs_multiplyfactor":{},"api/sql/Raster-operators/#rs_normalizeddifference":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/sql/Raster-operators/#rs_subtract":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/rdd/#use-spatial-indexes_2":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#read-other-attributes-in-an-spatialrdd":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#use-spatial-indexes_2":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{}},"title":{}}],["valid",{"_index":738,"text":{"api/sql/Function/":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_simplifypreservetopology":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/api/sql/GeoSparkSQL-Function/#st_simplifypreservetopology":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{}},"title":{}}],["valu",{"_index":430,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointn":{},"api/flink/Function/#st_transform":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Function/":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_pointn":{},"api/sql/Function/#st_transform":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Parameter/":{},"api/sql/Parameter/#explanation":{},"api/sql/Parameter/#usage":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_count":{},"api/sql/Raster-operators/#rs_greaterthan":{},"api/sql/Raster-operators/#rs_greaterthanequal":{},"api/sql/Raster-operators/#rs_lessthan":{},"api/sql/Raster-operators/#rs_lessthanequal":{},"api/sql/Raster-operators/#rs_logicaldifference":{},"api/sql/Raster-operators/#rs_logicalover":{},"api/sql/Raster-operators/#rs_mean":{},"api/sql/Raster-operators/#rs_modulo":{},"api/sql/Raster-operators/#rs_normalize":{},"api/sql/Raster-operators/#rs_squareroot":{},"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{},"archive/api/sql/GeoSparkSQL-Parameter/#usage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v091-geospark-core":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#retrieve-geometries":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["values_df",{"_index":4222,"text":{"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["var",{"_index":557,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/sql/#spatialpairrdd-to-dataframe":{},"archive/tutorial/sql/#spatialrdd-to-dataframe":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#initiate-sparksession":{},"archive/tutorial/viz/#store-the-image-on-disk":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#load-geoparquet":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/#spatialpairrdd-to-dataframe":{},"tutorial/sql/#spatialrdd-to-dataframe":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{},"tutorial/viz/#store-the-image-on-disk":{}},"title":{}}],["vari",{"_index":4246,"text":{"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{}},"title":{}}],["variabl",{"_index":3212,"text":{"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/release-manager/":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/install-python/":{},"setup/install-python/#setup-environment-variables":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{}},"title":{"community/release-manager/#4-add-gpg_tty-environment-variable":{},"setup/install-python/#setup-environment-variables":{}}}],["variou",{"_index":1260,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{}}],["varun",{"_index":3125,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["vector",{"_index":1763,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#sedona-viz":{},"tutorial/python-vector-osm/":{}},"title":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#example-of-spark-sedona-hdfs-with-slave-nodes-and-osm-vector-data-consults":{}}}],["vectoroverlayoper",{"_index":1765,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{}},"title":{}}],["venu",{"_index":3104,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["verb",{"_index":4171,"text":{"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["veri",{"_index":1558,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelization-and-pixel-aggregation":{},"setup/release-notes/":{},"setup/release-notes/#v110":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/viz/":{},"tutorial/viz/#pixelization-and-pixel-aggregation":{}},"title":{}}],["verifi",{"_index":70,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"community/contact/":{},"community/contact/#bug-reports":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/publish/":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"community/vote/#vote-a-sedona-release":{},"download/":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-a-geometry-type-column":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{}},"title":{"community/vote/#run-the-verify-script":{},"download/#verify-the-integrity":{}}}],["verify.out",{"_index":3472,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["verify.sh",{"_index":3469,"text":{"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["verion",{"_index":1916,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{}},"title":{}}],["versa",{"_index":3624,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["versatil",{"_index":4219,"text":{"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["version",{"_index":75,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_flipcoordinates":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_makevalid":{},"archive/api/GeoSpark-Scala-and-Java-API/":{},"archive/api/GeoSpark-Scala-and-Java-API/#scala-and-java-api":{},"archive/api/sql/GeoSparkSQL-javadoc/":{},"archive/api/sql/GeoSparkSQL-javadoc/#scala-and-java-api":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-core_1":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#python":{},"archive/tutorial/geospark-core-python/#supported-versions":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/geospark-sql-python/#supported-versions":{},"community/contributor/":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#3-update-mkdocsyml":{},"community/release-manager/":{},"community/release-manager/#0-software-requirement":{},"community/snapshot/":{},"community/vote/":{},"community/vote/#check-files-manually":{},"community/vote/#install-necessary-software":{},"community/vote/#run-the-verify-script":{},"download/":{},"setup/compile/":{},"setup/compile/#run-python-test":{},"setup/databricks/":{},"setup/databricks/#advanced-editions":{},"setup/install-python/":{},"setup/install-python/#install-sedona":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#jts2geojson-0161":{},"setup/maven-coordinates/#locationtech-jts-core-1180":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#snapshot-versions":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#global_2":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#sedona-100":{},"setup/release-notes/#sedona-101":{},"setup/release-notes/#sedona-110":{},"setup/release-notes/#sedona-111":{},"setup/release-notes/#sedona-120":{},"setup/release-notes/#sedona-121":{},"setup/release-notes/#sedona-130":{},"setup/release-notes/#sedona-131":{},"setup/release-notes/#v01-v07":{},"setup/release-notes/#v080-geospark-core":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/jupyter-notebook/":{},"tutorial/jupyter-notebook/#python-jupyter-notebook-examples":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/viz-gallery/":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-1x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#apache-spark-2x-versions":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"archive/tutorial/geospark-core-python/#supported-versions":{},"archive/tutorial/geospark-sql-python/#supported-versions":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/snapshot/":{},"community/snapshot/#1-upload-snapshot-versions":{},"community/snapshot/#publish-a-snapshot-version":{},"download/#versions":{},"setup/maven-coordinates/#snapshot-versions":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}}}],["version>23</vers",{"_index":3078,"text":{"community/develop/":{}},"title":{}}],["versu",{"_index":3542,"text":{"setup/databricks/":{},"setup/databricks/#advanced-editions":{}},"title":{}}],["vertex",{"_index":445,"text":{"api/flink/Function/":{},"api/flink/Function/#st_reverse":{},"api/sql/Function/":{},"api/sql/Function/#st_reverse":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#range-query-window":{},"tutorial/rdd/":{},"tutorial/rdd/#range-query-window":{}},"title":{}}],["vertic",{"_index":791,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivide":{}},"title":{}}],["veto",{"_index":2953,"text":{"community/contributor/":{},"community/contributor/#call-for-a-vote":{}},"title":{}}],["via",{"_index":601,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/download/cluster/":{},"archive/download/cluster/#start-your-cluster":{},"archive/tutorial/rdd/":{},"community/contributor/":{},"community/contributor/#pmc-annoucement":{},"community/publish/":{},"community/publish/#make-a-sedona-release":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/cluster/":{},"setup/cluster/#start-your-cluster":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"tutorial/rdd/":{}},"title":{"archive/tutorial/zeppelin/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}}}],["vice",{"_index":3623,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["view",{"_index":826,"text":{"api/sql/Function/":{},"api/sql/Function/#st_subdivideexplode":{},"api/viz/sql/":{},"api/viz/sql/#st_pixelize":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_makevalid":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#render-map-tiles":{},"archive/tutorial/viz/#render-the-image":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#transform-the-data":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-spatial-dataframe":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#render-the-image":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["virtualenvwrapp",{"_index":3525,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["visibl",{"_index":3436,"text":{"community/rule/":{},"community/rule/#make-a-pull-request":{}},"title":{}}],["visit",{"_index":1807,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["visual",{"_index":1240,"text":{"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#quick-start":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"community/publication/":{},"community/publication/#geosparkviz-visualization-system":{},"community/publication/#key-publications":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/release-notes/":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#v01-v07":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/viz-r/":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/viz/#why-scalable-map-visualization":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/download/zeppelin/#visualize-geosparksql-results":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#visualize-spatialrdd":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"community/publication/#geosparkviz-visualization-system":{},"setup/zeppelin/#visualize-sedonasql-results":{},"tutorial/viz-r/#map-visualization-applications-in-r-language":{},"tutorial/viz/#visualize-spatialrdd":{},"tutorial/viz/#why-scalable-map-visualization":{}}}],["visul",{"_index":4261,"text":{"tutorial/viz/":{}},"title":{}}],["viz",{"_index":1243,"text":{"api/viz/sql/":{},"api/viz/sql/#quick-start":{},"archive/api/viz/Babylon-Scala-and-Java-API/":{},"archive/api/viz/Babylon-Scala-and-Java-API/#scala-and-java-api-for-rdd":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#snapshot-versions":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v100":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v101":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v113":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#compatibility":{},"community/publish/":{},"community/publish/#fix-signature-issues":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/modules/":{},"setup/modules/#api-availability":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/release-notes/":{},"setup/release-notes/#v100":{},"setup/release-notes/#v101":{},"setup/release-notes/#v110":{},"setup/release-notes/#v112":{},"setup/release-notes/#v113":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{},"setup/zeppelin/":{},"setup/zeppelin/#compatibility":{},"tutorial/demo/":{},"tutorial/demo/#folder-structure":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/rdd/":{},"tutorial/rdd/#set-up-dependencies":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{},"tutorial/sql/":{},"tutorial/sql/#set-up-dependencies":{},"tutorial/viz/":{},"tutorial/viz/#initiate-sparksession":{},"tutorial/viz/#set-up-dependencies":{},"tutorial/viz/#store-the-image-on-disk":{},"tutorial/viz/#visualize-spatialrdd":{}},"title":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-113-and-earlier":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#geospark-viz-120-and-later":{},"archive/download/GeoSpark-All-Modules-Release-notes/#geospark-viz-old":{},"setup/release-notes/#geospark-viz-old":{},"setup/release-notes/#sedona-viz":{},"setup/release-notes/#viz":{},"setup/release-notes/#viz_1":{}}}],["viz_2.1",{"_index":1378,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-21_1":{}},"title":{}}],["viz_2.2",{"_index":1377,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-22_1":{}},"title":{}}],["viz_2.3",{"_index":1376,"text":{"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/":{},"archive/download/GeoSpark-All-Modules-Maven-Central-Coordinates/#for-sparksql-23_1":{}},"title":{}}],["viz_2.3:1.2.0",{"_index":1881,"text":{"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{}},"title":{}}],["volunt",{"_index":2823,"text":{"community/contact/":{},"community/contact/#community":{}},"title":{}}],["von",{"_index":2907,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["vongosling@apache.org",{"_index":2909,"text":{"community/contributor/":{},"community/contributor/#mentors":{}},"title":{}}],["voronoi",{"_index":1354,"text":{"archive/api/sql/GeoSparkSQL-Parameter/":{},"archive/api/sql/GeoSparkSQL-Parameter/#explanation":{}},"title":{}}],["vote",{"_index":2935,"text":{"community/contributor/":{},"community/contributor/#become-a-committer":{},"community/contributor/#call-for-a-vote":{},"community/contributor/#close-a-vote":{},"community/contributor/#nominate-a-committer-or-pmc-member":{},"community/contributor/#send-a-notice-to-ipmc":{},"community/contributor/#send-the-invitation":{},"community/publish/":{},"community/publish/#7-failed-vote":{},"community/publish/#announce-email":{},"community/publish/#make-a-sedona-release":{},"community/publish/#pass-email":{},"community/publish/#pass-email_1":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{}},"title":{"community/contributor/#call-for-a-vote":{},"community/contributor/#close-a-vote":{},"community/publish/#5-vote-in-dev-sedonaapacheorg":{},"community/publish/#6-vote-in-general-incubatorapacheorg":{},"community/publish/#7-failed-vote":{},"community/publish/#vote-email":{},"community/publish/#vote-email_1":{},"community/vote/":{},"community/vote/#vote-a-sedona-release":{}}}],["vote][result",{"_index":2962,"text":{"community/contributor/":{},"community/contributor/#close-a-vote":{}},"title":{}}],["vs",{"_index":3004,"text":{"community/contributor/":{},"community/contributor/#send-the-invitation":{}},"title":{}}],["w",{"_index":1093,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["w/o",{"_index":2140,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{}}}],["wa",{"_index":3152,"text":{"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["wahkiakum",{"_index":2652,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#create-a-geometry-type-column":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#create-a-geometry-type-column":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["wait",{"_index":1805,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/release-manager/":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{}},"title":{}}],["wakai",{"_index":1452,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["wang",{"_index":1454,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["want",{"_index":1017,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/viz/sql/":{},"api/viz/sql/#st_render":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/download/compile/":{},"archive/download/compile/#compile-geospark":{},"archive/download/project/":{},"archive/download/project/#open-geospark-template-project":{},"archive/download/project/#select-an-ide":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#generate-a-single-image":{},"community/contributor/":{},"community/contributor/#committer-done-template":{},"community/publish/":{},"community/publish/#3-update-mkdocsyml":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#maven-coordinates":{},"setup/maven-coordinates/#netcdf-java-542":{},"setup/maven-coordinates/#netcdf-java-542_1":{},"setup/maven-coordinates/#use-sedona-and-third-party-jars-separately":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#v112":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/viz/":{},"tutorial/viz/#generate-a-single-image":{}},"title":{}}],["warn",{"_index":591,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"api/sql/Constructor/#st_geomfromgeojson":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-source-code":{},"archive/download/project/":{},"archive/download/project/#package-the-project":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes_1":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/rdd/#use-spatial-indexes_1":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#dataframe-to-spatialrdd":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#pixelize-spatial-objects":{},"community/publish/":{},"community/publish/#make-a-sedona-release":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/platform/":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/zeppelin/":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-indexes_1":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/rdd/#use-spatial-indexes_1":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-to-spatialrdd":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{}},"title":{}}],["watch",{"_index":4225,"text":{"tutorial/viz-gallery/":{}},"title":{}}],["way",{"_index":619,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromgeojson":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromgeojson":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v091-geospark-core":{},"archive/download/overview/":{},"archive/download/overview/#install-geospark":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#use-spatial-partitioning":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#use-spatial-partitioning":{},"archive/tutorial/viz/":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"community/contributor/":{},"community/contributor/#mentors":{},"community/rule/":{},"community/rule/#make-a-pull-request":{},"setup/install-scala/":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#known-issue":{},"setup/release-notes/#v091-geospark-core":{},"tutorial/core-python/":{},"tutorial/core-python/#use-spatial-partitioning":{},"tutorial/demo/":{},"tutorial/demo/#submit-your-fat-jar-to-spark":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#store-non-spatial-attributes-in-geometries":{},"tutorial/rdd/":{},"tutorial/rdd/#use-spatial-partitioning":{},"tutorial/viz/":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{}},"title":{}}],["way(area)[\"highway",{"_index":3999,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#connecting-to-overpass-api-to-search-and-downloading-data-for-saving-into-hdfs":{}},"title":{}}],["we'r",{"_index":410,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{}},"title":{}}],["web",{"_index":3189,"text":{"community/publish/":{},"community/publish/#0-prepare-an-empty-script-file":{},"community/publish/#10-release-sedona-r-to-cran":{},"community/snapshot/":{},"community/snapshot/#0-prepare-an-empty-script-file":{},"setup/databricks/":{},"setup/databricks/#community-edition-free-tier":{}},"title":{"setup/databricks/#install-sedona-from-the-web-ui":{}}}],["webpag",{"_index":3307,"text":{"community/publish/":{},"community/publish/#7-failed-vote":{}},"title":{}}],["websit",{"_index":1808,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/download/project/":{},"archive/download/project/#quick-start":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/publish/":{},"community/publish/#11-publish-the-doc-website":{},"community/publish/#3-update-mkdocsyml":{},"community/publish/#announce-email":{},"community/rule/":{},"community/rule/#develop-a-document-contribution":{},"community/snapshot/":{},"community/snapshot/#publish-a-snapshot-version":{},"setup/cluster/":{},"setup/cluster/#preliminary":{},"setup/compile/":{},"setup/compile/#compile-the-documentation":{},"setup/compile/#mkdocs-website":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{}},"title":{"community/publish/#11-publish-the-doc-website":{},"setup/compile/#mkdocs-website":{}}}],["week",{"_index":2950,"text":{"community/contributor/":{},"community/contributor/#call-for-a-vote":{}},"title":{}}],["weight",{"_index":1249,"text":{"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#aggregate-pixels":{},"archive/tutorial/viz/#colorize-pixels":{},"archive/tutorial/viz/#create-tile-name":{},"tutorial/viz/":{},"tutorial/viz/#aggregate-pixels":{},"tutorial/viz/#colorize-pixels":{},"tutorial/viz/#create-tile-name":{}},"title":{}}],["weight:doubl",{"_index":1258,"text":{"api/viz/sql/":{},"api/viz/sql/#st_colorize":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_colorize":{}},"title":{}}],["welcom",{"_index":1974,"text":{"archive/tutorial/benchmark/":{},"archive/tutorial/benchmark/#benchmark":{},"community/contact/":{},"community/contact/#feature-requests":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{},"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"community/rule/#review-a-pull-request":{},"tutorial/benchmark/":{},"tutorial/benchmark/#benchmark":{}},"title":{}}],["well",{"_index":257,"text":{"api/flink/Function/":{},"api/flink/Function/#st_asbinary":{},"api/flink/Function/#st_asewkb":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_astext":{},"api/flink/Function/#st_isvalid":{},"api/sql/Function/":{},"api/sql/Function/#st_asbinary":{},"api/sql/Function/#st_asewkb":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_astext":{},"api/sql/Function/#st_isvalid":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_astext":{},"archive/api/sql/GeoSparkSQL-Function/#st_isvalid":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#choose-a-proper-spatial-rdd-constructor":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"community/contributor/":{},"community/contributor/#become-a-committer":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#choose-a-proper-spatial-rdd-constructor":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/demo/":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd-r/#what-are-spatialrdds":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{},"tutorial/sql/#initiate-sparksession":{}},"title":{}}],["wget",{"_index":3193,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/publish/#fix-signature-issues":{},"community/publish/#upload-releases":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["wgs84",{"_index":1003,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#transform-the-coordinate-reference-system":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#transform-the-coordinate-reference-system":{},"tutorial/rdd/":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{},"tutorial/sql/":{},"tutorial/sql/#transform-the-coordinate-reference-system":{}},"title":{}}],["wheel",{"_index":2022,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{"archive/tutorial/geospark-core-python/#installing-from-wheel-file":{},"archive/tutorial/geospark-sql-python/#installing-from-wheel-file":{}}}],["wherei",{"_index":3369,"text":{"community/release-manager/":{},"community/release-manager/#0-software-requirement":{}},"title":{}}],["wherev",{"_index":2708,"text":{"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#save-to-permanent-storage":{}},"title":{}}],["whether",{"_index":1022,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{}},"title":{}}],["whimsi",{"_index":3045,"text":{"community/contributor/":{},"community/contributor/#add-to-the-system":{}},"title":{}}],["whole",{"_index":2174,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#core-classes-and-methods":{}},"title":{}}],["whose",{"_index":297,"text":{"api/flink/Function/":{},"api/flink/Function/#st_buffer":{},"api/sql/Function/":{},"api/sql/Function/#st_buffer":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_buffer":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{}},"title":{}}],["wide",{"_index":3606,"text":{"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["width",{"_index":1009,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"api/sql/Raster-loader/#rs_array":{},"api/sql/Raster-operators/":{},"api/sql/Raster-operators/#rs_fetchregion":{}},"title":{}}],["width:int",{"_index":1085,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["width_in_px:str",{"_index":1122,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_html":{}},"title":{}}],["window",{"_index":1711,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v01-v07":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/geospark-core-python/#use-spatial-indexes":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#query-center-geometry":{},"archive/tutorial/rdd/#range-query-window":{},"archive/tutorial/rdd/#use-spatial-indexes":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#range-query":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/release-notes/":{},"setup/release-notes/#v01-v07":{},"tutorial/core-python/":{},"tutorial/core-python/#range-query-window":{},"tutorial/core-python/#tips":{},"tutorial/core-python/#use-spatial-indexes":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#query-center-geometry":{},"tutorial/rdd/#range-query-window":{},"tutorial/rdd/#use-spatial-indexes":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql/":{},"tutorial/sql/#range-query":{}},"title":{"archive/tutorial/geospark-core-python/#range-query-window":{},"archive/tutorial/rdd/#range-query-window":{},"tutorial/core-python/#range-query-window":{},"tutorial/rdd/#range-query-window":{}}}],["wip",{"_index":3293,"text":{"community/publish/":{},"community/publish/#vote-email_1":{}},"title":{}}],["withcolumn",{"_index":935,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{}},"title":{}}],["withcolumn(\"id",{"_index":4031,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["withcolumn(\"new",{"_index":4034,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#consulting-and-organizing-data-for-analisis":{}},"title":{}}],["within",{"_index":545,"text":{"api/flink/Predicate/":{},"api/flink/Predicate/#st_within":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#distance-join":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Optimizer/":{},"archive/api/sql/GeoSparkSQL-Optimizer/#distance-join":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#geosparksql":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#range-query":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/demo/":{},"tutorial/demo/#compile":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#range-query":{},"tutorial/rdd/":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-python/":{},"tutorial/sql-python/#sedonasql":{},"tutorial/sql/":{},"tutorial/sql/#range-query":{}},"title":{}}],["without",{"_index":1271,"text":{"api/viz/sql/":{},"archive/api/viz/sql/":{},"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-automatically":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"archive/tutorial/GeoSpark-Runnable-DEMO/":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/zeppelin/":{},"setup/compile/":{},"setup/compile/#compile-scala-java-source-code":{},"setup/databricks/":{},"setup/databricks/#pure-sql-environment":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{},"tutorial/core-python/":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/viz/":{},"tutorial/viz/#pixelize-spatial-objects":{},"tutorial/zeppelin/":{}},"title":{"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}}}],["wkb",{"_index":166,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/flink/Function/":{},"api/flink/Function/#st_asewkb":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromwkb":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkb":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#v112":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-typed-spatialrdd":{}},"title":{"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"tutorial/core-python/#read-from-wkb-file":{}}}],["wkb:binari",{"_index":168,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromwkb":{}},"title":{}}],["wkb:byte",{"_index":169,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromwkb":{}},"title":{}}],["wkb:string",{"_index":167,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromwkb":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromwkb":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkb":{}},"title":{}}],["wkb_geometries_loc",{"_index":2156,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-wkb-file":{}},"title":{}}],["wkbreader",{"_index":1479,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-wkb-file":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-wkb-file":{}},"title":{}}],["wkt",{"_index":159,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/flink/Function/":{},"api/flink/Function/#st_asewkt":{},"api/flink/Function/#st_transform":{},"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"api/sql/Function/":{},"api/sql/Function/#st_asewkt":{},"api/sql/Function/#st_transform":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#create-a-typed-spatialrdd":{},"archive/tutorial/geospark-core-python/#save-to-permanent-storage":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#create-a-generic-spatialrdd-behavoir-changed-in-v120":{},"archive/tutorial/rdd/#create-a-typed-spatialrdd":{},"archive/tutorial/rdd/#save-to-permanent-storage":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#load-data-from-files":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/overview/":{},"setup/overview/#complex-spatial-objects":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#improvement_1":{},"tutorial/core-python/":{},"tutorial/core-python/#create-a-typed-spatialrdd":{},"tutorial/core-python/#save-to-permanent-storage":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/flink/sql/#create-row-objects":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#create-a-generic-spatialrdd":{},"tutorial/rdd/#create-a-typed-spatialrdd":{},"tutorial/rdd/#save-to-permanent-storage":{},"tutorial/sql/":{},"tutorial/sql/#load-data-from-files":{},"tutorial/sql/#save-to-permanent-storage":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"tutorial/core-python/#read-from-wkt-file":{}}}],["wkt/wkb",{"_index":2348,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["wkt/wkb/geojson",{"_index":2062,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/rdd/":{},"tutorial/core-python/":{},"tutorial/rdd/":{}},"title":{}}],["wkt:string",{"_index":162,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_geomfromtext":{},"api/flink/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_geomfromtext":{},"api/sql/Constructor/#st_geomfromwkt":{},"api/sql/Constructor/#st_linefromtext":{},"api/sql/Constructor/#st_mlinefromtext":{},"api/sql/Constructor/#st_mpolyfromtext":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_geomfromwkt":{}},"title":{}}],["wkt_geometries_loc",{"_index":2153,"text":{"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-wkt-file":{}},"title":{}}],["wktcolumn",{"_index":2364,"text":{"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["wktpoint",{"_index":2788,"text":{"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{}},"title":{}}],["wktreader",{"_index":1478,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#read-from-wkt-file":{},"archive/tutorial/rdd/":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"tutorial/core-python/":{},"tutorial/core-python/#read-from-wkt-file":{},"tutorial/rdd/":{}},"title":{}}],["wolf",{"_index":473,"text":{"api/flink/Function/":{},"api/flink/Function/#st_transform":{},"api/sql/Function/":{},"api/sql/Function/#st_transform":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v110":{},"setup/release-notes/":{},"setup/release-notes/#v110":{}},"title":{}}],["work",{"_index":411,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_linemerge":{},"api/sql/Function/#st_linesubstring":{},"api/sql/Function/#st_makevalid":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_subdivideexplode":{},"api/sql/Optimizer/":{},"api/sql/Optimizer/#broadcast-join":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_linemerge":{},"archive/download/scalashell/":{},"archive/download/scalashell/#spark-scala-shell":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#installing-the-package":{},"archive/tutorial/geospark-core-python/#python":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#installation":{},"archive/tutorial/geospark-sql-python/#supported-shapely-objects":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#save-to-permanent-storage":{},"archive/tutorial/viz/":{},"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{},"community/contributor/#send-the-invitation":{},"community/develop/":{},"community/publication/":{},"community/publication/#key-publications":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"setup/databricks/":{},"setup/databricks/#community-edition-free-tier":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#introduction":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#python_1":{},"setup/release-notes/#sql_3":{},"tutorial/core-python/":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/demo/":{},"tutorial/demo/#run-template-projects-locally":{},"tutorial/flink/sql/":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/sql-pure-sql/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#supported-shapely-objects":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{},"tutorial/sql/":{},"tutorial/viz/":{}},"title":{"tutorial/sql-pure-sql/#work-with-data":{}}}],["worker",{"_index":1776,"text":{"archive/download/cluster/":{},"archive/download/cluster/#preliminary":{},"setup/cluster/":{},"setup/cluster/#preliminary":{}},"title":{}}],["workflow",{"_index":3429,"text":{"community/rule/":{},"community/rule/#contributing-to-apache-sedona":{},"setup/install-r/":{},"setup/install-r/#introduction":{}},"title":{}}],["workload",{"_index":3111,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["works.html",{"_index":3036,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["worri",{"_index":1951,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["worth",{"_index":3105,"text":{"community/publication/":{},"community/publication/#third-party-evaluation":{}},"title":{}}],["wrap",{"_index":4162,"text":{"tutorial/sql-python/":{},"tutorial/sql-python/#dataframe-style-api":{},"tutorial/sql/":{},"tutorial/sql/#dataframe-style-api":{}},"title":{}}],["wrapper",{"_index":1402,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v130":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/geospark-core-python/#supported-versions":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#introduction":{},"archive/tutorial/geospark-sql-python/#supported-versions":{},"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{},"setup/maven-coordinates/":{},"setup/maven-coordinates/#geotools-240":{},"setup/maven-coordinates/#use-sedona-fat-jars":{},"setup/release-notes/":{},"setup/release-notes/#global_1":{},"setup/release-notes/#global_2":{},"setup/release-notes/#v130":{},"setup/release-notes/#v131":{},"tutorial/core-python/":{},"tutorial/core-python/#introduction":{}},"title":{"setup/flink/platform/":{},"setup/platform/":{}}}],["wrapper/1.3.0",{"_index":3569,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-via-init-script-for-dbrs-73":{}},"title":{}}],["wrapper:1.1.0",{"_index":3986,"text":{"tutorial/python-vector-osm/":{},"tutorial/python-vector-osm/#registering-spark-session-adding-node-executor-configurations-and-sedona-registrator":{}},"title":{}}],["wrapper:1.3.0",{"_index":3555,"text":{"setup/databricks/":{},"setup/databricks/#install-sedona-from-the-web-ui":{},"setup/install-python/":{},"setup/install-python/#prepare-python-adapter-jar":{},"setup/install-r/":{},"setup/install-r/#connect-to-spark":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-automatically":{},"setup/install-scala/#download-sedona-jar-manually":{}},"title":{}}],["wrapper:geotool",{"_index":4127,"text":{"tutorial/sql-pure-sql/":{},"tutorial/sql-pure-sql/#initiate-session":{}},"title":{}}],["write",{"_index":941,"text":{"api/sql/Overview/":{},"api/sql/Overview/#quick-start":{},"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#quick-start":{},"archive/download/project/":{},"archive/download/project/#self-contained-spark-projects":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/rdd/":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-spatial-dataframe":{},"community/contributor/":{},"community/contributor/#committers":{},"community/release-manager/":{},"setup/flink/install-scala/":{},"setup/install-scala/":{},"setup/install-scala/#self-contained-spark-projects":{},"setup/release-notes/":{},"setup/release-notes/#highlights":{},"setup/release-notes/#sql-for-spark":{},"tutorial/core-python/":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#create-geometries-using-sedona-formatutils":{},"tutorial/rdd/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#register-package":{},"tutorial/sql/":{},"tutorial/sql/#save-geoparquet":{},"tutorial/viz/":{},"tutorial/viz/#create-spatial-dataframe":{}},"title":{"archive/tutorial/geospark-core-python/#write-a-distance-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-join-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-knn-query":{},"archive/tutorial/geospark-core-python/#write-a-spatial-range-query":{},"archive/tutorial/geospark-sql-python/#writing-application":{},"archive/tutorial/rdd/#write-a-distance-join-query":{},"archive/tutorial/rdd/#write-a-spatial-join-query":{},"archive/tutorial/rdd/#write-a-spatial-knn-query":{},"archive/tutorial/rdd/#write-a-spatial-range-query":{},"community/release-manager/#1-obtain-write-access-to-sedona-github-repo":{},"tutorial/core-python/#write-a-distance-join-query":{},"tutorial/core-python/#write-a-spatial-join-query":{},"tutorial/core-python/#write-a-spatial-knn-query":{},"tutorial/core-python/#write-a-spatial-range-query":{},"tutorial/rdd/#write-a-distance-join-query":{},"tutorial/rdd/#write-a-spatial-join-query":{},"tutorial/rdd/#write-a-spatial-knn-query":{},"tutorial/rdd/#write-a-spatial-range-query":{},"tutorial/sql-python/#writing-application":{}}}],["writer",{"_index":1047,"text":{"api/sql/Raster-loader/":{}},"title":{"api/sql/Raster-loader/#geotiff-dataframe-writer":{}}}],["writetocr",{"_index":1071,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{}},"title":{}}],["written",{"_index":1049,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-writer":{},"archive/download/compile/":{},"archive/download/compile/#compile-the-documentation":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#geospark-serializers":{},"archive/tutorial/geospark-core-python/#introduction":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#initiate-sparkcontext":{},"archive/tutorial/sql/":{},"archive/tutorial/sql/#initiate-sparksession":{},"archive/tutorial/viz/":{},"setup/compile/":{},"setup/compile/#mkdocs-website":{},"tutorial/core-python/":{},"tutorial/core-python/#apache-sedona-serializers":{},"tutorial/core-python/#introduction":{},"tutorial/demo/":{},"tutorial/demo/#scala-and-java-examples":{},"tutorial/flink/sql/":{},"tutorial/flink/sql/#register-sedonasql":{},"tutorial/rdd-r/":{},"tutorial/rdd-r/#creating-a-spatialrdd":{},"tutorial/rdd/":{},"tutorial/rdd/#initiate-sparkcontext":{},"tutorial/sql-pure-sql/":{},"tutorial/sql/":{},"tutorial/sql/#initiate-sparksession":{},"tutorial/viz/":{}},"title":{}}],["wrong",{"_index":1549,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v111":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v112":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/":{},"archive/tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"archive/tutorial/rdd/#transform-the-coordinate-reference-system":{},"setup/release-notes/":{},"setup/release-notes/#bug-fixes_1":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql-for-spark":{},"setup/release-notes/#v111":{},"setup/release-notes/#v112":{},"tutorial/core-python/":{},"tutorial/core-python/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/":{},"tutorial/rdd/#save-an-spatialrdd-spatialpartitioned-wo-indexed":{},"tutorial/rdd/#transform-the-coordinate-reference-system":{}},"title":{}}],["wrussia",{"_index":1455,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{}},"title":{}}],["wu",{"_index":2895,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{}},"title":{}}],["x",{"_index":201,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_point":{},"api/flink/Function/":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_transform":{},"api/flink/Function/#st_x":{},"api/flink/Function/#st_xmax":{},"api/flink/Function/#st_xmin":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{},"api/sql/Function/":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_x":{},"api/sql/Function/#st_xmax":{},"api/sql/Function/#st_xmin":{},"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_x":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"archive/tutorial/geospark-core-python/":{},"archive/tutorial/geospark-core-python/#output-format":{},"archive/tutorial/geospark-core-python/#output-format_3":{},"archive/tutorial/geospark-core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/core-python/":{},"tutorial/core-python/#output-format":{},"tutorial/core-python/#output-format_3":{},"tutorial/core-python/#read-other-attributes-in-an-spatialrdd":{},"tutorial/sql-r/":{},"tutorial/sql-r/#spatial-sql-applications-in-r-language":{}},"title":{}}],["x,i",{"_index":400,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{}},"title":{}}],["x,y,z",{"_index":401,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{}},"title":{}}],["x.x.x",{"_index":1913,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#pick-a-proper-geospark-version":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#pick-a-proper-sedona-version":{}},"title":{}}],["x/i",{"_index":1331,"text":{"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_transform":{}},"title":{}}],["x/y/z",{"_index":3705,"text":{"setup/release-notes/":{},"setup/release-notes/#bug-fixes":{}},"title":{}}],["x:decim",{"_index":203,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_point":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{}},"title":{}}],["xmax",{"_index":499,"text":{"api/flink/Function/":{},"api/flink/Function/#st_xmax":{},"api/sql/Function/":{},"api/sql/Function/#st_xmax":{}},"title":{}}],["xmin",{"_index":503,"text":{"api/flink/Function/":{},"api/flink/Function/#st_xmin":{},"api/sql/Function/":{},"api/sql/Function/#st_xmin":{}},"title":{}}],["xvf",{"_index":3201,"text":{"community/publish/":{},"community/publish/#1-check-asf-copyright-in-all-file-headers":{},"community/publish/#4-stage-and-upload-release-candidates":{},"community/vote/":{},"community/vote/#run-the-verify-script":{}},"title":{}}],["xxx.jar",{"_index":3521,"text":{"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["y",{"_index":202,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_point":{},"api/flink/Function/":{},"api/flink/Function/#st_flipcoordinates":{},"api/flink/Function/#st_force_2d":{},"api/flink/Function/#st_transform":{},"api/flink/Function/#st_y":{},"api/flink/Function/#st_ymax":{},"api/flink/Function/#st_ymin":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{},"api/sql/Function/":{},"api/sql/Function/#st_flipcoordinates":{},"api/sql/Function/#st_force_2d":{},"api/sql/Function/#st_transform":{},"api/sql/Function/#st_y":{},"api/sql/Function/#st_ymax":{},"api/sql/Function/#st_ymin":{},"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Function/":{},"archive/api/sql/GeoSparkSQL-Function/#st_y":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"community/publication/":{},"community/publication/#third-party-evaluation":{},"setup/compile/":{},"setup/compile/#run-python-test":{}},"title":{}}],["y:decim",{"_index":204,"text":{"api/flink/Constructor/":{},"api/flink/Constructor/#st_point":{},"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#st_point":{}},"title":{}}],["yarn",{"_index":3634,"text":{"setup/install-r/":{},"setup/install-r/#connect-to-spark":{}},"title":{}}],["ye",{"_index":539,"text":{"api/flink/Overview/":{},"api/flink/Overview/#introduction":{},"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"community/develop/":{}},"title":{}}],["yitao",{"_index":2880,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["yitaoli@apache.org",{"_index":2882,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["ylorbr",{"_index":2278,"text":{"archive/tutorial/geospark-sql-python/":{},"archive/tutorial/geospark-sql-python/#integration-with-geopandas-and-shapely":{},"tutorial/sql-python/":{},"tutorial/sql-python/#integration-with-geopandas-and-shapely":{}},"title":{}}],["you'd",{"_index":1954,"text":{"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/":{},"archive/tutorial/Advanced-Tutorial-Tune-your-GeoSpark-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{},"community/release-manager/":{},"community/release-manager/#2-prepare-secret-gpg-key":{},"community/release-manager/#5-get-github-personal-access-token-classic":{},"tutorial/Advanced-Tutorial-Tune-your-Application/":{},"tutorial/Advanced-Tutorial-Tune-your-Application/#cache-the-spatial-rdd-that-is-repeatedly-used":{}},"title":{}}],["you'll",{"_index":598,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#read-esri-shapefile":{},"archive/api/sql/GeoSparkSQL-Constructor/":{},"archive/api/sql/GeoSparkSQL-Constructor/#read-esri-shapefile":{},"archive/tutorial/rdd/":{},"tutorial/rdd/":{}},"title":{}}],["your",{"_index":3042,"text":{"community/contributor/":{},"community/contributor/#pmc-accept-and-icla-instruction":{}},"title":{}}],["your_path",{"_index":1006,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#geotiff-dataframe-loader":{}},"title":{}}],["your_sql",{"_index":932,"text":{"api/sql/Overview/":{},"api/sql/Overview/#function-list":{},"archive/api/sql/GeoSparkSQL-Overview/":{},"archive/api/sql/GeoSparkSQL-Overview/#function-list":{},"archive/tutorial/sql/":{},"tutorial/flink/sql/":{},"tutorial/sql-python/":{},"tutorial/sql-python/#introduction":{},"tutorial/sql/":{}},"title":{}}],["yourself",{"_index":1883,"text":{"archive/download/scalashell/":{},"archive/download/scalashell/#download-geospark-jar-manually":{},"community/contact/":{},"community/contact/#bug-reports":{},"setup/install-scala/":{},"setup/install-scala/#download-sedona-jar-manually":{}},"title":{}}],["you\u2019v",{"_index":2849,"text":{"community/contact/":{},"community/contact/#bug-reports":{}},"title":{}}],["yu",{"_index":1457,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/publication/":{},"community/publication/#a-tutorial-about-geospatial-data-management-in-spark":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparksim-traffic-simulator":{},"community/publication/#geosparkviz-visualization-system":{},"community/vote/":{},"community/vote/#run-the-verify-script":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"setup/release-notes/#v131":{}},"title":{}}],["z",{"_index":416,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/flink/Function/#st_z":{},"api/flink/Function/#st_zmax":{},"api/flink/Function/#st_zmin":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{},"api/sql/Function/#st_z":{},"api/sql/Function/#st_zmax":{},"api/sql/Function/#st_zmin":{},"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"setup/release-notes/":{},"setup/release-notes/#improvement_1":{},"setup/release-notes/#sql":{}},"title":{}}],["z(0",{"_index":443,"text":{"api/flink/Function/":{},"api/flink/Function/#st_pointonsurface":{},"api/sql/Function/":{},"api/sql/Function/#st_pointonsurface":{}},"title":{}}],["z:decim",{"_index":627,"text":{"api/sql/Constructor/":{},"api/sql/Constructor/#st_point":{}},"title":{}}],["zeppelin",{"_index":1288,"text":{"api/viz/sql/":{},"api/viz/sql/#st_encodeimage":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_encodeimage":{},"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v120":{},"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/download/zeppelin/#compatibility":{},"archive/download/zeppelin/#create-helium-folder-optional":{},"archive/download/zeppelin/#display-geosparkviz-results":{},"archive/download/zeppelin/#enable-geospark-zeppelin":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/download/zeppelin/#installation":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#large-scale-with-geosparkviz":{},"archive/tutorial/zeppelin/#small-scale-without-geosparkviz":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/publish/":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"setup/modules/":{},"setup/modules/#sedona-modules-for-apache-spark":{},"setup/overview/":{},"setup/overview/#rich-spatial-analytics-tools":{},"setup/release-notes/":{},"setup/release-notes/#v120":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"setup/zeppelin/#compatibility":{},"setup/zeppelin/#create-helium-folder-optional":{},"setup/zeppelin/#display-sedonaviz-results":{},"setup/zeppelin/#enable-sedona-zeppelin":{},"setup/zeppelin/#install-sedona-zeppelin":{},"setup/zeppelin/#installation":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#large-scale-with-sedonaviz":{},"tutorial/zeppelin/#small-scale-without-sedonaviz":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}},"title":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-dependencies-in-zeppelin-spark-interpreter":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"archive/download/zeppelin/#enable-geospark-zeppelin":{},"archive/download/zeppelin/#install-geospark-zeppelin":{},"archive/tutorial/zeppelin/":{},"archive/tutorial/zeppelin/#zeppelin-spark-notebook-demo":{},"community/publish/#2-update-sedona-python-r-and-zeppelin-versions":{},"community/publish/#9-release-sedona-python-and-zeppelin":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-dependencies-in-zeppelin-spark-interpreter":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{},"setup/zeppelin/#enable-sedona-zeppelin":{},"setup/zeppelin/#install-sedona-zeppelin":{},"tutorial/zeppelin/":{},"tutorial/zeppelin/#zeppelin-spark-notebook-demo":{}}}],["zeppelin.json",{"_index":1896,"text":{"archive/download/zeppelin/":{},"archive/download/zeppelin/#add-geospark-zeppelin-description-optional":{},"setup/zeppelin/":{},"setup/zeppelin/#add-sedona-zeppelin-description-optional":{}},"title":{}}],["zero",{"_index":1103,"text":{"api/sql/Raster-loader/":{},"api/sql/Raster-loader/#rs_base64":{}},"title":{}}],["zhang",{"_index":2900,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["zhu",{"_index":1459,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}],["zippartit",{"_index":1649,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v080-geospark-core":{},"setup/release-notes/":{},"setup/release-notes/#v080-geospark-core":{}},"title":{}}],["zishan",{"_index":3164,"text":{"community/publication/":{},"community/publication/#geosparksim-traffic-simulator":{}},"title":{}}],["zm",{"_index":406,"text":{"api/flink/Function/":{},"api/flink/Function/#st_ndims":{},"api/sql/Function/":{},"api/sql/Function/#st_ndims":{}},"title":{}}],["zongsi",{"_index":2899,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{},"community/publication/":{},"community/publication/#geospark-ecosystem":{},"community/publication/#geosparkviz-visualization-system":{}},"title":{}}],["zongsizhang",{"_index":2901,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["zongsizhang@apache.org",{"_index":2902,"text":{"community/contributor/":{},"community/contributor/#project-management-committee-pmc":{}},"title":{}}],["zoom",{"_index":1299,"text":{"api/viz/sql/":{},"api/viz/sql/#st_render":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{},"archive/tutorial/viz/":{},"archive/tutorial/viz/#create-tile-name":{},"archive/tutorial/viz/#generate-map-tiles":{},"archive/tutorial/viz/#why-scalable-map-visualization":{},"tutorial/viz/":{},"tutorial/viz/#create-tile-name":{},"tutorial/viz/#generate-map-tiles":{},"tutorial/viz/#render-map-tiles":{},"tutorial/viz/#why-scalable-map-visualization":{}},"title":{}}],["zoomlevel",{"_index":1302,"text":{"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{}},"title":{}}],["zoomlevel:int",{"_index":1304,"text":{"api/viz/sql/":{},"api/viz/sql/#st_tilename":{},"archive/api/viz/sql/":{},"archive/api/viz/sql/#st_tilename":{}},"title":{}}],["zverev",{"_index":1461,"text":{"archive/download/GeoSpark-All-Modules-Release-notes/":{},"archive/download/GeoSpark-All-Modules-Release-notes/#v131":{},"setup/release-notes/":{},"setup/release-notes/#v131":{}},"title":{}}]],"pipeline":["stemmer"],"version":"2.3.9"}}